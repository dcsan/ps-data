{
  "episodeId": "jsIt2sTB_vo",
  "channelSlug": "@machinelearningstreettalk",
  "title": "Robots downloading Skills (Like in the Matrix!)",
  "publishedAt": "2025-06-19T23:49:30.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Why did you guys decide to create a",
      "offset": 0.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "physical AI company? And what's wrong",
      "offset": 1.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "with large language models? People are",
      "offset": 4.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "saying that all you need to do is hook",
      "offset": 5.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "large language models up to the real",
      "offset": 8.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "world. And we've got physical AI. So, so",
      "offset": 10.08,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "what's the deal? Effectively, the body",
      "offset": 12.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "matters a great deal to cognition. And",
      "offset": 14.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "more than just the body, the physical",
      "offset": 16.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "environment, the actual world that we",
      "offset": 18.24,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "inhabit is bundled up together with what",
      "offset": 20.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "it means to be a mind, to be a thinking",
      "offset": 23.439,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "thing, to to exist and to live and to",
      "offset": 25.6,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "thrive in an environment. The lack of",
      "offset": 28.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "embodiment is really what is sort of",
      "offset": 31.119,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "tripping up adoption in physical AI",
      "offset": 33.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "today. We have all these solutions for",
      "offset": 35.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like training models and simulation. We",
      "offset": 36.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "think we can connect something like an",
      "offset": 39.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "LLM to them to drive behavior. But the",
      "offset": 41.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "fact is that those systems were not",
      "offset": 43.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "trained with inbodied contact with the",
      "offset": 45.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "real world.",
      "offset": 48.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "To state it a bit provocatively in some",
      "offset": 51.12,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "sense, you might say that",
      "offset": 53.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "state-of-the-art AI is stuck in data",
      "offset": 54.239,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "space as it were. Basically, these",
      "offset": 57.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "systems all operate within a data space.",
      "offset": 60,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "which you don't have at least explicitly",
      "offset": 63.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "in these models is like a representation",
      "offset": 65.439,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "of the world or the situation that is",
      "offset": 68.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "generating that data. Plato says like",
      "offset": 70.479,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "it's not even the sun that's creating",
      "offset": 72.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "these shadows, right? It's a flame",
      "offset": 74.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that's casting these shadows on a wall.",
      "offset": 76.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "So, we're only interacting with shadows.",
      "offset": 78.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "We're not interacting with the real",
      "offset": 80.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "stuff. Even with coding, for example,",
      "offset": 82.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "some people say, um, the reason the code",
      "offset": 84.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "isn't very good is because it's not",
      "offset": 87.36,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "running the code. It's not testing the",
      "offset": 89.04,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "code. If only we had tools. If only we",
      "offset": 90.479,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "could get results back, then we get this",
      "offset": 92.479,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "feedback loop. What is the sort of the",
      "offset": 94.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "bright difference between what you're",
      "offset": 97.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "proposing and something like that? I",
      "offset": 98.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "would say like being grounded in the",
      "offset": 100.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "world in some sense. So like no matter",
      "offset": 102.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "how you train these state-of-the-art",
      "offset": 104.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "feed forward gradient descentbased",
      "offset": 106.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "architectures, at the end of the day,",
      "offset": 108.88,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "they are only tethered to reality",
      "offset": 110.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "through us and our expressions of",
      "offset": 113.439,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "preferences.",
      "offset": 116.64,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "This episode of MLST is sponsored by",
      "offset": 119.439,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "Twofer AI Labs. It is a research lab",
      "offset": 121.439,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "which is headquartered in Zurich.",
      "offset": 124.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "They're moving to San Francisco as well.",
      "offset": 126.399,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "These guys are number one of the ARCV2",
      "offset": 128.56,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "leaderboard. They're genuinely",
      "offset": 130.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "fascinated in building the next",
      "offset": 132.239,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "generation of technology, the next",
      "offset": 134.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "innovation which will take large",
      "offset": 135.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "language models to the next stage. If",
      "offset": 137.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "that sounds like you, please get in",
      "offset": 140.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "touch with Benjamin Kruier. Go to",
      "offset": 142.319,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "twoferabs.ai.",
      "offset": 144.319,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "We have another episode of machine",
      "offset": 148,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "learning street talk and joining me",
      "offset": 150.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "today are two very very special people.",
      "offset": 151.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "We have Dr. Maxwell Ramstead who is",
      "offset": 154.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "without doubt one of the technical",
      "offset": 157.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "heavyweights of the active inference",
      "offset": 159.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "community. I think Maxwell it's not an",
      "offset": 161.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "exaggeration to say that other than",
      "offset": 163.68,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "Friston himself you've probably",
      "offset": 165.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "published more papers on active",
      "offset": 166.959,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "inference than anyone else. Is that",
      "offset": 168.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "fair? That's kind of you to say.",
      "offset": 170.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Anyway, um fans of the show will know",
      "offset": 173.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Maxwell very well. of course we've had",
      "offset": 175.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "him on a couple of times before and it's",
      "offset": 176.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "great to have you here Maxwell and and",
      "offset": 179.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "we also have Jason Fox now um as a bit",
      "offset": 180.4,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "of a background for the for the audience",
      "offset": 182.56,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "here you guys have created a company",
      "offset": 184.239,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "called Numinal and um Jason you're",
      "offset": 186.159,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "you're the CTO of of of Numol can you",
      "offset": 188.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "introduce yourself to the audience yeah",
      "offset": 191.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "thanks Tim uh yeah so um I I come at",
      "offset": 193.84,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "this from a much more traditional",
      "offset": 197.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "computer science background and just a",
      "offset": 199.04,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "you know down in the weeds engineer um",
      "offset": 201.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "I've been building tech for uh going on",
      "offset": 204.239,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "25 years uh across many different",
      "offset": 206.64,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "domains uh technical and industrial",
      "offset": 209.84,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "uh video game engines uh mixed reality",
      "offset": 213.04,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "um I worked in defense and robotics for",
      "offset": 217.2,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "a number of years uh kind of mid-career",
      "offset": 219.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "um and as you know I spent about eight",
      "offset": 224.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "years at Microsoft doing a lot of uh",
      "offset": 225.92,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "sort of really tip of the spear sort of",
      "offset": 228.48,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "like R&amp;D type work with partners um as a",
      "offset": 232.08,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "part of the partner catalyst team uh and",
      "offset": 234.879,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "that really led to uh a lot of applied",
      "offset": 238.56,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "ML uh just you know specifically around",
      "offset": 241.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "computer vision and you know there's",
      "offset": 244.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "often the case where we're having to",
      "offset": 246.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "take something like the hollow lens and",
      "offset": 248.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "apply computer vision to you know the",
      "offset": 250.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "many different camera systems on board",
      "offset": 252.56,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "that um and do something useful with it",
      "offset": 254.72,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "right or you know try to and the use",
      "offset": 258.799,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "cases are very interesting you know like",
      "offset": 261.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "um automakers like Toyota would would",
      "offset": 263.759,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "find use for like service and",
      "offset": 266.8,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "manufacturing. And um what that really",
      "offset": 268.479,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "uh led to was this uh for me personally",
      "offset": 272.479,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "this kind of love affair with um",
      "offset": 275.199,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "I guess",
      "offset": 279.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "uh digitizing",
      "offset": 281.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "an understanding of the real world, the",
      "offset": 282.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "physical world. And so I've spent a lot",
      "offset": 284.8,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "of my time focusing on technologies um",
      "offset": 286.96,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "at that intersection. And so, um, yeah,",
      "offset": 290.4,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "and then I've I've known Maxwell and",
      "offset": 294.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Jeff now for a number of years. Uh,",
      "offset": 296.88,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "Maxwell and I together created, I think,",
      "offset": 299.28,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "the industry's first active inference",
      "offset": 303.199,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "lab a few years ago. Uh, we're excited",
      "offset": 305.199,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "to be recreating that again here at",
      "offset": 309.039,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "Numinal and solving some real real real",
      "offset": 311.84,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "fundamental challenges in physical AI.",
      "offset": 316.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "And um just to contextualize this, you",
      "offset": 318.639,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "guys were at Versus before and of course",
      "offset": 321.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "we did some great content with with",
      "offset": 323.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Versus and um this might be interesting",
      "offset": 324.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "to the audience. Uh Jason and I were",
      "offset": 327.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "actually at Microsoft together at the",
      "offset": 329.84,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "same time. So um we were in we're in",
      "offset": 331.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "this group and and I was a principal",
      "offset": 333.759,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "software engineer at Microsoft and and",
      "offset": 335.28,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "we actually worked together I think on",
      "offset": 336.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "some on some similar projects. this",
      "offset": 338.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "isn't about 2017 kind of time, but um",
      "offset": 340.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "but it's just uh one of those massive",
      "offset": 343.44,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "coincidences that that that we're that",
      "offset": 345.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "we're here together, but anyway, um this",
      "offset": 347.199,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "raises so many questions that I think",
      "offset": 349.919,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "we'll foreshadow now and we'll get to",
      "offset": 351.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "later. You know, the obvious one being",
      "offset": 353.28,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "why did you guys decide to create a",
      "offset": 354.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "physical AI company and what's wrong",
      "offset": 356.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "with large language models? People are",
      "offset": 358.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "saying that all you need to do is hook",
      "offset": 360.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "large language models up to the real",
      "offset": 363.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "world and we've got physical AI. So, so",
      "offset": 364.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "what's the deal? But I think in order to",
      "offset": 367.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "get there, we need to go on a bit of an",
      "offset": 368.96,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "intellectual journey. So we'll just",
      "offset": 370.4,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "leave those questions hanging for now.",
      "offset": 371.68,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "Now, um, Maxwell, when I discovered Carl",
      "offset": 373.919,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "Fristen, it was an intellectual",
      "offset": 377.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "awakening for me. The the amazing thing",
      "offset": 379.68,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "about this podcast is is we just through",
      "offset": 382.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "curiosity more than anything else. We",
      "offset": 384.479,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "get to speak with some of the most",
      "offset": 386.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "brilliant people in the world. And for",
      "offset": 388,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "some reason, they say yes when we invite",
      "offset": 389.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "them. So, it's a win-win situation, more",
      "offset": 392,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "so for me than than for for them,",
      "offset": 394.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "perhaps. But um you know, Professor",
      "offset": 396,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Friston is is an absolutely incredible",
      "offset": 398.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "character and I want to get to this kind",
      "offset": 400.479,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "of embodiment and externalism thing",
      "offset": 402.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "because that was what really opened up",
      "offset": 405.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "my mind. We used to think about AI as",
      "offset": 406.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "being something which happens entirely",
      "offset": 409.68,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "inside the brain almost like we could",
      "offset": 412,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "just write a computer algorithm and it",
      "offset": 413.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "would capture all of the machinations of",
      "offset": 415.84,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "of cognizing of of being an intelligent",
      "offset": 418,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "being. Can you introduce this whole idea",
      "offset": 421.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "to us? So I think the the al the",
      "offset": 423.759,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "ultimate idea behind all this kind of",
      "offset": 426.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "physical AI embodied cognition is that",
      "offset": 429.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "uh effectively the body matters a great",
      "offset": 432.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "deal to cognition and more than just the",
      "offset": 434.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "body the physical environment the actual",
      "offset": 436.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "world that we inhabit is uh I mean",
      "offset": 438.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "bundled up together with what it means",
      "offset": 442,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "to be a mind to be a thinking thing to",
      "offset": 444.08,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "to exist and to live and to thrive in an",
      "offset": 446.479,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "environment. Um, so you know, you you",
      "offset": 449.759,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "might you might think of uh the embodied",
      "offset": 452.639,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "intelligence thesis spelled broadly um",
      "offset": 454.96,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "as I mean effectively this idea that uh",
      "offset": 458.8,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "the mind um in some sense encodes or",
      "offset": 462.319,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "reflects or is constrained by or depends",
      "offset": 466.319,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "on the specific material embodiment of",
      "offset": 468.88,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "the system and the the very specific",
      "offset": 472.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "layout the situation that the that the",
      "offset": 475.759,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "uh system is trying to adapt too. So, um",
      "offset": 478.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "you know, you were referring to",
      "offset": 481.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "externalism versus internalism. I mean,",
      "offset": 483.039,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "this is a long-standing debate in um",
      "offset": 485.919,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "cognitive science and in philosophy. Uh",
      "offset": 488.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "basically, what what counts as",
      "offset": 491.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "cognition? Is cognition just something",
      "offset": 493.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that happens in the head that involves",
      "offset": 495.599,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "the brain or is it something that is",
      "offset": 497.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "world involving? And I think um",
      "offset": 499.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "basically since the late 80s and early",
      "offset": 501.599,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "90s um what we have seen in cognitive",
      "offset": 504.08,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "science certainly in neuroscience and",
      "offset": 507.12,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "philosophy and related areas is um an",
      "offset": 509.759,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "increasing recognition of the importance",
      "offset": 512.959,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "of external factors. Well factors that",
      "offset": 515.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "were once considered external to",
      "offset": 518.159,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "cognition that are actually constitutive",
      "offset": 519.839,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "of it. Right? So having a body is not",
      "offset": 521.76,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "you know just you know an accident or",
      "offset": 525.12,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "optional to cognitive systems. All",
      "offset": 528.32,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "things that we consider intelligent uh",
      "offset": 532.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "do so through their embodied behavior in",
      "offset": 535.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "a world right. Um, so I mean this is",
      "offset": 537.6,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "relevant to AI and industry more",
      "offset": 540.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "generally because you know the frontier",
      "offset": 544.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "right now is applying AI systems in the",
      "offset": 546.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "real world right and uh there's reason",
      "offset": 549.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "to believe that you know if we want to",
      "offset": 551.68,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "do this appropriately and safely and at",
      "offset": 553.839,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "scale we should draw on you know the the",
      "offset": 557.2,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "way that cognition works in the real",
      "offset": 559.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "world the way that natural intelligence",
      "offset": 561.519,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "works in the in the world that we live",
      "offset": 563.36,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "in right um and So, you know, studying",
      "offset": 566.16,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "embodiment and what it brings to the",
      "offset": 569.92,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "table is going to be crucial. Um, and I",
      "offset": 572.399,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "think one of the things that uh is",
      "offset": 575.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "really important and follows from this",
      "offset": 577.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "embodied mind thesis is that what's",
      "offset": 579.839,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "required um to act appropriately in a",
      "offset": 582.24,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "world is to have a world model. Right?",
      "offset": 585.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "So, uh a mind is a model of a specific",
      "offset": 588.56,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "world, right? And of a specific body",
      "offset": 591.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "that acts in that world. And I think",
      "offset": 594.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "those are the big elements at least the",
      "offset": 596.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "conceptually that that allow us to frame",
      "offset": 599.279,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this discussion. Um and you know maybe",
      "offset": 601.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Jason can talk a little bit about the",
      "offset": 603.839,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the implications of this for like the",
      "offset": 606.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the field of physical AI which is you",
      "offset": 608.399,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "know robotics, drones and all of these",
      "offset": 610.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "systems that um act in the real world.",
      "offset": 612.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "Yeah. I think the the key takeaway from",
      "offset": 615.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "from that description, Maxwell, is that",
      "offset": 617.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "and your question earlier, Tim, um",
      "offset": 619.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "around LLMs is that the lack of",
      "offset": 622.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "embodiment is really what is is sort of",
      "offset": 625.04,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "tripping up adoption in physical AI",
      "offset": 628.48,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "today, right? It's um you know, we have",
      "offset": 630.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "all these solutions for like training",
      "offset": 633.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "models and simulation. We we think we",
      "offset": 635.6,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "can connect something like an LLM to",
      "offset": 638,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "them to drive behavior. Uh but the fact",
      "offset": 639.519,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "is that those systems were not trained",
      "offset": 642.399,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "with inbodied contact with the real",
      "offset": 645.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "world. Um they have no concept of the",
      "offset": 648.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "physics, the interactions that are",
      "offset": 651.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "required to understand, you know, how to",
      "offset": 653.2,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "manipulate things. Um and how to uh",
      "offset": 655.6,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "carve out space, understand space, move",
      "offset": 659.68,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "about space. Um that's that's one of the",
      "offset": 662.399,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "fundamental missing pieces, right? And",
      "offset": 665.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "so I think uh the the last conversation",
      "offset": 667.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "I think you had with Jeff, he got really",
      "offset": 670.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "deep into sort of like how language is a",
      "offset": 672.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "really poor representation of the world,",
      "offset": 674.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "right? The the actual world and the way",
      "offset": 677.36,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "that we're experiencing it. Um and I",
      "offset": 679.6,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "think we we Maxwell and I wholeheartedly",
      "offset": 683.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "agree with that statement, right? It's",
      "offset": 685.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "uh it's not a simple matter of",
      "offset": 688,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "connecting something that works wholly",
      "offset": 689.6,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "in a digital kind of vat online or on my",
      "offset": 691.76,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "computer to just something like a",
      "offset": 695.279,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "robotic system and expecting it to work.",
      "offset": 697.279,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "Um so I do think that embodiment is a is",
      "offset": 700.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "a fundamental key aspect to this. I mean",
      "offset": 703.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "to state it a bit provocatively in some",
      "offset": 705.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "sense you might say that",
      "offset": 707.519,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "state-of-the-art AI is um stuck in data",
      "offset": 708.48,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "space as it were. Um so you know",
      "offset": 712.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "state-of-the-art AI works by you know mo",
      "offset": 715.92,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "modeling this you know these vast",
      "offset": 718.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "amounts of like multi-dimensional",
      "offset": 720.959,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "multimodal data uh and I mean",
      "offset": 723.6,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "effectively extracting correlational",
      "offset": 726.399,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "information from those data sets and um",
      "offset": 729.36,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "yeah I mean what so you know consider uh",
      "offset": 733.279,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "you know next token prediction for like",
      "offset": 736.639,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "language generation or pattern",
      "offset": 739.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "completion in image uh generating",
      "offset": 741.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "systems.",
      "offset": 744,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "What basically these systems all operate",
      "offset": 744.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "within a data space, right? They they",
      "offset": 747.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "they",
      "offset": 750.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you feed data into them and what they",
      "offset": 752,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "what they generate effectively is is is",
      "offset": 754,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "data. Um what you what you don't have in",
      "offset": 756.399,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "or what you don't have at least",
      "offset": 760.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "explicitly in these models is like a",
      "offset": 761.68,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "representation of the world or the",
      "offset": 764.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "situation that is generating that data.",
      "offset": 767.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "So, I mean, in some sense, you might say",
      "offset": 769.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "that state-of-the-art AI is stuck in",
      "offset": 772,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Plato's cave. Um, so I mean, just for",
      "offset": 774,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "I'm sure most of, you know, the the",
      "offset": 777.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "viewers of MLST are familiar with, uh,",
      "offset": 779.519,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "Plato's, uh, Plato's cave, the allegory,",
      "offset": 781.76,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "please introduce it. So, I mean, uh,",
      "offset": 785.839,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Plato, uh, Plato was a, um, was a, I",
      "offset": 787.68,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "mean, appropriately enough, we call his",
      "offset": 791.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "position Platonism.",
      "offset": 793.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Basically Plato believed that what was",
      "offset": 795.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "really real were these like universal",
      "offset": 797.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "and variant forms. U so like you know uh",
      "offset": 799.36,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "the the form of triangle the the the",
      "offset": 803.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "form of you know the a human like the",
      "offset": 805.76,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "the these essences effectively and uh",
      "offset": 808.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "these were like um you know",
      "offset": 811.519,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "transtemporal. They existed outside of",
      "offset": 813.839,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "space and time. They didn't have a",
      "offset": 816.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "beginning, a middle and an end. Um and",
      "offset": 817.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "then the the things that we encountered",
      "offset": 820.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "uh in in the world of experience were in",
      "offset": 823.6,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "some sense um you know just mere images",
      "offset": 826.72,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "or copies of the actual transcendent",
      "offset": 830.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "forms that the Plato thought really",
      "offset": 833.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "existed. So um Plato's cave is this",
      "offset": 835.2,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "allegory where um he says imagine some",
      "offset": 838.48,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "prisoners chained to the the side of a",
      "offset": 841.36,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "cave and all they can see ever is the",
      "offset": 844.959,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "shadows that are projected uh by things",
      "offset": 848.32,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "you know as uh they walk by like a flame",
      "offset": 851.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "right so and and so you see like this",
      "offset": 854.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "indirectness Plato says like it's not",
      "offset": 857.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "even the sun that's creating these",
      "offset": 858.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "shadows right it's a flame uh that's",
      "offset": 860.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that's casting these shadows on a wall",
      "offset": 862.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "so what Plato says is like this is our",
      "offset": 864.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "epistemic situation most of the time,",
      "offset": 866.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "right? We're kind of we're we're only",
      "offset": 868.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "interacting with shadows. We're not",
      "offset": 870.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "interacting with the real stuff. Um so I",
      "offset": 872.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "mean I I don't I don't I'm not a",
      "offset": 876.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "platonist myself. I'm I'm borrowing that",
      "offset": 877.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "metaphor to say well basically the uh",
      "offset": 880.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "what what the LLMs and the image",
      "offset": 883.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "generators are doing is very similar to",
      "offset": 885.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "what uh you know the the slaves that",
      "offset": 888.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Plato was describing are doing in in in",
      "offset": 890.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that we we don't that these systems are",
      "offset": 893.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "not really interacting with the process",
      "offset": 895.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that's generating the data. So they're",
      "offset": 897.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "at one remove from you know the the",
      "offset": 899.6,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "actual world in some sense. Um so and I",
      "offset": 902.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "mean that gets even more problematic",
      "offset": 906.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "when you bring language into the mix,",
      "offset": 907.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "right? Because uh what is language?",
      "offset": 909.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Well, ra language is a a representation",
      "offset": 912.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "of a representation. It's a it's a",
      "offset": 914.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "compression of a compression, right? So",
      "offset": 917.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "I have a perceptual experience. Uh I",
      "offset": 919.36,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "generate these uh you know a a a model",
      "offset": 922.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "to basically explain you know what what",
      "offset": 926.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "is going on here. I have an",
      "offset": 928.56,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "understanding of the data if you want to",
      "offset": 929.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "put it that way. And then language is a",
      "offset": 931.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "way to represent my understanding and",
      "offset": 933.68,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "communicate it to you. So we're we're at",
      "offset": 936.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "we're we're now at at least two degrees",
      "offset": 939.199,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "removed from the world that's actually",
      "offset": 940.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "generating experience. I mean there",
      "offset": 942.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "there are conceptual and technical",
      "offset": 944.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "reasons why we wouldn't want robots uh",
      "offset": 946.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "acting in the world to be stuck in",
      "offset": 949.519,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Plato's cave. Um I mean obviously uh we",
      "offset": 951.199,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "would want you know uh systems acting in",
      "offset": 955.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the world to have some kind of direct",
      "offset": 957.92,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "access to the world that they're",
      "offset": 959.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "interacting with as opposed to this",
      "offset": 960.959,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "indirect kind of access. Um there's also",
      "offset": 962.72,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "reason to think that and um Silver and",
      "offset": 966.16,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "Sutton published a great paper recently.",
      "offset": 968.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "I think it's called welcome to the era",
      "offset": 971.519,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "of experience where they basically say",
      "offset": 973.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "well we've exhausted all of the the",
      "offset": 974.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "static data sets that have existed that",
      "offset": 977.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "exist currently right like there is no",
      "offset": 980.8,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "more data that's publicly available to",
      "offset": 982.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "train these systems so where to go from",
      "offset": 985.279,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "now well the only other place to go is",
      "offset": 987.279,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "to let these systems generate the data",
      "offset": 989.759,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "that that they want to model as they",
      "offset": 993.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "explore the world right so um so you",
      "offset": 995.759,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "know but this pivot to agent gener",
      "offset": 999.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "generated data has, you know, as a",
      "offset": 1001.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "consequence the that, you know, if these",
      "offset": 1003.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "systems are going to be generating data",
      "offset": 1006.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "themselves, then they need to be",
      "offset": 1008.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "embodied in a specific way, right? That",
      "offset": 1009.92,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "they need to be situated in a specific",
      "offset": 1012.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "environment and then apt to generate the",
      "offset": 1014.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "kinds of data uh that we find",
      "offset": 1016.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "interesting and that we can continue to",
      "offset": 1018.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "use to train these models. So, so I",
      "offset": 1020.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "think all of these things are like",
      "offset": 1023.839,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "crucially interconnected. Like there are",
      "offset": 1024.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "technical limitations that are pushing",
      "offset": 1026.959,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "us to this uh to this kind of embodied",
      "offset": 1028.72,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "turn in AI. Um on the one hand uh but",
      "offset": 1032.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "there are also conceptual reasons to",
      "offset": 1035.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "think that this is the only the only way",
      "offset": 1037.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "to do it right. Can I add a comment",
      "offset": 1039.679,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "here? Of course. So I think that um I",
      "offset": 1041.919,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "think so you mentioned language is a",
      "offset": 1045.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "compression and I wholeheartedly agree.",
      "offset": 1047.439,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "I think it's the wrong kind of",
      "offset": 1049.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "compression for physics, the physical",
      "offset": 1051.36,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "world, right? So I think that while we",
      "offset": 1053.679,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "might walk around and and sort of",
      "offset": 1056.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "perceive and understand the physical",
      "offset": 1059.679,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "world in sort of a compressionbased way",
      "offset": 1062.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "like otherwise I don't think we we would",
      "offset": 1065.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "work we wouldn't function right we",
      "offset": 1067.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "wouldn't be able to take in and process",
      "offset": 1068.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "everything. Um, I think it's a different",
      "offset": 1070.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "form of compression, right? And so then",
      "offset": 1073.12,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "we we find ways of",
      "offset": 1075.84,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "relating whatever that representation is",
      "offset": 1079.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "inside of our minds to other people in a",
      "offset": 1081.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "communal aspect so that we can",
      "offset": 1084.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "collaborate, coexist, you know, as a",
      "offset": 1086.96,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "society. Um, which is what language is",
      "offset": 1089.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "developed from, right? So that's that's",
      "offset": 1092.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "one thought I had. Maxwell, I know you",
      "offset": 1095.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "you probably have a much more in-depth",
      "offset": 1097.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "commentary on it, but so I think I think",
      "offset": 1099.039,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "the the embodiment thing is important",
      "offset": 1102.72,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "because um I mean you might say like you",
      "offset": 1104.64,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "might say that mind is intrinsically",
      "offset": 1109.2,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "related to you know adaptive intelligent",
      "offset": 1111.76,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "behavior in a situation right so I mean",
      "offset": 1116.08,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "it's it's it's not just that embodiment",
      "offset": 1119.44,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "adds something to intelligence it's that",
      "offset": 1121.84,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "It's embodiment is in some sense the",
      "offset": 1125.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "vehicle",
      "offset": 1127.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "you know through which we see",
      "offset": 1129.52,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "intelligence as manifest in the world",
      "offset": 1132.32,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "around us. Um you know and chat bots do",
      "offset": 1135.36,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "have an embodiment. It's a weird kind of",
      "offset": 1139.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "co-embodiment that we share with them in",
      "offset": 1141.679,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "some sense, right? Like um",
      "offset": 1144.72,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "you might argue that like where where",
      "offset": 1148.799,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "the where the grounding of the system",
      "offset": 1151.76,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "comes from is embodiment, right? Like",
      "offset": 1156.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "ultimately all of these symbols have to",
      "offset": 1159.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "like if if if if if the symbols that are",
      "offset": 1161.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "being shuffled around by an a an AI",
      "offset": 1164.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "system or presumably you know the the",
      "offset": 1166.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "computations that are realized by my",
      "offset": 1168.559,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "brain if they mean anything it's by",
      "offset": 1170.64,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "virtue of being embedded and you know",
      "offset": 1173.6,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "embodied within specific systems that's",
      "offset": 1177.28,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "where the the meaning of all these",
      "offset": 1180.32,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "tokens or or symbols or or whatever come",
      "offset": 1182.559,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "from at the end of the day. It it's it's",
      "offset": 1186.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "not just that like embodiment is like a",
      "offset": 1188.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "side thing. It's constitutive of what it",
      "offset": 1190.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "means to cognize. Um I mean like I was",
      "offset": 1192.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "saying, you know, chat bots have a a",
      "offset": 1195.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "weird kind of embodiment. I always kind",
      "offset": 1197.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "of feel like um we project like the we",
      "offset": 1200.32,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "we project the powers of cognition onto",
      "offset": 1203.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "chat bots for the most part, right? Like",
      "offset": 1206.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "what the LLM is doing is just",
      "offset": 1208.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "completing, you know, uh a token pattern",
      "offset": 1210.559,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "at the end of the day. Um the fact that",
      "offset": 1213.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "it is semantically relevant that comes",
      "offset": 1216.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "from human feedback. Like currently the",
      "offset": 1218.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "the systems that we're building make",
      "offset": 1220.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "sense because you know we have",
      "offset": 1222.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "outsourced",
      "offset": 1225.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "the the actual difficult labor of making",
      "offset": 1226.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "sense to humans right who at the end of",
      "offset": 1229.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the day are like you know literally",
      "offset": 1231.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "coders right who are like uh coders I",
      "offset": 1233.52,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "mean um raiders right people who like",
      "offset": 1237.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "will take outputs of of an LLM model and",
      "offset": 1240.159,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "then rate it according to it its its um",
      "offset": 1243.12,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "its conformance or discordance with like",
      "offset": 1247.12,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "what we think is a good output. So you",
      "offset": 1250.159,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "know the um the magic what what makes",
      "offset": 1253.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "these systems look intelligent is that",
      "offset": 1256.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "we have in effect projected our",
      "offset": 1258.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "intelligence into them and it's that so",
      "offset": 1260.88,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "that uh that is al I think also uh",
      "offset": 1263.919,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "relevant to this question of embodiment",
      "offset": 1267.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "like the these systems make sense",
      "offset": 1269.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "because there's a part of the system",
      "offset": 1270.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "somewhere right the human users that",
      "offset": 1272.48,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "actually are in contact with the world",
      "offset": 1275.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "and can tell you like no this this does",
      "offset": 1277.039,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "match up or not to you know what we",
      "offset": 1279.919,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "experience in reality. Um,",
      "offset": 1282.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "yeah. So, I I think it's really really",
      "offset": 1285.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "really critical to recognize the",
      "offset": 1288.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "important like the if if we're going to",
      "offset": 1289.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "do artificial intelligence, we have to",
      "offset": 1292.559,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "take the intelligence bit of AI",
      "offset": 1294.72,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "seriously and all intelligence is always",
      "offset": 1297.679,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "embodied and situated in a specific",
      "offset": 1301.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "context. Yeah, that that makes a lot of",
      "offset": 1303.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "sense. I mean, I think one way of",
      "offset": 1306.159,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "explaining this is it's not the",
      "offset": 1307.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "destination, it's how you got there. So",
      "offset": 1309.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "in the real world there are these these",
      "offset": 1312.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "dynamics at multiple scales and there's",
      "offset": 1314.32,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "a provenence to all of these just almost",
      "offset": 1317.36,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "unimaginable number of interactions",
      "offset": 1320.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "through time and causality is important",
      "offset": 1323.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "here because there's a there's a causal",
      "offset": 1325.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "graph or a light cone that you can trace",
      "offset": 1327.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "back through all of these interactions",
      "offset": 1329.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "that have happened previously. I I want",
      "offset": 1331.679,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "to give an example of a large language",
      "offset": 1333.679,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "model. I read this amazing paper by",
      "offset": 1334.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Kenneth Stanley the other day and it was",
      "offset": 1336.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "called the fractured representation",
      "offset": 1338.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "hypothesis. So he basically trained a",
      "offset": 1340.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "simple neural network to generate images",
      "offset": 1342.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "of apples and skulls. And when you look",
      "offset": 1344.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "at the the representation map, it's very",
      "offset": 1346.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "chaotic and and fractured. So if you do",
      "offset": 1348.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "parameter sweeps on it, the the image",
      "offset": 1351.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that's generated just looks distorted",
      "offset": 1353.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and and horrible. And he had another",
      "offset": 1355.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "version which was trained by humans",
      "offset": 1357.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "where the topology was learned over",
      "offset": 1359.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "time. And there was something about",
      "offset": 1360.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "capturing the the the provenence of",
      "offset": 1363.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "information. So you know at at",
      "offset": 1364.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "university you are taught knowledge at",
      "offset": 1366.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the most abstract level. Yet the kids",
      "offset": 1368.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "don't really get it. It's only after a",
      "offset": 1370.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "lifetime of of doing and interacting and",
      "offset": 1372.24,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "cognizing that you actually learn these",
      "offset": 1374.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "these kind of primitives of cognition,",
      "offset": 1377.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "this world modeling that you're talking",
      "offset": 1379.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "about. So chat GPT will give you an",
      "offset": 1381.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "answer to something. Whereas when you",
      "offset": 1383.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "really understand something, you have a",
      "offset": 1385.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "kind of computational graph in your mind",
      "offset": 1387.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "which is actually a very low-level",
      "offset": 1389.44,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "understanding of of how the world works.",
      "offset": 1392.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "And these things they're not they're not",
      "offset": 1395.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "plonistic. They these little kind of",
      "offset": 1397.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "cognitive components, they represent",
      "offset": 1399.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "regularities",
      "offset": 1402.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "in in in the world, regularities that",
      "offset": 1403.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "we've just acquired. And when you",
      "offset": 1406.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "understand things at this deeper level,",
      "offset": 1408.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "it allows you to be creative, right? So",
      "offset": 1410.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "so now your intuition is more likely to",
      "offset": 1412.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "be correct. You can now riff on things",
      "offset": 1415.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and compose things and modify things",
      "offset": 1417.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "because you understand it at a much",
      "offset": 1419.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "deeper level. But how do we how do we",
      "offset": 1420.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "acquire these kind of you know little",
      "offset": 1423.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "mini models of how the world works?",
      "offset": 1426.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Well, I mean you you were saying it it's",
      "offset": 1428.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "it's through experience. And I think",
      "offset": 1430.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "ultimately what happens is that we uh",
      "offset": 1432.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "our our cognitive systems are equipped",
      "offset": 1435.2,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "such that we extract the objects that",
      "offset": 1438.24,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "cause our sensations from the the",
      "offset": 1441.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "sensory data that we are um that we're",
      "offset": 1444.32,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "generating constantly in such a way that",
      "offset": 1446.96,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "uh these objects and object types are",
      "offset": 1450.4,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "represented to be composable.",
      "offset": 1453.44,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "So um you know uh this is how we",
      "offset": 1456.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "engineer systems right like we and this",
      "offset": 1459.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "is a slight maybe a slightly",
      "offset": 1462.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "reductionist take but I think we",
      "offset": 1463.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "effectively",
      "offset": 1466.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "extract objects from our experience uh",
      "offset": 1467.76,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "and we when we so when we understand",
      "offset": 1470.799,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "objects we understand them again and",
      "offset": 1473.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "this comes back to embodiment in terms",
      "offset": 1476.159,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "of the possible interactions that we can",
      "offset": 1477.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "have with those objects and this by the",
      "offset": 1479.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "way dovetales with uh literature on",
      "offset": 1482.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "ecological psychology ology, right? Um",
      "offset": 1484.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "what what we extract through interaction",
      "offset": 1487.6,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "are object types, right? That are",
      "offset": 1490.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "represented in terms of like possible",
      "offset": 1493.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "interactions with us and with other",
      "offset": 1495.679,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "objects. So the the representational",
      "offset": 1497.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "format that we use as humans is",
      "offset": 1500.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "inherently compositional.",
      "offset": 1502.24,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "Um so I mean I think that kind of gets",
      "offset": 1505.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "to what you were asking, right? So like",
      "offset": 1508.32,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "we we we learn objectbased object-",
      "offset": 1510.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "centered representations of the world",
      "offset": 1513.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "that are structured interactionally such",
      "offset": 1515.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "that they can be composed and you know",
      "offset": 1518.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "this is where the amazing abilities of",
      "offset": 1520.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "imagination and counterfactual thinking",
      "offset": 1522.559,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "of humans uh you know come to four.",
      "offset": 1525.2,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "Yeah, there is a a constructive way of",
      "offset": 1528,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "thinking about this, right? Which is",
      "offset": 1531.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "that, you know, the Plleonistic thing is",
      "offset": 1533.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that we can decompose into this",
      "offset": 1535.279,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "beautiful set of primitives how the",
      "offset": 1538.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "world works and anything you see is is",
      "offset": 1539.84,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "just compositions of of those things.",
      "offset": 1543.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Therefore, why why do you need to be",
      "offset": 1545.36,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "embedded in the work? Because you you",
      "offset": 1547.039,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "can already just just do the",
      "offset": 1548.559,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "composition. But there's there's",
      "offset": 1549.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "something more than that. Certainly with",
      "offset": 1551.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "with language for example, it has this",
      "offset": 1553.52,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "incredible diversity in complexity and",
      "offset": 1555.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "it just goes on forever. And and",
      "offset": 1558.559,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "certainly even though we know many, you",
      "offset": 1560.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "know, intuitive physics and we know a",
      "offset": 1563.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "lot of deep knowledge about how the",
      "offset": 1564.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "world works, we're still discovering",
      "offset": 1566.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "things and we can go in so many",
      "offset": 1568.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "different directions because knowledge",
      "offset": 1570,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "is perspectival and and it is",
      "offset": 1571.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "constructive in this way. But there are",
      "offset": 1573.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "regularities everywhere. You see you see",
      "offset": 1576.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the same things um occurring in",
      "offset": 1578.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "evolution in different parts of the",
      "offset": 1580.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "phlogenetic tree. You see different",
      "offset": 1582.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "types of things emerging in different",
      "offset": 1584.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "places. And this gets to this idea of a",
      "offset": 1586.24,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "real pattern and and Maxwell, please",
      "offset": 1588.799,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "tell me your lovely definition you gave",
      "offset": 1591.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "me the other day of of what is real. But",
      "offset": 1593.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "what why why do we see these kind of",
      "offset": 1595.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "like reoccurring motifs all over the",
      "offset": 1597.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "Well, I mean, you know, I think you're",
      "offset": 1599.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "there are some se several there's a set",
      "offset": 1601.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "of deep questions that just underwrite",
      "offset": 1603.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "what what you just asked, right? So,",
      "offset": 1606.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "like what what is what does it mean for",
      "offset": 1608.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "something to be real? I think is like",
      "offset": 1610.08,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "a vexed question. Um, but it's it's it's",
      "offset": 1614,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "sort of right there in in what you're",
      "offset": 1618.08,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "asking. I mean um when we were",
      "offset": 1619.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "discussing a few days ago, I offered up",
      "offset": 1621.039,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "a definition of uh the real which I I",
      "offset": 1623.679,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "draw from u you know philosophers",
      "offset": 1627.12,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "uh and philosophers like uh Merlo Ponti",
      "offset": 1630.159,
      "duration": 7.601
    },
    {
      "lang": "en",
      "text": "and um you know the Lanian psycho",
      "offset": 1633.6,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "psychoanalytic approach which is",
      "offset": 1637.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "something like well the the the real is",
      "offset": 1639.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "when you bump into something right the",
      "offset": 1641.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the real is when um what you experience",
      "offset": 1644,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "resists you in some way. I think so",
      "offset": 1647.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "that's one possible definition. I think",
      "offset": 1650.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it's a very phenomenological definition.",
      "offset": 1652.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "It it dovetales nicely with this whole",
      "offset": 1655.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "um active inference predictive coding",
      "offset": 1657.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "approach because it kind of suggests",
      "offset": 1659.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that well when you're interacting with",
      "offset": 1661.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "something real it's going to frustrate",
      "offset": 1663.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "your expectations about it at some level",
      "offset": 1665.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and then you will learn from that error",
      "offset": 1667.2,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "signal. um a slightly different version",
      "offset": 1669.44,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "of of the well not just slightly another",
      "offset": 1673.279,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "take on what counts as real is what you",
      "offset": 1676.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "were just describing Tim this this whole",
      "offset": 1679.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "real patterns approach by by Daniel",
      "offset": 1681.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "Dennett um well Denn is essentially",
      "offset": 1683.2,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "saying well um",
      "offset": 1686.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "things that are real um are I mean",
      "offset": 1689.279,
      "duration": 7.921
    },
    {
      "lang": "en",
      "text": "effectively emergent patterns so things",
      "offset": 1692.72,
      "duration": 8.079
    },
    {
      "lang": "en",
      "text": "that uh you know arise in some way and",
      "offset": 1697.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "gain enough stability so that they can",
      "offset": 1700.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "be, you know, recognized and perhaps",
      "offset": 1702.72,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "even act as like a a medium for further",
      "offset": 1705.76,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "patterns to to be developed. And I think",
      "offset": 1709.039,
      "duration": 8.081
    },
    {
      "lang": "en",
      "text": "uh you know that that is um a very u",
      "offset": 1711.919,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "conceptually satisfying way of talking",
      "offset": 1717.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "about like what is what is real and what",
      "offset": 1719.12,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "counts as a a thing ultimately. Yeah. I",
      "offset": 1721.679,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "mean because Dennit said that a real",
      "offset": 1725.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "pattern is any regularity that lets you",
      "offset": 1727.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "compress data and still predict what",
      "offset": 1729.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "comes next and if dropping the pattern",
      "offset": 1731.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "hurts prediction then it kind of it",
      "offset": 1733.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "earns its ontological keep. So there are",
      "offset": 1736.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "many examples like in the game of life",
      "offset": 1738.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "where we see these emergent macroscopic",
      "offset": 1740.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "phenomena or language is is a great",
      "offset": 1742.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "example and it's too complicated for us",
      "offset": 1744.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "to imagine you know we were talking",
      "offset": 1747.76,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "about this causal graph this",
      "offset": 1749.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "unimaginable amount of low-level",
      "offset": 1750.559,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "interactions that compounded together",
      "offset": 1752.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "produced this macroscopic phenomenon.",
      "offset": 1755.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "It's beyond our cognitive horizon to",
      "offset": 1757.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "even think about that. So we we see this",
      "offset": 1760.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "macroscopic phenomena and and we call",
      "offset": 1762.72,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "that a form of emergence. But this real",
      "offset": 1765.52,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "thing you said it pushes back on you,",
      "offset": 1769.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "right? Which which is interesting. So",
      "offset": 1771.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "there certainly seems to be a",
      "offset": 1773.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "relationship between language. You know,",
      "offset": 1774.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "some people think of language as being",
      "offset": 1777.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "an organism in of itself, a kind of",
      "offset": 1779.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "agent which itself pushes back. But this",
      "offset": 1781.039,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "this gets us into this really sticky",
      "offset": 1783.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "argument about the extent to which you",
      "offset": 1785.679,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "could have a pressure coming back down.",
      "offset": 1788.159,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "could could an emergent phenomenon",
      "offset": 1790.72,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "actually have causal power and and I",
      "offset": 1793.279,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "should say as well by the way that um",
      "offset": 1796.559,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "there's this wonderful guy called Mark",
      "offset": 1798.159,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "Bedal and in 1997 he had a paper called",
      "offset": 1800.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "weak emergence and he said emergent",
      "offset": 1802.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "phenomena are somehow constituted by and",
      "offset": 1804.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "generated from an underlying process and",
      "offset": 1807.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "he said they are somehow autonomous from",
      "offset": 1810,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "underlying processes and this is really",
      "offset": 1812,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "interesting because how can they be",
      "offset": 1813.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "autonomous if they're caused by the",
      "offset": 1815.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "underlying process and agency is a bit",
      "offset": 1817.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like this, you know, like one of the",
      "offset": 1820,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "definitions of agency is autonomy, which",
      "offset": 1821.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "means it's causally disconnected, even",
      "offset": 1823.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "though apparently it's not causally",
      "offset": 1825.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "disconnected. Then you get into these",
      "offset": 1827.2,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "weird metaphysical discussions because",
      "offset": 1828.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "if it's not reductionist, then you seem",
      "offset": 1830.799,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "to be getting something from nothing,",
      "offset": 1832.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "right? So, how do you wrestle with these",
      "offset": 1835.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "with these ideas? So, you know, this",
      "offset": 1837.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "distinction between weak and strong",
      "offset": 1839.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "emergence, I think, uh, hinges on",
      "offset": 1841.2,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "whether you want emergent things to have",
      "offset": 1843.44,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "causal powers or not. So um I mean weak",
      "offset": 1846.159,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "emergence uh at least in my reading of",
      "offset": 1850.32,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "it from from Bidau and others um",
      "offset": 1852.96,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "is I mean effectively epifenomenal like",
      "offset": 1856.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "what what Bidau is telling us is that",
      "offset": 1859.6,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "well um some emergent uh macrolevel",
      "offset": 1861.52,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "property some some excuse me some some",
      "offset": 1865.279,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "property at the macro level is emerges",
      "offset": 1867.679,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "from um you know dynamics at a at a",
      "offset": 1870.32,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "lower level. um if they uh if they can",
      "offset": 1874.88,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "be predicted to an extent uh but that",
      "offset": 1878.32,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "that you need simulation effectively to",
      "offset": 1882.399,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "like cash out the relationship between",
      "offset": 1884.559,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "levels. Um",
      "offset": 1886.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and you know in in the the paper that",
      "offset": 1889.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "you're referring to he makes the point",
      "offset": 1891.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that like this is not for him like just",
      "offset": 1892.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "an epistemic thing that this this is a",
      "offset": 1894.88,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "robust metaphysical thing. um like the",
      "offset": 1897.279,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "there there is this is not just a way of",
      "offset": 1900.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "talking about a pattern for for Bidal",
      "offset": 1902.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "like there's there's something new in",
      "offset": 1904.24,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "some sense that emerges uh but then you",
      "offset": 1906.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "know at least in that paper he does not",
      "offset": 1909.84,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "want to say that these um that these",
      "offset": 1912.64,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "emerging properties can have kind of",
      "offset": 1916.32,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "downward causal effects on the uh the",
      "offset": 1918.799,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "medium from which it emerged originally.",
      "offset": 1922.64,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "Um I mean I as someone who uh you know",
      "offset": 1925.679,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "worked in multiddisciplinary domains",
      "offset": 1928.399,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "like transcultural psychiatry I kind of",
      "offset": 1930.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "have some issue with that. So um you",
      "offset": 1932.96,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "know um I was talking to uh one of my",
      "offset": 1935.44,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "PhD supervisors uh at McGill. Uh you",
      "offset": 1938.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "know I worked under Carl Fristen at UCL",
      "offset": 1941.519,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "and Lawrence Kermayer at McGill u and",
      "offset": 1943.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Lawrence is a transcultural psychiatrist",
      "offset": 1946.32,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "a cultural psychiatrist. Um, and he's",
      "offset": 1949.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "interested in like the the the the I",
      "offset": 1952.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "mean, are they causal? The the",
      "offset": 1954.96,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "interactions between all these different",
      "offset": 1956.64,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "levels and um you know, as a as a uh",
      "offset": 1958.159,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "philosopher who you know is interested",
      "offset": 1962.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "in physics and mathematics and this kind",
      "offset": 1963.84,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "of thing, uh I I like nice sanitized",
      "offset": 1966.159,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "accounts of, you know, emergence and you",
      "offset": 1969.279,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "know, h how those things uh work. Um and",
      "offset": 1972.08,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "you know I'm I'm very influenced by um",
      "offset": 1975.279,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "uh accounts uh for example Max Klers's",
      "offset": 1978.24,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "um or uh Alicia Herrerero's uh who who",
      "offset": 1982,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "ultimately suggest that like what what",
      "offset": 1985.919,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "links levels of emergence together are",
      "offset": 1987.679,
      "duration": 8.561
    },
    {
      "lang": "en",
      "text": "uh constraints not causes. Um so I mean",
      "offset": 1991.44,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "what Kistler's argument and I think this",
      "offset": 1996.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "dovetales with some of the the new work",
      "offset": 1998.48,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "by Herrerero um they what they argue is",
      "offset": 2000.48,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "I mean there there are effectively two",
      "offset": 2003.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "different kinds of relationships that",
      "offset": 2005.679,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "can hold between levels of emergence uh",
      "offset": 2007.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "or levels of organization. Uh there's",
      "offset": 2010.559,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "composition which is just straight up I",
      "offset": 2012.88,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "am a proper part of you right so you",
      "offset": 2015.279,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "know um the way that like droplets make",
      "offset": 2017.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "up clouds for example and then",
      "offset": 2020.08,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "constraint",
      "offset": 2022,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "uh right so so the way that uh for",
      "offset": 2023.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "example like the architecture of a",
      "offset": 2025.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "circuit board will constrain the flow of",
      "offset": 2027.279,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "electrons uh and those are the only two",
      "offset": 2029.279,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "like metaphysically allowable forms of",
      "offset": 2032.48,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "interaction between levels. Uh the nice",
      "offset": 2036,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "thing about this is that you can talk",
      "offset": 2038.559,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "about you know forms of determinism",
      "offset": 2040.48,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "um that that don't just collapse into",
      "offset": 2044.159,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "like you know efficient causality right",
      "offset": 2046.399,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 2049.359,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "so yeah the you know Aristotle spoke of",
      "offset": 2050.879,
      "duration": 7.841
    },
    {
      "lang": "en",
      "text": "like four different kinds of cause uh",
      "offset": 2055.119,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "and uh you know three out of those four",
      "offset": 2058.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "were rejected during the uh the",
      "offset": 2061.919,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "development of you know modern science",
      "offset": 2064.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "during the enlightenment and all of that",
      "offset": 2066.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "stuff. Uh basically there you know",
      "offset": 2068.079,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "material um final",
      "offset": 2070.24,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "efficient and formal uh were the four",
      "offset": 2073.44,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "kinds of causes. Um so you know",
      "offset": 2077.599,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "basically what what the uh you know",
      "offset": 2080.879,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "following Decart and you know uh all of",
      "offset": 2083.04,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "the kind of empirical turn during the",
      "offset": 2086.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "enlightenment all of these other all of",
      "offset": 2088.399,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "the all of the non um efficient forms of",
      "offset": 2090.8,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "causality were kind of banished into",
      "offset": 2094,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "like the domain of like bad old",
      "offset": 2096.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "scholastic philosophy. And the only kind",
      "offset": 2098.56,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "of you know causation that was allowed",
      "offset": 2100.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to you know remain in circulation in",
      "offset": 2103.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "scientific discourse was this notion of",
      "offset": 2105.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "efficient causality. So like you know",
      "offset": 2107.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "think billiard balls uh Aristotle for",
      "offset": 2110.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Aristotle like efficient causation is",
      "offset": 2112.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "like when when the sculptor sculpts the",
      "offset": 2114.8,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the the the clay into the form. It's the",
      "offset": 2117.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "actual efficient process if you want to",
      "offset": 2120.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "think about it that way or or mechanism",
      "offset": 2122.8,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "through which um you know things affect",
      "offset": 2124.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "other things materially. The in the",
      "offset": 2128.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "enlightenment period we're talking about",
      "offset": 2130.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "like billiard balls",
      "offset": 2132.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "colliding into each other. So uh",
      "offset": 2134.8,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "basically the the kinds of uh you know",
      "offset": 2137.2,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "force transmission, energy transmission",
      "offset": 2140.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "that became the only like viable way of",
      "offset": 2143.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "talking about causality. Um but of",
      "offset": 2146.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "course there are like several different",
      "offset": 2148.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "you know ways of influencing thing of",
      "offset": 2150.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "things influencing other things that",
      "offset": 2154.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "don't that that don't follow this kind",
      "offset": 2155.68,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "of pattern. I mean um so Huerero um",
      "offset": 2157.44,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "talks about um constraints as things",
      "offset": 2161.359,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "that raise or lower the energy barrier",
      "offset": 2164.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "right the amount of energy required for",
      "offset": 2168,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "there to be a specific kind of",
      "offset": 2169.92,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "interaction. So that's cool because it",
      "offset": 2171.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it allows us to talk in a very I think",
      "offset": 2173.119,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "sensible way about forms of determinism",
      "offset": 2175.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "that are not mere energy transfer and",
      "offset": 2178.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "these are important right so uh they're",
      "offset": 2180.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "important in the setting context of",
      "offset": 2183.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "embodiment and in in the context of the",
      "offset": 2185.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "way the different levels of",
      "offset": 2187.839,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "self-organization",
      "offset": 2188.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "um interface um so you know the for",
      "offset": 2190.64,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "example like you know to take a to take",
      "offset": 2194,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "an example close to close to home that",
      "offset": 2196.32,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "we all care about in neuroscience you",
      "offset": 2198.32,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "the the whole architecture of the brain",
      "offset": 2201.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "like the the network structure of the",
      "offset": 2204.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "brain um certainly does have some kind",
      "offset": 2206.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "of deterministic influence on the",
      "offset": 2209.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "constituent modules and so on. Um, but",
      "offset": 2212,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "it's not just, you know, efficient",
      "offset": 2215.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "causation, right? Like that that",
      "offset": 2217.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "wouldn't make much sense. The but there",
      "offset": 2218.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "is a deterministic influence there. And",
      "offset": 2221.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "the way that networks influence",
      "offset": 2223.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "individual components of the network is",
      "offset": 2226.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "through this kind of constraint. And you",
      "offset": 2228,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "know, Huero has a nice philosophical",
      "offset": 2230.079,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "definition um in in in her new book. Um",
      "offset": 2232.48,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "like I was saying it constraints are",
      "offset": 2237.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "things that lower uh or raise the the",
      "offset": 2238.96,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "energetic barrier for there to be some",
      "offset": 2242.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "kind of interaction. But you know for",
      "offset": 2244.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Kistler constraints are you know more",
      "offset": 2246,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "understood in the mathematical sense of",
      "offset": 2248.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "like give me uh you know a system of",
      "offset": 2249.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "differential equations. Well each of",
      "offset": 2252.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "those equations imposes a new set of",
      "offset": 2254.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "constraints on the system that the",
      "offset": 2256.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "certain variables have to stay within",
      "offset": 2258.16,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "certain ranges. Um so yeah um I was",
      "offset": 2259.839,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "saying all of that because um the way",
      "offset": 2264.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that levels are I I would like to I I",
      "offset": 2266.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "submit for discussion at least the way",
      "offset": 2269.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that levels I think are connected are",
      "offset": 2271.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "through composition and constraint. Um",
      "offset": 2274.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "and that's a nice you know I think",
      "offset": 2277.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "philosophically sensible way of thinking",
      "offset": 2279.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "about things. An even more vex question",
      "offset": 2281.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "which is you know what is a thing",
      "offset": 2283.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "exactly right? um you know like we're",
      "offset": 2285.68,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "we've been working a lot on object",
      "offset": 2289.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "detection and you know the way that it's",
      "offset": 2291.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "treated in uh in machine learning and in",
      "offset": 2293.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "the active inference literature and like",
      "offset": 2295.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "I'm a pluralist about you know notions",
      "offset": 2297.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of objecthood right I think there are",
      "offset": 2300.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "several different you know logically",
      "offset": 2302.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "valid notions of object that you and",
      "offset": 2304.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "what we might mean by an object I think",
      "offset": 2306.48,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "the the least constrained version uh",
      "offset": 2308.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "which is also the least useful I think",
      "offset": 2311.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "um is the set theoretic one right which",
      "offset": 2313.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "is basically like just you A a thing is",
      "offset": 2315.76,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "a set. A set is a collection of other",
      "offset": 2318.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "sets. And you get this kind of, you",
      "offset": 2321.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "know, uh a nice, you know, recursive",
      "offset": 2323.04,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "notion uh a nice recursive definition.",
      "offset": 2326.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "But um you know, the problem is that",
      "offset": 2329.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that's too unconstrained, right? So, you",
      "offset": 2331.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "know, uh the the set comprised of like",
      "offset": 2333.839,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "my haircut, the planet Jupiter, um your",
      "offset": 2336.4,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "baseball cap, and you know, Jason's dog.",
      "offset": 2339.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "That's a that's a logical object, right?",
      "offset": 2342.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Uh but there's no coherence",
      "offset": 2345.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to that object. Like I think when we",
      "offset": 2347.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "talk about things, we we have the",
      "offset": 2349.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "impression that like things should hang",
      "offset": 2351.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "together in a special way, right? Like",
      "offset": 2353.599,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "if you poke a thing, then it it should",
      "offset": 2356.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "react to that poke in a way that's",
      "offset": 2359.119,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "characteristic of that thing, right?",
      "offset": 2360.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Like that's usually what we think of. So",
      "offset": 2363.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you know um in a lot of machine learning",
      "offset": 2365.92,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "work objects are defined u like you know",
      "offset": 2368.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "object recognition works in machine",
      "offset": 2371.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "learning but the objects are defined in",
      "offset": 2374.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "data space or feature space right um so",
      "offset": 2376.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "you know an object might be like an",
      "offset": 2379.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "identity um you know a a position",
      "offset": 2381.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "orientation",
      "offset": 2385.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and uh some translation rules and that's",
      "offset": 2387.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "a perfectly you know valid definition of",
      "offset": 2389.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "object in in Dennit's terms it would be",
      "offset": 2392.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "a real pattern right that appears in you",
      "offset": 2394.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "know a channel of visual information",
      "offset": 2397.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "that's a perfectly you know consistent",
      "offset": 2400.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "definition of object that's the kind of",
      "offset": 2402.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "thing also that will appear in language",
      "offset": 2404.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "right like I think um you know concepts",
      "offset": 2406.56,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "are you know you know loose collections",
      "offset": 2409.52,
      "duration": 8.079
    },
    {
      "lang": "en",
      "text": "in in this kind of way um but uh that's",
      "offset": 2412.64,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "not sufficient as a notion of object to",
      "offset": 2417.599,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "interact with things in the real world",
      "offset": 2420.72,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "like there are additional constraints",
      "offset": 2423.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "that pertain to the kinds of things that",
      "offset": 2426.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "we interact with on a daily basis like",
      "offset": 2429.04,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "physical real world objects are not just",
      "offset": 2431.68,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "like an identity an orientate or a pose",
      "offset": 2435.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and some translation features like there",
      "offset": 2438.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "there's some additional structure there",
      "offset": 2440.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and you know Tim Tim we've known each",
      "offset": 2443.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "other for a while you probably know",
      "offset": 2445.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "where I'm going with this uh but you",
      "offset": 2446.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "know the one of the things I like about",
      "offset": 2448.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "the free energy principle in active",
      "offset": 2450.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "inference is that they give you a nice",
      "offset": 2452.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "robust notion of object or object type",
      "offset": 2453.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "that inserts itself very naturally in",
      "offset": 2457.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "this kind of context. So you know um",
      "offset": 2459.44,
      "duration": 8.24
    },
    {
      "lang": "en",
      "text": "what what's missing from um the uh the",
      "offset": 2462.48,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "no the the the databased notion of",
      "offset": 2467.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "object is like the these additional",
      "offset": 2470.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "physical properties that physical",
      "offset": 2472.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "objects have and under the free energy",
      "offset": 2475.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "principle this is basically uh the",
      "offset": 2477.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "existence of a boundary.",
      "offset": 2478.96,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "So just for for uh the the benefit of",
      "offset": 2481.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "our listeners who may may not be",
      "offset": 2484.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "familiar with uh the free energy",
      "offset": 2486.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "principle as developed by Carl Fristen.",
      "offset": 2488.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "Um you can think of uh the free energy",
      "offset": 2490.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "principle as and this is heristically",
      "offset": 2493.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "you can think of the free energy",
      "offset": 2495.599,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "principle as an extension of the second",
      "offset": 2496.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "law of ther thermodynamics extending it",
      "offset": 2498.4,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "from closed systems to open systems that",
      "offset": 2501.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "have boundaries. You know, think of a",
      "offset": 2504.56,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "closed system, right? Like, you know, a",
      "offset": 2506.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "volume of gas. Just to be really simple.",
      "offset": 2509.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "What happens in a closed system is the",
      "offset": 2511.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "gradients are all consumed and the",
      "offset": 2513.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "system ends up arriving at thermodynamic",
      "offset": 2516.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "equilibrium. So, you might think like",
      "offset": 2518.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "there's a say a temperature or a",
      "offset": 2519.92,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "chemical gradient in in the cloud of gas",
      "offset": 2522.56,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "and through diffusion dynamics, right?",
      "offset": 2526,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "What the second law tells us is that",
      "offset": 2528.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "well, the the system will just tend to",
      "offset": 2530,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "be uniform. you know the the second law",
      "offset": 2532.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "basically is like the the law of my uh",
      "offset": 2534.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "can of soda pop going flat right like",
      "offset": 2537.2,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "you know it's it's uniformity uh is what",
      "offset": 2539.92,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "is achieved at the end um so what the",
      "offset": 2543.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "free energy principle is at the end of",
      "offset": 2546.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the day it's the same idea but like",
      "offset": 2548.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "physics in the presence of boundaries so",
      "offset": 2550.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you know reimagine that same system but",
      "offset": 2553.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "now there's a boundary in separating you",
      "offset": 2555.76,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "know the two chambers of gas um well I",
      "offset": 2558.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "mean in that context text just by",
      "offset": 2562,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "construction you said there's a boundary",
      "offset": 2564.16,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "so you're not going to get this strong",
      "offset": 2565.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "mixing right the gradients are not going",
      "offset": 2567.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "to be able to just you know uh be",
      "offset": 2569.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "consumed in the usual way what you get",
      "offset": 2571.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "instead is the next best thing which is",
      "offset": 2574.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "this kind of generalized synchrony",
      "offset": 2576.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "thisformational coupling it's like well",
      "offset": 2579.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "I can't mix into you right so the best",
      "offset": 2581.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "thing that I the next best thing that I",
      "offset": 2584,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "can do is be become like you",
      "offset": 2586.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "statistically",
      "offset": 2588.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "um so that's that's what the free energy",
      "offset": 2589.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "principle is like at uh at a very high",
      "offset": 2591.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "level and uh you know what the key",
      "offset": 2593.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "features of objecthood from that",
      "offset": 2596.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "definition are like objects have",
      "offset": 2598.72,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "boundaries.",
      "offset": 2600.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Objects interact with other objects at",
      "offset": 2601.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "their boundary and therefore the",
      "offset": 2604,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "statistics of the boundary allow you to",
      "offset": 2606,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "define different object types. Um and",
      "offset": 2608.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "that is precisely I think the kind of",
      "offset": 2611.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "thing that's missing in contemporary",
      "offset": 2613.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "machine learning. So you know again",
      "offset": 2615.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "there's nothing wrong with language and",
      "offset": 2617.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "there's nothing wrong with existing in",
      "offset": 2619.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "data space like the it's it's a good",
      "offset": 2620.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "thing for us that language is",
      "offset": 2623.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "unconstrained by physical reality.",
      "offset": 2625.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "That's what enables us to use language",
      "offset": 2627.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to imagine, you know, to imagine, you",
      "offset": 2628.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "know, counterfactual situations and to",
      "offset": 2631.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "imagine things like unicorns, right?",
      "offset": 2633.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "Like or whatever, right? To to imagine",
      "offset": 2636.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "things that are impossible. Like that's",
      "offset": 2639.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that's very useful, right? In in many",
      "offset": 2640.56,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "contexts. Uh",
      "offset": 2643.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "but you know, when you want to act in",
      "offset": 2646.319,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "the world, you want to be constrained by",
      "offset": 2648.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the physics of the situation that you're",
      "offset": 2652.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "trying to control. Yeah, that's really",
      "offset": 2654.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "beautiful. I think that that's actually",
      "offset": 2656,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "one of the best explanations I've ever",
      "offset": 2657.28,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "heard of of the free energy principle.",
      "offset": 2658.88,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "Thank you. It's only taken me 15 years",
      "offset": 2660.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "to Well, this is what we were saying",
      "offset": 2661.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "earlier that it actually takes decades",
      "offset": 2664.16,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "of wrestling and thinking about things",
      "offset": 2666.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "to to understand it at this level",
      "offset": 2669.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "because you you have these kind of like",
      "offset": 2671.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "low-level abstract functions of",
      "offset": 2673.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "understanding and you you can use that",
      "offset": 2675.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to, you know, re-represent and recast",
      "offset": 2676.72,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "and construct and create, you know, your",
      "offset": 2679.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "understanding of different situations.",
      "offset": 2681.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "But that that really evoked an image to",
      "offset": 2682.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "me. I'm almost imagining imagine you had",
      "offset": 2685.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "a computer game environment and you know",
      "offset": 2687.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "thermodynamics is is like you know just",
      "offset": 2690,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "a completely open space where all of the",
      "offset": 2692.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "little bits can just intermingle and it",
      "offset": 2694.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "just necessarily kind of just converges",
      "offset": 2696.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "to this to this equilibrium where you",
      "offset": 2698.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "know where where energy goes down and",
      "offset": 2700.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "now like imagine you know almost like a",
      "offset": 2703.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "quake 3 or a doom type level where you",
      "offset": 2705.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "have all of these walls and boundaries",
      "offset": 2707.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "all over the place and if I understand",
      "offset": 2709.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "correctly the the free energy principle",
      "offset": 2711.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "doesn't really help you figure out what",
      "offset": 2713.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the boundaries are. It's assuming that",
      "offset": 2716,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "if the boundaries are there, what",
      "offset": 2717.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "happens? That's correct. So, we still",
      "offset": 2719.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "have the fundamental problem of like",
      "offset": 2721.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "because this is this is presumably one",
      "offset": 2724.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "of the most important problems in",
      "offset": 2725.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "artificial intelligence is this",
      "offset": 2727.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "miraculous ability that we have just to",
      "offset": 2729.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "just to make sense of a scene to make",
      "offset": 2731.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "sense of of where we are. And and it",
      "offset": 2733.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "comes back to the emergence discussion",
      "offset": 2735.68,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "as well because I think these real",
      "offset": 2737.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "patterns that we used to think they're",
      "offset": 2738.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "actually an artifact of the kinds of",
      "offset": 2741.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "constraints between the layers that",
      "offset": 2744,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "you're talking about. So it's it's not",
      "offset": 2745.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "like they're completely like constructed",
      "offset": 2748.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "from nothing. There is there is a path",
      "offset": 2750.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "from the world that we live in and these",
      "offset": 2753.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "constraints and these boundaries and",
      "offset": 2755.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "these actually inform the kinds of",
      "offset": 2756.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "models that we do. Absolutely. I mean um",
      "offset": 2758.8,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "so Huerero um has in in her book um a",
      "offset": 2760.72,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "context changes everything um it's it's",
      "offset": 2765.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "really it's it's very interesting uh",
      "offset": 2768.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "book and",
      "offset": 2770.319,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "somewhat oversimplifying her argument",
      "offset": 2772.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "she says well there are different types",
      "offset": 2773.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of constraints that are related to",
      "offset": 2776,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "coherence in different ways and one",
      "offset": 2778.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "distinction that she makes is between",
      "offset": 2780,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "limiting constraints and enabling",
      "offset": 2781.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "constraints. So she says most of the",
      "offset": 2784.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "constraints that we consider in physics",
      "offset": 2786.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "are limiting right. So literally like",
      "offset": 2788.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the constraint exists because it limits",
      "offset": 2791.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "your ability to follow a certain",
      "offset": 2793.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "trajectory or to access a certain region",
      "offset": 2795.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "of your phase space. Uh so you know a",
      "offset": 2797.359,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "limiting constraint is like what",
      "offset": 2800.4,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "circuits do in a uh like a processor",
      "offset": 2802.24,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "right like so having you know different",
      "offset": 2806.48,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "literally different wires are canalizing",
      "offset": 2809.44,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "you know electron flow in one direction",
      "offset": 2812.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "as opposed to another you know and this",
      "offset": 2815.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "is what like gaps and all all of this",
      "offset": 2817.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "kind of thing in your architecture allow",
      "offset": 2819.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you're you're literally preventing",
      "offset": 2821.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "you know energy from moving in a certain",
      "offset": 2824.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "direction again and this is consistent",
      "offset": 2826.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "with her definition, right? By by",
      "offset": 2828.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "heightening or lowering the the",
      "offset": 2829.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "energetic barrier that's necessary for a",
      "offset": 2831.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "specific kind of interaction. Um, in",
      "offset": 2833.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "biology,",
      "offset": 2836.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Huareero points out constraints",
      "offset": 2838.16,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "typically have not a limiting",
      "offset": 2840.64,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "um connotation to them but an enabling",
      "offset": 2843.599,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "connotation to them. So constraints are",
      "offset": 2846.319,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "uh such that they they enable the system",
      "offset": 2850.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "to access regions of state space that",
      "offset": 2852.64,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "that they would not you know uh on their",
      "offset": 2855.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "own uh under ordinary circumstances. So",
      "offset": 2858.079,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "what she calls enabling constraints",
      "offset": 2860.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "are effectively constraints that allow a",
      "offset": 2863.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "new kind of stability or structure to",
      "offset": 2866.48,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "emerge which can then itself be you know",
      "offset": 2868.319,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "subject to selection and you know become",
      "offset": 2871.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "another kind of if you want to think",
      "offset": 2873.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "about it like that a medium for you know",
      "offset": 2875.359,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "new constraints to be added on top of.",
      "offset": 2878.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "So, I really like this because I I think",
      "offset": 2881.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "it allows you to talk about um you know,",
      "offset": 2883.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "the things that Mark Bedau thought were",
      "offset": 2885.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "kind of like, you know, philosophically",
      "offset": 2887.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "or metaphysically suspect, but in a very",
      "offset": 2889.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "elegant way. Like, none of this is",
      "offset": 2892.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "spooky. You know, if you it's it's no",
      "offset": 2894.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "more spooky to talk about, you know,",
      "offset": 2897.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "constraints and their effects on, you",
      "offset": 2899.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "know, the deterministic flow of a system",
      "offset": 2901.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "than it is to talk about the way that",
      "offset": 2904.079,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "wires, you know, canalize the flow of",
      "offset": 2905.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "electrons. like that that seems",
      "offset": 2908.559,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "perfectly sensible on the face of it.",
      "offset": 2910.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "It's not spooky. And you know, I think",
      "offset": 2912.319,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "uh all of these um kind of multi-cale",
      "offset": 2915.2,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "effects can be uh made sense of and can",
      "offset": 2919.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "be explained sensibly by appealing to",
      "offset": 2922.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "this same kind of explanatory strategy.",
      "offset": 2924.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Um",
      "offset": 2927.359,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the the question of detecting um objects",
      "offset": 2929.119,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "is uh a rather vexed one. I mean um you",
      "offset": 2932.559,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "know the uh yeah but we don't we don't",
      "offset": 2935.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "have to go into that. I think a like a",
      "offset": 2938.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "technical comment on that. So Maxwell",
      "offset": 2941.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "earlier you mentioned um you know",
      "offset": 2944.319,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "systems today learn in data space which",
      "offset": 2946.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "is almost entirely true. Um, I think",
      "offset": 2949.119,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "tying that back to the importance of",
      "offset": 2952.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "embodiment and experience is really",
      "offset": 2954.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "important here and why why these systems",
      "offset": 2956.559,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "don't sort of carve things out in",
      "offset": 2960,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "objects the same way that we do, right?",
      "offset": 2962.8,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "Um, and so we we're able to interact and",
      "offset": 2964.88,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "find the boundaries through a very",
      "offset": 2970.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "natural kind of interaction with the",
      "offset": 2972.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "world around us. And then that teaches",
      "offset": 2975.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "us how to then identify new types of",
      "offset": 2977.44,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "boundaries when we come across them,",
      "offset": 2980.88,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "right? And I think that gets back to",
      "offset": 2982.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "this really object- centered way of of",
      "offset": 2984.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "thinking about the world that's missing",
      "offset": 2986.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "from machine learning today. There's",
      "offset": 2989.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "there's approximations that the field is",
      "offset": 2991.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "is introducing through like physics",
      "offset": 2993.839,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "simulation. Um it's a very popular uh",
      "offset": 2996.319,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "technique for training uh particularly",
      "offset": 3000,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "reinforcement learning models for",
      "offset": 3002.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "robotics today which is I'm going to",
      "offset": 3003.76,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "like handcraft sort of a a physics scene",
      "offset": 3007.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "and I'm going to add some objects to it",
      "offset": 3010.319,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and then I'm going to run my simulation",
      "offset": 3012.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you know thousands or millions of times",
      "offset": 3015.359,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "over",
      "offset": 3017.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "um and expect a model to come out. And",
      "offset": 3018.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "so there is this notion and this need",
      "offset": 3021.04,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "and desire to introduce those types of",
      "offset": 3024,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "interactions with like physical objects",
      "offset": 3027.2,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "into the learning process that I think",
      "offset": 3030.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "is it's becoming more apparent and more",
      "offset": 3033.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "important um as we try to shift AI out",
      "offset": 3035.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "of you know digital space into physical",
      "offset": 3038.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "space. Yeah, I'm trying to understand",
      "offset": 3041.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "this because in the real world the",
      "offset": 3042.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "boundaries are just there and the",
      "offset": 3044.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "intelligence just is the world. It's",
      "offset": 3047.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it's just physics, right? So it it just",
      "offset": 3049.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "manifests itself in the way that you",
      "offset": 3051.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "were just describing Maxwell. But if we",
      "offset": 3053.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "want to build artificial intelligence,",
      "offset": 3055.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "then you get this kind of partial",
      "offset": 3058.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "observability where you're a thing and",
      "offset": 3060.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you might not know where all the other",
      "offset": 3063.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "boundaries are. And what you're",
      "offset": 3065.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "describing here is a form of",
      "offset": 3067.44,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "intelligence where you're modeling the",
      "offset": 3068.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "interaction dynamics. So we're saying at",
      "offset": 3071.359,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "some level of resolution we can model",
      "offset": 3074.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "almost affordances I think is the",
      "offset": 3077.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "technical term. So there's a thing over",
      "offset": 3079.44,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "here and this is the interface and I can",
      "offset": 3081.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "do these things with that thing and",
      "offset": 3083.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "maybe part of this process is I actually",
      "offset": 3084.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "need to figure out what that thing is",
      "offset": 3086.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and what I can do with it. Absolutely.",
      "offset": 3088.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "That's kind of ex exploration and",
      "offset": 3091.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "exploitation, right? And that's why, you",
      "offset": 3093.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "know, systems like active inference, I",
      "offset": 3096.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "think, lend themselves very well to that",
      "offset": 3098.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "style of learning through interaction.",
      "offset": 3101.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "Yes. So, could you could you sketch out",
      "offset": 3104,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "how how that works? So, um because",
      "offset": 3105.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "there's a bit of a blank slate problem",
      "offset": 3107.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "as well. Let's imagine that we we build",
      "offset": 3109.92,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "because Maxwell we we we spoke about",
      "offset": 3112.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "this the other day about whether you're",
      "offset": 3115.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "a functionalist or not because you know",
      "offset": 3116.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "certainly people like John Cell they",
      "offset": 3118.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "made the argument that you as well as",
      "offset": 3120.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "these these algorithms that we have you",
      "offset": 3123.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "actually need this causal embeddedness",
      "offset": 3125.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you need brains you need machines that",
      "offset": 3127.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "actually operate in in the real world",
      "offset": 3130,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "and you know I certainly spoke with",
      "offset": 3132.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Yosha back you know quite recently and",
      "offset": 3135.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and his his view was very much that you",
      "offset": 3137.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "have these kind of software agents and",
      "offset": 3139.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "currently they're being simulated by our",
      "offset": 3142.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "brains but they could be you know run uh",
      "offset": 3144,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "in in silicone. So there is a bit of a",
      "offset": 3146.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "lingering question for me there whether",
      "offset": 3148.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "you actually think that such an",
      "offset": 3150.16,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "intelligence must be embodied in the",
      "offset": 3151.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "real world or if if we could model it",
      "offset": 3155.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "differently maybe we wouldn't need to.",
      "offset": 3156.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "But let's just be practical for a I may",
      "offset": 3158.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "be uh I may be misunderstanding Yosha's",
      "offset": 3160.559,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "argument, but um I I kind of see him as",
      "offset": 3162.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "an arc platonist in the sense that like",
      "offset": 3165.119,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "what he thinks is is really real are are",
      "offset": 3168.16,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "like these functions which he by which",
      "offset": 3171.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "he means mathematical functions right",
      "offset": 3173.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "which are like implemented and multiply",
      "offset": 3174.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "realized by you know agents like us in",
      "offset": 3177.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the physical world. Um so he's",
      "offset": 3179.839,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "definitely a functionalist. Um I don't",
      "offset": 3182.16,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "know if I um if I adopt um the same",
      "offset": 3185.119,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "perspective. Um so I mean just taking a",
      "offset": 3188.72,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "few steps back um I think it might be",
      "offset": 3192.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "useful to you know where do the",
      "offset": 3195.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "primitives come from is a question that",
      "offset": 3197.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "you asked earlier. So you know where",
      "offset": 3198.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "where do like the atomic elements of",
      "offset": 3201.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "thought come from at the end of the day.",
      "offset": 3203.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Um, so I think a useful question to",
      "offset": 3205.359,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "consider in that intellectual context",
      "offset": 3208.96,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "is, well, why do we label things at all?",
      "offset": 3211.839,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Like why why do we use labels to",
      "offset": 3215.2,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "designate things? Well, a good label um",
      "offset": 3217.839,
      "duration": 8.081
    },
    {
      "lang": "en",
      "text": "improves my predictive grip on the",
      "offset": 3222.64,
      "duration": 9.36
    },
    {
      "lang": "en",
      "text": "world, right? and provides uh a simple",
      "offset": 3225.92,
      "duration": 9.199
    },
    {
      "lang": "en",
      "text": "like compressed explanation of the data",
      "offset": 3232,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "that I'm trying to explain. So um you",
      "offset": 3235.119,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "know why do we call um you know hydrogen",
      "offset": 3238,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "atoms hydrogen atoms or helium atoms",
      "offset": 3242.24,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "helium atoms? It's because um you know",
      "offset": 3245.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3248.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "hydrogen atoms have specific properties",
      "offset": 3250.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "that mean that they behave in certain",
      "offset": 3253.599,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "stereotyped ways. And by labeling a",
      "offset": 3256.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "collection, you know, like literally",
      "offset": 3260,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "like by labeling this zoo of subatomic",
      "offset": 3262.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "particles that hangs together as a a",
      "offset": 3264.559,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "hydrogen atom, then I'm able to, you",
      "offset": 3267.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "know, I I have some kind of explanatory",
      "offset": 3270.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "or predictive grip on the situation. It",
      "offset": 3272.8,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "it literally lowers the entropy of my",
      "offset": 3275.119,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "observations. It lowers the the surprise",
      "offset": 3277.359,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "that I that I have when observing them,",
      "offset": 3280.16,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "but that I have labeled them in a",
      "offset": 3283.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "certain way. Right? So, I mean,",
      "offset": 3285.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "presumably this is what the brain is",
      "offset": 3287.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "doing, right? Like there there there's",
      "offset": 3289.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "uh the brain has access to like these",
      "offset": 3291.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "dynamic data sets that it's generating",
      "offset": 3293.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "continuously through this kind of",
      "offset": 3296.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "sensory palpation of the world. And um",
      "offset": 3298,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "you know from at least from an active",
      "offset": 3301.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "inference point of view what's going on",
      "offset": 3303.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "is essentially hypothesis testing or you",
      "offset": 3304.96,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "know label testing right so um you know",
      "offset": 3308.079,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "uh on the assumption that like what I'm",
      "offset": 3311.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "encountering here is an object of a",
      "offset": 3313.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "specific type then I should expect this",
      "offset": 3315.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "or that you know data to be generated",
      "offset": 3317.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "and then well oops that actually that",
      "offset": 3320.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "wasn't a cat that was a small dog right",
      "offset": 3322.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "and then uh like my my my label was",
      "offset": 3325.04,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "inappropriate my hypothesis was uh you",
      "offset": 3328,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "know uh wrong. So I generated some error",
      "offset": 3330.8,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "and then I I change my hypothesis. I try",
      "offset": 3334.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "a new label. It's more appropriate. I",
      "offset": 3336.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "get more predictive power. So presumably",
      "offset": 3338.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "this is sort of what's going on. Like",
      "offset": 3340.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "the brain is trying to just to create a",
      "offset": 3342.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "compressed",
      "offset": 3345.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "representation or explanation of the",
      "offset": 3347.28,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "data sources that it is privy to and",
      "offset": 3349.44,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "that it's generating through embodied",
      "offset": 3352.559,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "intelligent action in the world. Um, so",
      "offset": 3354.799,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "yeah, I mean, um,",
      "offset": 3358.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "and this is I think again this this",
      "offset": 3360.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "echoes the embodied intelligence thesis.",
      "offset": 3363.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Um, there there is no such thing as",
      "offset": 3365.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "general intelligence. I want to say like",
      "offset": 3367.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "and I know that's perhaps like a",
      "offset": 3370.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "provocation, but like I think all",
      "offset": 3372.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "intelligence is situationally specific",
      "offset": 3374.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "for precisely these reasons, right? like",
      "offset": 3377.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "so you're dealing you're grounded in a",
      "offset": 3379.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "specific data set that's being generated",
      "offset": 3381.44,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "by a specific kind of exploratory",
      "offset": 3383.52,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "uh behavior right and I I don't mean",
      "offset": 3386.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "exploratory in the sense of like",
      "offset": 3388.799,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "exploitation versus exploration I mean",
      "offset": 3390.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "like this kind of sensory palpation of",
      "offset": 3391.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the world that we constantly you know",
      "offset": 3393.839,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "engage in and you know the things that",
      "offset": 3395.52,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "populate our ontology are you know are",
      "offset": 3398.799,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "um equivalent to the set of labels that",
      "offset": 3402.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "we deploy to make our you know to make",
      "offset": 3405.44,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "sense of our sensory data. By which I",
      "offset": 3408.16,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "mean like to compress it and to make",
      "offset": 3411.28,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "subsequent sensory data less surprising.",
      "offset": 3414.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Yeah, that that makes sense. I mean, the",
      "offset": 3416.799,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "thing that that springs to my mind",
      "offset": 3417.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "though is is you're proposing a",
      "offset": 3419.359,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "different form of artificial",
      "offset": 3421.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "intelligence than open AI. There's a big",
      "offset": 3422.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "narrative at the moment in the valley",
      "offset": 3425.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "that, you know, people are talking about",
      "offset": 3427.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "physical AI. They're saying that we",
      "offset": 3428.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "should put large language models or",
      "offset": 3431.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "similar into the brains of robots and",
      "offset": 3433.359,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "have them interact with the world. so",
      "offset": 3435.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "that they can do something akin to what",
      "offset": 3438.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "you're talking about. They can even with",
      "offset": 3439.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "coding for example some people say um",
      "offset": 3441.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the reason the code isn't very good is",
      "offset": 3444.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "because it's not running the code. It's",
      "offset": 3446.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "not testing the code. If only we had",
      "offset": 3447.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "tools. If only we could get results back",
      "offset": 3449.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "then we get this feedback loop. What is",
      "offset": 3452.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "the sort of the bright difference",
      "offset": 3454.4,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "between what you're proposing and",
      "offset": 3455.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "something like that? I would say like",
      "offset": 3457.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "being grounded in the world in some",
      "offset": 3459.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "sense. So like no matter how you train",
      "offset": 3461.599,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "these these uh you know state-of-the-art",
      "offset": 3463.68,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "feed forward you know gradient",
      "offset": 3467.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "descentbased architectures at the end of",
      "offset": 3469.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "the day um they they are only tethered",
      "offset": 3471.839,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "to reality through us and our",
      "offset": 3475.44,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "expressions of preferences",
      "offset": 3478.96,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "um and that's a huge problem uh and I",
      "offset": 3481.599,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "don't see any way out of that",
      "offset": 3485.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "architecture effectively I mean um you",
      "offset": 3487.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "know uh silver and sutton point out that",
      "offset": 3489.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like something was lost when we moved to",
      "offset": 3492,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the era of big data. Like if you think",
      "offset": 3494,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of like the first machine learning",
      "offset": 3496.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "systems that were using reinforcement",
      "offset": 3498.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "learning like part of their power was",
      "offset": 3500,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "that they were exploring you know the",
      "offset": 3502.24,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "problem space on their own. Um and they",
      "offset": 3504.559,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "um Sutton and Silver call this the era",
      "offset": 3509.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "of simulation where like you know the",
      "offset": 3511.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "very early systems like operated in",
      "offset": 3513.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "these simplified sandboxes and sure they",
      "offset": 3515.44,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "were limited because like they're not",
      "offset": 3517.839,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "exploring the real world with all of its",
      "offset": 3519.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "vagaries and contingencies right like",
      "offset": 3520.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "there's they're exploring these ultra",
      "offset": 3523.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "sananitized like simplified environments",
      "offset": 3525.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "but there was a kind of",
      "offset": 3527.44,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "self-directedness that you ended up",
      "offset": 3528.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "losing in the era of big data um and you",
      "offset": 3530.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "know silver and Sutton argue that this",
      "offset": 3533.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "next era that's creeping up on us will",
      "offset": 3535.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "be a return to that kind of like",
      "offset": 3538.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "autonomous data generation um which is",
      "offset": 3540,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "really critical I think to to have like",
      "offset": 3543.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "actually intelligent systems and this is",
      "offset": 3546.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "what I I don't think um current AI",
      "offset": 3548.64,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "architectures are really able to do for",
      "offset": 3551.76,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "like a a wide variety of reasons I mean",
      "offset": 3553.839,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "but in particular because they're not",
      "offset": 3557.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "grounded they're not connected in the",
      "offset": 3560.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "right way to reality so just to diffuse",
      "offset": 3562.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "a few possible objections like we're not",
      "offset": 3564.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "claiming that there aren't implicit",
      "offset": 3566.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "representations of the world in you know",
      "offset": 3568.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "say a large language model. Surely there",
      "offset": 3571.04,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "must be right because they are trained",
      "offset": 3573.92,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "on data sets that that that are that",
      "offset": 3576.64,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "that h you know feature these objects. I",
      "offset": 3579.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "I if they if they are predictively",
      "offset": 3582.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "powerful and if they work correctly then",
      "offset": 3585.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "then they will implicitly have you know",
      "offset": 3587.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "a representation of the world in there.",
      "offset": 3590,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "But it's not the kind of thing that you",
      "offset": 3592.079,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "can reason on, right? Or or that you can",
      "offset": 3593.68,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "use to make plans because it's implicit.",
      "offset": 3596.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "It's distributed. Somewhere in this",
      "offset": 3598.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "like, you know, messy, you know, jumble",
      "offset": 3601.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "of billions of parameters is like a",
      "offset": 3603.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "representation of, you know, Maxwell",
      "offset": 3606.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "talking to Tim for example or whatever,",
      "offset": 3608.799,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "right? like uh presumably like you know",
      "offset": 3611.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "it's there somewhere but it it's not",
      "offset": 3614.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "there in such a format that you know the",
      "offset": 3616.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the system could could use that to like",
      "offset": 3619.52,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "guide intelligent patterns of behavior",
      "offset": 3622,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "is is the contention. Yeah. You couldn't",
      "offset": 3625.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "go pluck that out of the network and",
      "offset": 3627.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "then use it somewhere else. Yeah. Jason,",
      "offset": 3630.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "do you want to maybe talk about like the",
      "offset": 3632.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "discreetness of these things and like",
      "offset": 3634.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "their use in say like you know game",
      "offset": 3635.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "environments and this kind of thing",
      "offset": 3637.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "because that that I think is like the",
      "offset": 3639.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "the problem Jason just pointed to at",
      "offset": 3640.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "like the the these objects are not",
      "offset": 3643.359,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "represented in the way that you could",
      "offset": 3645.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "just pluck out and then you know edit or",
      "offset": 3646.799,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "you know they're not discreet",
      "offset": 3649.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "you know recogniz there's certain like",
      "offset": 3652.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "rigidity to that right where like",
      "offset": 3655.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "because I don't know how it's broken",
      "offset": 3658,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "down I can't go just carve out uh that",
      "offset": 3659.599,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "representation of that particular object",
      "offset": 3662.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "or that behavior and then repurpose it",
      "offset": 3665.04,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "maybe in a a new or a smaller context",
      "offset": 3667.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "for example and so there's this lack of",
      "offset": 3671.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "composability that's inherent in these",
      "offset": 3672.96,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "systems right so and if you think about",
      "offset": 3675.359,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "you know how we learn and how we move",
      "offset": 3679.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "about the world and how some of the most",
      "offset": 3681.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "I think efficient and effective systems",
      "offset": 3683.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in the world that that even humans have",
      "offset": 3685.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "produced like composition is very",
      "offset": 3687.359,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "important to that Yeah. Um especially",
      "offset": 3689.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "for efficiency. And when we're talking",
      "offset": 3692.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "about physical systems that are",
      "offset": 3694.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "untethered to like power sources,",
      "offset": 3696.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "they've got a self-contain",
      "offset": 3699.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "self-containment to them where they have",
      "offset": 3700.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "their own battery pack. You know,",
      "offset": 3702.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "efficiency is extremely important,",
      "offset": 3704.559,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "right? And so",
      "offset": 3706.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "um being able to or having to like",
      "offset": 3709.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "transport a data center, you know, in a",
      "offset": 3711.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "robot to kind of host these",
      "offset": 3714.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "multi-billion parameter models.",
      "offset": 3716.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "And quite honestly, it's kind of a",
      "offset": 3718.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "non-starter in any production grade",
      "offset": 3720.079,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "system, right? And so I think um I think",
      "offset": 3723.04,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "learning",
      "offset": 3726.96,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "into sort of composable bits or modules",
      "offset": 3729.119,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "is extremely important uh as we move",
      "offset": 3732.079,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "forward here into architectures. Yeah.",
      "offset": 3734.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "Yeah. I mean, if if we've learned",
      "offset": 3737.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "anything from the deepseek moment, it's",
      "offset": 3739.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that, you know, a mixture of experts",
      "offset": 3741.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "architecture will always outperform like",
      "offset": 3743.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "one monolithic",
      "offset": 3745.92,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "architecture. Um, you know, uh, so even",
      "offset": 3748.319,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "the LLM, you know, um, purists, if you",
      "offset": 3752.4,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "will, will are moving away from like the",
      "offset": 3756,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the monolithic omnimodel kind of model",
      "offset": 3758.079,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "of AI. We're kind of taking that to its",
      "offset": 3761.28,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "logical extreme to say, well, what what",
      "offset": 3764.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "you really want is um collections of",
      "offset": 3766.799,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "models that are situationally",
      "offset": 3770.319,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "specific, right? That that that are very",
      "offset": 3773.119,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "good at doing certain kinds of things um",
      "offset": 3775.52,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "and that are like attuned to like",
      "offset": 3779.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "specific kinds of situations. Like",
      "offset": 3781.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "that's that's that's the way that",
      "offset": 3783.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "intelligence occurs, you know, in",
      "offset": 3784.88,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "nature. Yeah. It's also um it's it's",
      "offset": 3787.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "ironic that",
      "offset": 3790.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "LLM fans do not think that intelligence",
      "offset": 3792.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "is specialized. And it's ironic because",
      "offset": 3795.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "LLMs are the most specialized possible",
      "offset": 3798.319,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "form of intelligence. They they are they",
      "offset": 3800.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "learn these jagged fractured",
      "offset": 3802.799,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "representations which are basically just",
      "offset": 3805.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "memorizing, you know, very very specific",
      "offset": 3807.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "things. It's very specialized. Um as you",
      "offset": 3810,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "were saying, Jason, they're not robust.",
      "offset": 3812.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "They don't learn things abstractly.",
      "offset": 3814,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "They're not compositional. They're not",
      "offset": 3815.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "iterative. They work best when humans",
      "offset": 3817.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "use them in a compositional iterative",
      "offset": 3820.319,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "way. Certainly coding is a great example",
      "offset": 3822.079,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "of this. You know, you do this generate",
      "offset": 3823.839,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "test loop and the human with their",
      "offset": 3826.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "understanding of the world is",
      "offset": 3828.799,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "identifying in interesting candidates",
      "offset": 3830.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "and you're running and you're running",
      "offset": 3831.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and you're kind of you're basically",
      "offset": 3833.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "doing the cognizing. You're you're using",
      "offset": 3835.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the language model a bit like Photoshop.",
      "offset": 3837.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "That's exactly right. That's what I was",
      "offset": 3840.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "suggesting earlier. The magic comes from",
      "offset": 3841.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the user at the end of the day. like",
      "offset": 3843.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it's the user that that that both",
      "offset": 3846,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "generates this iterative loop that",
      "offset": 3848.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you're talking about that that makes the",
      "offset": 3850.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "system so useful and also you know the",
      "offset": 3852,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "semantic grounding comes from the agent.",
      "offset": 3855.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "I'm I'm the one who tells the system at",
      "offset": 3857.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the end of the day like this was a",
      "offset": 3859.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "meaningless like you know uh monkeys on",
      "offset": 3860.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "their typewriters kind of thing or",
      "offset": 3863.76,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "actually this was a very deep and",
      "offset": 3865.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "insightful thing that was just produced",
      "offset": 3866.799,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "like all of the meaning comes from us",
      "offset": 3868.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "and you know we we draw that meaning",
      "offset": 3871.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "from our specific situation that we're",
      "offset": 3873.28,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "embedded in because we have an",
      "offset": 3875.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "understanding of context right and of",
      "offset": 3876.799,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "the world that we inhabit and for for an",
      "offset": 3879.28,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "AI system to to you know be safe to",
      "offset": 3882.88,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "deploy Even it it needs to have",
      "offset": 3886.16,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "something like this situated embedded",
      "offset": 3889.039,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "understanding of itself and other agents",
      "offset": 3892.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "within a given context. Yeah,",
      "offset": 3895.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "absolutely. And it's not to say that we",
      "offset": 3897.039,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "aren't a bit like, you know, there's the",
      "offset": 3898.72,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "drunken walk analogy where you do",
      "offset": 3900.16,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "something a thousand times and one of",
      "offset": 3901.839,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the guys will actually solve the maze or",
      "offset": 3903.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "whatever you you use the the monkeys on",
      "offset": 3905.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "the keyboard, but you know, it's a",
      "offset": 3907.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "similar type of thing. But um I guess",
      "offset": 3908.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "where we're getting to here though is",
      "offset": 3910.799,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "that it's it's not just what we said",
      "offset": 3912.319,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "before. It's also things like efficiency",
      "offset": 3914,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "and continual learning. I mean, yes, you",
      "offset": 3916,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "can do continual learning with neural",
      "offset": 3917.52,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "networks. It just becomes quite",
      "offset": 3919.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "intractable to do. So, but the other",
      "offset": 3920.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "fundamental thing, well, it also",
      "offset": 3922.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "degenerates into noise, right? Like I I",
      "offset": 3923.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "I always find it very interesting that,",
      "offset": 3925.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you know, these these experiments where",
      "offset": 3927.359,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "they hook LLMs up into themselves and",
      "offset": 3928.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "then feed. So what what happens is it",
      "offset": 3931.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "just degenerates into just you know",
      "offset": 3933.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "noise which isn't surprising if you",
      "offset": 3936.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "understand what's going on under the",
      "offset": 3938.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "hood and and everything like uh but yeah",
      "offset": 3939.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "basically like if if there wasn't a",
      "offset": 3942.799,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "human in the loop to add structure and",
      "offset": 3944.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "input semantics it degenerates into",
      "offset": 3947.68,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "meaningless noise right so not that not",
      "offset": 3950.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that noise is unimportant right we we",
      "offset": 3952.799,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you know image generation works because",
      "offset": 3954.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "of diffusion and this kind of stuff like",
      "offset": 3957.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it's it's necessary it's a necessary",
      "offset": 3959.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "part of this knowledge generation thing.",
      "offset": 3961.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "But if you just do that, then it it",
      "offset": 3963.839,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "degenerates into nothingness. Oh yeah.",
      "offset": 3966.079,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Um so so I want to add a So actually I",
      "offset": 3968.559,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "have really good interactions with LLMs.",
      "offset": 3972.079,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "I think that they they help me think",
      "offset": 3974.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "through stuff, right? Um whatever it may",
      "offset": 3976.4,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "be. It might be a um something I'm",
      "offset": 3979.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "writing up a slide deck. It it",
      "offset": 3982.16,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "introduces me to new structures of",
      "offset": 3983.92,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "information that I am not aware of,",
      "offset": 3986.559,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "right? Um, but it's still at the end of",
      "offset": 3988.799,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the day, it's me taking the structure",
      "offset": 3991.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "and then doing something useful with it,",
      "offset": 3993.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "right? I I I often find that like I can",
      "offset": 3995.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "have it spit out a document and then",
      "offset": 3998.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "I've got to replace the content of the",
      "offset": 4000.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "document, but I I keep the structure of",
      "offset": 4002.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "what it gave me, right? And so I think",
      "offset": 4005.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it's very interesting",
      "offset": 4007.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "um in discovering these new types of",
      "offset": 4009.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "structures that maybe your system's",
      "offset": 4011.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "unaware of and just sort of kind of put",
      "offset": 4012.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "that in the context of a physical",
      "offset": 4015.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "system. Um, you know, let's say we build",
      "offset": 4017.039,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "systems that want to explore and then",
      "offset": 4020.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "exploit. Well, that exploration phase",
      "offset": 4022.64,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "needs to come from somewhere, right? And",
      "offset": 4025.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "it could be it could be driven by",
      "offset": 4028.079,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "language models, right? Like introducing",
      "offset": 4031.2,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "new ideas to the system just like we uh",
      "offset": 4033.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "we have new ideas introduced to us",
      "offset": 4036.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "through reading and other forms of",
      "offset": 4038.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "communication and media, right? So, oh",
      "offset": 4041.039,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "yeah, totally. I mean, to build on that,",
      "offset": 4043.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "we're not haters, right? like we we",
      "offset": 4045.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "don't think that these technologies are",
      "offset": 4047.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "like you know useless. Uh to the",
      "offset": 4048.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "contrary I mean they they can be greatly",
      "offset": 4051.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "empowering. Um but that's that's I think",
      "offset": 4053.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "the point like they they should be",
      "offset": 4056.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "considered as like tools that in the",
      "offset": 4058.16,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "best case enable cognitive enhancement.",
      "offset": 4060.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "They are absolutely inappropriate as",
      "offset": 4062.799,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "replacements for for humans, you know,",
      "offset": 4065.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "uh and in part because they're not",
      "offset": 4068.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "grounded in anything in anything that",
      "offset": 4070,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "like matters to us, right? They they",
      "offset": 4072,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "have no understanding of the norms that",
      "offset": 4075.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "govern specific situations and so on.",
      "offset": 4077.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "They they they don't even have an",
      "offset": 4080,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "explicit representation of the objects",
      "offset": 4081.359,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "and agents in a given situation, right?",
      "offset": 4084.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "So, you know, you wouldn't want this",
      "offset": 4086.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "kind of thing to act autonomously in the",
      "offset": 4088.559,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "world, right? They're inappropriate as",
      "offset": 4091.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the kind of foundation layer for",
      "offset": 4093.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "physical AI. Something else is required,",
      "offset": 4095.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "which is what, you know, we're busy",
      "offset": 4098.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "cooking at Numinal. Um, but",
      "offset": 4100,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "state-of-the-art systems are still very",
      "offset": 4102.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "useful if if you can allow a human in",
      "offset": 4104.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the loop. It's just, you know, they're",
      "offset": 4106.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "not going to be useful in in the context",
      "offset": 4108.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "where people hope to deploy physical AI",
      "offset": 4110.319,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "like edge devices, drones, and robotics,",
      "offset": 4112.48,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "right? Yeah. Some of my favorite",
      "offset": 4116.08,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "hallucinations from uh LLM systems are",
      "offset": 4118.08,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "the kind that sort of they kind of",
      "offset": 4122.319,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "confabulate this capability that they",
      "offset": 4124.799,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "don't really have, like this affordance",
      "offset": 4127.679,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that they have, but they really don't,",
      "offset": 4130.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "right? And so you can imagine what that",
      "offset": 4131.759,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "would manifest like in a physical",
      "offset": 4134.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "system. It's like so I'm thinking, you",
      "offset": 4136.48,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "know, reasoning using a reasoning model",
      "offset": 4140,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "and it comes up with, you know, I have a",
      "offset": 4142.88,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "I must have a a third leg that I can use",
      "offset": 4146.159,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "or maybe I have wheels but I don't.",
      "offset": 4148.719,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "Maybe I'm a bipedal robot, right? And",
      "offset": 4150.799,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "now I I dream of or kind of hallucinate",
      "offset": 4155.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "this capability that I don't have and",
      "offset": 4158.719,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "then I try to do something that ends up",
      "offset": 4160.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "being, you know, kind of catastrophic or",
      "offset": 4162.239,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "dangerous in a real world setting,",
      "offset": 4164,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "right? Yeah. So that's one of the one of",
      "offset": 4166,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the things we need to be cautious about,",
      "offset": 4168.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "I think, when tying language models",
      "offset": 4169.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "directly to the control systems of these",
      "offset": 4171.679,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "things. Uh as such as the cases like VAS",
      "offset": 4174.96,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "or vision language action models. Yeah,",
      "offset": 4178.56,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "I do find it genuinely fascinating how",
      "offset": 4180.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "they are simultaneously",
      "offset": 4183.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "incredibly useful and they give with one",
      "offset": 4185.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "hand and they take with the other hand",
      "offset": 4187.839,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "at the same time. Like if if I've got a",
      "offset": 4189.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "a medical problem, talking to 03 is",
      "offset": 4190.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "better than talking to your doctor. Yet",
      "offset": 4193.679,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "if you want to come up with an idea for",
      "offset": 4195.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "a YouTube video, the worst or actually",
      "offset": 4197.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "create anything, do do any writing, the",
      "offset": 4199.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "worst thing you can possibly do is talk",
      "offset": 4201.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to an LLM. You know, humans have this",
      "offset": 4203.52,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "this miraculous ability to come up with",
      "offset": 4206,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "ideas because ideas interesting ideas",
      "offset": 4208.239,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "are always on the long tail, right?",
      "offset": 4211.28,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "They're never in the head of the",
      "offset": 4212.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "distribution. So, um, but anyway, like",
      "offset": 4214.239,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "you you guys you're building this kind",
      "offset": 4216.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of compositional system where the models",
      "offset": 4218.8,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "and and the objects are first class,",
      "offset": 4221.52,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "right? So I if I understand correctly",
      "offset": 4224.239,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "you're you're designing a kind of system",
      "offset": 4226.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "which is going to be a little bit like",
      "offset": 4228.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the open AI but but instead of it being",
      "offset": 4230.4,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "a large language model it'll be a",
      "offset": 4233.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "marketplace of models and these models",
      "offset": 4235.679,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "because we were saying before the reason",
      "offset": 4238.56,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "why LLMs aren't autonomous right it's",
      "offset": 4239.92,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "interesting that people think they are",
      "offset": 4242.719,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "because we kind of discount the the",
      "offset": 4244.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "human supervision but that they're not",
      "offset": 4245.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "autonomous because they don't understand",
      "offset": 4248.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the world at an abstract level right so",
      "offset": 4249.52,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "you're almost going to build a",
      "offset": 4252.88,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "marketplace of models where in specific",
      "offset": 4254.239,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "situations these models can be trained",
      "offset": 4256.159,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "doing this active sense making using",
      "offset": 4259.199,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "something akin to active inference and",
      "offset": 4261.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "then they can be published and consumed",
      "offset": 4264.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "by other people. So you're almost",
      "offset": 4266,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "building the next cloud of models is is",
      "offset": 4267.84,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "that a fair representation? Yeah. So if",
      "offset": 4270.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "you read our um our white paper how to",
      "offset": 4273.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "build a brain that's precisely what",
      "offset": 4275.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "we're describing. I mean and you know",
      "offset": 4278,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the idea there is we should draw on um",
      "offset": 4279.6,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "the way that you know cognition actually",
      "offset": 4282.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "emerged in nature. So that the the way",
      "offset": 4285.44,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "the brain um evolved we think you know",
      "offset": 4288.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "again this comes back to the embodied",
      "offset": 4292,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "intelligence thesis right brains evolve",
      "offset": 4293.679,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "to mirror a specific kind of you know",
      "offset": 4296.159,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "situation or world. uh they do so by",
      "offset": 4299.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "basically you know labeling and",
      "offset": 4302.32,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "extracting objects from sensory data and",
      "offset": 4304.64,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "you know as uh brains became more",
      "offset": 4308.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "sophisticated the ability that's",
      "offset": 4311.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "unlocked is the combin the incremental",
      "offset": 4313.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "combination of these different modules",
      "offset": 4315.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "into like super systems. um the you know",
      "offset": 4318.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "so u you know human cognition is",
      "offset": 4322,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "multimodal and it's it it because it uh",
      "offset": 4323.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "arises from a combination you know an",
      "offset": 4327.199,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "integration of modality specific systems",
      "offset": 4329.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "uh and this is what enables us to you",
      "offset": 4333.28,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "know perform in such a general way. So",
      "offset": 4335.36,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "uh the idea is that you know artificial",
      "offset": 4338.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "intelligence should emerge from this",
      "offset": 4341.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "kind of network structure in much the",
      "offset": 4343.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "same way that the brain's capabilities",
      "offset": 4345.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "emerged historically uh through",
      "offset": 4347.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "evolution and through learning. Yeah. So",
      "offset": 4350,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the composition is very important I",
      "offset": 4352.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "think um it's not just composition and",
      "offset": 4354.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "so there's there is this idea of a sort",
      "offset": 4357.36,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "of repository for physical system",
      "offset": 4359.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "behaviors or skills. um I call them",
      "offset": 4362.719,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "behavior packs as sort of a a way of of",
      "offset": 4365.04,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "making it piffy. But um it's not just",
      "offset": 4368.48,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "about being able to query and find",
      "offset": 4371.679,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "those. It's about tying them together",
      "offset": 4373.199,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "meaningfully at the edge on the physical",
      "offset": 4375.04,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "system, right? And so this is where uh",
      "offset": 4377.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "active inference plays a key role,",
      "offset": 4380.32,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "right? As that sort of integrator",
      "offset": 4382.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "um maybe not necessarily at the top",
      "offset": 4386.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "level, but at a level that's meaningful",
      "offset": 4388.4,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "to the system. Um, and being able to uh",
      "offset": 4390.56,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "pull the right models or or determine",
      "offset": 4394.64,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "that it needs to pull a new model is",
      "offset": 4396.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "probably a better way to put it. Uh, and",
      "offset": 4399.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "when that's appropriate. Yeah. You know,",
      "offset": 4401.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "the nice thing about basian approaches",
      "offset": 4403.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "is that you're you're you're always",
      "offset": 4405.28,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "trying to quantify what you don't know,",
      "offset": 4407.199,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "right? So, by adopting a basian",
      "offset": 4410.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "architecture, you can develop a system",
      "offset": 4412.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "that goes, hey, actually, like I don't",
      "offset": 4414,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "really know what what this data pattern",
      "offset": 4415.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "is. Like I've never encountered this",
      "offset": 4418.239,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "before. So you know can I draw on you",
      "offset": 4420.159,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "know the the systems to which I'mworked",
      "offset": 4424.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "maybe you have a model for this kind of",
      "offset": 4426.8,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "data pattern and then we can make sense",
      "offset": 4428.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "of this dynamically and I mean that's",
      "offset": 4430.239,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "how the brain works right like the the",
      "offset": 4432.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the brain is a collective sense making",
      "offset": 4433.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "machine where like you know a pattern",
      "offset": 4436.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "gets shuffled around here and if it",
      "offset": 4438.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "doesn't get you know if it's not",
      "offset": 4440,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "mastered by you know the the brain",
      "offset": 4441.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "regions that are active more regions get",
      "offset": 4443.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "recruited and it it it is also like you",
      "offset": 4445.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "know it's sort of it's the idea is to",
      "offset": 4448.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "solve problems collectively in the same",
      "offset": 4450.64,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "way that you know neurons selforganize",
      "offset": 4453.04,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "to solve problems and dynamically I",
      "offset": 4456.08,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "would say too. So like if if I'm a",
      "offset": 4458.8,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "robotic arm and I'm you know used to",
      "offset": 4462,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "manipulating a certain type of object",
      "offset": 4465.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and now I have a new object that's",
      "offset": 4467.36,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "introduced in front of me. What do I do?",
      "offset": 4469.6,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "Right? I have no agency really to decide",
      "offset": 4473.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "to to try anything different or load a",
      "offset": 4476.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "new model to handle that different type",
      "offset": 4479.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of object. And so, you know, being able",
      "offset": 4481.04,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "to in that case say phone a friend or,",
      "offset": 4483.92,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "you know, dial up tank in the matrix,",
      "offset": 4487.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "right? Um, to download a new skill, I",
      "offset": 4490.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "think is going to be incredibly",
      "offset": 4492.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "important for the successful deployment",
      "offset": 4493.84,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "of physical AI into systems that, you",
      "offset": 4496.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "know, are doing real work, right, the",
      "offset": 4499.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "way that we want them to. So guys, I'm",
      "offset": 4501.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "going to ask a difficult question on the",
      "offset": 4503.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "value chain and the revenue model.",
      "offset": 4506,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Certainly, if if we look at OpenAI, they",
      "offset": 4507.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "first of all, they they scrape up all of",
      "offset": 4510.64,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "the data on the internet and that's very",
      "offset": 4512.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "valuable and they have to have millions",
      "offset": 4514.239,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "and millions of GPUs and they're very",
      "offset": 4517.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "expensive and and that's very valuable",
      "offset": 4519.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and and then there's this model that you",
      "offset": 4521.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "pay them based on consumption and they",
      "offset": 4523.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "they've got all the secret source.",
      "offset": 4525.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "You're describing a model where if",
      "offset": 4527.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "anything, the people using the models",
      "offset": 4529.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "are generating the value themselves",
      "offset": 4531.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "because they're actually using it.",
      "offset": 4533.679,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "They're installing it in their robots.",
      "offset": 4535.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "They're they're doing this active",
      "offset": 4537.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "inference and it's being trained on on",
      "offset": 4538.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "data. So I I guess the first question is",
      "offset": 4540.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "where do you guys make the money? But",
      "offset": 4543.199,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "isn't it a weird inversion that the",
      "offset": 4544.56,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "people using the models are kind of",
      "offset": 4546.239,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "generating the value into the system?",
      "offset": 4547.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "Well, it is. and and Jason you can talk",
      "offset": 4549.6,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "to how the value is generated uh in in a",
      "offset": 4552.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "second but I just want to draw attention",
      "offset": 4555.04,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "to the fact that what's actually",
      "offset": 4556.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "valuable is the data",
      "offset": 4557.84,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "so you know uh model weights are",
      "offset": 4560.32,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "valuable to an extent but it I mean if",
      "offset": 4563.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "if if we've learned anything from the",
      "offset": 4566.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "deepseek moment um from a business",
      "offset": 4568.4,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "perspective and if if there's anything",
      "offset": 4571.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "to draw from techniques like knowledge",
      "offset": 4573.199,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "distillation it's that like you know",
      "offset": 4575.199,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "being the proprietary owner of a a set",
      "offset": 4577.679,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "of weights is no longer an efficient",
      "offset": 4580.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "business mode for an AI company, right?",
      "offset": 4583.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Like if if I can just hook up into your",
      "offset": 4585.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "API and then you know train up my own",
      "offset": 4587.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "system and just it's it's not it's not",
      "offset": 4590.159,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "going to be viable, right? Um, and you",
      "offset": 4592.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "know, not this isn't to mention that",
      "offset": 4595.76,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "like you know, all of the data that they",
      "offset": 4597.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "scraped off the internet, like you know,",
      "offset": 4599.199,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "how many times does the copyright symbol",
      "offset": 4601.04,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "or the trademark symbol appear in in the",
      "offset": 4603.28,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "data set like you know they're exposing",
      "offset": 4606.159,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "themselves and they have like you know",
      "offset": 4608.719,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "these lawsuits are happening. They're",
      "offset": 4610.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "exposing themselves to unbelievable like",
      "offset": 4612.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "unbelievably like painful and expensive",
      "offset": 4615.04,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "lawsuits. So I think you know the",
      "offset": 4618.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "business model that they're pursuing it",
      "offset": 4620.719,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "doesn't work. it won't actually generate",
      "offset": 4622.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "revenue that they they are floating",
      "offset": 4624.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "right now because they've received",
      "offset": 4626.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "billions of dollars in in investment",
      "offset": 4628.32,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "from you know from from very wellendowed",
      "offset": 4631.6,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "uh you know funders",
      "offset": 4635.199,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "um but as a business model I don't think",
      "offset": 4638.159,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "it scales um and you know also we've",
      "offset": 4640.4,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "even if it did we've reached the limit",
      "offset": 4644,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "of that data source right like these",
      "offset": 4645.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "models are already trained on all of the",
      "offset": 4647.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "publicly accessible data on the internet",
      "offset": 4649.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "there's nowhere else to go from here.",
      "offset": 4652.64,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "Which I mean brings us back to the",
      "offset": 4654.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "silver and Sutton argument like where",
      "offset": 4657.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "where is where is the new data going to",
      "offset": 4658.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "come from? Well, it can only come from",
      "offset": 4660.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the systems themselves generating data",
      "offset": 4663.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "through this autonomous exploration and",
      "offset": 4665.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "palpation of the world. Um I realize I",
      "offset": 4667.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "haven't talked about like how this makes",
      "offset": 4670.56,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "money. Jason, do you want to segue? No,",
      "offset": 4672,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "no. So well we get into that in a minute",
      "offset": 4673.84,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "but I I you raised a really important",
      "offset": 4676.239,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "point Maxwell which is that you know LLM",
      "offset": 4678.239,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "companies has been successful largely",
      "offset": 4681.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "due to them being able to scrape the",
      "offset": 4684.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "whole of the internet right so you've",
      "offset": 4686.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "got this amazing rich canonical data",
      "offset": 4688.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "source of like human knowledge that",
      "offset": 4691.92,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "they're able to you know organize into a",
      "offset": 4693.6,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "really curated and high quality data set",
      "offset": 4697.199,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "for training and that type of data set",
      "offset": 4699.679,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "does not exist for the physical world",
      "offset": 4702.08,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "and I would argue would be impossible to",
      "offset": 4704.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "collect in any meaningful way, right?",
      "offset": 4707.199,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "And so it's got to be put together,",
      "offset": 4709.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "pieced together",
      "offset": 4712.56,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "um I think you know composed together,",
      "offset": 4714.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "right? Getting back to compositionality",
      "offset": 4717.199,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "um by people a community that want to",
      "offset": 4719.679,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "ultimately benefit from um the",
      "offset": 4724.159,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "ecosystem, right? And so I think that's",
      "offset": 4726.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "a that's an important thing to think",
      "offset": 4730.239,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "about here. There's a",
      "offset": 4731.679,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "um Nvidia is actually really really good",
      "offset": 4734.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "about sort of promoting this this new",
      "offset": 4736.8,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "emerging physical AI community. Um and",
      "offset": 4739.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "in fact, sorry, just a little bit of a",
      "offset": 4743.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "tangent. Um Jim Fan, who's the one of",
      "offset": 4744.8,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "the leads researchers over there, um he",
      "offset": 4748.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "he has this new concept called the",
      "offset": 4751.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "physical touring test that he's shared",
      "offset": 4753.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "uh in the last few weeks here where it's",
      "offset": 4755.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "a it's a missy like scene. And it's like",
      "offset": 4758.159,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "a living room and it's just got trash",
      "offset": 4761.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and pizza boxes and beer bottles and",
      "offset": 4763.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "everything. All this, you know, there",
      "offset": 4765.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "was a party the night before, right? And",
      "offset": 4766.96,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "and what I want to happen is that it",
      "offset": 4770.56,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "gets cleaned up and a new um like candle",
      "offset": 4773.679,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "light dinner is set up for my my partner",
      "offset": 4777.6,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "and I uh for the following evening and I",
      "offset": 4781.04,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "cannot tell if it was done by a human or",
      "offset": 4783.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "a robot. And so, so that's sort of like",
      "offset": 4786.159,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "the physical terrain test um as he as he",
      "offset": 4788.8,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "puts it. And I think it's a brilliant",
      "offset": 4791.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "kind of challenge out into the community",
      "offset": 4794.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "of what ultimately the goal is uh for",
      "offset": 4796.56,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "practitioners in the space. And so",
      "offset": 4799.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "circling back to kind of the the",
      "offset": 4803.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "community effort that's required I think",
      "offset": 4805.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to solve that problem and pass that",
      "offset": 4807.52,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "physical terrain test. It's going to",
      "offset": 4809.84,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "take um it's going to take people",
      "offset": 4811.199,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "enabling that data collection out at the",
      "offset": 4815.36,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "edge on robots and then compiling it",
      "offset": 4818.08,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "back into a centralized source",
      "offset": 4821.6,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "that the whole then the whole community",
      "offset": 4824.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "uh can take advantage of. Yeah. And and",
      "offset": 4827.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "it it allows people to monetize their",
      "offset": 4829.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "own data sets and their own models in in",
      "offset": 4831.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "a way that benefits everyone as well.",
      "offset": 4833.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Yeah. And if there's a proprietary,",
      "offset": 4836.08,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "you know, set of interactions or",
      "offset": 4838.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "behaviors that I want to keep closed, I",
      "offset": 4840.239,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "can I have that option. Um,",
      "offset": 4842.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you know, there's ways of monetizing",
      "offset": 4845.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that for us, right, that we don't need",
      "offset": 4847.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to get too deep into, but you know, it's",
      "offset": 4849.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "kind of enterprise versus, you know, uh,",
      "offset": 4851.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "run-of-the-mill street dev community",
      "offset": 4854.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "type engagement, right? Yeah. Yeah. So,",
      "offset": 4857.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "first of all, you you make an important",
      "offset": 4859.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "point, Jason. Certainly, if you look at",
      "offset": 4861.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the enterprise LLM companies, they are",
      "offset": 4863.28,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "mostly direct to consumer. Most",
      "offset": 4866.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "corporations do not want to use them.",
      "offset": 4869.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "And that's why certainly cohhere is an",
      "offset": 4871.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "example. They've completely shifted",
      "offset": 4872.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "their model. They only do enterprise and",
      "offset": 4874.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "they only do private deployments because",
      "offset": 4876.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "every single enterprise, the number one",
      "offset": 4878.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "thing they say is, I want to put a",
      "offset": 4880.159,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "boundary around this thing. I I'm not",
      "offset": 4882,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "I'm not sending my data to you. Right?",
      "offset": 4883.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "That's that's very very important. But I",
      "offset": 4885.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "want to push back a little bit on what",
      "offset": 4887.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you were saying about it's it's you know",
      "offset": 4888.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "like open AI is only training on all the",
      "offset": 4891.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "data on the internet. Look at Google for",
      "offset": 4893.679,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "example. People think that it's powerful",
      "offset": 4896,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "because of page rank. That's not really",
      "offset": 4898.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the case at all. Um all of these sort of",
      "offset": 4900.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "statistical knowledge is learned through",
      "offset": 4903.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "interaction with the users. Right? So",
      "offset": 4904.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you get all of these tail queries and",
      "offset": 4907.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "users put a query in and then they click",
      "offset": 4909.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "on a result and then you know Google is",
      "offset": 4911.679,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "learning the relevance of that from the",
      "offset": 4913.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "users. And it's exactly the same with",
      "offset": 4915.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "LLM companies. We're seeing this it's",
      "offset": 4917.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "quite a surreptitious sneaky transition",
      "offset": 4919.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "that people aren't completely aware of.",
      "offset": 4921.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "But now certainly a lot of the um the",
      "offset": 4923.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "information that OpenAI learns is",
      "offset": 4926.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "through people interacting with it.",
      "offset": 4927.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "That's how they build their engagement",
      "offset": 4929.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "models and increasingly it's being wired",
      "offset": 4931.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "up to tools and you're installing on",
      "offset": 4933.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "your phone. Um but I think the important",
      "offset": 4935.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "point though is that there's something",
      "offset": 4937.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "very magical about interactive data. So",
      "offset": 4939.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "certainly Tesla, they've got lots of",
      "offset": 4942.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "physical AI data and Google has street",
      "offset": 4944.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "map data and whatnot, but when you have",
      "offset": 4946.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "a human in the loop, you're actually",
      "offset": 4948.4,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "learning something. Even if it's one",
      "offset": 4950,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "step removed, you're learning something",
      "offset": 4951.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "about how the real world works and then",
      "offset": 4953.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you're kind of putting that in the chain",
      "offset": 4955.679,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "of how you train your model. Would you",
      "offset": 4957.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "agree with that? I would say I I would",
      "offset": 4958.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "say yes. Uh but what what that tells you",
      "offset": 4960.88,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "is that they're aware of the limitations",
      "offset": 4962.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "of their original business model. Right?",
      "offset": 4964.719,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "So uh why why is this kind of",
      "offset": 4967.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "interaction interesting from a business",
      "offset": 4969.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "perspective? Well, first of all, it's",
      "offset": 4971.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "new data that you're generating when the",
      "offset": 4973.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the the problem is that you've ran out",
      "offset": 4976.32,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "of data to train. So your users are",
      "offset": 4978,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "generating new data. That's great. And",
      "offset": 4980.239,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "it's data that's grounded in the",
      "offset": 4982.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "situation, preferences, and competence",
      "offset": 4984.8,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "of a user. But I think people don't",
      "offset": 4987.52,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "realize that they're the product in in",
      "offset": 4990.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that kind of setting, right? So I mean",
      "offset": 4993.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "these business models are going to float",
      "offset": 4995.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "for so long as people are uh you know",
      "offset": 4996.96,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "unaware of the the exploitation or are",
      "offset": 4999.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "willing to go along with it because they",
      "offset": 5002.239,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "get some kind of gain out of it",
      "offset": 5003.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "presumably like you know you learn you",
      "offset": 5005.12,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "get a lot from using you know Google's",
      "offset": 5008,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "uh services so you get something out of",
      "offset": 5010.639,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "it. Um, but I think when especially when",
      "offset": 5013.36,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "enterprise and individuals realize that",
      "offset": 5016.32,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "like really where the value is is the",
      "offset": 5019.199,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "data and that you know and that they're",
      "offset": 5021.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "just giving it away to these companies",
      "offset": 5024.4,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "who are then making an enormous profit",
      "offset": 5026.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "by kind of consolidating and codifying",
      "offset": 5028.239,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "that data like I think once consumers um",
      "offset": 5030.32,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "and customers become more aware of that",
      "offset": 5034,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you'll see less of it and you'll see a",
      "offset": 5036.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "pivot towards people trying to like you",
      "offset": 5038.8,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "know opt into systems that allow them to",
      "offset": 5040.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "monetize and commercialize their data",
      "offset": 5043.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "and the models that were fitted on their",
      "offset": 5045.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "data. I mean the I think it's a what",
      "offset": 5048.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "you're seeing is basically like",
      "offset": 5050.8,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "ignorance driven you know um",
      "offset": 5052.159,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "yeah because this is some this kind of",
      "offset": 5056.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "data is something that these companies",
      "offset": 5059.04,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "will one day want to pay for I would",
      "offset": 5060.56,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "imagine um because you're going to run",
      "offset": 5062.719,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "out of it like yeah well so so the data",
      "offset": 5065.199,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "is very important I think um you know in",
      "offset": 5068.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "some way we're providing a a method for",
      "offset": 5071.199,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "collecting the data but there's another",
      "offset": 5074,
      "duration": 9.36
    },
    {
      "lang": "en",
      "text": "um couple stages from modeling to actual",
      "offset": 5077.84,
      "duration": 8.16
    },
    {
      "lang": "en",
      "text": "like real use in a physical system,",
      "offset": 5083.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "right? And you know, if I'm using",
      "offset": 5086,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "simulation to train, it's referred to as",
      "offset": 5088.159,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "the sim to real gap. It's like, okay, my",
      "offset": 5090,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "model behaves great in simulation, but",
      "offset": 5093.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "when I put it on a robot, it goes",
      "offset": 5094.8,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "haywire, right? um because feedback uh",
      "offset": 5096.56,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "motor noise, sensor noise, you know,",
      "offset": 5100.719,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "things that the real world brings to the",
      "offset": 5103.36,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "table. Um and so that is another part of",
      "offset": 5105.76,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "the value chain that we're addressing in",
      "offset": 5110.4,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "physical AI. So think of what we're",
      "offset": 5113.12,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "building as not just sort of the a cloud",
      "offset": 5115.679,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "kind of repository, but it's ultimately",
      "offset": 5118.719,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "kind of the do a Docker ecosystem with",
      "offset": 5121.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "all the tools to then go from modeling",
      "offset": 5124.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "to deployment in a very seamless",
      "offset": 5127.12,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "fashion, right? with gates along the way",
      "offset": 5129.92,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "for um QA testing your model right in",
      "offset": 5133.36,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "simulation",
      "offset": 5137.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "testing it you know we we haven't talked",
      "offset": 5139.44,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "about this a great deal but I think",
      "offset": 5141.84,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "there's an opportunity to provide a sort",
      "offset": 5144.239,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "of a a physical unit test if you will",
      "offset": 5146.639,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "for my models by having having a",
      "offset": 5149.84,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "menagerie of robots available to provide",
      "offset": 5152.8,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "that service to end users to customers",
      "offset": 5155.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "and so they get to test what the model",
      "offset": 5158.4,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "will do on hardware before they put it",
      "offset": 5161.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "on their own production hardware, right?",
      "offset": 5164.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "So, I think there's an opportunity for a",
      "offset": 5166.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "service like that um that we're we're",
      "offset": 5169.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "looking into, we're pursuing. Um but",
      "offset": 5171.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "ultimately like that that deployment",
      "offset": 5173.52,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "path is is really really a tricky",
      "offset": 5176.48,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "technical challenge today. Um and it for",
      "offset": 5179.84,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "a variety of reasons obviously the model",
      "offset": 5183.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "behavior reason being one of the biggest",
      "offset": 5185.199,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "ones but um you know there's a lot of uh",
      "offset": 5186.88,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "of fragmentation in um in deploying the",
      "offset": 5189.76,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "models um you know I think I thought",
      "offset": 5194,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "every robot used uh robotic operating",
      "offset": 5197.36,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "system but it turns out only about half",
      "offset": 5200.4,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "of them do right and so um that was a",
      "offset": 5202.719,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "misconception that I had and and so now",
      "offset": 5206.719,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "you've got to then deal with uh",
      "offset": 5209.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "companies, you know, practitioners",
      "offset": 5211.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "deploying in their own sort of native",
      "offset": 5213.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "frameworks and ecosystems and address",
      "offset": 5215.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "that as well, right? Yeah. So, yeah, I",
      "offset": 5218.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "mean, I guess this is the secret source",
      "offset": 5220.88,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "of what you guys are building, right?",
      "offset": 5222.4,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "Because there are many forms of",
      "offset": 5223.679,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "brittleleness in all the things that we",
      "offset": 5225.04,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "just discussed. Certainly, people have",
      "offset": 5226.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "different types of of robots in in",
      "offset": 5228.32,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "slightly different situations, but",
      "offset": 5230.4,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "you're you're describing something which",
      "offset": 5232.239,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "is a cross between like AWS, Docker, um",
      "offset": 5233.679,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "Kaggle, and maybe GitHub. and or hugging",
      "offset": 5237.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "face maybe hug yeah hugging face is",
      "offset": 5241.199,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "better than GitHub yeah I think that's a",
      "offset": 5242.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "good way to think about it and um yeah",
      "offset": 5244.239,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you mentioned docker now docker for",
      "offset": 5246.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "folks who don't know it was a revolution",
      "offset": 5248.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "in cloud technology because you know",
      "offset": 5250,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "cloud did this thing called platform as",
      "offset": 5252,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "a service and that was great but it was",
      "offset": 5253.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "actually a clever form of lock in you",
      "offset": 5255.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "know so you would be locked into using",
      "offset": 5257.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Azure instead of AWS so you know this",
      "offset": 5259.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "this um this this docker thing and then",
      "offset": 5261.84,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "we had kubernetes and and essentially it",
      "offset": 5264,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the key the the key thing about docker",
      "offset": 5266.239,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "is it's about immutability so you could",
      "offset": 5267.76,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "kind",
      "offset": 5269.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "represents um a portable snapshot of an",
      "offset": 5270.639,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "application running on a on an operating",
      "offset": 5273.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "system and and you know you can install",
      "offset": 5276.239,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "this thing anywhere and it's exactly the",
      "offset": 5278.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "same version of Linux. It's exactly the",
      "offset": 5281.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "same version of the application. So you",
      "offset": 5283.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "get this reproducibility. It's testable",
      "offset": 5284.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and whatnot. But what you what you guys",
      "offset": 5287.199,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "are doing is a little bit different to",
      "offset": 5289.52,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "that though, isn't it? Because you're",
      "offset": 5290.639,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "building something which is doing active",
      "offset": 5291.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "inference. It's it's doing continual",
      "offset": 5294.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "learning. It's changing all over the",
      "offset": 5296.08,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "time, you know, it's changing all the",
      "offset": 5297.36,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "time. So I don't know how you would",
      "offset": 5298.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "design that. Would you have kind of like",
      "offset": 5300.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "a snapshot of the model at a particular",
      "offset": 5301.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "point in time and then maybe you would",
      "offset": 5304.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "do some additional kind of active",
      "offset": 5306.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "inference and then a month later you",
      "offset": 5308.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "would have another snapshot. How would",
      "offset": 5309.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you get the benefit of adaptability and",
      "offset": 5311.36,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "reproducibility at the same time? Yeah.",
      "offset": 5314.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "So I think the um so you're right Docker",
      "offset": 5316.239,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "provided a really nice it almost solved",
      "offset": 5318.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "the like what runs on my computer",
      "offset": 5320.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "problem. Yeah. Um right in deployment.",
      "offset": 5322.88,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "Um but even then you know um once you",
      "offset": 5325.84,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "deploy a docker container you attach it",
      "offset": 5329.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to a storage system then",
      "offset": 5331.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "it becomes its own sort of instance of",
      "offset": 5334.159,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "that container right um and and it",
      "offset": 5336.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "changes over time in different ways than",
      "offset": 5338.8,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "other instances and so I think the the",
      "offset": 5340.639,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "analogy there is that that that's going",
      "offset": 5344.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to happen in any physical system is that",
      "offset": 5346.159,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "there's going to be nuances to both the",
      "offset": 5348.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "physical system itself and the",
      "offset": 5353.12,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "environment. that it's interacting with",
      "offset": 5354.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that that the active inference is going",
      "offset": 5356.639,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "to help pick up on, right? And so in one",
      "offset": 5358.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "way it's going to be just sort of unique",
      "offset": 5362.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "to that instance of a system but then",
      "offset": 5364.159,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "you know there are ways of saving off",
      "offset": 5367.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "what's learned back to a centralized",
      "offset": 5369.84,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "data source and then incorporating that",
      "offset": 5372.32,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "into let's say you know uh Rubik's cube",
      "offset": 5375.04,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "you know robotic docker container v2",
      "offset": 5379.679,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "right so can I feed and now I have this",
      "offset": 5382.719,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "feedback loop of learning that's not",
      "offset": 5385.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "just at the local level but it's sort",
      "offset": 5386.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "sort of at a metal level in the whole",
      "offset": 5390.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "ecosystem. Beautiful. Well, um guys, I",
      "offset": 5391.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "think I think we've come to time. So,",
      "offset": 5394.159,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "it's been an absolute honor having you",
      "offset": 5396.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "both on the show. I I really appreciate",
      "offset": 5397.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "you coming on. Always a pleasure, Tim.",
      "offset": 5399.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Yeah, Tim, thank you so much. Uh it is",
      "offset": 5401.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "quite the honor and uh so so thank you",
      "offset": 5403.84,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "for all the content that you generate.",
      "offset": 5406.4,
      "duration": 4.44
    }
  ],
  "cleanText": "Why did you guys decide to create a physical AI company? And what's wrong with large language models? People are saying that all you need to do is hook large language models up to the real world. And we've got physical AI. So, so what's the deal? Effectively, the body matters a great deal to cognition. And more than just the body, the physical environment, the actual world that we inhabit is bundled up together with what it means to be a mind, to be a thinking thing, to exist and to live and to thrive in an environment. The lack of embodiment is really what is sort of tripping up adoption in physical AI today. We have all these solutions for like training models and simulation. We think we can connect something like an LLM to them to drive behavior. But the fact is that those systems were not trained with inbodied contact with the real world.\n\nTo state it a bit provocatively in some sense, you might say that state-of-the-art AI is stuck in data space as it were. Basically, these systems all operate within a data space. What you don't have at least explicitly in these models is like a representation of the world or the situation that is generating that data. Plato says like it's not even the sun that's creating these shadows, right? It's a flame that's casting these shadows on a wall. So, we're only interacting with shadows. We're not interacting with the real stuff. Even with coding, for example, some people say, the reason the code isn't very good is because it's not running the code. It's not testing the code. If only we had tools. If only we could get results back, then we get this feedback loop. What is the sort of the bright difference between what you're proposing and something like that? I would say like being grounded in the world in some sense. So like no matter how you train these state-of-the-art feed forward gradient descentbased architectures, at the end of the day, they are only tethered to reality through us and our expressions of preferences.\n\nThis episode of MLST is sponsored by Tufa AI Labs. It is a research lab which is headquartered in Zurich. They're moving to SF as well. These guys are number one of the ARCv2 leaderboard. They're genuinely fascinated in building the next generation of technology, the next innovation which will take large language models to the next stage. If that sounds like you, please get in touch with Benjamin Kruier. Go to https://tufalabs.ai/.\n\nWe have another episode of machine learning street talk and joining me today are two very very special people. We have Dr. Maxwell Ramstead who is without doubt one of the technical heavyweights of the active inference community. I think Maxwell it's not an exaggeration to say that other than Friston himself you've probably published more papers on active inference than anyone else. Is that fair? That's kind of you to say. Anyway, fans of the show will know Maxwell very well. Of course we've had him on a couple of times before and it's great to have you here Maxwell and and we also have Jason Fox. Now, as a bit of a background for the audience here, you guys have created a company called Noumenal and Jason, you're the CTO of Noumenal. Can you introduce yourself to the audience? Yeah, thanks Tim. Uh yeah, so I come at this from a much more traditional computer science background and just a you know down in the weeds engineer. I've been building tech for going on 25 years across many different domains, technical and industrial, video game engines, mixed reality. I worked in defense and robotics for a number of years kind of mid-career and as you know I spent about eight years at Microsoft doing a lot of sort of really tip of the spear sort of like R&D type work with partners and that really led to a lot of applied ML just you know specifically around computer vision and you know there's often the case where we're having to take something like the hollow lens and apply computer vision to the many different camera systems on board that and do something useful with it, right? Or you know try to and the use cases are very interesting, you know, like automakers like Toyota would find use for like service and manufacturing. And what that really led to was this for me personally this kind of love affair with I guess digitizing an understanding of the real world, the physical world. And so, I've spent a lot of my time focusing on technologies at that intersection. And so, um, yeah, and then I've I've known Maxwell and Jeff now for a number of years. Maxwell and I together created, I think, the industry's first active inference lab a few years ago. We're excited to be recreating that again here at Noumenal and solving some real real real fundamental challenges in physical AI. And just to contextualize this, you guys were at Versus before and of course we did some great content with with Versus and this might be interesting to the audience. Jason and I were actually at Microsoft together at the same time. So we were in we're in this group and and I was a principal software engineer at Microsoft and and we actually worked together I think on some on some similar projects. This isn't about 2017 kind of time, but but it's just one of those massive coincidences that that that we're that we're here together, but anyway, this raises so many questions that I think we'll foreshadow now and we'll get to later. You know, the obvious one being why did you guys decide to create a physical AI company and what's wrong with large language models? People are saying that all you need to do is hook large language models up to the real world and we've got physical AI. So, so what's the deal? But I think in order to get there, we need to go on a bit of an intellectual journey. So we'll just leave those questions hanging for now.\n\nNow, Maxwell, when I discovered Carl Fristen, it was an intellectual awakening for me. The the amazing thing about this podcast is is we just through curiosity more than anything else. We get to speak with some of the most brilliant people in the world. And for some reason, they say yes when we invite them. So, it's a win-win situation, more so for me than than for for them, perhaps. But you know, Professor Friston is is an absolutely incredible character and I want to get to this kind of embodiment and externalism thing because that was what really opened up my mind. We used to think about AI as being something which happens entirely inside the brain almost like we could just write a computer algorithm and it would capture all of the machinations of cognizing of being an intelligent being. Can you introduce this whole idea to us? So I think the the ultimate idea behind all this kind of physical AI embodied cognition is that effectively the body matters a great deal to cognition and more than just the body the physical environment the actual world that we inhabit is I mean bundled up together with what it means to be a mind to be a thinking thing to exist and to live and to thrive in an environment. Um, so you know, you you might you might think of the embodied intelligence thesis spelled broadly as I mean effectively this idea that the mind in some sense encodes or reflects or is constrained by or depends on the specific material embodiment of the system and the the very specific layout the situation that the that the system is trying to adapt too. So, um you know, you were referring to externalism versus internalism. I mean, this is a long-standing debate in cognitive science and in philosophy. Basically, what what counts as cognition? Is cognition just something that happens in the head that involves the brain or is it something that is world involving? And I think basically since the late 80s and early 90s what we have seen in cognitive science certainly in neuroscience and philosophy and related areas is an increasing recognition of the importance of external factors. Well factors that were once considered external to cognition that are actually constitutive of it. Right? So having a body is not you know just you know an accident or optional to cognitive systems. All things that we consider intelligent do so through their embodied behavior in a world right. Um, so I mean this is relevant to AI and industry more generally because you know the frontier right now is applying AI systems in the real world right and there's reason to believe that you know if we want to do this appropriately and safely and at scale we should draw on you know the the way that cognition works in the real world the way that natural intelligence works in the in the world that we live in right and So, you know, studying embodiment and what it brings to the table is going to be crucial. Um, and I think one of the things that is really important and follows from this embodied mind thesis is that what's required to act appropriately in a world is to have a world model. Right? So, a mind is a model of a specific world, right? And of a specific body that acts in that world. And I think those are the big elements at least the conceptually that that allow us to frame this discussion. Um and you know maybe Jason can talk a little bit about the the implications of this for like the the field of physical AI which is you know robotics, drones and all of these systems that act in the real world.\n\nYeah. I think the key takeaway from from that description, Maxwell, is that and your question earlier, Tim, around LLMs is that the lack of embodiment is really what is is sort of tripping up adoption in physical AI today, right? It's um you know, we have all these solutions for like training models and simulation. We think we can connect something like an LLM to them to drive behavior. Uh but the fact is that those systems were not trained with inbodied contact with the real world. Um they have no concept of the physics, the interactions that are required to understand, you know, how to manipulate things. Um and how to carve out space, understand space, move about space. Um that's that's one of the fundamental missing pieces, right? And so I think the last conversation I think you had with Jeff, he got really deep into sort of like how language is a really poor representation of the world, right? The the actual world and the way that we're experiencing it. Um and I think we we Maxwell and I wholeheartedly agree with that statement, right? It's uh it's not a simple matter of connecting something that works wholly in a digital kind of vat online or on my computer to just something like a robotic system and expecting it to work. Um so I do think that embodiment is a is a fundamental key aspect to this. I mean to state it a bit provocatively in some sense you might say that state-of-the-art AI is um stuck in data space as it were. Um so you know state-of-the-art AI works by you know modeling this you know these vast amounts of like multi-dimensional multimodal data and I mean effectively extracting correlational information from those data sets and um yeah I mean what so you know consider next token prediction for like language generation or pattern completion in image generating systems.\nWhat basically these systems all operate within a data space, right? They they they you feed data into them and what they what they generate effectively is is is data. Um what you what you don't have in or what you don't have at least explicitly in these models is like a representation of the world or the situation that is generating that data. So, I mean, in some sense, you might say that state-of-the-art AI is stuck in Plato's cave. Um, so I mean, just for I'm sure most of, you know, the the viewers of MLST are familiar with, uh, Plato's, uh, Plato's cave, the allegory, please introduce it. So, I mean, uh, Plato, uh, Plato was a, um, was a, I mean, appropriately enough, we call his position Platonism. Basically Plato believed that what was really real were these like universal and variant forms. So like you know the form of triangle the the the form of you know the a human like the the these essences effectively and these were like um you know transtemporal. They existed outside of space and time. They didn't have a beginning, a middle and an end. Um and then the the things that we encountered in in the world of experience were in some sense um you know just mere images or copies of the actual transcendent forms that Plato thought really existed. So um Plato's cave is this allegory where um he says imagine some prisoners chained to the the side of a cave and all they can see ever is the shadows that are projected by things you know as they walk by like a flame right so and and so you see like this indirectness Plato says like it's not even the sun that's creating these shadows right it's a flame that's that's casting these shadows on a wall so what Plato says is like this is our epistemic situation most of the time, right? We're kind of we're we're only interacting with shadows. We're not interacting with the real stuff. Um so I mean I I don't I don't I'm not a platonist myself. I'm I'm borrowing that metaphor to say well basically the what what the LLMs and the image generators are doing is very similar to what you know the the slaves that Plato was describing are doing in in in that we we don't that these systems are not really interacting with the process that's generating the data. So they're at one remove from you know the the actual world in some sense. Um so and I mean that gets even more problematic when you bring language into the mix, right? Because what is language? Well, language is a a representation of a representation. It's a it's a compression of a compression, right? So I have a perceptual experience. I generate these you know a a a model to basically explain you know what what is going on here. I have an understanding of the data if you want to put it that way. And then language is a way to represent my understanding and communicate it to you. So we're we're at we're we're now at at least two degrees removed from the world that's actually generating experience. I mean there there are conceptual and technical reasons why we wouldn't want robots acting in the world to be stuck in Plato's cave. Um I mean obviously we would want you know systems acting in the world to have some kind of direct access to the world that they're interacting with as opposed to this indirect kind of access.\n\n\nWe've exhausted all of the static data sets that have existed that exist currently, right? Like there is no more data that's publicly available to train these systems. So where to go from now? Well, the only other place to go is to let these systems generate the data that they want to model as they explore the world, right? So, um, so you know, but this pivot to agent-generated data has, you know, as a consequence, that, you know, if these systems are going to be generating data themselves, then they need to be embodied in a specific way, right? That they need to be situated in a specific environment and then apt to generate the kinds of data uh that we find interesting and that we can continue to use to train these models. So, so I think all of these things are like crucially interconnected. Like there are technical limitations that are pushing us to this uh to this kind of embodied turn in AI. Um, on the one hand, uh, but there are also conceptual reasons to think that this is the only the only way to do it, right? Can I add a comment here? Of course. So I think that um, I think so you mentioned language is a compression, and I wholeheartedly agree. I think it's the wrong kind of compression for physics, the physical world, right? So I think that while we might walk around and and sort of perceive and understand the physical world in sort of a compression-based way, like otherwise I don't think we would work, we wouldn't function, right? We wouldn't be able to take in and process everything. Um, I think it's a different form of compression, right? And so then we we find ways of relating whatever that representation is inside of our minds to other people in a communal aspect so that we can collaborate, coexist, you know, as a society. Um, which is what language is developed from, right? So that's that's one thought I had. Maxwell, I know you you probably have a much more in-depth commentary on it, but so I think I think the the embodiment thing is important because um, I mean, you might say like, you might say that mind is intrinsically related to, you know, adaptive intelligent behavior in a situation, right? So I mean, it's it's it's not just that embodiment adds something to intelligence, it's that it's embodiment is in some sense the vehicle, you know, through which we see intelligence as manifest in the world around us. Um, you know, and chat bots do have an embodiment. It's a weird kind of co-embodiment that we share with them in some sense, right? Like um, you might argue that like where where the where the grounding of the system comes from is embodiment, right? Like ultimately all of these symbols have to, like, if if if if the symbols that are being shuffled around by an AI system or presumably, you know, the the computations that are realized by my brain, if they mean anything, it's by virtue of being embedded and you know, embodied within specific systems. That's where the the meaning of all these tokens or or symbols or or whatever come from at the end of the day. It it's it's not just that like embodiment is like a side thing. It's constitutive of what it means to cognize. Um, I mean, like I was saying, you know, chat bots have a a weird kind of embodiment. I always kind of feel like um, we project like the we we project the powers of cognition onto chat bots for the most part, right? Like what the LLM is doing is just completing, you know, uh, a token pattern at the end of the day. Um, the fact that it is semantically relevant, that comes from human feedback. Like currently the the systems that we're building make sense because, you know, we have outsourced the the actual difficult labor of making sense to humans, right? Who at the end of the day are like, you know, literally coders, right? Who are like uh, coders, I mean, um, raiders, right? People who like will take outputs of of an LLM model and then rate it according to its its um, its conformance or discordance with like what we think is a good output. So, you know, the um, the magic, what what makes these systems look intelligent is that we have in effect projected our intelligence into them, and it's that so that uh, that is al I think also uh, relevant to this question of embodiment, like the these systems make sense because there's a part of the system somewhere, right? The human users that actually are in contact with the world and can tell you like, no, this this does match up or not to, you know, what we experience in reality. Um, yeah. So, I I think it's really, really, really critical to recognize the important, like the if if we're going to do artificial intelligence, we have to take the intelligence bit of AI seriously, and all intelligence is always embodied and situated in a specific context. Yeah, that that makes a lot of sense. I mean, I think one way of explaining this is it's not the destination, it's how you got there. So in the real world, there are these these dynamics at multiple scales, and there's a provenence to all of these just almost unimaginable number of interactions through time, and causality is important here because there's a there's a causal graph or a light cone that you can trace back through all of these interactions that have happened previously. I I want to give an example of a large language model. I read this amazing paper by Kenneth Stanley the other day, and it was called the fractured representation hypothesis. So he basically trained a simple neural network to generate images of apples and skulls. And when you look at the the representation map, it's very chaotic and and fractured. So if you do parameter sweeps on it, the the image that's generated just looks distorted and and horrible. And he had another version which was trained by humans where the topology was learned over time. And there was something about capturing the the the provenence of information. So, you know, at at university, you are taught knowledge at the most abstract level. Yet the kids don't really get it. It's only after a lifetime of of doing and interacting and cognizing that you actually learn these these kind of primitives of cognition, this world modeling that you're talking about. So chat GPT will give you an answer to something. Whereas when you really understand something, you have a kind of computational graph in your mind which is actually a very low-level understanding of of how the world works. And these things, they're not they're not plonistic. They these little kind of cognitive components, they represent regularities in in in the world, regularities that we've just acquired. And when you understand things at this deeper level, it allows you to be creative, right? So so now your intuition is more likely to be correct. You can now riff on things and compose things and modify things because you understand it at a much deeper level. But how do we how do we acquire these kind of you know, little mini models of how the world works? Well, I mean, you you were saying it, it's it's through experience. And I think ultimately what happens is that we uh, our our cognitive systems are equipped such that we extract the objects that cause our sensations from the the sensory data that we are um, that we're generating constantly in such a way that uh, these objects and object types are represented to be composable. So um, you know, uh, this is how we engineer systems, right? Like we and this is a slight, maybe a slightly reductionist take, but I think we effectively extract objects from our experience uh, and we when we so when we understand objects, we understand them again, and this comes back to embodiment in terms of the possible interactions that we can have with those objects, and this by the way, dovetails with uh, literature on ecological psychology ology, right? Um, what what we extract through interaction are object types, right? That are represented in terms of like possible interactions with us and with other objects. So the the representational format that we use as humans is inherently compositional. Um, so I mean, I think that kind of gets to what you were asking, right? So like we we we learn object-based object-centered representations of the world that are structured interactionally such that they can be composed, and you know, this is where the amazing abilities of imagination and counterfactual thinking of humans uh, you know, come to four. Yeah, there is a a constructive way of thinking about this, right? Which is that, you know, the Plleonistic thing is that we can decompose into this beautiful set of primitives how the world works, and anything you see is is just compositions of of those things. Therefore, why why do you need to be embedded in the work? Because you you can already just just do the composition. But there's there's something more than that. Certainly with with language, for example, it has this incredible diversity in complexity, and it just goes on forever. And and certainly even though we know many, you know, intuitive physics, and we know a lot of deep knowledge about how the world works, we're still discovering things, and we can go in so many different directions because knowledge is perspectival and and it is constructive in this way. But there are regularities everywhere. You see you see the same things um occurring in evolution in different parts of the phlogenetic tree. You see different types of things emerging in different places. And this gets to this idea of a real pattern, and and Maxwell, please tell me your lovely definition you gave me the other day of of what is real. But what why why do we see these kind of like reoccurring motifs all over the Well, I mean, you know, I think you're there are some se several, there's a set of deep questions that just underwrite what what you just asked, right? So, like what what is what does it mean for something to be real? I think is like a vexed question. Um, but it's it's it's sort of right there in in what you're asking. I mean, um, when we were discussing a few days ago, I offered up a definition of uh, the real, which I I draw from u, you know, philosophers uh, and philosophers like uh, Merlo Ponti and um, you know, the Lanian psycho psychoanalytic approach, which is something like, well, the the the real is when you bump into something, right? The the real is when um, what you experience resists you in some way. I think so that's one possible definition. I think it's a very phenomenological definition. It it dovetails nicely with this whole um, active inference predictive coding approach because it kind of suggests that, well, when you're interacting with something real, it's going to frustrate your expectations about it at some level, and then you will learn from that error signal. um, a slightly different version of of the well, not just slightly, another take on what counts as real is what you were just describing, Tim, this this whole real patterns approach by by Daniel Dennett. Um, well, Dennit is essentially saying, well, um, things that are real um, are I mean, effectively emergent patterns, so things that uh, you know, arise in some way and gain enough stability so that they can be, you know, recognized and perhaps even act as like a a medium for further patterns to to be developed. And I think uh, you know, that that is um, a very u conceptually satisfying way of talking about like what is what is real and what counts as a a thing ultimately. Yeah. I mean, because Dennit said that a real pattern is any regularity that lets you compress data and still predict what comes next, and if dropping the pattern hurts prediction, then it kind of it earns its ontological keep. So there are many examples like in the game of life where we see these emergent macroscopic phenomena, or language is is a great example, and it's too complicated for us to imagine, you know, we were talking about this causal graph, this unimaginable amount of low-level interactions that compounded together produced this macroscopic phenomenon. It's beyond our cognitive horizon to even think about that. So we we see this macroscopic phenomena and and we call that a form of emergence. But this real thing you said it pushes back on you, right? Which which is interesting. So there certainly seems to be a relationship between language. You know, some people think of language as being an organism in of itself, a kind of agent which itself pushes back. But this this gets us into this really sticky argument about the extent to which you could have a pressure coming back down. Could could an emergent phenomenon actually have causal power, and and I should say as well, by the way, that um, there's this wonderful guy called Mark Bedal, and in 1997, he had a paper called weak emergence, and he said emergent phenomena are somehow constituted by and generated from an underlying process, and he said they are somehow autonomous from underlying processes, and this is really interesting because how can they be autonomous if they're caused by the underlying process, and agency is a bit like this, you know, like one of the definitions of agency is autonomy, which means it's causally disconnected, even though apparently it's not causally disconnected. Then you get into these weird metaphysical discussions because if it's not reductionist, then you seem to be getting something from nothing, right? So, how do you wrestle with these with these ideas? So, you know, this distinction between weak and strong emergence, I think, uh, hinges on whether you want emergent things to have causal powers or not. So, um, I mean, weak emergence, uh, at least in my reading of it from from Bidau and others, um, is I mean, effectively epifenomenal, like what what Bidau is telling us is that, well, um, some emergent uh, macrolevel property, some some excuse me, some some property at the macro level is emerges from um, you know, dynamics at a at a lower level. um, if they uh, if they can be predicted to an extent, uh, but that that you need simulation effectively to like cash out the relationship between levels. Um, and you know, in in the the paper that you're referring to, he makes the point that like this is not for him like just an epistemic thing, that this this is a robust metaphysical thing. um, like the there there is this is not just a way of talking about a pattern for for Bidal, like there's there's something new in some sense that emerges, uh, but then, you know, at least in that paper, he does not want to say that these um, that these emerging properties can have kind of downward causal effects on the uh, the medium from which it emerged originally. Um, I mean, I as someone who uh, you know, worked in multidiciplinary domains like transcultural psychiatry, I kind of have some issue with that. So, um, you know, um, I was talking to uh, one of my PhD supervisors uh, at McGill. Uh, you know, I worked under Carl Fristen at UCL and Lawrence Kermayer at McGill u, and Lawrence is a transcultural psychiatrist, a cultural psychiatrist. Um, and he's interested in like the the the the I mean, are they causal? The the interactions between all these different levels and um, you know, as a as a uh, philosopher who you know, is interested in physics and mathematics and this kind of thing, uh, I I like nice sanitized accounts of, you know, emergence and you know, h how those things uh, work. Um, and you know, I'm I'm very influenced by um, uh, accounts uh, for example, Max Klers's um, or uh, Alicia Herrerero's uh, who\n\n\nUltimately, suggest that like what links levels of emergence together are constraints, not causes.\nSo, I mean, what Kistler's argument, and I think this dovetails with some of the new work by Huerero, they argue is, I mean, there are effectively two different kinds of relationships that can hold between levels of emergence or levels of organization.\nThere's composition, which is just straight up, I am a proper part of you, right?\nSo, you know, the way that like droplets make up clouds, for example, and then constraint, right?\nSo, the way that, for example, like the architecture of a circuit board will constrain the flow of electrons, and those are the only two like metaphysically allowable forms of interaction between levels.\nThe nice thing about this is that you can talk about, you know, forms of determinism that don't just collapse into like, you know, efficient causality, right?\nSo, yeah, you know, Aristotle spoke of like four different kinds of cause, and three out of those four were rejected during the development of, you know, modern science during the Enlightenment and all of that stuff.\nBasically, there, you know, material, final, efficient, and formal were the four kinds of causes.\nSo, you know, basically what the, you know, following Descartes and, you know, all of the kind of empirical turn during the Enlightenment, all of these other, all of the non-efficient forms of causality were kind of banished into the domain of like bad old scholastic philosophy.\nAnd the only kind of, you know, causation that was allowed to remain in circulation in scientific discourse was this notion of efficient causality.\nSo, like, you know, think billiard balls.\nAristotle, for Aristotle, like efficient causation is like when the sculptor sculpts the clay into the form.\nIt's the actual efficient process, if you want to think about it that way, or mechanism through which, you know, things affect other things materially.\nIn the Enlightenment period, we're talking about like billiard balls colliding into each other.\nSo, basically, the kinds of, you know, force transmission, energy transmission that became the only like viable way of talking about causality.\nBut, of course, there are like several different, you know, ways of influencing things, of things influencing other things that don't, that don't follow this kind of pattern.\nI mean, so Huerero talks about constraints as things that raise or lower the energy barrier, right?\nThe amount of energy required for there to be a specific kind of interaction.\nSo, that's cool because it allows us to talk in a very, I think, sensible way about forms of determinism that are not mere energy transfer, and these are important, right?\nSo, they're important in the setting context of embodiment and in the context of the way the different levels of self-organization interface.\nSo, you know, for example, like, you know, to take an example close to home that we all care about in neuroscience, the whole architecture of the brain, like the network structure of the brain, certainly does have some kind of deterministic influence on the constituent modules and so on.\nBut it's not just, you know, efficient causation, right?\nLike, that wouldn't make much sense.\nBut there is a deterministic influence there.\nAnd the way that networks influence individual components of the network is through this kind of constraint.\nAnd, you know, Huerero has a nice philosophical definition in her new book.\nLike I was saying, constraints are things that lower or raise the energetic barrier for there to be some kind of interaction.\nBut, you know, for Kistler, constraints are, you know, more understood in the mathematical sense of like, give me a system of differential equations.\nWell, each of those equations imposes a new set of constraints on the system that certain variables have to stay within certain ranges.\nSo, yeah, I was saying all of that because the way that levels are, I would like to, I submit for discussion at least, the way that levels I think are connected are through composition and constraint.\nAnd that's a nice, you know, I think, philosophically sensible way of thinking about things.\nAn even more vexed question, which is, you know, what is a thing exactly, right?\nYou know, like we've been working a lot on object detection and, you know, the way that it's treated in machine learning and in the active inference literature, and like I'm a pluralist about, you know, notions of objecthood, right?\nI think there are several different, you know, logically valid notions of object that you, and what we might mean by an object.\nI think the least constrained version, which is also the least useful, I think, is the set theoretic one, right?\nWhich is basically like just, you know, a thing is a set.\nA set is a collection of other sets.\nAnd you get this kind of, you know, a nice, you know, recursive notion, a nice recursive definition.\nBut, you know, the problem is that that's too unconstrained, right?\nSo, you know, the set comprised of like my haircut, the planet Jupiter, your baseball cap, and Jason's dog, that's a logical object, right?\nBut there's no coherence to that object.\nLike, I think when we talk about things, we have the impression that like things should hang together in a special way, right?\nLike, if you poke a thing, then it should react to that poke in a way that's characteristic of that thing, right?\nLike, that's usually what we think of.\nSo, you know, in a lot of machine learning work, objects are defined, like, you know, object recognition works in machine learning, but the objects are defined in data space or feature space, right?\nSo, you know, an object might be like an identity, a position, orientation, and some translation rules, and that's a perfectly, you know, valid definition of object.\nIn Dennit's terms, it would be a real pattern, right?\nThat appears in, you know, a channel of visual information.\nThat's a perfectly, you know, consistent definition of object.\nThat's the kind of thing also that will appear in language, right?\nLike, I think, you know, concepts are, you know, loose collections in this kind of way.\nBut that's not sufficient as a notion of object to interact with things in the real world.\nLike, there are additional constraints that pertain to the kinds of things that we interact with on a daily basis.\nLike, physical, real-world objects are not just like an identity, an orientate or a pose, and some translation features.\nLike, there's some additional structure there.\nAnd, you know, Tim, we've known each other for a while, you probably know where I'm going with this, but, you know, one of the things I like about the free energy principle in active inference is that they give you a nice, robust notion of object or object type that inserts itself very naturally in this kind of context.\nSo, you know, what's missing from the, the, the data-based notion of object is like these additional physical properties that physical objects have.\nAnd under the free energy principle, this is basically the existence of a boundary.\nSo, just for the benefit of our listeners who may not be familiar with the free energy principle as developed by Carl Friston, you can think of the free energy principle, and this is heuristically, you can think of the free energy principle as an extension of the second law of thermodynamics, extending it from closed systems to open systems that have boundaries.\nYou know, think of a closed system, right?\nLike, you know, a volume of gas, just to be really simple.\nWhat happens in a closed system is the gradients are all consumed and the system ends up arriving at thermodynamic equilibrium.\nSo, you might think like there's a say a temperature or a chemical gradient in the cloud of gas, and through diffusion dynamics, right?\nWhat the second law tells us is that, well, the system will just tend to be uniform.\nYou know, the second law basically is like the law of my can of soda pop going flat, right?\nLike, you know, it's uniformity is what is achieved at the end.\nSo, what the free energy principle is at the end of the day, it's the same idea, but like physics in the presence of boundaries.\nSo, you know, reimagine that same system, but now there's a boundary in separating, you know, the two chambers of gas.\nWell, I mean, in that context, text, just by construction, you said there's a boundary, so you're not going to get this strong mixing, right?\nThe gradients are not going to be able to just, you know, be consumed in the usual way.\nWhat you get instead is the next best thing, which is this kind of generalized synchrony, this formational coupling.\nIt's like, well, I can't mix into you, right?\nSo, the best thing that I, the next best thing that I can do is be become like you statistically.\nSo, that's what the free energy principle is like at a very high level.\nAnd, you know, what the key features of objecthood from that definition are, like, objects have boundaries.\nObjects interact with other objects at their boundary, and therefore the statistics of the boundary allow you to define different object types.\nAnd that is precisely, I think, the kind of thing that's missing in contemporary machine learning.\nSo, you know, again, there's nothing wrong with language, and there's nothing wrong with existing in data space.\nLike, it's a good thing for us that language is unconstrained by physical reality.\nThat's what enables us to use language to imagine, you know, to imagine, you know, counterfactual situations and to imagine things like unicorns, right?\nLike, or whatever, right?\nTo imagine things that are impossible.\nLike, that's very useful, right?\nIn many contexts.\nBut, you know, when you want to act in the world, you want to be constrained by the physics of the situation that you're trying to control.\nYeah, that's really beautiful.\nI think that that's actually one of the best explanations I've ever heard of of the free energy principle.\nThank you.\nIt's only taken me 15 years to...\nWell, this is what we were saying earlier, that it actually takes decades of wrestling and thinking about things to understand it at this level because you have these kind of like low-level abstract functions of understanding, and you can use that to, you know, re-represent and recast and construct and create, you know, your understanding of different situations.\nBut that really evoked an image to me.\nI'm almost imagining, imagine you had a computer game environment, and you know, thermodynamics is like, you know, just a completely open space where all of the little bits can just intermingle, and it just necessarily kind of just converges to this, to this equilibrium where, you know, where energy goes down.\nAnd now, like, imagine, you know, almost like a Quake 3 or a Doom type level where you have all of these walls and boundaries all over the place.\nAnd if I understand correctly, the free energy principle doesn't really help you figure out what the boundaries are.\nIt's assuming that if the boundaries are there, what happens?\nThat's correct.\nSo, we still have the fundamental problem of like, because this is, this is presumably one of the most important problems in artificial intelligence, is this miraculous ability that we have just to make sense of a scene, to make sense of where we are.\nAnd it comes back to the emergence discussion as well because I think these real patterns that we used to think, they're actually an artifact of the kinds of constraints between the layers that you're talking about.\nSo, it's not like they're completely constructed from nothing.\nThere is a path from the world that we live in and these constraints and these boundaries and these actually inform the kinds of models that we do.\nAbsolutely.\nI mean, so Huerero has, in her book, a context changes everything.\nIt's really, it's very interesting book, and somewhat oversimplifying her argument, she says, well, there are different types of constraints that are related to coherence in different ways.\nAnd one distinction that she makes is between limiting constraints and enabling constraints.\nSo, she says most of the constraints that we consider in physics are limiting, right?\nSo, literally, like the constraint exists because it limits your ability to follow a certain trajectory or to access a certain region of your phase space.\nSo, you know, a limiting constraint is like what circuits do in a processor, right?\nLike, so having, you know, different, literally different wires are canalizing, you know, electron flow in one direction as opposed to another, you know, and this is what like gaps and all, all of this kind of thing in your architecture allow, you're literally preventing, you know, energy from moving in a certain direction again, and this is consistent with her definition, right?\nBy heightening or lowering the energetic barrier that's necessary for a specific kind of interaction.\nIn biology, Huerero points out constraints typically have not a limiting connotation to them, but an enabling connotation to them.\nSo, constraints are such that they enable the system to access regions of state space that they would not, you know, on their own, under ordinary circumstances.\nSo, what she calls enabling constraints are effectively constraints that allow a new kind of stability or structure to emerge, which can then itself be, you know, subject to selection and, you know, become another kind of, if you want to think about it like that, a medium for, you know, new constraints to be added on top of.\nSo, I really like this because I think it allows you to talk about, you know, the things that Mark Bedau thought were kind of like, you know, philosophically or metaphysically suspect, but in a very elegant way.\nLike, none of this is spooky.\nYou know, if you, it's no more spooky to talk about, you know, constraints and their effects on, you know, the deterministic flow of a system than it is to talk about the way that wires, you know, canalize the flow of electrons.\nLike, that that seems perfectly sensible on the face of it.\nIt's not spooky.\nAnd, you know, I think all of these kind of multi-scale effects can be made sense of and can be explained sensibly by appealing to this same kind of explanatory strategy.\nThe question of detecting objects is a rather vexed one.\nI mean, you know, the, yeah, but we don't, we don't have to go into that.\nI think a technical comment on that.\nSo, Maxwell, earlier you mentioned, you know, systems today learn in data space, which is almost entirely true.\nI think tying that back to the importance of embodiment and experience is really important here and why these systems don't sort of carve things out in objects the same way that we do, right?\nAnd so, we're able to interact and find the boundaries through a very natural kind of interaction with the world around us.\nAnd then that teaches us how to then identify new types of boundaries when we come across them, right?\nAnd I think that gets back to this really object-centered way of thinking about the world that's missing from machine learning today.\n\n\nThere's approximations that the field is introducing through like physics simulation.\nUm, it's a very popular technique for training, uh, particularly reinforcement learning models for robotics today, which is I'm going to like handcraft sort of a physics scene, and I'm going to add some objects to it, and then I'm going to run my simulation, you know, thousands or millions of times over.\nUm, and expect a model to come out.\nAnd so there is this notion and this need and desire to introduce those types of interactions with like physical objects into the learning process that I think is it's becoming more apparent and more important, um, as we try to shift AI out of, you know, digital space into physical space.\nYeah, I'm trying to understand this because in the real world, the boundaries are just there, and the intelligence just is the world.\nIt's it's just physics, right?\nSo it it just manifests itself in the way that you were just describing, Dr. Maxwell Ramstead.\nBut if we want to build artificial intelligence, then you get this kind of partial observability where you're a thing, and you might not know where all the other boundaries are.\nAnd what you're describing here is a form of intelligence where you're modeling the interaction dynamics.\nSo we're saying at some level of resolution, we can model almost affordances, I think is the technical term.\nSo there's a thing over here, and this is the interface, and I can do these things with that thing, and maybe part of this process is I actually need to figure out what that thing is and what I can do with it.\nAbsolutely.\nThat's kind of exploration and exploitation, right?\nAnd that's why, you know, systems like active inference, I think, lend themselves very well to that style of learning through interaction.\nYes.\nSo, could you, could you sketch out how how that works?\nSo, um, because there's a bit of a blank slate problem as well.\nLet's imagine that we we build, because Dr. Maxwell Ramstead, we we we spoke about this the other day about whether you're a functionalist or not, because you know, certainly people like John Cell, they made the argument that you as well as these these algorithms that we have, you actually need this causal embeddedness, you need brains, you need machines that actually operate in in the real world.\nAnd you know, I certainly spoke with Yosha back, you know, quite recently, and and his his view was very much that you have these kind of software agents, and currently they're being simulated by our brains, but they could be, you know, run, uh, in in silicone.\nSo there is a bit of a lingering question for me there, whether you actually think that such an intelligence must be embodied in the real world, or if if we could model it differently, maybe we wouldn't need to.\nBut let's just be practical for a, I may be, uh, I may be misunderstanding Yosha's argument, but um, I I kind of see him as an arc platonist in the sense that like what he thinks is is really real are are like these functions, which he by which he means mathematical functions, right, which are like implemented and multiply realized by, you know, agents like us in the physical world.\nUm, so he's definitely a functionalist.\nUm, I don't know if I, um, if I adopt, um, the same perspective.\nUm, so I mean, just taking a few steps back, um, I think it might be useful to, you know, where do the primitives come from, is a question that you asked earlier.\nSo you know, where where do like the atomic elements of thought come from at the end of the day?\nUm, so I think a useful question to consider in that intellectual context is, well, why do we label things at all?\nLike why, why do we use labels to designate things?\nWell, a good label, um, improves my predictive grip on the world, right?\nAnd provides, uh, a simple like compressed explanation of the data that I'm trying to explain.\nSo, um, you know, why do we call, um, you know, hydrogen atoms hydrogen atoms or helium atoms helium atoms?\nIt's because, um, you know, um, hydrogen atoms have specific properties that mean that they behave in certain stereotyped ways.\nAnd by labeling a collection, you know, like literally like by labeling this zoo of subatomic particles that hangs together as a hydrogen atom, then I'm able to, you know, I I have some kind of explanatory or predictive grip on the situation.\nIt it literally lowers the entropy of my observations.\nIt lowers the the surprise that I that I have when observing them, but that I have labeled them in a certain way.\nRight?\nSo, I mean, presumably this is what the brain is doing, right?\nLike there there there's uh the brain has access to like these dynamic data sets that it's generating continuously through this kind of sensory palpation of the world.\nAnd um, you know, from at least from an active inference point of view, what's going on is essentially hypothesis testing or you know, label testing, right?\nSo, um, you know, uh, on the assumption that like what I'm encountering here is an object of a specific type, then I should expect this or that, you know, data to be generated, and then, well, oops, that actually that wasn't a cat, that was a small dog, right?\nAnd then, uh, like my my my label was inappropriate, my hypothesis was, uh, you know, uh, wrong.\nSo I generated some error, and then I I change my hypothesis.\nI try a new label.\nIt's more appropriate.\nI get more predictive power.\nSo presumably this is sort of what's going on.\nLike the brain is trying to just to create a compressed representation or explanation of the data sources that it is privy to and that it's generating through embodied intelligent action in the world.\nUm, so yeah, I mean, um, and this is I think again, this this echoes the embodied intelligence thesis.\nUm, there there is no such thing as general intelligence.\nI want to say like, and I know that's perhaps like a provocation, but like I think all intelligence is situationally specific for precisely these reasons, right?\nLike so you're dealing, you're grounded in a specific data set that's being generated by a specific kind of exploratory, uh, behavior, right?\nAnd I I don't mean exploratory in the sense of like exploitation versus exploration, I mean like this kind of sensory palpation of the world that we constantly, you know, engage in, and you know, the things that populate our ontology are, you know, are, um, equivalent to the set of labels that we deploy to make our, you know, to make sense of our sensory data.\nBy which I mean like to compress it and to make subsequent sensory data less surprising.\nYeah, that that makes sense.\nI mean, the thing that that springs to my mind though is is you're proposing a different form of artificial intelligence than OpenAI.\nThere's a big narrative at the moment in the valley that, you know, people are talking about physical AI.\nThey're saying that we should put large language models or similar into the brains of robots and have them interact with the world.\nSo that they can do something akin to what you're talking about.\nThey can even with coding, for example, some people say, um, the reason the code isn't very good is because it's not running the code.\nIt's not testing the code.\nIf only we had tools.\nIf only we could get results back, then we get this feedback loop.\nWhat is the sort of the bright difference between what you're proposing and something like that?\nI would say like being grounded in the world in some sense.\nSo like no matter how you train these these, uh, you know, state-of-the-art feed forward, you know, gradient descent-based architectures, at the end of the day, um, they they are only tethered to reality through us and our expressions of preferences, um, and that's a huge problem, uh, and I don't see any way out of that architecture effectively.\nI mean, um, you know, uh, Silver and Sutton point out that like something was lost when we moved to the era of big data.\nLike if you think of like the first machine learning systems that were using reinforcement learning, like part of their power was that they were exploring, you know, the problem space on their own.\nUm, and they, um, Sutton and Silver call this the era of simulation, where like, you know, the very early systems like operated in these simplified sandboxes, and sure they were limited because like they're not exploring the real world with all of its vagaries and contingencies, right?\nLike there's they're exploring these ultra-sanitized, like simplified environments, but there was a kind of self-directedness that you ended up losing in the era of big data, um, and you know, Silver and Sutton argue that this next era that's creeping up on us will be a return to that kind of like autonomous data generation, um, which is really critical, I think, to to have like actually intelligent systems, and this is what I I don't think, um, current AI architectures are really able to do for like a wide variety of reasons, I mean, but in particular because they're not grounded, they're not connected in the right way to reality.\nSo just to diffuse a few possible objections, like we're not claiming that there aren't implicit representations of the world in, you know, say a large language model.\nSurely there must be, right?\nBecause they are trained on data sets that that that h, you know, feature these objects.\nI, I, if they, if they are predictively powerful and if they work correctly, then then they will implicitly have, you know, a representation of the world in there.\nBut it's not the kind of thing that you can reason on, right?\nOr or that you can use to make plans because it's implicit.\nIt's distributed.\nSomewhere in this like, you know, messy, you know, jumble of billions of parameters is like a representation of, you know, Dr. Maxwell Ramstead talking to Tim, for example, or whatever, right?\nLike, uh, presumably like, you know, it's there somewhere, but it it's not there in such a format that, you know, the the system could could use that to like guide intelligent patterns of behavior, is is the contention.\nYeah.\nYou couldn't go pluck that out of the network and then use it somewhere else.\nYeah.\nJason, do you want to maybe talk about like the discreetness of these things and like their use in say like, you know, game environments and this kind of thing, because that that I think is like the the problem Jason just pointed to at like the the these objects are not represented in the way that you could just pluck out and then, you know, edit or, you know, they're not discreet, you know, recogniz, there's certain like rigidity to that, right?\nWhere like, because I don't know how it's broken down, I can't go just carve out, uh, that representation of that particular object or that behavior and then repurpose it maybe in a new or a smaller context, for example.\nAnd so there's this lack of composability that's inherent in these systems, right?\nSo, and if you think about, you know, how we learn and how we move about the world and how some of the most, I think, efficient and effective systems in the world that that even humans have produced, like composition is very important to that.\nYeah.\nUm, especially for efficiency.\nAnd when we're talking about physical systems that are untethered to like power sources, they've got a self-contain, self-containment to them where they have their own battery pack.\nYou know, efficiency is extremely important, right?\nAnd so, um, being able to or having to like transport a data center, you know, in a robot to kind of host these multi-billion parameter models.\nAnd quite honestly, it's kind of a non-starter in any production grade system, right?\nAnd so I think, um, I think learning into sort of composable bits or modules is extremely important, uh, as we move forward here into architectures.\nYeah.\nYeah.\nI mean, if if we've learned anything from the deepseek moment, it's that, you know, a mixture of experts architecture will always outperform like one monolithic architecture.\nUm, you know, uh, so even the LLM, you know, um, purists, if you will, will are moving away from like the the monolithic omnimodel kind of model of AI.\nWe're kind of taking that to its logical extreme to say, well, what what you really want is, um, collections of models that are situationally specific, right?\nThat that that are very good at doing certain kinds of things, um, and that are like attuned to like specific kinds of situations.\nLike that's that's that's the way that intelligence occurs, you know, in nature.\nYeah.\nIt's also, um, it's it's ironic that LLM fans do not think that intelligence is specialized.\nAnd it's ironic because LLMs are the most specialized possible form of intelligence.\nThey they are, they learn these jagged fractured representations, which are basically just memorizing, you know, very, very specific things.\nIt's very specialized.\nUm, as you were saying, Jason, they're not robust.\nThey don't learn things abstractly.\nThey're not compositional.\nThey're not iterative.\nThey work best when humans use them in a compositional iterative way.\nCertainly coding is a great example of this.\nYou know, you do this generate test loop, and the human with their understanding of the world is identifying in interesting candidates, and you're running, and you're running, and you're kind of, you're basically doing the cognizing.\nYou're you're using the language model a bit like Photoshop.\nThat's exactly right.\nThat's what I was suggesting earlier.\nThe magic comes from the user at the end of the day.\nLike it's the user that that that both generates this iterative loop that you're talking about that that makes the system so useful, and also, you know, the semantic grounding comes from the agent.\nI'm I'm the one who tells the system at the end of the day, like this was a meaningless, like, you know, uh, monkeys on their typewriters kind of thing, or actually this was a very deep and insightful thing that was just produced.\nLike all of the meaning comes from us, and you know, we we draw that meaning from our specific situation that we're embedded in because we have an understanding of context, right?\nAnd of the world that we inhabit, and for for an AI system to to you know, be safe to deploy, even it needs to have something like this situated embedded understanding of itself and other agents within a given context.\nYeah, absolutely.\nAnd it's not to say that we aren't a bit like, you know, there's the drunken walk analogy where you do something a thousand times, and one of the guys will actually solve the maze or whatever, you you use the the monkeys on the keyboard, but you know, it's a similar type of thing.\nBut, um, I guess where we're getting to here though is that it's it's not just what we said before.\nIt's also things like efficiency and continual learning.\nI mean, yes, you can do continual learning with neural networks.\nIt just becomes quite intractable to do.\nSo, but the other fundamental thing, well, it also degenerates into noise, right?\nLike I I I always find it very interesting that, you know, these these experiments where they hook LLMs up into themselves and then feed.\nSo what what happens is it just degenerates into just, you know, noise, which isn't surprising if you understand what's going on under the hood and and everything like, uh, but yeah, basically like if if there wasn't a human in the loop to add structure and input semantics, it degenerates into meaningless noise, right?\nSo not that not that noise is unimportant, right?\nWe we you know, image generation works because of diffusion, and this kind of\n\n\nStuff like, it's necessary. It's a necessary part of this knowledge generation thing. But if you just do that, then it degenerates into nothingness. Oh yeah. Um, so, so I want to add a... So, actually, I have really good interactions with LLMs. I think that they help me think through stuff, right? Um, whatever it may be. It might be a, um, something I'm writing up a slide deck. It introduces me to new structures of information that I am not aware of, right? Um, but it's still, at the end of the day, it's me taking the structure and then doing something useful with it, right? I, I, I often find that, like, I can have it spit out a document, and then I've got to replace the content of the document, but I, I keep the structure of what it gave me, right? And so I think it's very interesting, um, in discovering these new types of structures that maybe your system's unaware of, and just sort of kind of put that in the context of a physical system. Um, you know, let's say we build systems that want to explore and then exploit. Well, that exploration phase needs to come from somewhere, right? And it could be, it could be driven by language models, right? Like introducing new ideas to the system, just like we, uh, we have new ideas introduced to us through reading and other forms of communication and media, right? So, oh yeah, totally. I mean, to build on that, we're not haters, right? Like, we, we don't think that these technologies are, like, you know, useless. Uh, to the contrary, I mean, they, they can be greatly empowering. Um, but that's, that's, I think, the point, like, they, they should be considered as, like, tools that, in the best case, enable cognitive enhancement. They are absolutely inappropriate as replacements for, for humans, you know, uh, and in part because they're not grounded in anything, in anything that, like, matters to us, right? They, they have no understanding of the norms that govern specific situations and so on. They, they, they don't even have an explicit representation of the objects and agents in a given situation, right? So, you know, you wouldn't want this kind of thing to act autonomously in the world, right? They're inappropriate as the kind of foundation layer for physical AI. Something else is required, which is what, you know, we're busy cooking at Noumenal. Um, but state-of-the-art systems are still very useful if, if you can allow a human in the loop. It's just, you know, they're not going to be useful in, in the context where people hope to deploy physical AI, like edge devices, drones, and robotics, right? Yeah. Some of my favorite hallucinations from, uh, LLM systems are the kind that sort of, they kind of confabulate this capability that they don't really have, like this affordance that they have, but they really don't, right? And so you can imagine what that would manifest like in a physical system. It's like, so I'm thinking, you know, reasoning using a reasoning model, and it comes up with, you know, I have a, I must have a, a third leg that I can use, or maybe I have wheels, but I don't. Maybe I'm a bipedal robot, right? And now I, I dream of, or kind of hallucinate this capability that I don't have, and then I try to do something that ends up being, you know, kind of catastrophic or dangerous in a real-world setting, right? Yeah. So that's one of the, one of the things we need to be cautious about, I think, when tying language models directly to the control systems of these things. Uh, as such as the cases like VLA or vision language action models. Yeah, I do find it genuinely fascinating how they are simultaneously incredibly useful, and they give with one hand and they take with the other hand at the same time. Like, if, if I've got a medical problem, talking to 03 is better than talking to your doctor. Yet, if you want to come up with an idea for a YouTube video, the worst, or actually create anything, do, do any writing, the worst thing you can possibly do is talk to an LLM. You know, humans have this, this miraculous ability to come up with ideas because ideas, interesting ideas, are always on the long tail, right? They're never in the head of the distribution. So, um, but anyway, like, you, you guys, you're building this kind of compositional system where the models and, and the objects are first class, right? So, I, if I understand correctly, you're, you're designing a kind of system which is going to be a little bit like the OpenAI, but, but instead of it being a large language model, it'll be a marketplace of models, and these models, because we were saying before, the reason why LLMs aren't autonomous, right? It's interesting that people think they are because we kind of discount the, the human supervision, but that they're not autonomous because they don't understand the world at an abstract level, right? So you're almost going to build a marketplace of models where, in specific situations, these models can be trained doing this active sense-making using something akin to active inference, and then they can be published and consumed by other people. So you're almost building the next cloud of models. Is, is that a fair representation? Yeah. So if you read our, um, our white paper, how to build a brain, that's precisely what we're describing. I mean, and you know, the idea there is, we should draw on, um, the way that, you know, cognition actually emerged in nature. So that the, the way the brain, um, evolved, we think, you know, again, this comes back to the embodied intelligence thesis, right? Brains evolve to mirror a specific kind of, you know, situation or world. Uh, they do so by basically, you know, labeling and extracting objects from sensory data, and you know, as, uh, brains became more sophisticated, the ability that's unlocked is the combin, the incremental combination of these different modules into, like, super systems. Um, the, you know, so, you know, human cognition is multimodal, and it's, it, it, because it, uh, arises from a combination, you know, an integration of modality-specific systems, uh, and this is what enables us to, you know, perform in such a general way. So, uh, the idea is that, you know, artificial intelligence should emerge from this kind of network structure in much the same way that the brain's capabilities emerged historically, uh, through evolution and through learning. Yeah. So the composition is very important, I think. Um, it's not just composition, and so there's, there is this idea of a sort of repository for physical system behaviors or skills. Um, I call them behavior packs as sort of a, a way of, of making it pithy. But, um, it's not just about being able to query and find those. It's about tying them together meaningfully at the edge on the physical system, right? And so this is where, uh, active inference plays a key role, right? As that sort of integrator, um, maybe not necessarily at the top level, but at a level that's meaningful to the system. Um, and being able to, uh, pull the right models, or, or determine that it needs to pull a new model is probably a better way to put it. Uh, and when that's appropriate. Yeah. You know, the nice thing about Bayesian approaches is that you're, you're, you're always trying to quantify what you don't know, right? So, by adopting a Bayesian architecture, you can develop a system that goes, hey, actually, like, I don't really know what, what this data pattern is. Like, I've never encountered this before. So, you know, can I draw on, you know, the, the systems to which I'm worked? Maybe you have a model for this kind of data pattern, and then we can make sense of this dynamically. And I mean, that's how the brain works, right? Like, the, the, the brain is a collective sense-making machine where, like, you know, a pattern gets shuffled around here, and if it doesn't get, you know, if it's not mastered by, you know, the, the brain regions that are active, more regions get recruited, and it, it, it is also, like, you know, it's sort of, it's the idea is to solve problems collectively in the same way that, you know, neurons self-organize to solve problems and dynamically, I would say, too. So, like, if, if I'm a robotic arm, and I'm, you know, used to manipulating a certain type of object, and now I have a new object that's introduced in front of me, what do I do? Right? I have no agency, really, to decide to, to try anything different or load a new model to handle that different type of object. And so, you know, being able to, in that case, say, phone a friend or, you know, dial up tank in the Matrix, right? Um, to download a new skill, I think is going to be incredibly important for the successful deployment of physical AI into systems that, you know, are doing real work, right, the way that we want them to. So, guys, I'm going to ask a difficult question on the value chain and the revenue model. Certainly, if, if we look at OpenAI, they, first of all, they, they scrape up all of the data on the internet, and that's very valuable, and they have to have millions and millions of GPUs, and they're very expensive, and, and that's very valuable, and, and then there's this model that you pay them based on consumption, and they, they've got all the secret sauce. You're describing a model where, if anything, the people using the models are generating the value themselves because they're actually using it. They're installing it in their robots. They're, they're doing this active inference, and it's being trained on, on data. So, I, I guess the first question is, where do you guys make the money? But isn't it a weird inversion that the people using the models are kind of generating the value into the system? Well, it is. And, and Jason, you can talk to how the value is generated, uh, in, in a second, but I just want to draw attention to the fact that what's actually valuable is the data. So, you know, uh, model weights are valuable to an extent, but it, I mean, if, if, if we've learned anything from the DeepSeek moment, um, from a business perspective, and if, if there's anything to draw from techniques like knowledge distillation, it's that, like, you know, being the proprietary owner of a, a set of weights is no longer an efficient business mode for an AI company, right? Like, if, if I can just hook up into your API, and then, you know, train up my own system, and just, it's, it's not, it's not going to be viable, right? Um, and, you know, not this isn't to mention that, like, you know, all of the data that they scraped off the internet, like, you know, how many times does the copyright symbol or the trademark symbol appear in, in the data set? Like, you know, they're exposing themselves, and they have, like, you know, these lawsuits are happening. They're exposing themselves to unbelievable, like, unbelievably, like, painful and expensive lawsuits. So I think, you know, the business model that they're pursuing, it doesn't work. It won't actually generate revenue that they, they are floating right now because they've received billions of dollars in, in investment from, you know, from, from very well-endowed, uh, you know, funders. Um, but as a business model, I don't think it scales. Um, and, you know, also, we've, even if it did, we've reached the limit of that data source, right? Like, these models are already trained on all of the publicly accessible data on the internet. There's nowhere else to go from here. Which, I mean, brings us back to the Silver and Sutton argument, like, where, where is, where is the new data going to come from? Well, it can only come from the systems themselves generating data through this autonomous exploration and palpation of the world. Um, I realize I haven't talked about, like, how this makes money. Jason, do you want to segue? No, no. So, well, we get into that in a minute, but I, I, you raised a really important point, Maxwell, which is that, you know, LLM companies have been successful largely due to them being able to scrape the whole of the internet, right? So you've got this amazing, rich, canonical data source of, like, human knowledge that they're able to, you know, organize into a really curated and high-quality data set for training, and that type of data set does not exist for the physical world, and I would argue would be impossible to collect in any meaningful way, right? And so it's got to be put together, pieced together, um, I think, you know, composed together, right? Getting back to compositionality. Um, by people, a community that want to ultimately benefit from, um, the ecosystem, right? And so I think that's a, that's an important thing to think about here. There's a, um, Nvidia is actually really, really good about sort of promoting this, this new emerging physical AI community. Um, and in fact, sorry, just a little bit of a tangent. Um, Jim Fan, who's the one of the leads researchers over there, um, he, he has this new concept called the physical Turing test that he's shared, uh, in the last few weeks here, where it's a, it's a messy, like, scene. And it's like a living room, and it's just got trash and pizza boxes and beer bottles and everything. All this, you know, there was a party the night before, right? And and what I want to happen is that it gets cleaned up, and a new, um, like, candlelight dinner is set up for my, my partner and I, uh, for the following evening, and I cannot tell if it was done by a human or a robot. And so, so that's sort of like the physical terrain test, um, as he, as he puts it. And I think it's a brilliant kind of challenge out into the community of what ultimately the goal is, uh, for practitioners in the space. And so, circling back to kind of the, the community effort that's required, I think, to solve that problem and pass that physical terrain test, it's going to take, um, it's going to take people enabling that data collection out at the edge on robots, and then compiling it back into a centralized source that the whole, then the whole community, uh, can take advantage of. Yeah. And and it it allows people to monetize their own data sets and their own models in, in a way that benefits everyone as well. Yeah. And if there's a proprietary, you know, set of interactions or behaviors that I want to keep closed, I can, I have that option. Um, you know, there's ways of monetizing that for us, right, that we don't need to get too deep into, but, you know, it's kind of enterprise versus, you know, uh, run-of-the-mill street dev community type engagement, right? Yeah. Yeah. So, first of all, you, you make an important point, Jason. Certainly, if you look at the enterprise LLM companies, they are mostly direct to consumer. Most corporations do not want to use them. And that's why, certainly, Cohere is an example. They've completely shifted their model. They only do enterprise, and they only do private deployments because every single enterprise, the number one thing they say is, I want to put a boundary around this thing. I, I'm not, I'm not sending my data to you. Right? That's, that's very, very important. But I want to push back a little bit on what you were saying about it's, it's, you know, like, OpenAI is only training on all the data on the internet. Look at Google for\n\n\nPeople think that it's powerful because of page rank. That's not really the case at all. Um all of these sort of statistical knowledge is learned through interaction with the users. Right? So you get all of these tail queries and users put a query in and then they click on a result and then you know Google is learning the relevance of that from the users. And it's exactly the same with LLM companies. We're seeing this, it's quite a surreptitious, sneaky transition that people aren't completely aware of. But now certainly a lot of the um the information that OpenAI learns is through people interacting with it. That's how they build their engagement models and increasingly it's being wired up to tools and you're installing on your phone. Um but I think the important point though is that there's something very magical about interactive data. So certainly Tesla, they've got lots of physical AI data and Google has street map data and whatnot, but when you have a human in the loop, you're actually learning something. Even if it's one step removed, you're learning something about how the real world works and then you're kind of putting that in the chain of how you train your model. Would you agree with that? I would say I I would say yes. Uh but what what that tells you is that they're aware of the limitations of their original business model. Right? So uh why why is this kind of interaction interesting from a business perspective? Well, first of all, it's new data that you're generating when the the the problem is that you've ran out of data to train. So your users are generating new data. That's great. And it's data that's grounded in the situation, preferences, and competence of a user. But I think people don't realize that they're the product in in that kind of setting, right? So I mean these business models are going to float for so long as people are uh you know unaware of the the exploitation or are willing to go along with it because they get some kind of gain out of it presumably like you know you learn you get a lot from using you know Google's uh services so you get something out of it. Um, but I think when especially when enterprise and individuals realize that like really where the value is is the data and that you know and that they're just giving it away to these companies who are then making an enormous profit by kind of consolidating and codifying that data like I think once consumers um and customers become more aware of that you'll see less of it and you'll see a pivot towards people trying to like you know opt into systems that allow them to monetize and commercialize their data and the models that were fitted on their data. I mean the I think it's a what you're seeing is basically like ignorance driven you know um yeah because this is some this kind of data is something that these companies will one day want to pay for I would imagine um because you're going to run out of it like yeah well so so the data is very important I think um you know in some way we're providing a a method for collecting the data but there's another um couple stages from modeling to actual like real use in a physical system, right? And you know, if I'm using simulation to train, it's referred to as the sim to real gap. It's like, okay, my model behaves great in simulation, but when I put it on a robot, it goes haywire, right? um because feedback uh motor noise, sensor noise, you know, things that the real world brings to the table. Um and so that is another part of the value chain that we're addressing in physical AI. So think of what we're building as not just sort of the a cloud kind of repository, but it's ultimately kind of the do a Docker ecosystem with all the tools to then go from modeling to deployment in a very seamless fashion, right? with gates along the way for um QA testing your model right in simulation testing it you know we we haven't talked about this a great deal but I think there's an opportunity to provide a sort of a a physical unit test if you will for my models by having having a menagerie of robots available to provide that service to end users to customers and so they get to test what the model will do on hardware before they put it on their own production hardware, right? So, I think there's an opportunity for a service like that um that we're we're looking into, we're pursuing. Um but ultimately like that that deployment path is is really really a tricky technical challenge today. Um and it for a variety of reasons obviously the model behavior reason being one of the biggest ones but um you know there's a lot of uh of fragmentation in um in deploying the models um you know I think I thought every robot used uh robotic operating system but it turns out only about half of them do right and so um that was a misconception that I had and and so now you've got to then deal with uh companies, you know, practitioners deploying in their own sort of native frameworks and ecosystems and address that as well, right? Yeah. So, yeah, I mean, I guess this is the secret sauce of what you guys are building, right? Because there are many forms of brittleness in all the things that we just discussed. Certainly, people have different types of of robots in in slightly different situations, but you're you're describing something which is a cross between like AWS, Docker, um Kaggle, and maybe GitHub. and or hugging face maybe hug yeah hugging face is better than GitHub yeah I think that's a good way to think about it and um yeah you mentioned docker now docker for folks who don't know it was a revolution in cloud technology because you know cloud did this thing called platform as a service and that was great but it was actually a clever form of lock in you know so you would be locked into using Azure instead of AWS so you know this this um this this docker thing and then we had kubernetes and and essentially it the key the the key thing about docker is it's about immutability so you could kind represents um a portable snapshot of an application running on a on an operating system and and you know you can install this thing anywhere and it's exactly the same version of Linux. It's exactly the same version of the application. So you get this reproducibility. It's testable and whatnot. But what you what you guys are doing is a little bit different to that though, isn't it? Because you're building something which is doing active inference. It's it's doing continual learning. It's changing all over the time, you know, it's changing all the time. So I don't know how you would design that. Would you have kind of like a snapshot of the model at a particular point in time and then maybe you would do some additional kind of active inference and then a month later you would have another snapshot. How would you get the benefit of adaptability and reproducibility at the same time? Yeah. So I think the um so you're right Docker provided a really nice it almost solved the like what runs on my computer problem. Yeah. Um right in deployment. Um but even then you know um once you deploy a docker container you attach it to a storage system then it becomes its own sort of instance of that container right um and and it changes over time in different ways than other instances and so I think the the analogy there is that that that's going to happen in any physical system is that there's going to be nuances to both the physical system itself and the environment. that it's interacting with that that the active inference is going to help pick up on, right? And so in one way it's going to be just sort of unique to that instance of a system but then you know there are ways of saving off what's learned back to a centralized data source and then incorporating that into let's say you know uh Rubik's cube you know robotic docker container v2 right so can I feed and now I have this feedback loop of learning that's not just at the local level but it's sort sort of at a metal level in the whole ecosystem. Beautiful. Well, um guys, I think I think we've come to time. So, it's been an absolute honor having you both on the show. I I really appreciate you coming on. Always a pleasure, Tim. Yeah, Tim, thank you so much. Uh it is quite the honor and uh so so thank you for all the content that you generate.\n",
  "dumpedAt": "2025-07-21T18:43:25.542Z"
}