{
  "episodeId": "35r0iSajXjA",
  "channelSlug": "@machinelearningstreettalk",
  "title": "Oxford Professor: \"AIs are strange new minds\"",
  "publishedAt": "2025-06-17T03:22:18.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Superman 3 is a terrible movie, but",
      "offset": 0.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "there's this wonderful scene. So, I",
      "offset": 2.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "think there's a kind of giant computer",
      "offset": 4.16,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "that goes rogue in Superman 3. And",
      "offset": 5.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "there's this wonderful scene where",
      "offset": 7.919,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "there's this female character and you",
      "offset": 9.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "know she's sort of the the machine is",
      "offset": 11.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "just kind of like waking up and she",
      "offset": 13.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "tries to she's just sort of walking past",
      "offset": 15.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "it and the machine kind of like sucks",
      "offset": 17.039,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "her in. And she she gets kind of like",
      "offset": 19.92,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "stuck there and then what the machine",
      "offset": 23.279,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "does is it gradually like kind of puts",
      "offset": 25.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "armor plating on her and replaces her",
      "offset": 28.24,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "eyes with lasers and basically turns her",
      "offset": 30.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "into a sort of like automaton.",
      "offset": 32.719,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "And it's a very compelling scene. I",
      "offset": 35.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "think I was like terrified by it as a",
      "offset": 38.399,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "child, which is probably why I remember",
      "offset": 39.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it. But like that is a sort of metaphor",
      "offset": 40.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "for like you know what h what is",
      "offset": 44.32,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "happening to us, right? You know we're",
      "offset": 46,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "worried about the robots taking over or",
      "offset": 47.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "whatever. But in a way it's more like us",
      "offset": 50.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "being sucked into the machine, right? We",
      "offset": 52.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "become part just like that poor, you",
      "offset": 55.52,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "know, character. Um we get turned into",
      "offset": 57.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "we get turned into something we are not.",
      "offset": 60.719,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "you become part of that system and it it",
      "offset": 63.12,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "erodess your authenticity and in a way",
      "offset": 67.439,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "it erodess your humanity. People often",
      "offset": 70.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "say, well, you know, kind of chat GBT,",
      "offset": 72.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of course, it was exposed to more. I",
      "offset": 74.799,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "think I have the analogy in my book.",
      "offset": 76.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "It's exposed to the same amount of",
      "offset": 77.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "language as if, you know, a single human",
      "offset": 79.84,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "was continually learning language from",
      "offset": 82.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the middle of the last ice age or",
      "offset": 84.479,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "something like that, right? Is that's",
      "offset": 86,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "how much data it's exposed to. But it's",
      "offset": 87.119,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "a false analogy, right? It's a false",
      "offset": 89.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "analogy because we don't learn language",
      "offset": 91.6,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "like Chad GBT does, right? So language",
      "offset": 94.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "models are trained in a kind of like you",
      "offset": 98.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "might think of it as it's almost like a",
      "offset": 100.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Lamarian way right one generation of",
      "offset": 102.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "training if you think of a training",
      "offset": 105.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "episode right whatever happens in that",
      "offset": 106.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "gets inherited by the next training",
      "offset": 108.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "episode right that's not how we work",
      "offset": 111.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "right my memories are not inherited by",
      "offset": 112.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "my kids there's this fundamental",
      "offset": 114.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "disconnect we're Darwinian the models",
      "offset": 116.32,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "are sort of like I don't guess you could",
      "offset": 117.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "call them Lamarian so we're here in",
      "offset": 119.2,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "Oxford today to speak with Professor",
      "offset": 121.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Christopher Summerfield he's just",
      "offset": 123.439,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "written this book called these Strange",
      "offset": 125.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "New Minds, how AI learned to talk and",
      "offset": 127.04,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "what that means. He spoke about the",
      "offset": 130.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "history of artificial intelligence and",
      "offset": 132.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "how the allure of AI is to build a",
      "offset": 134,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "machine that can know what is true and",
      "offset": 136.56,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "what is right. Imagine a world in which",
      "offset": 138.879,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "everything",
      "offset": 142.879,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "was like that, but it could actually",
      "offset": 144.879,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "talk back to you and it could simulate",
      "offset": 146.72,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "all of the kind of social and emotional",
      "offset": 149.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "types of interaction that we have with",
      "offset": 152.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "people that we care about. So, you know,",
      "offset": 154.8,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the milk in your fridge is like your",
      "offset": 157.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "best friend, right? This is a very",
      "offset": 158.879,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "strange world in which, you know, of",
      "offset": 161.519,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "course that's a silly example. the milk",
      "offset": 164.879,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "in the fridge is never going to be your",
      "offset": 166.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "best friend. But, you know, kind of like",
      "offset": 167.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "there are, you know, as as I mentioned",
      "offset": 169.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "earlier, there are already, you know,",
      "offset": 171.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "kind of large numbers of people who are",
      "offset": 174.16,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "engaging with AI in ways that are kind",
      "offset": 176.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of like that mimic the sorts of",
      "offset": 179.84,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "interactions they have with other",
      "offset": 181.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "people. I thought that grounding you",
      "offset": 182.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "would need, you know, kind of like",
      "offset": 184.64,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "sensory signals. You need, you know, you",
      "offset": 186.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "can't know what a cat is just by reading",
      "offset": 188.319,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "about cats in books. You need to",
      "offset": 190.64,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "actually see a cat. But it turned out I",
      "offset": 192,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "was wrong. and so were many many many",
      "offset": 193.599,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "other people. And that is to my mind",
      "offset": 195.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "perhaps the most astonishing scientific",
      "offset": 198.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "discovery of the 21st century is that",
      "offset": 199.92,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "supervised learning is so good that you",
      "offset": 202.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "can actually learn about almost",
      "offset": 205.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "everything you need to know about the",
      "offset": 207.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "nature of reality. At least to have a",
      "offset": 208.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "conversation that every educated human",
      "offset": 210.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "would say is an intelligent conversation",
      "offset": 213.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "without ever having any sensory",
      "offset": 215.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "knowledge of the world just through",
      "offset": 218.64,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "words. That is mind-blowing.",
      "offset": 220.48,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "This podcast is supported by Google. Hey",
      "offset": 225.519,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "everyone, David here, one of the product",
      "offset": 228.319,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "leads for Google Gemini. Check out V3,",
      "offset": 230.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "our state-of-the-art AI video generation",
      "offset": 233.519,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "model in the Gemini app, which lets you",
      "offset": 235.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "create highquality 8-second videos with",
      "offset": 238.239,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "native audio generation. Try it with the",
      "offset": 240.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Google AI Pro plan or get the highest",
      "offset": 243.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "access with the Ultra plan. Sign up at",
      "offset": 245.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "gemini.google to get started and show us",
      "offset": 247.84,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "what you create.",
      "offset": 250.48,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "I'm Bajan Kusier. I'm starting an AI",
      "offset": 254.72,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "research lab called Tufalabs. It is",
      "offset": 257.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "funded from past ventures involving",
      "offset": 259.359,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "machine learning. So, we're a small",
      "offset": 261.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "group of highly motivated and",
      "offset": 263.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "hardworking uh people and the main",
      "offset": 265.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "thread that we are going to do is trying",
      "offset": 268.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to make models that reason effectively",
      "offset": 270.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and long-term trying to do AGI research.",
      "offset": 272.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "One of the big advantage is because",
      "offset": 275.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "we're early, there's going to be high",
      "offset": 276.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "freedom and high impact as someone new",
      "offset": 278.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "at twofabs. You can check out positions",
      "offset": 280.639,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "at twofabs.ai.",
      "offset": 283.6,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "So, um, Professor Summerfield, I have to",
      "offset": 288.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "congratulate you on this book. Your your",
      "offset": 291.28,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "previous book was my favorite book that",
      "offset": 292.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "I've ever read in in AI. Um, it's up",
      "offset": 294.479,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "there with Melanie Mitchell's book. And",
      "offset": 296.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "actually, Melanie Mitchell reviewed your",
      "offset": 299.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "new book as well. She did. So, um, very",
      "offset": 300.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "generously. Yeah. I'm a big fan of",
      "offset": 303.199,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "Melanie. So, um, you've been writing",
      "offset": 305.52,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "this for a couple of years and of course",
      "offset": 307.28,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "you actually extolled in in the the",
      "offset": 308.479,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "afterward that it takes quite a long",
      "offset": 310,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "time to get these things into",
      "offset": 311.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "publication and the space is moving very",
      "offset": 313.039,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "very quickly, but can can you give us a",
      "offset": 315.44,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "bit of an elevator pitch of of the book?",
      "offset": 317.199,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "Yeah, sure. So, uh, the book Yes, as you",
      "offset": 319.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "said, it was actually finished at the",
      "offset": 321.84,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "end of 2023. So that is kind of like",
      "offset": 323.44,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "cast your mind back to the sort of",
      "offset": 327.199,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "medieval period of AI if you like 12 14",
      "offset": 329.68,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "months after CHP had just been uh",
      "offset": 334.16,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "released. Uh yeah. So um the idea of the",
      "offset": 336.639,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "book was that um at that time and I",
      "offset": 341.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "guess you know to a large extent still",
      "offset": 344.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "today there was considerable debate over",
      "offset": 345.84,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "like what is the kind of cognitive",
      "offset": 348.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "status of these title of the book",
      "offset": 351.68,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "strange new minds that we seem to have",
      "offset": 354.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "created and are now increasingly",
      "offset": 356.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "interacting with. And that debate, the",
      "offset": 357.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the debate that I heard and I heard, you",
      "offset": 360.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "know, the same debate going on in",
      "offset": 362.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "academic conferences and down the pub,",
      "offset": 364.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the debate was, you know, kind of like",
      "offset": 367.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "should we think of these things as",
      "offset": 369.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "actually a bit like us? Are they",
      "offset": 371.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "thinking, you know, kind of are they",
      "offset": 373.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "reasoning? Are they understanding? And",
      "offset": 374.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of course, this very quickly became a",
      "offset": 376.96,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "highly polarized debate. And um that",
      "offset": 379.68,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "debate was kind of like on the one hand",
      "offset": 383.84,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "a bunch of people who you know really",
      "offset": 386.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "sort of vehemently rejected the idea",
      "offset": 389.199,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "that these tools could ever be anything",
      "offset": 390.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like us. It's just computer code which",
      "offset": 392.56,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "is of course true. And then on the other",
      "offset": 395.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "hand, you know, you had people who were",
      "offset": 397.199,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "like absolutely astonished by not just",
      "offset": 398.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "by the capability but by the pace of",
      "offset": 402.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "progress and thought, you know, kind of",
      "offset": 403.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "like we really are on course finally",
      "offset": 405.6,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "finally to build something that is like",
      "offset": 408,
      "duration": 8.4
    },
    {
      "lang": "en",
      "text": "as competent in a general way as humans.",
      "offset": 411.44,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "And this debate was playing out and I",
      "offset": 416.4,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "was like well this debate is not really",
      "offset": 418.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "grounded in I don't hear the language of",
      "offset": 420.639,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "cognition being used to un to scaffold",
      "offset": 424,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "this debate. So this debate is being had",
      "offset": 427.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "by people who care deeply about this",
      "offset": 429.759,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "issue but are not trained in kind of",
      "offset": 432.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "like a grounded computational sense of",
      "offset": 435.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "what does it actually mean to think?",
      "offset": 437.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "What does it actually mean to understand",
      "offset": 438.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "something? And so I thought as a",
      "offset": 441.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "cognitive scientist who has done a lot",
      "offset": 444.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "of work in AI, I probably quite well",
      "offset": 446.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "placed to talk about that. So that was",
      "offset": 448,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "sort of part one. And then you know kind",
      "offset": 449.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "of I also have for the past five years",
      "offset": 452.4,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "been very very interested in the um the",
      "offset": 456,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "implications of AI for society. And so I",
      "offset": 459.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "was working on that problem when I was",
      "offset": 462.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "at DeepMind and we were doing work to",
      "offset": 464.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "try and understand how AI could be used",
      "offset": 467.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "to kind of intervene directly in society",
      "offset": 469.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "in the economy um to help people find",
      "offset": 471.52,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "agreement. Um and at the time when I",
      "offset": 473.68,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "wrote the book I was just about to move",
      "offset": 477.44,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "to the AI as it was then AI safety",
      "offset": 479.28,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "institute in UK government um to work",
      "offset": 481.759,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "more on that. So I had a kind of",
      "offset": 484.639,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "understanding of like the landscape of",
      "offset": 486.24,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "um deployment risks, thinking about how",
      "offset": 490.479,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "AI might change the way that we live our",
      "offset": 492.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "lives and I thought probably putting",
      "offset": 494.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "those things together, I had enough of a",
      "offset": 496.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "unique perspective to write a book about",
      "offset": 498.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "it. So that's what I did. The the",
      "offset": 500.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "discourse is quite fractured and and you",
      "offset": 502.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "speak about this in great detail. You",
      "offset": 505.039,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "speak about the um you know the the the",
      "offset": 506.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "hypers, the anti-hypers, the the safety",
      "offset": 508.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "hypers and so on. And um early on in the",
      "offset": 510.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "book you kind of trace this back to two",
      "offset": 514,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "intellectual threads going back to the",
      "offset": 515.76,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "ancient Greeks. So Aristotle and Plato",
      "offset": 518.719,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "basically empir empiricism and and",
      "offset": 521.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "rationalism. C can you kind of sketch",
      "offset": 523.599,
      "duration": 4.001
    },
    {
      "lang": "en",
      "text": "that out? Yeah, sure. Well, the history",
      "offset": 525.839,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "of AI has itself been kind of kind of",
      "offset": 527.6,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "repeated a an ancient philosophical",
      "offset": 531.92,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "debate about whether the fundamental",
      "offset": 535.36,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "nature of bu building a mind including",
      "offset": 538.72,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "our mind is fundamentally about learning",
      "offset": 541.44,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "from experience or about reasoning",
      "offset": 545.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "particularly reasoning over latent or",
      "offset": 548.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "unobservable states right and that",
      "offset": 550.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "reasoning over unobservable states is of",
      "offset": 552.8,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "course traced back to Plato that's kind",
      "offset": 554.24,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "of this idea that you know kind of",
      "offset": 555.519,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "everything is fundamentally",
      "offset": 557.12,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "unobservable. we just get this sort of",
      "offset": 557.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "shadows on the cave wall or the light on",
      "offset": 559.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "the retina and we have to impute what's",
      "offset": 561.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "there and the you know the the",
      "offset": 563.839,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "corresponding view which you might trace",
      "offset": 566.08,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "back to Aristotle you know this idea",
      "offset": 567.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "that there is kind of um yeah that",
      "offset": 568.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "everything comes from experience and the",
      "offset": 570.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "history of AI of course was that very",
      "offset": 572.48,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "debate playing out actually in kind of",
      "offset": 574.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like in the workshop so to speak right",
      "offset": 576.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "or like at least or at least on the on",
      "offset": 578.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the on the keyboard so you know kind of",
      "offset": 580.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "on the one hand you know originally good",
      "offset": 583.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "old fashioned AI was structured around",
      "offset": 585.44,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "the idea that you know kind of we sort",
      "offset": 588.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "of know what how to work out what is",
      "offset": 591.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "true. And the reason we know how to work",
      "offset": 594.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "out what is true is because we have a",
      "offset": 596.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "kind of like long tradition back through",
      "offset": 598.08,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "kind of positivism and you know kind of",
      "offset": 600.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "early theories of reasoning back to bool",
      "offset": 603.279,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "and you know even lienets before that",
      "offset": 605.839,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "the idea that you know kind of like you",
      "offset": 609.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "can use logic to work out what is true.",
      "offset": 611.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "It is unassalably true that you know",
      "offset": 613.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "kind of like if I say that you know all",
      "offset": 615.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "men are Greek and Aristotle is a man",
      "offset": 618.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "then Aristotle is Greek right that is",
      "offset": 620.399,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "just like true by definition and so that",
      "offset": 622.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "seemed like a really sensible way to",
      "offset": 625.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "build AI right like you put in those",
      "offset": 627.68,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "primitives and you crank the handle and",
      "offset": 629.92,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "like you know if you've got enough",
      "offset": 634.16,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "computational power then you can derive",
      "offset": 635.279,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "really really complex things and it",
      "offset": 637.279,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "worked right it worked um so in the",
      "offset": 640.399,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "1950s um New and Simon built the the",
      "offset": 643.36,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "logic theorist right which I like to say",
      "offset": 647.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "is the first super intelligence 1958",
      "offset": 649.68,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "right so it's a a an AI system that was",
      "offset": 652.48,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "able to prove theorems",
      "offset": 656.24,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "that uh to prove theorems with a greater",
      "offset": 658.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "um kind of like well it was able to",
      "offset": 663.279,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "prove many of the theorems that were in",
      "offset": 664.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Brussell Whitehead's print mathematica",
      "offset": 666.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "which is like already a feat and it was",
      "offset": 668.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "able to find more elegant solutions to",
      "offset": 669.76,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "many of those theorems. So like that's",
      "offset": 672.8,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "astonishing. So you know initially it",
      "offset": 676.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "seemed like this kind of reasoning",
      "offset": 678.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "approach worked. Um and then you know",
      "offset": 680.079,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "kind of like of course",
      "offset": 683.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "what happened is that as the problems",
      "offset": 686.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that we tried to tackle with this kind",
      "offset": 688.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of approach moved from these very",
      "offset": 691.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "abstract sort of clean problems about",
      "offset": 693.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "maths and logic and we started to tackle",
      "offset": 695.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "problems in the real world. we ran into",
      "offset": 698.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "a fundamental problem which is that the",
      "offset": 700,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "real world just isn't kind of like all",
      "offset": 701.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that clean and nice and neat in the way",
      "offset": 704.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "that you know kind of like reasoning",
      "offset": 706.8,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "problems are designed to solve. So the",
      "offset": 708.399,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "world is full of weird exceptions which",
      "offset": 710.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "you know don't fundamentally aren't",
      "offset": 712.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "fundamentally amanable to analysis with",
      "offset": 715.6,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "like logic and so you know kind of like",
      "offset": 718.24,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "you had this other corresponding",
      "offset": 721.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "approach which is like the the learning",
      "offset": 724.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "approach or the empiricist approach and",
      "offset": 726.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "that was where neural networks and the",
      "offset": 728,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "deep learning revolution ultimately came",
      "offset": 730,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "from. Isn't it a crazy time to be alive",
      "offset": 731.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "though? I interviewed the CEO of one of",
      "offset": 733.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the largest companion bot platforms and",
      "offset": 734.959,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "the in the comment section uh there was",
      "offset": 739.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "a lot of negativity and you actually",
      "offset": 741.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "mentioned I think in your afterward that",
      "offset": 743.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "um it seems strange to us now that we",
      "offset": 745.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "would want to have a relationship with",
      "offset": 748,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "an AI companion and maybe we might",
      "offset": 750.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "revise that belief in in in a few years",
      "offset": 752.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "time but but I mean more broadly though",
      "offset": 754.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you said in your book that language is",
      "offset": 756.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "basically the biggest gift that has ever",
      "offset": 758.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "been given to us. It allows us to",
      "offset": 760.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "acquire knowledge and and communicate it",
      "offset": 763.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and it survives many generations. And I",
      "offset": 764.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "guess the the Rubicon moment with this",
      "offset": 767.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "technology maturing was chat GPT that",
      "offset": 769.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that changed everything in November",
      "offset": 772.16,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "2022. Sketch that out for me. Well, I",
      "offset": 774.16,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "mean, you know, the history of NLP, I",
      "offset": 778.24,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "guess, has been told many times,",
      "offset": 780.24,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "probably by people more qualified than",
      "offset": 781.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "me, but you know, kind of like we talked",
      "offset": 782.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "earlier about this kind of back and",
      "offset": 784.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "forth between learning and reasoning",
      "offset": 786.56,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and, you know, kind of in the history of",
      "offset": 788.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "NLP, what played out was exactly the",
      "offset": 789.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "same question, right? So NLP natural",
      "offset": 792.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "language processing as a sub field of AI",
      "offset": 795.04,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "and you know kind of the as in more",
      "offset": 797.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "general the sort of more general",
      "offset": 801.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "symbolic AI movement you know kind of",
      "offset": 803.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the early models were basically attempts",
      "offset": 805.2,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "to to define the computations that lead",
      "offset": 808.56,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "to the generation of valid sentences",
      "offset": 813.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "right that's basically the gauntlet that",
      "offset": 815.2,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "Chsky lays down in his 1958 book and you",
      "offset": 817.279,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "know there are a set of rules which like",
      "offset": 820.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "you know if you could just apply them",
      "offset": 823.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "all lawfully they would allow for the",
      "offset": 825.12,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "generation of sentences that you know",
      "offset": 828.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "kind of like obey the rules that we",
      "offset": 831.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "would all understand you know to be like",
      "offset": 834.16,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "what makes a valid sentence so syntax",
      "offset": 837.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "right Charles was mainly concerned with",
      "offset": 840.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "English of course so he's worried about",
      "offset": 842.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "English syntax but like so that movement",
      "offset": 843.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "you know kind of of course was then just",
      "offset": 847.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "like neural networks came along in the",
      "offset": 849.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "wider field was then challenged by",
      "offset": 850.959,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "statistical approaches. And that went",
      "offset": 853.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "back and forth and back and forth and",
      "offset": 854.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "back and forth. And you know, when the",
      "offset": 856,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "deep learning revolution happened by",
      "offset": 859.6,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "2015, we had models that could you could",
      "offset": 861.76,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "train a model on the complete works of",
      "offset": 866.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "Shakespeare",
      "offset": 868,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "and it could generate something that",
      "offset": 869.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "looked a lot like Shakespeare, but it",
      "offset": 871.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "didn't make any sense. And so still you",
      "offset": 873.519,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "know kind of even when the deep learning",
      "offset": 876.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "revolution was in full swing",
      "offset": 878.399,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "most people including myself thought",
      "offset": 880.88,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "there is no way that the mere",
      "offset": 884.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "application of like powerful function",
      "offset": 886.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "approximation and lots of data is going",
      "offset": 889.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to solve this problem. I did not believe",
      "offset": 890.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that to be true. I thought that I think",
      "offset": 892.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "like any other people that you would",
      "offset": 894.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "need grounding. You would need you know",
      "offset": 896.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "kind of like sensory signals. You need",
      "offset": 898.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "you know you can't know what a cat is",
      "offset": 900.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "just by reading about cats in books. you",
      "offset": 902.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "need to actually see a cat. Um, but it",
      "offset": 904.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "turned out I was wrong and so were many",
      "offset": 907.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "many many other people. And that is that",
      "offset": 909.44,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "is to my mind an absolutely astonishing",
      "offset": 912.16,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "perhaps the most astonishing scientific",
      "offset": 916.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "discovery of the 21st century is that",
      "offset": 918.079,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "you supervised learning is so good that",
      "offset": 921.04,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "you can actually learn about almost",
      "offset": 925.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "everything you need to know about the",
      "offset": 927.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "nature of reality at least to have a",
      "offset": 928.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "conversation that every educated human",
      "offset": 930.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "would say is an intelligent conversation",
      "offset": 933.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "without ever having any sensory",
      "offset": 935.36,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "knowledge of the world. just through",
      "offset": 938.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "words. That is mind-blowing and I think",
      "offset": 940.639,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "it changes the way we think about many",
      "offset": 943.44,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "many things. Certainly changes how I",
      "offset": 944.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "think about things. So one big theme in",
      "offset": 946.639,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "the book is this dichotomy between um",
      "offset": 948.72,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "equivalentists and um um",
      "offset": 951.68,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "exceptionalists. So some folks argue",
      "offset": 954.639,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that humans are exceptional and the",
      "offset": 957.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "kinds of cognizing that language models",
      "offset": 959.199,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "do are not really, you know, in the same",
      "offset": 961.44,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "category. Yeah. So I mean that",
      "offset": 964.079,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "distinction is a cartoon. So, of course,",
      "offset": 967.519,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you know, kind of like everyone has a",
      "offset": 970.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "different view about the relationship",
      "offset": 972.079,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "between AI and humans or or or",
      "offset": 974.88,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "biological intelligence in general. And",
      "offset": 978.079,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "you know, kind of like the evidence",
      "offset": 980.959,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "clearly admits a spectrum of different",
      "offset": 983.519,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "views. Um, but I found it useful in the",
      "offset": 986.16,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "book to kind of cartoon extremes of that",
      "offset": 988.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "continuum. And you know, kind of at one",
      "offset": 991.279,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "end you have people who I think probably",
      "offset": 994.16,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "just kind of like ideologically reject",
      "offset": 996.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the idea that something that is",
      "offset": 998.959,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "non-human",
      "offset": 1000.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "could ever use could it that that we",
      "offset": 1002.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "should refer to that refer to whatever",
      "offset": 1005.68,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "that system is doing behaviorally or",
      "offset": 1008.72,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "cognitively using the same vocabulary as",
      "offset": 1011.6,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "we used to apply to a human. So you know",
      "offset": 1014.639,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "kind of like clearly today's models are",
      "offset": 1017.519,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "capable of reasoning at levels which is",
      "offset": 1019.92,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "beyond the capability of most even",
      "offset": 1023.199,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "educated humans today right certainly",
      "offset": 1025.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "when it comes to formal problems like",
      "offset": 1028,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "maths and logic and so on. So it can",
      "offset": 1029.28,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "reason like a human. But there are",
      "offset": 1033.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "people who I think just fundamentally",
      "offset": 1035.12,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "think that we shouldn't think of that as",
      "offset": 1037.76,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "reasoning because we should kind of like",
      "offset": 1040.799,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "circumscribe",
      "offset": 1044.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the definition of reasoning as something",
      "offset": 1046.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "that humans do. And that is a stance",
      "offset": 1048.24,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "which I think is not really it's not",
      "offset": 1051.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "really about",
      "offset": 1054.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the empirical evidence although some",
      "offset": 1056.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "people kind of construe it to be that",
      "offset": 1059.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "way by saying oh the models aren't",
      "offset": 1060.559,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "actually that good at reasoning which I",
      "offset": 1062.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "think is a you know even in 2023 it was",
      "offset": 1063.679,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "a hard to defend view now it's probably",
      "offset": 1066.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "an even harder to defend view but I",
      "offset": 1068.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "think it's kind of like it comes from a",
      "offset": 1070.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "place which is like a sort of radical",
      "offset": 1072.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "humanism right it's a sort of it is a",
      "offset": 1074.799,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "desire to kind of like really ring fence",
      "offset": 1077.44,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "a set of cognitive concepts and think of",
      "offset": 1081.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "them as uniquely human. And like for",
      "offset": 1084.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "people who care about humans, which by",
      "offset": 1086.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the way includes me, like I can see why",
      "offset": 1088.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that's really important. But what it",
      "offset": 1090.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "does lead you down the road of is kind",
      "offset": 1091.84,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "of like a a a refusal to kind of ever",
      "offset": 1093.84,
      "duration": 8.24
    },
    {
      "lang": "en",
      "text": "see the cognition that an AI will engage",
      "offset": 1098.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "in and the cognition that a human will",
      "offset": 1102.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "engage in as comparable even when their",
      "offset": 1103.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "kind of capabilities are clearly",
      "offset": 1107.36,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "matched. So that's what I call kind of",
      "offset": 1108.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "exceptionalists because in a way they're",
      "offset": 1110.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "sort of like you know kind of they they",
      "offset": 1112.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "they are espousing a view of human",
      "offset": 1114.72,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "exceptionalism. Humans are special and",
      "offset": 1116.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "different. End of story. And you know",
      "offset": 1117.919,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "somewhat kind of cheekily in the book I",
      "offset": 1120.88,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "compare that to kind of earlier",
      "offset": 1123.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "instances of human exceptionalism. Of",
      "offset": 1125.919,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "course that occurred when you know",
      "offset": 1127.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Darwin first proposed that you know we",
      "offset": 1128.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "weren't kind of uniquely created by God",
      "offset": 1130.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "but were actually related to all the",
      "offset": 1132.559,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "other species and like you know kind of",
      "offset": 1133.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "when the heliocentric model um you know",
      "offset": 1135.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "kind of first became established and was",
      "offset": 1138.16,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "rejected by the Catholic Church and so",
      "offset": 1140.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "on. But that was kind of I guess those",
      "offset": 1141.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "analogies give color but fundamentally",
      "offset": 1143.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you know I think it is a defensible",
      "offset": 1146.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "position but it but it's it's not a it's",
      "offset": 1147.679,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "an ideological position I think. Yes. So",
      "offset": 1150.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you invoke this notion called the duck",
      "offset": 1153.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "test. You know basically if it looks",
      "offset": 1155.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "like a duck and quacks like a duck we",
      "offset": 1157.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "should call it a duck. And um and by",
      "offset": 1159.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "extension I I guess you would call",
      "offset": 1161.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "yourself a functionalist which is this",
      "offset": 1163.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "idea that it's not about the internal",
      "offset": 1165.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "constitution or the mechanism but but",
      "offset": 1167.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "it's about the the function that it",
      "offset": 1168.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "performs. And we can use this",
      "offset": 1170.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "information metaphor to say well you",
      "offset": 1172,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "know if we have an AI system over here",
      "offset": 1173.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "which is doing cognizing and it's doing",
      "offset": 1175.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the same types of things then we could",
      "offset": 1177.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "reasonably make the inf inference that",
      "offset": 1179.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "it's appropriate to use mentalistic",
      "offset": 1181.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "language to describe it. That's",
      "offset": 1183.12,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "absolutely right. Yeah. And you're",
      "offset": 1184.72,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "absolutely right to say that it's a",
      "offset": 1186.08,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "functionalist perspective and that is",
      "offset": 1187.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "broadly my perspective. Um I think you",
      "offset": 1188.799,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "know kind of once again that",
      "offset": 1192.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "functionalism you know it's it's kind of",
      "offset": 1194,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "like from a scientific standpoint right",
      "offset": 1196.64,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "I'm like if it reasons like a human then",
      "offset": 1198.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "we may as well use the term reasoning",
      "offset": 1202.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "but that doesn't imply a broader set of",
      "offset": 1204.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "equivalents right that doesn't for",
      "offset": 1206.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "example imply moral equivalence it",
      "offset": 1207.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "doesn't apply you know it doesn't it",
      "offset": 1210.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "doesn't mean that you know kind of like",
      "offset": 1212.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the motivations or you know",
      "offset": 1214.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "relationships we have with AI are",
      "offset": 1216.72,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "similar to those we have with humans",
      "offset": 1218.64,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "absolutely not of course they're",
      "offset": 1219.919,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "completely different. Um but it does",
      "offset": 1221.039,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "mean that you know when purely you know",
      "offset": 1224.16,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "if you put on cognitive scientist hat",
      "offset": 1225.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and you're really just thinking about",
      "offset": 1227.919,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "you know let's let's talk dirty about",
      "offset": 1229.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "information processing then you know",
      "offset": 1232.559,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "kind of like that functionalist",
      "offset": 1234.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "perspective yeah if it walks if it",
      "offset": 1236.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "quacks like a duck it's you may as well",
      "offset": 1238.24,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "call it a duck. The anthropomorphism",
      "offset": 1240.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "thing makes it a little bit more tricky.",
      "offset": 1243.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "And I I think um in in a film if you see",
      "offset": 1245.039,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "um a robot peel the face away and all of",
      "offset": 1248.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "a sudden you you see they're not they're",
      "offset": 1250.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "not a human they're a robot and the",
      "offset": 1252.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "intuition there is that they have a",
      "offset": 1254.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "different mechanism and this is what",
      "offset": 1256.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "John S was getting at when he was",
      "offset": 1258.48,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "talking about the Chinese room argument",
      "offset": 1259.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "and um I read what you had to say about",
      "offset": 1261.28,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "that. So I think I think S was saying",
      "offset": 1263.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that when when you take um a type of",
      "offset": 1265.919,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "process and you represent it in silicone",
      "offset": 1269.12,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "as computation sands the machine which",
      "offset": 1272.32,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "because we are biio machines so we are",
      "offset": 1275.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "causally embedded in in the world and",
      "offset": 1278.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "when when we do things there's this you",
      "offset": 1280.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "know large kind of light cone of",
      "offset": 1282.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "low-level interactions that happen and",
      "offset": 1285.039,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "and I guess this is his notion of",
      "offset": 1287.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "semantics and and I I think um professor",
      "offset": 1289.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "summer you subs subscribed to something",
      "offset": 1293.12,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "called a distributional notion of",
      "offset": 1294.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "semantics which is that we can actually",
      "offset": 1296.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "remove things from the physical world",
      "offset": 1299.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and recreate patterns of activity in",
      "offset": 1301.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "silicone and and for all intents and",
      "offset": 1304.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "purposes it would have the same meaning",
      "offset": 1306.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "that's that yeah I mean I I I do",
      "offset": 1308.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "subscribe to that view I mean I think",
      "offset": 1311.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "that you know kind of of course as a not",
      "offset": 1313.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "only a cognitive scientist but a",
      "offset": 1315.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "neuroscientist I'm uniquely aware that",
      "offset": 1316.799,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "you know whilst there are many",
      "offset": 1320.88,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "differences between machine learning",
      "offset": 1322.159,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "systems and the computations that go on",
      "offset": 1323.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "in the brain. There are also like",
      "offset": 1325.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "astonishing similarities, right? At the",
      "offset": 1327.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "level of kind of certainly at the",
      "offset": 1330,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "algorithmic level, not not clearly at",
      "offset": 1331.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the implementational level, you know,",
      "offset": 1334.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "kind of like, you know, neural networks",
      "offset": 1335.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "don't tend to have, you know, um they",
      "offset": 1337.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "don't have to have they don't have many",
      "offset": 1340.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "many different types of sinapses and we",
      "offset": 1341.76,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "don't have many different type you don't",
      "offset": 1343.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "have basket cells and you know, fast",
      "offset": 1344.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "inhibitory inter neurons and things like",
      "offset": 1346.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "that. But there is at the level of the",
      "offset": 1348.24,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "neural network there is a striking",
      "offset": 1350.96,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "similarity. And you know kind of the",
      "offset": 1354.799,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "most reasonable assumption to me is that",
      "offset": 1358,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "there are broad shared computational",
      "offset": 1362.24,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "principles that happen when you take",
      "offset": 1365.36,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "networks of neurons that are wired up to",
      "offset": 1369.52,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "have some dense interconnecting and you",
      "offset": 1373.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "know for the most part recurrent. We",
      "offset": 1376.4,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "have to remember the transform is not a",
      "offset": 1377.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "recurrent architecture. So it probably",
      "offset": 1378.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "mim it uses tricks to mimic what a",
      "offset": 1380.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "recurrent architecture does. But like",
      "offset": 1383.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "for the most part recurrent network and",
      "offset": 1384.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "we know that because we know for example",
      "offset": 1388.48,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "that the way that information after",
      "offset": 1390.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "various after optimization has been",
      "offset": 1393.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "applied and actually sometimes even",
      "offset": 1396.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "before optimization has been applied. We",
      "offset": 1397.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "know that there are striking",
      "offset": 1399.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "similarities in the semantic",
      "offset": 1401.12,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "representations that you can read out of",
      "offset": 1404.4,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "those two classes of network biological",
      "offset": 1407.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and artificial by doing experiments,",
      "offset": 1409.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "right? So you know kind of we know that",
      "offset": 1411.679,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "you can go into the brains of monkeys or",
      "offset": 1413.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "if you have access to it humans while",
      "offset": 1417.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "neuro imaging or whatever and you can",
      "offset": 1418.88,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "see patterns of representation that",
      "offset": 1420.96,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "express themselves in terms of not just",
      "offset": 1424.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "you know in terms of like coding",
      "offset": 1427.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "properties but in terms of like neural",
      "offset": 1429.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "manifolds in terms of like neural",
      "offset": 1430.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "geometry express themselves very much",
      "offset": 1432.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like in the neural network. So you know",
      "offset": 1434.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "kind of like the substrate",
      "offset": 1437.12,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "is shared in some very loose sense. The",
      "offset": 1439.6,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "behavior is shared",
      "offset": 1444.08,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "in some you know perhaps not so loose",
      "offset": 1447.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "sense. And",
      "offset": 1450.159,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "to me it makes sense to you know kind of",
      "offset": 1452.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "science as a puzzle right like you get",
      "offset": 1455.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "bits of information and you try to come",
      "offset": 1457.279,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "up with the most parimmonious",
      "offset": 1458.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "explanation. And for me, the most",
      "offset": 1460.32,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "parsimmonious explanation is that by,",
      "offset": 1461.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "you know, kind of like sheer kind of",
      "offset": 1465.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "like a mixture of like luck and like,",
      "offset": 1467.76,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "you know, trying enormously hard, we've",
      "offset": 1471.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "kind of got to a place where we've built",
      "offset": 1474.32,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "something that is a bit like a brain.",
      "offset": 1476.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "And lo and behold, it does stuff that is",
      "offset": 1477.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "a bit like a brain. That doesn't mean it",
      "offset": 1479.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "does everything. And it also doesn't",
      "offset": 1481.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "mean that it is like a human in the",
      "offset": 1483.52,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "sense that like meaning how we should",
      "offset": 1486.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "treat it, how we should think of it. But",
      "offset": 1488.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it does mean that the computations are",
      "offset": 1491.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "most likely shared. I realize this is a",
      "offset": 1492.799,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "difficult argument to make and and there",
      "offset": 1495.279,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "were some scornful comments in in your",
      "offset": 1497.36,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "book about this, but um there are some",
      "offset": 1498.96,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "people who still make the argument that",
      "offset": 1500.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "it only appears to be reasoning and",
      "offset": 1502.159,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "understanding, but it's not really. And",
      "offset": 1503.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "is it possible that Chomsky could still",
      "offset": 1505.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "be right in some sense? So you know his",
      "offset": 1507.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "ideas obviously he's a rationalist but",
      "offset": 1509.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "it's this platonistic idea essentially",
      "offset": 1511.679,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "that um the laws of nature have bestowed",
      "offset": 1513.6,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "our brains with the with with with the",
      "offset": 1517.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "the secret you know functions that",
      "offset": 1519.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "explain how the universe works and and",
      "offset": 1521.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "in a sense he he's quite similar to a",
      "offset": 1524.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "lot of folks now he's he's a",
      "offset": 1526.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "computationalist he doesn't subscribe to",
      "offset": 1528.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "this causal graph thing um but he does",
      "offset": 1530.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "think that the brain is a touring",
      "offset": 1533.2,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "machine and we should do this recursive",
      "offset": 1534.799,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "merge type stuff but Um, is it possible",
      "offset": 1536.559,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "that empiricism seems to work, but it's",
      "offset": 1540,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "kind of like a pile of sand and Chomsky",
      "offset": 1543.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "would still be right if only it were",
      "offset": 1545.919,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "possible to have like the low-level",
      "offset": 1547.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "stuff. Yeah. I mean I think you know",
      "offset": 1549.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "kind of the what we will find out my",
      "offset": 1550.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "guess is that what the end point will be",
      "offset": 1553.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "are when we sort of look back after",
      "offset": 1556.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "perhaps having you know figured this",
      "offset": 1558.48,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "stuff out is that in the end the",
      "offset": 1560.159,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "dichotomy that was set up and that we",
      "offset": 1563.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "thought about literally for millennia",
      "offset": 1565.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "actually is kind of a question of",
      "offset": 1568.08,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "perspective right so in a way there is a",
      "offset": 1570,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "way in which the rationalist broadly",
      "offset": 1573.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "construing",
      "offset": 1575.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "is really important for computation. But",
      "offset": 1577.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "what they were wrong about is how you",
      "offset": 1580.799,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "acquire the ability to reason. So I",
      "offset": 1582.48,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "think what we have learned since 2019 is",
      "offset": 1585.6,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "that the types of computations that you",
      "offset": 1589.76,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "need to reason about the world can be",
      "offset": 1593.52,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "learned through large scale parameter",
      "offset": 1596.08,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "optimization through through through",
      "offset": 1599.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "function approximation essentially",
      "offset": 1601.039,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "through training a neural network and",
      "offset": 1602.48,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "that so so in a sense Chsky kind of is",
      "offset": 1604.799,
      "duration": 7.841
    },
    {
      "lang": "en",
      "text": "not wrong that you know there are rules",
      "offset": 1608.88,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "to language those rules need to be",
      "offset": 1612.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "learned.",
      "offset": 1615.039,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "It was just wrong about how they got",
      "offset": 1616.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "learned, right? And like, you know, of",
      "offset": 1617.919,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "course, there's always a slight of hand",
      "offset": 1620,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "in saying, well, you're born, this is",
      "offset": 1621.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "inborn because it really just begs the",
      "offset": 1622.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "question of how it's inborn, right? And,",
      "offset": 1625.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you know, where does that where does",
      "offset": 1627.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "that gene that allows you to do",
      "offset": 1629.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "recursion or merge or whatever, where",
      "offset": 1631.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "does it come from? And, you know, kind",
      "offset": 1633.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "of like what was the pressure that that",
      "offset": 1635.679,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "got it there? And you know I think that",
      "offset": 1637.279,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 1640.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "there is there is a there is a subtlety",
      "offset": 1642.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "to an argument that's often not kind of",
      "offset": 1645.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "expanded on. And I think it is that you",
      "offset": 1648.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "know of course we are born with the",
      "offset": 1650,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "predisposition to learn language. And we",
      "offset": 1653.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "know that that is not just kind of like",
      "offset": 1655.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "an accident, right? Because other",
      "offset": 1657.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "species, even highly highly intelligent",
      "offset": 1659.2,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "species like chimpanzees and gorillas,",
      "offset": 1662.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "capable of really really sophisticated",
      "offset": 1664.799,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "forms of social interaction, you know,",
      "offset": 1666.799,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "political machinations and so on. They",
      "offset": 1669.6,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "can't learn structured language. So they",
      "offset": 1673.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "can learn to communicate, but they can't",
      "offset": 1676.799,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "learn to communicate in like infinitely",
      "offset": 1678.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "expressive sentences, right? that guided",
      "offset": 1680.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "by lawful syntax",
      "offset": 1682.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "and the fact that they can't do that",
      "offset": 1684.559,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "tells us that there is something special",
      "offset": 1687.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "about our evolution",
      "offset": 1689.919,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and so the question is how do you",
      "offset": 1692.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "explain that in the in the deep learning",
      "offset": 1694.399,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "framework right and people often say",
      "offset": 1696.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "well you know kind of chatgpt of course",
      "offset": 1698.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it was exposed to more I think I have",
      "offset": 1701.039,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the analogy in my book it's exposed to",
      "offset": 1702.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the same amount of language as if you",
      "offset": 1704.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "know a single human was continually",
      "offset": 1706.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "learning language from the middle of the",
      "offset": 1709.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "last ice age or something like that,",
      "offset": 1710.799,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "right? Is that's how much data it's",
      "offset": 1712.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "exposed to. But it's a false analogy,",
      "offset": 1713.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "right? It's a false analogy because we",
      "offset": 1716.64,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "don't learn language like Chad GBT does,",
      "offset": 1718.88,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "right? So language models are trained in",
      "offset": 1722.159,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "a kind of like you might think of it as",
      "offset": 1725.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "it's almost like a Lamarian way, right?",
      "offset": 1727.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "One generation of training, if you think",
      "offset": 1730.399,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "of a training episode, right? Whatever",
      "offset": 1732.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "happens in that gets inherited by the",
      "offset": 1734,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "next training episode, right? That's not",
      "offset": 1736.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "how we work, right? my memories are not",
      "offset": 1738,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "inherited by my kids. Right? So there's",
      "offset": 1740,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "this fundamental disconnect. We're",
      "offset": 1743.36,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "Darwinian. The models are sort of like I",
      "offset": 1744.64,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "don't guess you could call them",
      "offset": 1746.399,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "Lamarian.",
      "offset": 1747.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "And so you can't compare the amount of",
      "offset": 1749.039,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "training that JGBT has to the amount of",
      "offset": 1753.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "training that we have because it's just",
      "offset": 1756.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "kind of like apples and oranges, right?",
      "offset": 1757.6,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "what happens in a person's lifetime",
      "offset": 1760.559,
      "duration": 7.761
    },
    {
      "lang": "en",
      "text": "is like it's been guided although it's",
      "offset": 1764.08,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "not you know it doesn't have the content",
      "offset": 1768.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "in that you know I live in Britain but",
      "offset": 1771.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "if I had you know my kids have been born",
      "offset": 1773.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "in Japan they would grow up speaking",
      "offset": 1775.84,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "Japanese it's been but it's been guided",
      "offset": 1776.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "by all of the other generations of",
      "offset": 1779.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "learning which like inculcate this",
      "offset": 1781.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "predisposition to learning language",
      "offset": 1782.88,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "right and we never think of language",
      "offset": 1784.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "models in that way it's like metal",
      "offset": 1785.919,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "learning actually it's really just like",
      "offset": 1787.76,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "metalarning",
      "offset": 1788.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "And so Chsky is right that we are born",
      "offset": 1790,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "with prior because those priors are the",
      "offset": 1792.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "the earlier cycles of Darwinian",
      "offset": 1795.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "evolution that are that everything that",
      "offset": 1798.32,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "went on before we were born, right, as",
      "offset": 1801.36,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "individuals. And so this kind of like I",
      "offset": 1804.559,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "think when we talk about data efficiency",
      "offset": 1807.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and we try to make claims about data",
      "offset": 1811.279,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "efficiency between biological and",
      "offset": 1812.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "artificial intelligence, we need to be",
      "offset": 1814.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "really really specific about whether",
      "offset": 1816,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "we're talking about fogyny or ontogyny.",
      "offset": 1817.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "So evolution or development and neither",
      "offset": 1820.399,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "really works as a comparator.",
      "offset": 1822.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "So it's just more complicated.",
      "offset": 1825.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "Is is it possible that we're being",
      "offset": 1828.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "deceived in some way though because",
      "offset": 1830.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "there are certainly computational",
      "offset": 1832,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "limitations with neural networks? There",
      "offset": 1834.559,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "are um complexity limitations,",
      "offset": 1836.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "learnability um limitations. So we we",
      "offset": 1838.399,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "kind of know that there are certain",
      "offset": 1842,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "types of things that the networks can't",
      "offset": 1843.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "do that that we can do and we are",
      "offset": 1845.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "susceptible to this",
      "offset": 1848.559,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "anthropomorphization. You you mentioned",
      "offset": 1849.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "this wonderful experiment where it was",
      "offset": 1851.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like a cartoon of arrows kind of",
      "offset": 1853.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "interacting with each other and and",
      "offset": 1855.2,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "humans interpret them as as agents. And",
      "offset": 1856.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "this is the grumpy bully agent and there",
      "offset": 1858.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "was the the Eliza um machine as well you",
      "offset": 1860.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "know where it was a very simple program",
      "offset": 1863.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "which was quite sickopantic and and",
      "offset": 1865.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "people really um you know took deeper",
      "offset": 1867.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "meaning from that. Is is it possible",
      "offset": 1870.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "that we're reading more into what's",
      "offset": 1872.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "going on here than is actually the case?",
      "offset": 1874.559,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Well, it's definitely true that we are",
      "offset": 1876.399,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "intrinsically prone to attribute kind of",
      "offset": 1878.399,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "like much more elaborate forms of",
      "offset": 1882.399,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "cognition to all other non-human agents",
      "offset": 1885.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "actually where simpler explanations may",
      "offset": 1889.2,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "be available. Right? Everyone who is a",
      "offset": 1891.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "pet owner will be very familiar with",
      "offset": 1894.159,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "this concept. Right? It's like the",
      "offset": 1896.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "easiest thing in the world to kind of",
      "offset": 1897.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "like attribute complex humanlike states",
      "offset": 1899.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "to your cat or your dog or your hamster.",
      "offset": 1902,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Um, when it may or may not be merited,",
      "offset": 1904.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "right? We know that people have been",
      "offset": 1906.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "doing this for centuries, right? So,",
      "offset": 1908.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "psychologists know about the clever",
      "offset": 1910.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "hands effect. Clever hands effect. Very",
      "offset": 1912.48,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "famously, there was a performing horse",
      "offset": 1914.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "which apparently could do mathematics,",
      "offset": 1917.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "so simple arithmetic. And you know it",
      "offset": 1919.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "did so by repeatedly stamping its its",
      "offset": 1921.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "hoof the correct number of times to",
      "offset": 1924.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "solve a sum. Um but you know of course",
      "offset": 1926.64,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "it wasn't actually doing mathematics.",
      "offset": 1930.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "What it was doing was checking whether",
      "offset": 1933.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "its trainer gave it a kind of like",
      "offset": 1935.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "unconscious signal that it should stop",
      "offset": 1937.84,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "tapping. And so of course, you know, we",
      "offset": 1940.08,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "are always prone to kind of want to",
      "offset": 1943.039,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "imputee these more complex thoughts and",
      "offset": 1946.559,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "feelings and emotional states or complex",
      "offset": 1949.76,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "abilities to models. I don't deny that",
      "offset": 1953.919,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "for a moment. But, you know, kind of",
      "offset": 1956.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "when you look at today's frontier",
      "offset": 1959.519,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "models,",
      "offset": 1960.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that may be going on. You know, we may",
      "offset": 1962.64,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "be thinking, &quot;Oh, it's really my",
      "offset": 1964.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "friend.&quot; When actually it's not. But in",
      "offset": 1965.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "terms of the raw capability, the numbers",
      "offset": 1968.08,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "are the numbers, right? The models are",
      "offset": 1970.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "just really good. And there's no denying",
      "offset": 1973.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "that. Yes, they can't do everything.",
      "offset": 1974.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "There's lots of things they can't do and",
      "offset": 1977.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "they're still not fully robust, but they",
      "offset": 1979.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "are really good. It's not they're not",
      "offset": 1980.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "just clever hands. You you said yourself",
      "offset": 1983.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "something in the book which intrigued",
      "offset": 1986.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "me, which is that um even you know",
      "offset": 1987.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "cognitive scientists and neuroscientists",
      "offset": 1989.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and and and psychologists don't really",
      "offset": 1991.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "know what the answer to the question is.",
      "offset": 1993.84,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "If you said what is thinking when we",
      "offset": 1995.44,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "talk about these mentalistic properties",
      "offset": 1996.88,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "and of course um about this",
      "offset": 1998.24,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "intentionality thing you know that the",
      "offset": 1999.919,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "agency in interpreting the um the the",
      "offset": 2001.519,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "sort of intentions of cartoon arrows",
      "offset": 2005.2,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "that are interacting with each other and",
      "offset": 2007.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "and Daniel Dennett of course coined this",
      "offset": 2008.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "intentional stance which is that",
      "offset": 2010.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "essentially we we need to to understand",
      "offset": 2012.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the world. It's a very complex place and",
      "offset": 2014.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and that's where perhaps some of these",
      "offset": 2017.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "mentalistic properties come from. Do do",
      "offset": 2019.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "you subscribe to an idea? I read this",
      "offset": 2021.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "wonderful book called um The Mind is",
      "offset": 2023.039,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Flat by Nick Chaita and one of my",
      "offset": 2024.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "favorites. Yeah, a lot of these",
      "offset": 2026.159,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "mentalistic properties even even in",
      "offset": 2028,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "humans perhaps are a bit of an illusion.",
      "offset": 2029.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "What what do you think? Um I love that",
      "offset": 2032.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "book. Yeah, I mean that book essentially",
      "offset": 2034.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "argues that you know kind of like we",
      "offset": 2036.32,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "draw heavily upon prior experience to",
      "offset": 2039.6,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "formulate what we like. So in other",
      "offset": 2043.84,
      "duration": 5.999
    },
    {
      "lang": "en",
      "text": "words, our preferences are a product of",
      "offset": 2046.08,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "not just of like kind of some kind of",
      "offset": 2049.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "internal value function which is",
      "offset": 2052.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "different for everyone. You know, kind",
      "offset": 2054.48,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "of like you like apples more than",
      "offset": 2055.839,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "oranges and I like oranges more than",
      "offset": 2057.2,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "apples, but it's actually due to our",
      "offset": 2058.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "memories for our past experiences. So",
      "offset": 2060.399,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you don't actually like apples more than",
      "offset": 2062.24,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "oranges, but you just think you do",
      "offset": 2063.919,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "because you had an apple this morning",
      "offset": 2065.119,
      "duration": 2.161
    },
    {
      "lang": "en",
      "text": "and you're like, &quot;Oh, I had an apple",
      "offset": 2066.159,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "this morning. I must like apples more",
      "offset": 2067.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "than oranges.&quot; So it's this beautiful",
      "offset": 2068.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "theory which in which you know kind of",
      "offset": 2070.48,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "like we essentially construct ourselves",
      "offset": 2073.28,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "out of our own actions and you know kind",
      "offset": 2076.72,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "of it can it can account for an",
      "offset": 2079.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "astonishing broad range of phenomena.",
      "offset": 2081.359,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "Um,",
      "offset": 2084.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "do we do that? You know, I think I",
      "offset": 2086.72,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "that's a scientific theory, but I think,",
      "offset": 2089.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you know, kind of in our everyday",
      "offset": 2090.879,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "interaction with other agents, so",
      "offset": 2093.04,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "animals with technology, like we do the",
      "offset": 2097.2,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "opposite, like we impute, this is what",
      "offset": 2099.76,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Dennett says, right? We impute, you",
      "offset": 2103.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "know, far more than is due often, right?",
      "offset": 2105.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "So, you know, your car fails to start in",
      "offset": 2108.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the morning and you get cross with it,",
      "offset": 2110.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "you know, as if it was just being",
      "offset": 2114,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "stubborn. But of course, there's no",
      "offset": 2115.359,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "point getting stuck with it. Stop",
      "offset": 2117.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "getting cross with it, right? And that",
      "offset": 2118.8,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "is an example of the intentional stance.",
      "offset": 2121.359,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "It is undoubtedly true that for example,",
      "offset": 2124.32,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "you know, kind of like when interacting",
      "offset": 2128,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "with the models, people are very very",
      "offset": 2130.32,
      "duration": 8.56
    },
    {
      "lang": "en",
      "text": "prone to attribute intentionality. So in",
      "offset": 2134.64,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "the technical kind of like um",
      "offset": 2138.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "philosophical sense of the word, right?",
      "offset": 2141.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "In other words, that that they there is",
      "offset": 2143.68,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "something kind of like that it is like",
      "offset": 2146.72,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "to be that thing, right? And people are",
      "offset": 2149.599,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "really prone to attribute that sense of",
      "offset": 2153.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "like, you know, they have some essence,",
      "offset": 2156.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "some sense of what it is like to be",
      "offset": 2158.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "themselves to",
      "offset": 2160.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "probably all forms of technology, but",
      "offset": 2163.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "especially to AI because they can talk",
      "offset": 2164.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "back. People do that all the time. Um,",
      "offset": 2166.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you know, this is manifest in so many",
      "offset": 2169.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "different ways. you know, of course, the",
      "offset": 2171.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "types of interactions that people have",
      "offset": 2173.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "with today's frontier models, starting",
      "offset": 2175.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "with Blake Le Moine, who of course, you",
      "offset": 2178,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "know, famously I talk about in the book",
      "offset": 2179.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "famously, um, you know, kind of argued",
      "offset": 2181.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "that after his interactions with was",
      "offset": 2183.68,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "lambda that it was it was sentient",
      "offset": 2186.079,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "and playing out today in like, you know,",
      "offset": 2189.52,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "we see that, you know, two of the top",
      "offset": 2192.56,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "100 most visited websites in the world",
      "offset": 2196.32,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "are companion applications. These are",
      "offset": 2198.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "generative AI systems that are trained",
      "offset": 2202,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to behave as if they are your friend.",
      "offset": 2203.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Why are they so popular? Because they're",
      "offset": 2206.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "good at that. But not just but they",
      "offset": 2207.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "don't have to be that good because",
      "offset": 2209.599,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "people are really prone to be, you know,",
      "offset": 2211.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "to think of them as if they were a",
      "offset": 2215.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "person.",
      "offset": 2217.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "Yes, that is undoubtedly true. But I",
      "offset": 2218.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "think it's possible to hold that view",
      "offset": 2221.119,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "and to be cognizant of our",
      "offset": 2224.079,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "predisposition to do this, but also",
      "offset": 2227.599,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "still to be sober about the capability.",
      "offset": 2230.16,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "I think it's just a different question,",
      "offset": 2234.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "right? The capability question is like",
      "offset": 2236.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "how do you get something that can, you",
      "offset": 2238.8,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "know, solve simultaneous equations if",
      "offset": 2241.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "they're posed in natural language? Like",
      "offset": 2244.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "how do you do that? That is a that is a",
      "offset": 2246.24,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "problem that we did not know how to",
      "offset": 2247.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "answer in 2018. We know how to answer it",
      "offset": 2249.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "now.",
      "offset": 2251.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "And the system which we implemented to",
      "offset": 2253.76,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "solve that problem shares highlevel",
      "offset": 2257.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "computational principles with what our",
      "offset": 2260.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "best understanding of what the brain is",
      "offset": 2262.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "doing. Also a lot of things that are",
      "offset": 2263.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "different but it does share those",
      "offset": 2266.24,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "principles. And the most parsimmonious",
      "offset": 2267.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "explanation for how it can do it is that",
      "offset": 2269.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "it's basically drawing on those",
      "offset": 2272.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "principles, the same principles in my",
      "offset": 2274.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "view. Coming on to the the alignment",
      "offset": 2276.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "thing a little bit, you um you said that",
      "offset": 2277.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "wouldn't it be amazing if we could have",
      "offset": 2279.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "an artificial intelligence that would",
      "offset": 2281.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "know what was right epistemically and",
      "offset": 2283.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "and also what is right ethically. One of",
      "offset": 2285.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the things I'm most proud about in",
      "offset": 2288,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "having written this book is so it is now",
      "offset": 2289.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "more than it's a year and a half since I",
      "offset": 2292.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "finished writing it. And in the closing",
      "offset": 2294.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "chapters I talk about three things that",
      "offset": 2296.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "I'm worried about for the future. And",
      "offset": 2298.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the three things that I'm worried about",
      "offset": 2301.599,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "that I said I was worried about are",
      "offset": 2303.04,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "still the three things that I'm worried",
      "offset": 2304.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "about. So I'm quite so at least that has",
      "offset": 2305.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "not kind of gone stale which is like",
      "offset": 2308.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "given the pace of change is not kind of",
      "offset": 2309.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "definitely not given. So I think it's",
      "offset": 2312.16,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "quite surprising. Okay. So what are",
      "offset": 2313.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "those three things? So I say number one,",
      "offset": 2315.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "I'm worried about like the translation",
      "offset": 2317.68,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "of kind of like systems that generate",
      "offset": 2320.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "information that allows the user to",
      "offset": 2324.079,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "behave in some way giving way to systems",
      "offset": 2326.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that directly behave on the user's",
      "offset": 2329.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "behalf. Right? So what we now call",
      "offset": 2332.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "agentic AI um we were even calling it",
      "offset": 2333.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "then. So I'm worried about that. I'm",
      "offset": 2336.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "worried about personalization. So the",
      "offset": 2338.56,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "extent to which models instead of",
      "offset": 2341.599,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "satisfying kind of like some general",
      "offset": 2345.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "collective sense of what is right can be",
      "offset": 2347.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "tailored to everyone's individual sense",
      "offset": 2349.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "of what is right. You know if you're an",
      "offset": 2351.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "individual who like you know has a set",
      "offset": 2353.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "of beliefs and preferences that you're",
      "offset": 2356.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "quite attached to that sounds like quite",
      "offset": 2358.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "a nice idea. But until you think about",
      "offset": 2359.68,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "there are an awful lot of people out in",
      "offset": 2361.68,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "the world who have beliefs and",
      "offset": 2362.88,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "preferences that you definitely",
      "offset": 2364.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "definitely wouldn't want reinforcing and",
      "offset": 2365.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you think that personalized AI that's",
      "offset": 2367.44,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "exactly what it would do. Right? So if",
      "offset": 2369.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you take aentic systems and personalized",
      "offset": 2371.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "systems and you put them together and",
      "offset": 2374,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you imagine what deployment looks like",
      "offset": 2375.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "what it looks like is a vision that",
      "offset": 2377.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "we've been has the companies have been",
      "offset": 2380.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "talking about for several years now",
      "offset": 2383.2,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "which is personal AI right so everyone",
      "offset": 2384.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "has personal AI and it is a medium",
      "offset": 2386.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "through which they interact with the",
      "offset": 2389.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "world takes actions on their behalf",
      "offset": 2390.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "probably like you know it is a it is a",
      "offset": 2392.4,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "conduit for information resources",
      "offset": 2394.48,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "and like offers as a layer of protection",
      "offset": 2398.72,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "and so on. So what that what that really",
      "offset": 2400.64,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "is a world in which there is kind of",
      "offset": 2404.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "like a there is a there is a sort of",
      "offset": 2407.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "social economy amongst humans but there",
      "offset": 2410.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "is also a parallel social economy",
      "offset": 2412.72,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "amongst the agents that we have and use",
      "offset": 2415.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "to interact with the world. And that",
      "offset": 2418.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "might sound kind of a bit sci-fi, but",
      "offset": 2420.64,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "actually I don't think it's all that",
      "offset": 2422.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "sci-fi, right? It's really not all that",
      "offset": 2423.28,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "weird to imagine that we will have, you",
      "offset": 2426.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "know, we will interact with the world in",
      "offset": 2429.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "a way that is technologically mediated",
      "offset": 2431.44,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "because that's all we do already. Almost",
      "offset": 2433.04,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "everything we do is technologically",
      "offset": 2434.32,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "mediated. It's not weird to imagine that",
      "offset": 2435.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the technologies that we use to interact",
      "offset": 2438.079,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "with the world instead of being",
      "offset": 2439.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "rulebased like they mostly are now will",
      "offset": 2440.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "be optimization based. They'll have like",
      "offset": 2442.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "minimal forms of agency. It's like why",
      "offset": 2444.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "not? So you create this kind of like",
      "offset": 2446.8,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "multi- aent parallel kind of you know if",
      "offset": 2449.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "you like it's like a it's like almost",
      "offset": 2452.72,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "like a culture you can think of it as a",
      "offset": 2454.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "culture and the trouble is that we know",
      "offset": 2455.44,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "that when you get you know lots of kind",
      "offset": 2458.64,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "of um if you if you build a system and",
      "offset": 2462,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "that system is complex and it can",
      "offset": 2465.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "interact in complex ways then you get",
      "offset": 2467.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "complex system effects and you know it's",
      "offset": 2469.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "it can be nonlinear and it can it's it's",
      "offset": 2471.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "um you know has weird dynamics and can",
      "offset": 2474.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "have feed back loops and so on. And",
      "offset": 2476.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that's exactly what happened in that",
      "offset": 2479.52,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "flash crash. Yeah. And actually there's",
      "offset": 2480.8,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "been, you know, maybe I don't know",
      "offset": 2482.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "dozens of flash crashes. The most famous",
      "offset": 2483.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "one was in 2011, the one that I talk",
      "offset": 2486,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "about in the book. So you can think",
      "offset": 2487.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "about like what are the complex system",
      "offset": 2489.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "dynamics that emerge where we are all",
      "offset": 2491.68,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "kind of like represented by AI. And",
      "offset": 2494.319,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "the reason why I think we should worry",
      "offset": 2499.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "about that is because like you know we",
      "offset": 2500.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "have",
      "offset": 2502.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "that you you can think of the norms that",
      "offset": 2504.88,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "we've evolved socially and culturally",
      "offset": 2507.92,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "as a set of principles that curtail",
      "offset": 2511.92,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "those complex system dynamics.",
      "offset": 2515.599,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "So we have evolved in such a way that",
      "offset": 2518.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "you know we generate we have a set of",
      "offset": 2521.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "predispositions which generate a set of",
      "offset": 2523.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "kind of like constraints on our social",
      "offset": 2525.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "interaction that stop to a large extent",
      "offset": 2527.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "those runaway processes. They're not",
      "offset": 2530.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "perfect. Sometimes we go to war.",
      "offset": 2532.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Sometimes like crazy stuff happens but",
      "offset": 2534.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "like for the most part you know we",
      "offset": 2536.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "particularly you know reasonably small",
      "offset": 2539.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "groups and for long periods we can live",
      "offset": 2541.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "in relatively stable harmonious",
      "offset": 2543.92,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "societies. But the trouble is that the",
      "offset": 2546.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "models won't have those knobs, right?",
      "offset": 2549.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "There's or at least there's no reason",
      "offset": 2551.76,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "why they should have them. And the",
      "offset": 2552.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "question is, what are the constraints",
      "offset": 2555.359,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "that prevent the same sort of weird",
      "offset": 2558.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "runaway dynamics that might lead to like",
      "offset": 2561.44,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "you know flash crash like events",
      "offset": 2564.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "and I don't think we have an answer to",
      "offset": 2567.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "that. That's why it worries me. Yes. And",
      "offset": 2569.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "um designing in constraints would",
      "offset": 2571.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "actually limit the technology in quite a",
      "offset": 2573.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "strong way. It's a it's a really",
      "offset": 2574.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "interesting thing to think about though",
      "offset": 2576.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "because in the physical world the",
      "offset": 2578,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "constraints are quite strict and then",
      "offset": 2580.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "language is a kind of virtual organism",
      "offset": 2582.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that supervenes on us has more degrees",
      "offset": 2585.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "of freedom and this new type of AI",
      "offset": 2586.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "technology that we're inventing arguably",
      "offset": 2589.359,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "as you say has even more degrees of",
      "offset": 2591.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "freedom. So constraining it is is a is a",
      "offset": 2592.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "real challenge. Yeah, absolutely. And I",
      "offset": 2594.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "think you know kind of like we the the",
      "offset": 2596.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the sheer even if you had systems which",
      "offset": 2598.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "were perfectly aligned which of course",
      "offset": 2601.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "is not you know not not an assumption",
      "offset": 2603.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "any of us reasonably can make but if you",
      "offset": 2605.52,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "did um the sheer pace and volume of",
      "offset": 2607.68,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "activity that AI can generate is not",
      "offset": 2612.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "something that our systems are prepared",
      "offset": 2615.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "for. Right? So system most systems",
      "offset": 2617.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "operate under the assumption that there",
      "offset": 2621.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "are like reasonable frictions that",
      "offset": 2622.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "prevent the system from collapsing. So a",
      "offset": 2625.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "good example is like um the legal",
      "offset": 2628,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "system, right? So you know many people",
      "offset": 2630,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "know that it is possible particularly it",
      "offset": 2633.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "depends on the jurisdiction but it's",
      "offset": 2634.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "pretty much possible to engage in what",
      "offset": 2636.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "often is often called lawfare. So",
      "offset": 2639.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "adversarial",
      "offset": 2641.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "use of kind of speurious legal challenge",
      "offset": 2642.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and there are certain jurisdictions",
      "offset": 2645.68,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "where it's just strictly optimal to do",
      "offset": 2646.96,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "that because the cost of defending",
      "offset": 2648.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "yourself is so high that people will",
      "offset": 2649.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "just capitulate and you can make money,",
      "offset": 2652.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "right? There are frictions that prevent",
      "offset": 2653.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "like most people from doing that, right?",
      "offset": 2656.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "It's like most people don't have legal",
      "offset": 2658.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "training. Most people, you know, kind of",
      "offset": 2659.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "like don't know how to do that. Most",
      "offset": 2661.52,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "people don't know the grounds in which",
      "offset": 2663.04,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "you could do it. It's a lot of work.",
      "offset": 2664.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "You've got to file paperwork. you know,",
      "offset": 2665.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you've got to you there's there's domain",
      "offset": 2667.44,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "specific knowledge that you need. If we",
      "offset": 2669.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "remove those frictions so that you can",
      "offset": 2672.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "just like with a few sentences say",
      "offset": 2675.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "please do this and you have a system",
      "offset": 2676.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that goes and does it then you suddenly",
      "offset": 2678.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "have a you suddenly live in a very",
      "offset": 2681.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "different world because like lots and",
      "offset": 2682.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "lots of people can do this.",
      "offset": 2684.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "There are many many other such examples.",
      "offset": 2687.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "I was speaking with Connor Leehy about",
      "offset": 2689.52,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "this and he was talking about this",
      "offset": 2691.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "phenomenon called the fog of war which",
      "offset": 2692.56,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "is that we slowly lose control through",
      "offset": 2694.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "illegibility. Yeah. So I just you can",
      "offset": 2697.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "imagine based on what you said that you",
      "offset": 2700.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "have all of these agents and they are",
      "offset": 2702.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "even you know when when a country is",
      "offset": 2704.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "invaded or when some geopolitical event",
      "offset": 2706,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "happened the average person doesn't",
      "offset": 2707.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "understand why that is because it's the",
      "offset": 2709.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "culmination of so many counterveilling",
      "offset": 2710.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "forces and and and these systems are",
      "offset": 2712.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "just very complex to understand. So you",
      "offset": 2714.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "can imagine a world that becomes so",
      "offset": 2716.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "abstract and I also wanted to point out",
      "offset": 2718.319,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "that this doesn't require because you",
      "offset": 2721.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "know some people think of AI as a",
      "offset": 2722.8,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "cultural technology a bit like a library",
      "offset": 2724.72,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "or something like that and then there's",
      "offset": 2726.319,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "this almost doomer narrative that it's",
      "offset": 2727.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that it's agentic and and this that and",
      "offset": 2729.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the other but you don't need it to be",
      "offset": 2731.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "strong for all of these things to",
      "offset": 2733.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "happen. Yeah. And so, you know, kind of",
      "offset": 2735.52,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "the human analogy in AGI of course",
      "offset": 2738.079,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "overlooks the fact that although",
      "offset": 2741.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "collectively what we've done is",
      "offset": 2744.079,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "astonishing individually we're actually",
      "offset": 2746.4,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "extraordinarily vulnerable and just not",
      "offset": 2750.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "all that good at life in general on our",
      "offset": 2752.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "own. Right? So, you know, kind of the",
      "offset": 2754.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "classic like you know you and a chimp on",
      "offset": 2756.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "a desert island, my money's on the",
      "offset": 2758.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "chimp, right? So you know kind of like",
      "offset": 2760.8,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "that is we our strength is our ability",
      "offset": 2763.52,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "to cooperate individually. We are not",
      "offset": 2767.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "all that strong right. So you know kind",
      "offset": 2769.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "of like this notion of like a lone",
      "offset": 2772.16,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "intelligence that is like us but much",
      "offset": 2775.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "much better I think is kind of a strange",
      "offset": 2778.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "one. Like what we should actually worry",
      "offset": 2780.8,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "about is the unexpected externalities",
      "offset": 2782.72,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "that come from linking together lots of",
      "offset": 2787.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "potentially weak systems to create",
      "offset": 2789.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "something which is like probably",
      "offset": 2791.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "completely unlike us and unlike our",
      "offset": 2795.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "culture and society but which we can't",
      "offset": 2796.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "control. And I didn't know the fog of",
      "offset": 2798.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "war analogy that's very nice but my",
      "offset": 2801.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "favorite paper which talked about this",
      "offset": 2803.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "recently is from David Duvenor. So he's",
      "offset": 2804.96,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "written this really nice paper and",
      "offset": 2806.88,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "others written this really nice paper",
      "offset": 2807.92,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "called gradual disempowerment and it",
      "offset": 2808.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "expresses a threat model which I have",
      "offset": 2810.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "subscribed to for a really long time and",
      "offset": 2812.88,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "which I talk about in the book which is",
      "offset": 2814.319,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "you know kind of broadly exactly that",
      "offset": 2815.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "that we sort of gradually",
      "offset": 2817.599,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "lock ourselves in to the use of",
      "offset": 2820.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "optimization based technologies and the",
      "offset": 2823.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "complex system interactions between",
      "offset": 2825.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "those systems sort of write us out of",
      "offset": 2827.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "the equation.",
      "offset": 2829.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "And",
      "offset": 2831.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the interesting thing about that analogy",
      "offset": 2833.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "which is this is point is not made",
      "offset": 2835.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "either in the book or in David's paper",
      "offset": 2837.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "is that in a way it's co co-extensive",
      "offset": 2840,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "with what happens anyway right so if you",
      "offset": 2843.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "think about a corporation right the the",
      "offset": 2845.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the world we have created through like",
      "offset": 2847.04,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "you know through hegemonic capitalism",
      "offset": 2849.76,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "with like large corporations for example",
      "offset": 2853.28,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "in many ways large corporations they are",
      "offset": 2856.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "things that are more powerful than any",
      "offset": 2859.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "one person in a way that they kind of",
      "offset": 2861.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like they run under their own",
      "offset": 2863.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "imperatives and with their own rules and",
      "offset": 2865.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "with their own incentives and with their",
      "offset": 2868.079,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "own dynamics and that for many they are",
      "offset": 2869.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "so powerful that there is no one person",
      "offset": 2872.319,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "that could kind of stop them. Right? So",
      "offset": 2873.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "we sort of have a model for what this",
      "offset": 2876,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "would look like. It's just that of",
      "offset": 2878.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "course you know in the case of like",
      "offset": 2880.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "large complex systems like the",
      "offset": 2882.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "corporation the interactions are slow",
      "offset": 2883.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "because they're largely human mediated.",
      "offset": 2886,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "It's like email, you know, or Slack and,",
      "offset": 2887.599,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "you know, kind of like the the the dynam",
      "offset": 2890.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "everything is kind of like humans are",
      "offset": 2893.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the cogs in the wheel or the the cogs in",
      "offset": 2895.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "the machine. Sorry. Yes. But in the case",
      "offset": 2897.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "of AI, it's going to happen at warp",
      "offset": 2899.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "speed, right? I suppose it's an",
      "offset": 2902.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "interesting time because I mean, just",
      "offset": 2904.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "look at Alpha Fold for example. This",
      "offset": 2906.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "technology can be used for",
      "offset": 2907.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "revolutionizing science potentially, but",
      "offset": 2910,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "there are so many um downsides as well",
      "offset": 2912.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "potentially. I mean what downsides do",
      "offset": 2915.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you think we need to be most cautious",
      "offset": 2917.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "about socially? If if you think about",
      "offset": 2919.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "what",
      "offset": 2922.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "many how many products work? So of",
      "offset": 2924.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "course you know kind of like firms",
      "offset": 2926.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "advertise products and um they do so by",
      "offset": 2928.24,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "by branding those products right. So",
      "offset": 2932.4,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "branding is a kind of it's a it's a way",
      "offset": 2934.319,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "of",
      "offset": 2938.64,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "trying to get us to engage with",
      "offset": 2940.4,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "something a bit like as if it was a",
      "offset": 2943.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "human, right? Where that something is",
      "offset": 2946.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "maybe it's not the product itself, maybe",
      "offset": 2948.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it's the company, it's the brand and you",
      "offset": 2949.52,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "know that is more or less successful.",
      "offset": 2952.64,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "Imagine a world in which everything",
      "offset": 2955.68,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "was like that, but it could actually",
      "offset": 2960.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "talk back to you and it could simulate",
      "offset": 2962.24,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "all of the kind of social and emotional",
      "offset": 2965.359,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "types of interaction that we have with",
      "offset": 2968.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "people that we care about. So, you know,",
      "offset": 2970.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the milk in your fridge is like your",
      "offset": 2972.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "best friend, right? This is a very",
      "offset": 2974.319,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "strange world in which, you know, of",
      "offset": 2976.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "course that's a silly example. the milk",
      "offset": 2980.4,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "in the fridge is never going to be your",
      "offset": 2982,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "best friend. But, you know, kind of like",
      "offset": 2983.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "there are, you know, as as I mentioned",
      "offset": 2985.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "earlier, there are already, you know,",
      "offset": 2987.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "kind of large numbers of people who are",
      "offset": 2989.599,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "engaging with AI in ways that are kind",
      "offset": 2992.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "of like that mimic the sorts of",
      "offset": 2995.359,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "interactions they have with other",
      "offset": 2996.8,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "people. And this creates a whole bunch",
      "offset": 2997.839,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of vulnerabilities and a lot of people",
      "offset": 3001.119,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "have talked about like, you know, risks",
      "offset": 3002.319,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "to mental health and so on. And we",
      "offset": 3003.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "should be we should be really aware of",
      "offset": 3004.96,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "that, especially where, you know,",
      "offset": 3006.96,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "vulnerable people or minors are",
      "offset": 3008.16,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "concerned. But I think there's another",
      "offset": 3009.52,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "issue which is talked about much less",
      "offset": 3011.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "and that is the the the degree to which",
      "offset": 3012.559,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "that will give the the organizations",
      "offset": 3016,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "that build these systems power over",
      "offset": 3019.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "people. you talked about you said that",
      "offset": 3022.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "AI increases our agency and I would",
      "offset": 3024.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "actually like in a way that is true but",
      "offset": 3025.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "I actually think that it's it's there's",
      "offset": 3028.319,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "also a really powerful sense in which is",
      "offset": 3030.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the opposite is true right just as you",
      "offset": 3031.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "know kind of like access to social media",
      "offset": 3034.88,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "gives you in theory access to lots and",
      "offset": 3037.44,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "lots of information and you know kind of",
      "offset": 3041.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "like that should be empowering actually",
      "offset": 3044.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "most people's practical experience of it",
      "offset": 3046.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "is that they spend a lot of time doing",
      "offset": 3048.96,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "something that they think is a bit",
      "offset": 3050.559,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "stupid and would rather be doing",
      "offset": 3051.839,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "something else. Yes, I'm I'm glad you",
      "offset": 3052.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "brought that up. It's it's a weird",
      "offset": 3054.559,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "phenomenon. This comes into the labor",
      "offset": 3056.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "market disruptions. I think initially",
      "offset": 3057.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "for some people certainly now if you",
      "offset": 3059.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "fire up cursor and you can build a",
      "offset": 3061.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "software business in a week in that",
      "offset": 3063.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "sense it increases your agency but",
      "offset": 3065.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "actually everybody else has this",
      "offset": 3067.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "capability and the the the long-term or",
      "offset": 3069.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "even the medium-term is it sequesters",
      "offset": 3071.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "your agency. It takes your agency away",
      "offset": 3073.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "massively and and this is this is a huge",
      "offset": 3075.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "problem. Yeah. I mean I think that this",
      "offset": 3077.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "is you know this is true. This is not a",
      "offset": 3079.44,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "unique problem to AI, right? You know,",
      "offset": 3082.079,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "kind of you could see like the trend of",
      "offset": 3084.559,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "increasing organization in society,",
      "offset": 3088.72,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "right? In a way, it liberates us in lots",
      "offset": 3092.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "of ways, right? The things that you can",
      "offset": 3095.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "do in a society which is organized",
      "offset": 3097.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "collectively are much greater than",
      "offset": 3101.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "things you can do on your own. Right?",
      "offset": 3103.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Your opportunity is enormously",
      "offset": 3105.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "increased. But at the same time in order",
      "offset": 3107.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "for that society to function it has to",
      "offset": 3109.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "curtail what you can do right and I",
      "offset": 3111.599,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "think you can see you know technology as",
      "offset": 3114.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the natural culmination of that process",
      "offset": 3116.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "right you know technology it gives us",
      "offset": 3118.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "freedoms which we wouldn't otherwise",
      "offset": 3120.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "have we do things we wouldn't otherwise",
      "offset": 3122,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "do and of course there's an imperative",
      "offset": 3124.16,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "to seize those opportunities not at",
      "offset": 3126,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "least because they're usually",
      "offset": 3129.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "economically you know really beneficial",
      "offset": 3130.079,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "but it's like a kind of fouian pact",
      "offset": 3134,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "right When you buy into that, you lock",
      "offset": 3137.119,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "yourself into the use of that technology",
      "offset": 3139.839,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "and you know that plays out in all sorts",
      "offset": 3143.119,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "of like trivial ways. Like how good are",
      "offset": 3145.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "you at making a fire from scratch",
      "offset": 3147.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "without a box of matches? I don't know",
      "offset": 3149.599,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "about you, but I wouldn't be able to do",
      "offset": 3151.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "it, right? I'm locked in. This is like a",
      "offset": 3152.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "basic thing that we need to survive and",
      "offset": 3155.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "I couldn't do it, right? So I know I",
      "offset": 3156.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "wonder whether this would be ailarated",
      "offset": 3158.8,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "when we have a more um diffused",
      "offset": 3160.4,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "distributed AI. you know, you were kind",
      "offset": 3162.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "of um alluding to Daniel Dennis",
      "offset": 3164.079,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "counterfeit people article in the",
      "offset": 3165.839,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "Atlantic and I was lucky enough to",
      "offset": 3167.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "interview him about that before he died",
      "offset": 3168.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "and um you know he was basically saying",
      "offset": 3170.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that um when when everyone starts",
      "offset": 3172.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "talking you know you mentioned the milk",
      "offset": 3174.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "but maybe maybe the milk in the fridge",
      "offset": 3176.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "will be an agent everything will be an",
      "offset": 3178.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "agent and unfortunately we start to see",
      "offset": 3180.16,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "this weird behavior when we see any kind",
      "offset": 3184.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of interaction online and it's it's",
      "offset": 3186.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "so-called counterfeit people so you know",
      "offset": 3189.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "um and we acquire Yes, because we just",
      "offset": 3191.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "stop participating because the world",
      "offset": 3193.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "suddenly looks very strange to us. But I",
      "offset": 3195.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "also see the opposite which is that we",
      "offset": 3198.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "become counterfeit people. So if you",
      "offset": 3199.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "look at the way people behave on on",
      "offset": 3201.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "LinkedIn and social media now, it's",
      "offset": 3203.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "becoming far more robotic and it's just",
      "offset": 3205.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "almost the the meaning of the entire",
      "offset": 3207.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "system seems to be eroding. Yeah. Yeah.",
      "offset": 3209.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Absolutely. There is like I mean you",
      "offset": 3212.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "know you you could call it like a crisis",
      "offset": 3214.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of authenticity, right? And I think you",
      "offset": 3216.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "can see this broadly in society like you",
      "offset": 3218.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "know kind of because our modes of",
      "offset": 3221.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "interaction become so stylized",
      "offset": 3223.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "that we we lose that sense of",
      "offset": 3227.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "authenticity right there are so many",
      "offset": 3229.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "dependencies you know we always have to",
      "offset": 3231.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "present ourselves as being like you know",
      "offset": 3233.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "kind of in line with the party line you",
      "offset": 3235.2,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "just asked me something that I wasn't",
      "offset": 3237.28,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "able to answer right you know kind of",
      "offset": 3238.559,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "like because I have other dependencies",
      "offset": 3240.16,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "like there is a there is a loss of",
      "offset": 3243.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "authenticity in our communications",
      "offset": 3245.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Because in the in a complex world we",
      "offset": 3248,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "represent many interests",
      "offset": 3249.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 3252.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that I think is a natural byproduct of",
      "offset": 3254.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "our kind of like becoming part of the",
      "offset": 3257.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "system, right? I love this uh my",
      "offset": 3260,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "favorite metaphor for this um is you",
      "offset": 3263.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "know I I I woke up in the middle of the",
      "offset": 3266.559,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "night and it just hit me one night which",
      "offset": 3268.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "is have you I don't know if you remember",
      "offset": 3270.319,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Superman 3. Superman 3 is a terrible",
      "offset": 3272,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "movie but there's this wonderful scene.",
      "offset": 3274.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "So, I think there's a kind of giant",
      "offset": 3276.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "computer that goes rogue in Superman 3.",
      "offset": 3278.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "And there's this wonderful scene where",
      "offset": 3280.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "there's this female character and, you",
      "offset": 3282.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "know, she's sort of the the machine is",
      "offset": 3284.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "just kind of like waking up and she",
      "offset": 3286.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "tries to she's just sort of walking past",
      "offset": 3288.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "it and the machine kind of like sucks",
      "offset": 3290.16,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "her in. And she she gets kind of like",
      "offset": 3293.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "stuck there. And then what the machine",
      "offset": 3296.319,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "does is it gradually like kind of puts",
      "offset": 3298.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "armor plating on her and replaces her",
      "offset": 3301.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "eyes with lasers and basically turns her",
      "offset": 3303.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "into a sort of like automaton.",
      "offset": 3305.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "And it's a very compelling scene. I",
      "offset": 3308.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "think I was like terrified by it as a",
      "offset": 3311.52,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "child, which is probably why I remember",
      "offset": 3312.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it. But like that is a sort of metaphor",
      "offset": 3314.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "for like you know what h what is",
      "offset": 3317.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "happening to us, right? You know we're",
      "offset": 3319.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "worried about the robots taking over or",
      "offset": 3320.559,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "whatever. But in a way it's more like us",
      "offset": 3323.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "being sucked into the machine right we",
      "offset": 3325.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "become part just like that poor you know",
      "offset": 3328.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "character um we get turned into we get",
      "offset": 3331.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "turned into something we are not by",
      "offset": 3334.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "technology and I don't think this is not",
      "offset": 3336,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "a comment that is specifically about AI",
      "offset": 3337.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "I think this happens this happens to",
      "offset": 3340,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "every person who you know has to go to a",
      "offset": 3342.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "press conference or every person who has",
      "offset": 3344.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "to you know kind of like represent you",
      "offset": 3347.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "know their organization or a broader",
      "offset": 3350.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "group of people you become part of that",
      "offset": 3352.72,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "system and it it erodess your",
      "offset": 3356.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "authenticity and in a way it erodess",
      "offset": 3359.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "your humanity.",
      "offset": 3361.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Yes. Um last time I came to interview I",
      "offset": 3364,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "I I went to Luchiano Feridi directly",
      "offset": 3366.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "afterwards and his argument is kind of",
      "offset": 3369.359,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "similar about us becoming insconed into",
      "offset": 3372.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the infosphere and it changes our",
      "offset": 3374.319,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "ontology. Perhaps you're arguing more",
      "offset": 3376.319,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "from an agentual point of view but I",
      "offset": 3378.559,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "think you know it's it's it's quite",
      "offset": 3380,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "related. Well, I I think you know kind",
      "offset": 3381.52,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "of as a psychologist, we have",
      "offset": 3383.119,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "dramatically underindexed on the extent",
      "offset": 3386.559,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "to which what is good for us is actually",
      "offset": 3389.04,
      "duration": 8.48
    },
    {
      "lang": "en",
      "text": "about our agency, our control and not",
      "offset": 3393.839,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "about reward. So you know kind of like",
      "offset": 3397.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "we have of course you know economics,",
      "offset": 3401.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "psychology, machine learning have all",
      "offset": 3402.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "grown up with this notion that like",
      "offset": 3404.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "utility maximization is like the",
      "offset": 3406,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "fundamental framework for understanding",
      "offset": 3407.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "behavior and that's expressed of course",
      "offset": 3409.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "most prominently in ML in in ML through",
      "offset": 3411.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "reinforcement learning. Um but you know",
      "offset": 3413.28,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "kind of like of course like when you",
      "offset": 3416.64,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "actually look at of and of course you",
      "offset": 3418.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "know this is not to everyone needs to be",
      "offset": 3420.319,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "warm and have enough to eat right but",
      "offset": 3422.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "once those basic needs are satisfied",
      "offset": 3423.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like if you look and even sometimes when",
      "offset": 3426.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "they're not if you look in development",
      "offset": 3427.839,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "and if you take a sideways view at a lot",
      "offset": 3431.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of kind of both healthy and abnormal",
      "offset": 3433.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "psychology what you can see is that what",
      "offset": 3435.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "people really care about is control.",
      "offset": 3438.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "People need to understand and by control",
      "offset": 3441.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "I really mean formally like your ability",
      "offset": 3443.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "to have predictable influence on a",
      "offset": 3446.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "system.",
      "offset": 3448.88,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "So in machine learning this often gets",
      "offset": 3450.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "quantified as like this wonderful notion",
      "offset": 3452.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of empowerment right but like the idea",
      "offset": 3453.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that you know what we want to maximize",
      "offset": 3456.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "is the mutual information between our",
      "offset": 3458,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "actions and kind of future states for",
      "offset": 3459.76,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "example either immediate or delayed. Um",
      "offset": 3462.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 3466.319,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "um that is agency by the way. And that",
      "offset": 3467.839,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "is that is agency. And I think that we",
      "offset": 3470.559,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "you know kind of we really really you",
      "offset": 3474,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "know if you think of like kids you know",
      "offset": 3475.92,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "kids just two examples you know the",
      "offset": 3479.04,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "extent to which kids will explore the",
      "offset": 3481.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "world you know the extent to which they",
      "offset": 3482.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "will take actions to try and understand",
      "offset": 3484.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "like why if I tap that thing or why if I",
      "offset": 3486.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "take my dinner and throw it on the floor",
      "offset": 3489.04,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "what's going to happen? Oh look I have",
      "offset": 3490.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "control or I cry. Oh, look my dad's",
      "offset": 3491.92,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "gonna come. Like I have control. I can",
      "offset": 3495.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "understand that system. Like that's what",
      "offset": 3497.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "they're doing, right? Right through to",
      "offset": 3498.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you know kind of like you know in",
      "offset": 3501.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "adulthood forms or adolescence adulthood",
      "offset": 3503.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "forms of pathological control like too",
      "offset": 3505.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "much control like you know you can see",
      "offset": 3508.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "OCD compulsive disorder as need for too",
      "offset": 3510.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "much control. So anyway, I digress, but",
      "offset": 3513.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "like control is really really important",
      "offset": 3515.92,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "and I think we when thinking about the",
      "offset": 3518.64,
      "duration": 8.479
    },
    {
      "lang": "en",
      "text": "impact of technology on our well-being,",
      "offset": 3522.96,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "that conversation needs to be grounded",
      "offset": 3527.119,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "in a robust understanding of how",
      "offset": 3529.119,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "important it is to us to have a a",
      "offset": 3531.68,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "predictable influence on our world. And",
      "offset": 3535.04,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "what a lot of AI or a lot of",
      "offset": 3538.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "technological penetration actually does",
      "offset": 3540.799,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "is make our actions kind of",
      "offset": 3543.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "unpredictable. It's like that. This is",
      "offset": 3545.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the frustration that happens whenever",
      "offset": 3548,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "you interact with a website that doesn't",
      "offset": 3549.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "quite work or you know you get a",
      "offset": 3550.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "computer says no answer or you know",
      "offset": 3552.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "two-factor authentification but then",
      "offset": 3555.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "there's no internet and you're like ah",
      "offset": 3557.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it's like you've lost control. But that",
      "offset": 3558.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "control you in the systems that we",
      "offset": 3561.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "evolved",
      "offset": 3564.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "to the the the environment that we",
      "offset": 3565.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "evolved for that control is much more",
      "offset": 3567.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you know it's much more readily",
      "offset": 3570.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "available. Isn't that fascinating? There",
      "offset": 3571.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "there have been studies I'm I'm sure",
      "offset": 3573.44,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "you're familiar with this one where um",
      "offset": 3575.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "managers in an organization this study",
      "offset": 3577.359,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "was in the 70s or something like that",
      "offset": 3579.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "and they they um had fewer rates of",
      "offset": 3580.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "heart disease because they had more",
      "offset": 3582.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "power and and then the the underlings",
      "offset": 3584.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "would would get disease much more",
      "offset": 3586.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "regularly. And if you think about it",
      "offset": 3588.559,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "with social media and even with these",
      "offset": 3590.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "chatbot platforms, so this this um I",
      "offset": 3591.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "interviewed the team that that built all",
      "offset": 3594.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the engagement hacking algorithms and",
      "offset": 3596.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "they were incredibly proud that they",
      "offset": 3598.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "were, you know, their average session",
      "offset": 3600.16,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "length was 90 minutes and they were",
      "offset": 3601.76,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "talking all about how they would do",
      "offset": 3603.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "model merging and send, you know, send",
      "offset": 3604.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "this response and this response and keep",
      "offset": 3606,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "them hooked, keep them there for longer.",
      "offset": 3607.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "And in a sense, that is that's dopamine",
      "offset": 3609.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "hacking is about giving random rewards,",
      "offset": 3611.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "right? And and it's it's it's a",
      "offset": 3614.16,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "disempowering thing along the lines you",
      "offset": 3615.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "said. And that is that is the kind of",
      "offset": 3617.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "modus operandi for all technology now.",
      "offset": 3619.44,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "Yeah. Absolutely. Yeah. Variable",
      "offset": 3621.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "reinforcement schedule is the most most",
      "offset": 3623.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "best way to train animals including",
      "offset": 3625.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "humans. And we are susceptible the in",
      "offset": 3627.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that the the unpredictable nature of the",
      "offset": 3629.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "reward engages us with the system and",
      "offset": 3631.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "what makes us come because we want to",
      "offset": 3634.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "control the system right we want to know",
      "offset": 3636.4,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "how do I make the reward come and of",
      "offset": 3638.559,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "course if you can't then you keep on",
      "offset": 3641.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "trying and trying and trying. Yeah. I",
      "offset": 3643.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "mean, you know,",
      "offset": 3645.92,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "we live in a world in which the",
      "offset": 3648.319,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "pe people have a lot of liberty about",
      "offset": 3652.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "like how they spend their time. And I",
      "offset": 3655.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "think that's as it should be. You know,",
      "offset": 3657.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "I don't you know, I don't think we",
      "offset": 3660.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "should I don't think we should legislate",
      "offset": 3662.24,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "against frivolity, right? you know, if",
      "offset": 3665.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "people want to spend a lot of time on",
      "offset": 3668.079,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "TikTok, collectively, I understand that",
      "offset": 3669.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "that's bad. But, you know, kind of like",
      "offset": 3671.2,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "it is also we we for better or worse",
      "offset": 3674.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "live in a world in which that is",
      "offset": 3678.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "permissible or we live in a country at",
      "offset": 3679.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "least in which that is permissible.",
      "offset": 3681.44,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "um where I think we need to",
      "offset": 3684.72,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "be cautious, you know, so but so so you",
      "offset": 3688.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "know kind of what what what I'm saying",
      "offset": 3691.359,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "is that you know kind of that kind of",
      "offset": 3692.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "hacking you know maybe it's undesirable",
      "offset": 3694.079,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "I might deem it undesirable but you know",
      "offset": 3698.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "collectively as a society there are many",
      "offset": 3700.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "things that are undesirable you know",
      "offset": 3702.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "alcohol is also addictive but you know",
      "offset": 3705.119,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "I'm probably going to have a beer as",
      "offset": 3707.119,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "soon as this is done right so you know",
      "offset": 3708.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "kind of there that we make those choices",
      "offset": 3710.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "but I think that there are",
      "offset": 3711.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "vulnerabilities. There are people who",
      "offset": 3714.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "are uniquely vulnerable",
      "offset": 3715.92,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "where that kind of liberty to kind of",
      "offset": 3718.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "hack if you like spills over into",
      "offset": 3721.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "something that can be really actively",
      "offset": 3724.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "harmful and can lead of course to you",
      "offset": 3725.44,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "know people to do you know to self harm",
      "offset": 3728.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "and there have been tragic cases as well",
      "offset": 3732.4,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "as I'm sure you already as I'm sure you",
      "offset": 3734.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "know in which you know people have even",
      "offset": 3735.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "taken their own life under influence",
      "offset": 3737.68,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "which was which came from an AI system",
      "offset": 3740.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "with which they interacting in this kind",
      "offset": 3744.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "of like companion mode. Do you think it",
      "offset": 3745.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "makes sense to think of evolution as",
      "offset": 3747.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "having a goal?",
      "offset": 3750.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Um probably not. Right. So there's this",
      "offset": 3752.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "great, you know, kind of like this great",
      "offset": 3754.079,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "way of thinking about um there's a paper",
      "offset": 3756.16,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "that I really like which um draws upon",
      "offset": 3760,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "the analogy of the kind of like blind",
      "offset": 3763.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "progress of evolution, right? That you",
      "offset": 3766.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "know kind of it's a selection mechanism",
      "offset": 3768.079,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that is not teological, right? It",
      "offset": 3769.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "doesn't have a purpose. It just happens.",
      "offset": 3771.359,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "and you know kind of argues that um you",
      "offset": 3774.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "know kind of we should think of kind of",
      "offset": 3777.52,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "um evolution training in neural networks",
      "offset": 3780.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in a similar way right that it's kind of",
      "offset": 3782.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like it's very blind",
      "offset": 3784.16,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "um and you know kind of like I",
      "offset": 3786.559,
      "duration": 8.161
    },
    {
      "lang": "en",
      "text": "think that yeah that the I I think that",
      "offset": 3790.559,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "there is a fundamental difference",
      "offset": 3794.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "between evolution and the way that",
      "offset": 3796.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "optimization happens put it that way and",
      "offset": 3799.039,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "we could learn a lot in thinking about",
      "offset": 3800.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "neural networks from thinking about the",
      "offset": 3803.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "purposeless",
      "offset": 3806.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "optimization that happens in evolution.",
      "offset": 3808.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Basically, it's a really um interesting",
      "offset": 3810.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "topic for me. I was speaking with",
      "offset": 3812.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Kenneth Stanley the other day and he",
      "offset": 3813.839,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "he's done a lot of work about",
      "offset": 3815.44,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "open-endedness. And of course, Tim",
      "offset": 3816.559,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Tashel works with Deep Mind. Yeah. In",
      "offset": 3818.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "Tim Rock Tashaw's paper with um Edward",
      "offset": 3820.079,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "Hughes. Yeah. Yeah. The open-ended",
      "offset": 3822.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "system. An open-ended system is one from",
      "offset": 3823.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the perspective of an observer that",
      "offset": 3826.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "produces a sequence of events which are",
      "offset": 3828.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "um learnable and novel. Yeah. Yes.",
      "offset": 3830.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Exactly. It's about learnability, isn't",
      "offset": 3833.839,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "it? Yeah. Yeah. Um Joel Lemon, have you",
      "offset": 3835.76,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "have you had Joel Lemon on the show?",
      "offset": 3839.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "Yeah. So Joel has written really really",
      "offset": 3841.359,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "nicely about this. I mean Yeah. So I",
      "offset": 3843.039,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "largely share his view and very close to",
      "offset": 3846.88,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "Tim and Ed's view which is that um Yeah.",
      "offset": 3849.599,
      "duration": 7.921
    },
    {
      "lang": "en",
      "text": "So the the world is open-ended and",
      "offset": 3853.599,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "optimizing for open-ended systems using",
      "offset": 3857.52,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "kind of like wellsp specified kind of",
      "offset": 3860.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "narrow optimization towards a narrow",
      "offset": 3863.68,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "goal is just doomed to failure, right?",
      "offset": 3865.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "And there is probably something really",
      "offset": 3868.799,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "deep about the way the the purposeless",
      "offset": 3870.72,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "selection that happens in evolution",
      "offset": 3874.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "conferring robustness",
      "offset": 3877.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "because it doesn't precisely optimize",
      "offset": 3879.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "for this narrow goal, but rather what it",
      "offset": 3881.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "creates is this like astonishing",
      "offset": 3883.52,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "heterogeneity, right? And the",
      "offset": 3885.359,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "optimization algorithms that we use are",
      "offset": 3888.799,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "all completely opposite, right? They are",
      "offset": 3891.599,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "basically tailored for homogeneity. like",
      "offset": 3894.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "heterogeneity is a bug and that's why",
      "offset": 3897.359,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "LLMs show mode collapse. It's why, you",
      "offset": 3899.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "know, kind of like you get this kind of",
      "offset": 3902.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like, you know, this um platonic",
      "offset": 3904.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "hypothesis, you know, the idea that",
      "offset": 3906.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "we're gradually converging towards kind",
      "offset": 3908.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "of like essentially one common shared",
      "offset": 3911.119,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "set of representations, right? It's like",
      "offset": 3913.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. Yeah. Evolution doesn't do",
      "offset": 3916.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that. Kenneth wrote this wonderful paper",
      "offset": 3918.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "called the um the fractured entangled",
      "offset": 3920.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "representation hypothesis. Oh, I don't",
      "offset": 3923.039,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "know that paper. So um with um with",
      "offset": 3925.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Joel, I'm not sure if Joel was was part",
      "offset": 3927.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "of this, but he was on why greatness",
      "offset": 3929.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "cannot be planned. They did this thing",
      "offset": 3931.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "called Pickreeder and that was like",
      "offset": 3932.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Flickr where it was supervised by a",
      "offset": 3935.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "diverse source of humans and the humans",
      "offset": 3937.92,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "could pick interesting image generators",
      "offset": 3940.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "which were CPN compositional pattern",
      "offset": 3942.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "producing networks and you could create",
      "offset": 3945.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "this fogyny and they they speak about",
      "offset": 3947.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this concept called deception which is",
      "offset": 3949.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that the stepping stones that lead",
      "offset": 3951.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "somewhere interesting don't resemble the",
      "offset": 3952.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "interesting thing. So humans have this",
      "offset": 3954.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "this kind of idea of what's interesting",
      "offset": 3957.2,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "because we seem to know the world well",
      "offset": 3959.44,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "and with a few steps in the fogyny they",
      "offset": 3962.319,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "they found these um pictures of",
      "offset": 3965.039,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "butterflies and apples and when you do",
      "offset": 3968.079,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "parameter sweeps on the networks because",
      "offset": 3971.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "they so abstractly understand the",
      "offset": 3973.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "objects the apple would actually get",
      "offset": 3975.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "bigger. One one neuron would make it",
      "offset": 3977.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "bigger one neuron would make the stem",
      "offset": 3979.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "swing. And if you train a neural network",
      "offset": 3981.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "with stochastic gradient descent to do",
      "offset": 3983.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the same thing and you do parameter",
      "offset": 3985.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "sweeps, it's just it's like spaghetti",
      "offset": 3987.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "all over the place. So they'll",
      "offset": 3990.559,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "hypothesis and this this seems like an",
      "offset": 3991.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "obvious thing to say. If we could have a",
      "offset": 3993.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "sparse representation which mirrored the",
      "offset": 3996.16,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "world then the creative leaps because",
      "offset": 3998.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the knowledge is evolvable. We could",
      "offset": 4002.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "trust it with autonomy because it would",
      "offset": 4004.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "do the right thing. Yeah, that's",
      "offset": 4005.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "amazing. So I don't know about this",
      "offset": 4007.68,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "paper. It sounds like I should read it.",
      "offset": 4009.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "I mean the idea that yeah that you have",
      "offset": 4010.88,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "these that it's difficult to get places",
      "offset": 4013.52,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "because the interim states are not",
      "offset": 4017.359,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "highly valuable. I mean I guess this is",
      "offset": 4019.76,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "like you know kind of you this is a very",
      "offset": 4022.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "old argument. This is the basis of like",
      "offset": 4025.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Paley's watchmaker argument, right? It's",
      "offset": 4026.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like how did we ever get the eye? You",
      "offset": 4029.359,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "couldn't possibly evolve that. It's just",
      "offset": 4031.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "too complicated. But yeah, those",
      "offset": 4032.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "gradients must be there, right? The",
      "offset": 4035.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "gradients are there. I have to say, um,",
      "offset": 4037.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Professor Summerfield, the pros, the way",
      "offset": 4039.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that you've written this book is very",
      "offset": 4042,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "impressive to me. It's one of the best",
      "offset": 4043.76,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "written pieces of of writing I've ever",
      "offset": 4045.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "seen. And it couldn't it occurred to me",
      "offset": 4047.359,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "whether you were deliberately",
      "offset": 4049.92,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "making it so creative as for it to be",
      "offset": 4053.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "impossible to be mistaken for AI",
      "offset": 4056.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "generated content. Um I I don't know",
      "offset": 4058.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "whether this is may maybe I've I've you",
      "offset": 4061.039,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "know my my standards are so low now",
      "offset": 4063.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "because you know in shitification and",
      "offset": 4065.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "all of that but it it was remarkable.",
      "offset": 4067.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "But were you were you thinking that were",
      "offset": 4069.359,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "you sort of like leaning into the",
      "offset": 4071.119,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "creativity a little bit? I I love to",
      "offset": 4072.24,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "write. I love to find new ways to",
      "offset": 4074.799,
      "duration": 8.161
    },
    {
      "lang": "en",
      "text": "explain things to convey ideas. So",
      "offset": 4079.359,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "that's a it's for me it's a selfish",
      "offset": 4082.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "pleasure. It didn't cross my mind uh",
      "offset": 4084.799,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that people might think that I had used",
      "offset": 4087.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "chatb to write the book but I guess in",
      "offset": 4089.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "hindsight that's a kind of very sensible",
      "offset": 4091.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "way of thinking about it. But no I yeah",
      "offset": 4093.2,
      "duration": 3.999
    },
    {
      "lang": "en",
      "text": "it was all me.",
      "offset": 4095.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "That is my been an absolute honor. Thank",
      "offset": 4097.199,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "you so much. Thank you.",
      "offset": 4099.279,
      "duration": 3.88
    }
  ],
  "cleanText": "Superman 3 is a terrible movie, but there's this wonderful scene.\nSo, I think there's a kind of giant computer that goes rogue in Superman 3.\nAnd there's this wonderful scene where there's this female character and you know she's sort of the the machine is just kind of like waking up and she tries to she's just sort of walking past it and the machine kind of like sucks her in.\nAnd she she gets kind of like stuck there and then what the machine does is it gradually like kind of puts armor plating on her and replaces her eyes with lasers and basically turns her into a sort of like automaton.\nAnd it's a very compelling scene.\nI think I was like terrified by it as a child, which is probably why I remember it.\nBut like that is a sort of metaphor for like you know what h what is happening to us, right?\nYou know we're worried about the robots taking over or whatever.\nBut in a way it's more like us being sucked into the machine, right?\nWe become part just like that poor, you know, character.\nUm we get turned into we get turned into something we are not.\nYou become part of that system and it it erodes your authenticity and in a way it erodes your humanity.\nPeople often say, well, you know, kind of ChatGPT, of course, it was exposed to more.\nI think I have the analogy in my book.\nIt's exposed to the same amount of language as if, you know, a single human was continually learning language from the middle of the last ice age or something like that, right?\nIs that's how much data it's exposed to.\nBut it's a false analogy, right?\nIt's a false analogy because we don't learn language like ChatGPT does, right?\nSo language models are trained in a kind of like you might think of it as it's almost like a Lamarckian way right one generation of training if you think of a training episode right whatever happens in that gets inherited by the next training episode right that's not how we work right my memories are not inherited by my kids there's this fundamental disconnect we're Darwinian the models are sort of like I don't guess you could call them Lamarckian so we're here in Oxford today to speak with Professor Christopher Summerfield.\nHe's just written this book called These Strange New Minds: How AI Learned to Talk and What It Means.\nHe spoke about the history of artificial intelligence and how the allure of AI is to build a machine that can know what is true and what is right.\nImagine a world in which everything was like that, but it could actually talk back to you and it could simulate all of the kind of social and emotional types of interaction that we have with people that we care about.\nSo, you know, the milk in your fridge is like your best friend, right?\nThis is a very strange world in which, you know, of course that's a silly example.\nThe milk in the fridge is never going to be your best friend.\nBut, you know, kind of like there are, you know, as as I mentioned earlier, there are already, you know, kind of large numbers of people who are engaging with AI in ways that are kind of like that mimic the sorts of interactions they have with other people.\nI thought that grounding you would need, you know, kind of like sensory signals.\nYou need, you know, you can't know what a cat is just by reading about cats in books.\nYou need to actually see a cat.\nBut it turned out I was wrong.\nAnd so were many many many other people.\nAnd that is to my mind perhaps the most astonishing scientific discovery of the 21st century is that supervised learning is so good that you can actually learn about almost everything you need to know about the nature of reality.\nAt least to have a conversation that every educated human would say is an intelligent conversation without ever having any sensory knowledge of the world just through words.\nThat is mind-blowing.\nThis podcast is supported by Google.\nHey everyone, David here, one of the product leads for Google Gemini.\nCheck out Veo3, our state-of-the-art AI video generation model in the Gemini app, which lets you create highquality 8-second videos with native audio generation.\nTry it with the Google AI Pro plan or get the highest access with the Ultra plan.\nSign up at gemini.google to get started and show us what you create.\nI'm Bajan Kusier.\nI'm starting an AI research lab called Tufa AI Labs.\nIt is funded from past ventures involving machine learning.\nSo, we're a small group of highly motivated and hardworking uh people and the main thread that we are going to do is trying to make models that reason effectively and long-term trying to do AGI research.\nOne of the big advantages is because we're early, there's going to be high freedom and high impact as someone new at Tufa AI Labs.\nYou can check out positions at tufa.ai.\nSo, um, Professor Summerfield, I have to congratulate you on this book.\nYour your previous book was my favorite book that I've ever read in in AI.\nUm, it's up there with Melanie Mitchell's book.\nAnd actually, Melanie Mitchell reviewed your new book as well.\nShe did.\nSo, um, very generously.\nYeah.\nI'm a big fan of Melanie.\nSo, um, you've been writing this for a couple of years and of course you actually extolled in in the the afterward that it takes quite a long time to get these things into publication and the space is moving very very quickly, but can can you give us a bit of an elevator pitch of of the book?\nYeah, sure.\nSo, uh, the book Yes, as you said, it was actually finished at the end of 2023.\nSo that is kind of like cast your mind back to the sort of medieval period of AI if you like 12 14 months after ChatGPT had just been uh released.\nUh yeah.\nSo um the idea of the book was that um at that time and I guess you know to a large extent still today there was considerable debate over like what is the kind of cognitive status of these title of the book strange new minds that we seem to have created and are now increasingly interacting with.\nAnd that debate, the the debate that I heard and I heard, you know, the same debate going on in academic conferences and down the pub, the debate was, you know, kind of like should we think of these things as actually a bit like us?\nAre they thinking, you know, kind of are they reasoning?\nAre they understanding?\nAnd of course, this very quickly became a highly polarized debate.\nAnd um that debate was kind of like on the one hand a bunch of people who you know really sort of vehemently rejected the idea that these tools could ever be anything like us.\nIt's just computer code which is of course true.\nAnd then on the other hand, you know, you had people who were like absolutely astonished by not just by the capability but by the pace of progress and thought, you know, kind of like we really are on course finally finally to build something that is like as competent in a general way as Humans.\nAnd this debate was playing out and I was like well this debate is not really grounded in I don't hear the language of cognition being used to un to scaffold this debate.\nSo this debate is being had by people who care deeply about this issue but are not trained in kind of like a grounded computational sense of what does it actually mean to think?\nWhat does it actually mean to understand something?\nAnd so I thought as a cognitive scientist who has done a lot of work in AI, I probably quite well placed to talk about that.\nSo that was sort of part one.\nAnd then you know kind of I also have for the past five years been very very interested in the um the implications of AI for society.\nAnd so I was working on that problem when I was at DeepMind and we were doing work to try and understand how AI could be used to kind of intervene directly in society in the economy um to help people find agreement.\nUm and at the time when I wrote the book I was just about to move to the AI as it was then AI safety institute in UK government um to work more on that.\nSo I had a kind of understanding of like the landscape of um deployment risks, thinking about how AI might change the way that we live our lives and I thought probably putting those things together, I had enough of a unique perspective to write a book about it.\nSo that's what I did.\nThe the discourse is quite fractured and and you speak about this in great detail.\nYou speak about the um you know the the the hypers, the anti-hypers, the the safety hypers and so on.\nAnd um early on in the book you kind of trace this back to two intellectual threads going back to the ancient Greeks.\nSo Aristotle and Plato basically empiricism and and rationalism.\nC can you kind of sketch that out?\nYeah, sure.\nWell, the history of AI has itself been kind of kind of repeated a an ancient philosophical debate about whether the fundamental nature of bu building a mind including our mind is fundamentally about learning from experience or about reasoning particularly reasoning over latent or unobservable states right and that reasoning over unobservable states is of course traced back to Plato that's kind of this idea that you know kind of everything is fundamentally unobservable.\nWe just get this sort of shadows on the cave wall or the light on the retina and we have to impute what's there and the you know the the corresponding view which you might trace back to Aristotle you know this idea that there is kind of um yeah that everything comes from experience and the history of AI of course was that very debate playing out actually in kind of like in the workshop so to speak right or like at least or at least on the on the on the keyboard so you know kind of on the one hand you know originally good old fashioned AI was structured around the idea that you know kind of we sort of know what how to work out what is true.\nAnd the reason we know how to work out what is true is because we have a kind of like long tradition back through kind of positivism and you know kind of early theories of reasoning back to bool and you know even lienets before that the idea that you know kind of like you can use logic to work out what is true.\nIt is unassalably true that you know kind of like if I say that you know all men are Greek and Aristotle is a man then Aristotle is Greek right that is just like true by definition and so that seemed like a really sensible way to build AI right like you put in those primitives and you crank the handle and like you know if you've got enough computational power then you can derive really really complex things and it worked right it worked um so in the 1950s um Newell and Simon built the the logic theorist right which I like to say is the first super intelligence 1958 right so it's a a an AI system that was able to prove theorems that uh to prove theorems with a greater um kind of like well it was able to prove many of the theorems that were in Brussell Whitehead's print mathematica which is like already a feat and it was able to find more elegant solutions to many of those theorems.\nSo like that's astonishing.\nSo you know initially it seemed like this kind of reasoning approach worked.\nUm and then you know kind of like of course what happened is that as the problems that we tried to tackle with this kind of approach moved from these very abstract sort of clean problems about maths and logic and we started to tackle problems in the real world.\nWe ran into a fundamental problem which is that the real world just isn't kind of like all that clean and nice and neat in the way that you know kind of like reasoning problems are designed to solve.\nSo the world is full of weird exceptions which you know don't fundamentally aren't fundamentally amenable to analysis with like logic and so you know kind of like you had this other corresponding approach which is like the the learning approach or the empiricist approach and that was where neural networks and the deep learning revolution ultimately came from.\nIsn't it a crazy time to be alive though?\nI interviewed the CEO of one of the largest companion bot platforms and the in the comment section uh there was a lot of negativity and you actually mentioned I think in your afterward that um it seems strange to us now that we would want to have a relationship with an AI companion and maybe we might revise that belief in in in a few years time but but I mean more broadly though you said in your book that language is basically the biggest gift that has ever been given to us.\nIt allows us to acquire knowledge and and communicate it and it survives many generations.\nAnd I guess the the Rubicon moment with this technology maturing was ChatGPT that that changed everything in November 2022.\nSketch that out for me.\nWell, I mean, you know, the history of NLP, I guess, has been told many times, probably by people more qualified than me, but you know, kind of like we talked earlier about this kind of back and forth between learning and reasoning and, you know, kind of in the history of NLP, what played out was exactly the same question, right?\nSo NLP natural language processing as a sub field of AI and you know kind of the as in more general the sort of more general symbolic AI movement you know kind of the early models were basically attempts to to define the computations that lead to the generation of valid sentences right that's basically the gauntlet that Chomsky lays down in his 1958 book and you know there are a set of rules which like you know if you could just apply them all lawfully they would allow for the generation of sentences that you know kind of like obey the rules that we would all understand you know to be like what makes a valid sentence so syntax right Charles was mainly concerned with English of course so he's worried about English syntax but like so that movement you know kind of of course was then just like neural networks came along in the wider field was then challenged by statistical approaches.\nAnd that went back and forth and back and forth and back and forth.\nAnd you know, when the deep learning revolution happened by 2015, we had models that could you could train a model on the complete works of Shakespeare and it could generate something that looked a lot like Shakespeare, but it didn't make any sense.\nAnd so still you know kind of even when the deep learning revolution was in full swing most people including myself thought there is no way that the mere application of like powerful function approximation and lots of data is going to solve this problem.\nI did not believe that to be true.\nI thought that I think like any other people that you would need grounding.\nYou would need you know kind of like sensory signals.\nYou need you know you can't know what a cat is just by reading about cats in books.\nYou need to actually see a cat.\nUm, but it turned out I was wrong and so were many many many other people.\nAnd that is that is to my mind an absolutely astonishing perhaps the most astonishing scientific discovery of the 21st century is that you supervised learning is so good that you can actually learn about almost everything you need to know about the nature of reality at least to have a conversation that every educated human would say is an intelligent conversation without ever having any sensory knowledge of the world.\nJust through words\n\n\nThat is mind-blowing, and I think it changes the way we think about many, many things. Certainly changes how I think about things. So one big theme in the book is this dichotomy between um equivalentists and um exceptionalists. So some folks argue that humans are exceptional, and the kinds of cognizing that language models do are not really, you know, in the same category. Yeah. So I mean that distinction is a cartoon. So, of course, you know, kind of like everyone has a different view about the relationship between AI and Humans or or biological intelligence in general. And you know, kind of like the evidence clearly admits a spectrum of different views. Um, but I found it useful in the book to kind of cartoon extremes of that continuum. And you know, kind of at one end you have people who I think probably just kind of like ideologically reject the idea that something that is non-human could ever use, could it, that we should refer to that, refer to whatever that system is doing behaviorally or cognitively using the same vocabulary as we used to apply to a human. So you know, kind of like clearly today's models are capable of reasoning at levels which is beyond the capability of most even educated humans today, right? Certainly when it comes to formal problems like maths and logic and so on. So it can reason like a human. But there are people who I think just fundamentally think that we shouldn't think of that as reasoning because we should kind of like circumscribe the definition of reasoning as something that humans do. And that is a stance which I think is not really, it's not really about the empirical evidence, although some people kind of construe it to be that way by saying, oh, the models aren't actually that good at reasoning, which I think is a, you know, even in 2023, it was a hard to defend view, now it's probably an even harder to defend view, but I think it's kind of like it comes from a place which is like a sort of radical humanism, right? It's a sort of it is a desire to kind of like really ring fence a set of cognitive concepts and think of them as uniquely human. And like for people who care about Humans, which by the way includes me, like I can see why that's really important. But what it does lead you down the road of is kind of like a a a refusal to kind of ever see the cognition that an AI will engage in and the cognition that a Human will engage in as comparable even when their kind of capabilities are clearly matched. So that's what I call kind of exceptionalists because in a way they're sort of like, you know, kind of they they they are espousing a view of Human exceptionalism. Humans are special and different. End of story. And you know, somewhat kind of cheekily in the book I compare that to kind of earlier instances of Human exceptionalism. Of course that occurred when you know Darwin first proposed that you know we weren't kind of uniquely created by God, but were actually related to all the other species and like you know kind of when the heliocentric model um you know kind of first became established and was rejected by the Catholic Church and so on. But that was kind of I guess those analogies give color, but fundamentally, you know, I think it is a defensible position, but it but it's it's not a, it's an ideological position, I think. Yes. So you invoke this notion called the duck test. You know, basically if it looks like a duck and quacks like a duck, we should call it a duck. And um and by extension I I guess you would call yourself a functionalist, which is this idea that it's not about the internal constitution or the mechanism, but but it's about the the function that it performs. And we can use this information metaphor to say, well, you know, if we have an AI system over here which is doing cognizing and it's doing the same types of things, then we could reasonably make the inference that it's appropriate to use mentalistic language to describe it. That's absolutely right. Yeah. And you're absolutely right to say that it's a functionalist perspective, and that is broadly my perspective. Um I think you know, kind of once again that functionalism, you know, it's it's kind of like from a scientific standpoint, right? I'm like, if it reasons like a human, then we may as well use the term reasoning, but that doesn't imply a broader set of equivalents, right? That doesn't, for example, imply moral equivalence, it doesn't apply, you know, it doesn't, it doesn't mean that, you know, kind of like the motivations or you know, relationships we have with AI are similar to those we have with Humans, absolutely not, of course they're completely different. Um, but it does mean that, you know, when purely, you know, if you put on cognitive scientist hat and you're really just thinking about, you know, let's let's talk dirty about information processing, then you know, kind of like that functionalist perspective, yeah, if it walks, if it quacks like a duck, it's you may as well call it a duck. The anthropomorphism thing makes it a little bit more tricky. And I I think um in in a film if you see um a robot peel the face away and all of a sudden you you see they're not they're not a human, they're a robot, and the intuition there is that they have a different mechanism, and this is what John S was getting at when he was talking about the Chinese room argument, and um I read what you had to say about that. So I think I think S was saying that when when you take um a type of process and you represent it in silicone as computation, sans the machine, which because we are biio machines, so we are causally embedded in in the world, and when when we do things, there's this you know, large kind of light cone of low-level interactions that happen, and and I guess this is his notion of semantics, and and I I think um Professor Summerfield, you subscribed to something called a distributional notion of semantics, which is that we can actually remove things from the physical world and recreate patterns of activity in silicone, and and for all intents and purposes, it would have the same meaning. That's that, yeah, I mean I I I do subscribe to that view. I mean I think that you know, kind of of course as a not only a cognitive scientist, but a neuroscientist, I'm uniquely aware that you know, whilst there are many differences between machine learning systems and the computations that go on in the brain. There are also like astonishing similarities, right? At the level of kind of certainly at the algorithmic level, not not clearly at the implementational level, you know, kind of like, you know, neural networks don't tend to have, you know, um they don't have to have, they don't have many, many different types of sinapses and we don't have many different type, you don't have basket cells and you know, fast inhibitory inter neurons and things like that. But there is at the level of the neural network, there is a striking similarity. And you know, kind of the most reasonable assumption to me is that there are broad shared computational principles that happen when you take networks of neurons that are wired up to have some dense interconnecting and you know, for the most part recurrent. We have to remember the transform is not a recurrent architecture. So it probably mim, it uses tricks to mimic what a recurrent architecture does. But like for the most part recurrent network and we know that because we know for example that the way that information after various after optimization has been applied and actually sometimes even before optimization has been applied. We know that there are striking similarities in the semantic representations that you can read out of those two classes of network, biological and artificial by doing experiments, right? So you know, kind of we know that you can go into the brains of monkeys or if you have access to it, Humans while neuro imaging or whatever, and you can see patterns of representation that express themselves in terms of not just you know, in terms of like coding properties, but in terms of like neural manifolds, in terms of like neural geometry, express themselves very much like in the neural network. So you know, kind of like the substrate is shared in some very loose sense. The behavior is shared in some you know, perhaps not so loose sense. And to me it makes sense to you know, kind of science as a puzzle, right? Like you get bits of information and you try to come up with the most parimmonious explanation. And for me, the most parsimmonious explanation is that by, you know, kind of like sheer kind of like a mixture of like luck and like, you know, trying enormously hard, we've kind of got to a place where we've built something that is a bit like a brain. And lo and behold, it does stuff that is a bit like a brain. That doesn't mean it does everything. And it also doesn't mean that it is like a Human in the sense that like meaning how we should treat it, how we should think of it. But it does mean that the computations are most likely shared. I realize this is a difficult argument to make, and and there were some scornful comments in in your book about this, but um there are some people who still make the argument that it only appears to be reasoning and understanding, but it's not really. And is it possible that Chomsky could still be right in some sense? So you know, his ideas, obviously he's a rationalist, but it's this platonistic idea essentially that um the laws of nature have bestowed our brains with the with with with the the secret, you know, functions that explain how the universe works, and and in a sense he he's quite similar to a lot of folks now, he's a computationalist, he doesn't subscribe to this causal graph thing, um but he does think that the brain is a touring machine and we should do this recursive merge type stuff, but Um, is it possible that empiricism seems to work, but it's kind of like a pile of sand and Chomsky would still be right if only it were possible to have like the low-level stuff? Yeah. I mean I think you know, kind of the what we will find out, my guess is that what the end point will be are when we sort of look back after perhaps having you know, figured this stuff out is that in the end the dichotomy that was set up and that we thought about literally for millennia actually is kind of a question of perspective, right? So in a way there is a way in which the rationalist broadly construing is really important for computation. But what they were wrong about is how you acquire the ability to reason. So I think what we have learned since 2019 is that the types of computations that you need to reason about the world can be learned through large scale parameter optimization, through through through function approximation, essentially through training a neural network, and that so so in a sense Chsky kind of is not wrong that you know, there are rules to language, those rules need to be learned. It was just wrong about how they got learned, right? And like, you know, of course, there's always a slight of hand in saying, well, you're born, this is inborn because it really just begs the question of how it's inborn, right? And, you know, where does that, where does that gene that allows you to do recursion or merge or whatever, where does it come from? And, you know, kind of like what was the pressure that that got it there? And you know I think that um there is there is a there is a subtlety to an argument that's often not kind of expanded on. And I think it is that you know, of course we are born with the predisposition to learn language. And we know that that is not just kind of like an accident, right? Because other species, even highly, highly intelligent species like chimpanzees and gorillas, capable of really, really sophisticated forms of social interaction, you know, political machinations and so on. They can't learn structured language. So they can learn to communicate, but they can't learn to communicate in like infinitely expressive sentences, right? That guided by lawful syntax, and the fact that they can't do that tells us that there is something special about our evolution, and so the question is how do you explain that in the in the deep learning framework, right? And people often say, well, you know, kind of ChatGPT, of course, it was exposed to more, I think I have the analogy in my book, it's exposed to the same amount of language as if you know, a single Human was continually learning language from the middle of the last ice age or something like that, right? Is that's how much data it's exposed to. But it's a false analogy, right? It's a false analogy because we don't learn language like Chad GBT does, right? So language models are trained in a kind of like you might think of it as it's almost like a Lamarian way, right? One generation of training, if you think of a training episode, right? Whatever happens in that gets inherited by the next training episode, right? That's not how we work, right? My memories are not inherited by my kids. Right? So there's this fundamental disconnect. We're Darwinian. The models are sort of like, I don't guess you could call them Lamarian. And so you can't compare the amount of training that JGBT has to the amount of training that we have because it's just kind of like apples and oranges, right? What happens in a person's lifetime is like it's been guided, although it's not, you know, it doesn't have the content in that, you know, I live in Britain, but if I had, you know, my kids have been born in Japan, they would grow up speaking Japanese, it's been, but it's been guided by all of the other generations of learning which like inculcate this predisposition to learning language, right? And we never think of language models in that way, it's like metal learning, actually, it's really just like metalarning. And so Chsky is right that we are born with priors because those priors are the the earlier cycles of Darwinian evolution that are that everything that went on before we were born, right, as individuals. And so this kind of like I think when we talk about data efficiency and we try to make claims about data efficiency between biological and artificial intelligence, we need to be really, really specific about whether we're talking about fogyny or ontogyny. So evolution or development, and neither really works as a comparator. So it's just more complicated. Is is it possible that we're being deceived in some way though because there are certainly computational limitations with neural networks? There are um complexity limitations, learnability um limitations. So we we kind of know that there are certain types of things that the networks can't do that that we can do, and we are susceptible to this anthropomorphization. You you mentioned this wonderful experiment where it was like a cartoon of arrows kind of interacting with each other and and Humans interpret them as as agents. And this is the grumpy bully agent, and there was the the Eliza um machine as well, you know, where it was a very simple program which was quite sickopantic, and and people really um you know, took deeper meaning from that. Is is it possible that we're reading more into what's going on here than is actually the case? Well, it's definitely true that we are intrinsically prone to attribute kind of like much more elaborate forms of cognition to all\n\n\nOther non-human agents, actually, where simpler explanations may be available, right? Everyone who is a pet owner will be very familiar with this concept, right? It's like the easiest thing in the world to kind of like attribute complex humanlike states to your cat or your dog or your hamster, um, when it may or may not be merited, right? We know that people have been doing this for centuries, right? So, psychologists know about the Clever Hans effect. Clever Hans effect. Very famously, there was a performing horse which apparently could do mathematics, so simple arithmetic. And, you know, it did so by repeatedly stamping its hoof the correct number of times to solve a sum. Um, but, you know, of course, it wasn't actually doing mathematics. What it was doing was checking whether its trainer gave it a kind of like unconscious signal that it should stop tapping. And so, of course, you know, we are always prone to kind of want to impute these more complex thoughts and feelings and emotional states or complex abilities to models. I don't deny that for a moment. But, you know, kind of when you look at today's frontier models, that may be going on. You know, we may be thinking, \"Oh, it's really my friend,\" when actually it's not. But in terms of the raw capability, the numbers are the numbers, right? The models are just really good, and there's no denying that. Yes, they can't do everything. There's lots of things they can't do, and they're still not fully robust, but they are really good. It's not they're not just Clever Hans. You said yourself something in the book which intrigued me, which is that, um, even, you know, cognitive scientists and neuroscientists and and and psychologists don't really know what the answer to the question is. If you said what is thinking when we talk about these mentalistic properties and, of course, um, about this intentionality thing, you know, that the agency in interpreting the, um, the the sort of intentions of cartoon arrows that are interacting with each other, and Daniel Dennett, of course, coined this intentional stance, which is that essentially we we need to to understand the world. It's a very complex place, and and that's where perhaps some of these mentalistic properties come from. Do you subscribe to an idea? I read this wonderful book called, um, The Mind is Flat by Nick Chater, and one of my favorites. Yeah, a lot of these mentalistic properties, even even in Humans, perhaps are a bit of an illusion. What what do you think? Um, I love that book. Yeah, I mean, that book essentially argues that, you know, kind of like we draw heavily upon prior experience to formulate what we like. So, in other words, our preferences are a product of not just of like kind of some kind of internal value function which is different for everyone. You know, kind of like you like apples more than oranges, and I like oranges more than apples, but it's actually due to our memories for our past experiences. So you don't actually like apples more than oranges, but you just think you do because you had an apple this morning, and you're like, \"Oh, I had an apple this morning. I must like apples more than oranges.\" So it's this beautiful theory which in which, you know, kind of like we essentially construct ourselves out of our own actions, and you know, kind of it can it can account for an astonishing broad range of phenomena. Um, do we do that? You know, I think I that's a scientific theory, but I think, you know, kind of in our everyday interaction with other agents, so animals with technology, like we do the opposite, like we impute, this is what Dennett says, right? We impute, you know, far more than is due often, right? So, you know, your car fails to start in the morning, and you get cross with it, you know, as if it was just being stubborn. But, of course, there's no point getting stuck with it. Stop getting cross with it, right? And that is an example of the intentional stance. It is undoubtedly true that, for example, you know, kind of like when interacting with the models, people are very, very prone to attribute intentionality. So in the technical kind of like, um, philosophical sense of the word, right? In other words, that that they there is something kind of like that it is like to be that thing, right? And people are really prone to attribute that sense of like, you know, they have some essence, some sense of what it is like to be themselves to probably all forms of technology, but especially to AI because they can talk back. People do that all the time. Um, you know, this is manifest in so many different ways. You know, of course, the types of interactions that people have with today's frontier models, starting with Blake LeMoine, who, of course, you know, famously I talk about in the book, famously, um, you know, kind of argued that after his interactions with was lambda that it was it was sentient and playing out today in like, you know, we see that, you know, two of the top 100 most visited websites in the world are companion applications. These are generative AI systems that are trained to behave as if they are your friend. Why are they so popular? Because they're good at that. But not just, but they don't have to be that good because people are really prone to be, you know, to think of them as if they were a person. Yes, that is undoubtedly true. But I think it's possible to hold that view and to be cognizant of our predisposition to do this, but also still to be sober about the capability. I think it's just a different question, right? The capability question is like, how do you get something that can, you know, solve simultaneous equations if they're posed in natural language? Like, how do you do that? That is a that is a problem that we did not know how to answer in 2018. We know how to answer it now. And the system which we implemented to solve that problem shares high-level computational principles with what our best understanding of what the brain is doing. Also a lot of things that are different, but it does share those principles. And the most parsimonious explanation for how it can do it is that it's basically drawing on those principles, the same principles in my view. Coming on to the the alignment thing a little bit, you, um, you said that wouldn't it be amazing if we could have an artificial intelligence that would know what was right epistemically and and also what is right ethically. One of the things I'm most proud about in having written this book is, so it is now more than it's a year and a half since I finished writing it. And in the closing chapters, I talk about three things that I'm worried about for the future. And the three things that I'm worried about that I said I was worried about are still the three things that I'm worried about. So I'm quite so at least that has not kind of gone stale, which is like, given the pace of change, is not kind of definitely not given. So I think it's quite surprising. Okay. So what are those three things? So I say number one, I'm worried about like the translation of kind of like systems that generate information that allows the user to behave in some way giving way to systems that directly behave on the user's behalf, right? So what we now call agentic AI, um, we were even calling it then. So I'm worried about that. I'm worried about personalization. So the extent to which models, instead of satisfying kind of like some general collective sense of what is right, can be tailored to everyone's individual sense of what is right. You know, if you're an individual who, like, you know, has a set of beliefs and preferences that you're quite attached to, that sounds like quite a nice idea. But until you think about there are an awful lot of people out in the world who have beliefs and preferences that you definitely, definitely wouldn't want reinforcing, and you think that personalized AI, that's exactly what it would do, right? So if you take agentic systems and personalized systems and you put them together and you imagine what deployment looks like, what it looks like is a vision that we've been has the companies have been talking about for several years now, which is personal AI, right? So everyone has personal AI, and it is a medium through which they interact with the world, takes actions on their behalf, probably like, you know, it is a it is a conduit for information resources and like offers as a layer of protection and so on. So what that what that really is a world in which there is kind of like a there is a there is a sort of social economy amongst Humans, but there is also a parallel social economy amongst the agents that we have and use to interact with the world. And that might sound kind of a bit sci-fi, but actually I don't think it's all that sci-fi, right? It's really not all that weird to imagine that we will have, you know, we will interact with the world in a way that is technologically mediated because that's all we do already. Almost everything we do is technologically mediated. It's not weird to imagine that the technologies that we use to interact with the world, instead of being rule-based like they mostly are now, will be optimization-based. They'll have like minimal forms of agency. It's like, why not? So you create this kind of like multi-agent parallel kind of, you know, if you like, it's like a it's like almost like a culture, you can think of it as a culture, and the trouble is that we know that when you get, you know, lots of kind of, um, if you if you build a system and that system is complex and it can interact in complex ways, then you get complex system effects, and you know, it's it can be nonlinear, and it can it's it's, um, you know, has weird dynamics and can have feedback loops and so on. And that's exactly what happened in that flash crash. Yeah. And actually there's been, you know, maybe I don't know, dozens of flash crashes. The most famous one was in 2011, the one that I talk about in the book. So you can think about like what are the complex system dynamics that emerge where we are all kind of like represented by AI. And the reason why I think we should worry about that is because like, you know, we have that you you can think of the norms that we've evolved socially and culturally as a set of principles that curtail those complex system dynamics. So we have evolved in such a way that, you know, we generate we have a set of predispositions which generate a set of kind of like constraints on our social interaction that stop to a large extent those runaway processes. They're not perfect. Sometimes we go to war. Sometimes like crazy stuff happens, but like for the most part, you know, we particularly, you know, reasonably small groups and for long periods, we can live in relatively stable, harmonious societies. But the trouble is that the models won't have those knobs, right? There's or at least there's no reason why they should have them. And the question is, what are the constraints that prevent the same sort of weird runaway dynamics that might lead to like, you know, flash crash-like events, and I don't think we have an answer to that. That's why it worries me. Yes. And, um, designing in constraints would actually limit the technology in quite a strong way. It's a it's a really interesting thing to think about though, because in the physical world, the constraints are quite strict, and then language is a kind of virtual organism that supervenes on us, has more degrees of freedom, and this new type of AI technology that we're inventing, arguably, as you say, has even more degrees of freedom. So constraining it is is a is a real challenge. Yeah, absolutely. And I think, you know, kind of like we the the the sheer even if you had systems which were perfectly aligned, which of course is not, you know, not not an assumption any of us reasonably can make, but if you did, um, the sheer pace and volume of activity that AI can generate is not something that our systems are prepared for, right? So system most systems operate under the assumption that there are like reasonable frictions that prevent the system from collapsing. So a good example is like, um, the legal system, right? So, you know, many people know that it is possible, particularly it depends on the jurisdiction, but it's pretty much possible to engage in what often is often called lawfare. So adversarial use of kind of speurious legal challenge, and there are certain jurisdictions where it's just strictly optimal to do that because the cost of defending yourself is so high that people will just capitulate, and you can make money, right? There are frictions that prevent like most people from doing that, right? It's like most people don't have legal training. Most people, you know, kind of like don't know how to do that. Most people don't know the grounds in which you could do it. It's a lot of work. You've got to file paperwork. You know, you've got to you there's there's domain-specific knowledge that you need. If we remove those frictions so that you can just like with a few sentences say, please do this, and you have a system that goes and does it, then you suddenly have a you suddenly live in a very different world because like lots and lots of people can do this. There are many, many other such examples. I was speaking with Connor Leahy about this, and he was talking about this phenomenon called the fog of war, which is that we slowly lose control through illegibility. Yeah. So I just you can imagine based on what you said that you have all of these agents, and they are even you know, when when a country is invaded or when some geopolitical event happened, the average person doesn't understand why that is because it's the culmination of so many counterveilling forces, and and and these systems are just very complex to understand. So you can imagine a world that becomes so abstract, and I also wanted to point out that this doesn't require because, you know, some people think of AI as a cultural technology, a bit like a library or something like that, and then there's this almost doomer narrative that it's that it's agentic and and this that and the other, but you don't need it to be strong for all of these things to happen. Yeah. And so, you know, kind of the Human analogy in AGI, of course, overlooks the fact that although collectively what we've done is astonishing, individually we're actually extraordinarily vulnerable and just not all that good at life in general on our own, right? So, you know, kind of the classic like, you know, you and a chimp on a desert island, my money's on the chimp, right? So, you know, kind of like that is we our strength is our ability to cooperate, individually we are not all that strong, right? So, you know, kind of like this notion of like a lone intelligence that is like us but much, much better, I think is kind of a strange one. Like what we should actually worry about is the unexpected externalities that come from linking together lots of potentially weak systems to create something which is like probably completely unlike us and unlike our culture and society, but which we can't control. And I didn't know\n\n\nThe fog of war analogy, that's very nice, but my favorite paper, which talked about this recently, is from David Duvenaud. So, he's written this really nice paper, and others written this really nice paper called Gradual Disempowerment, and it expresses a threat model which I have subscribed to for a really long time and which I talk about in the book, which is, you know, kind of broadly exactly that: that we sort of gradually lock ourselves into the use of optimization-based technologies, and the complex system interactions between those systems sort of write us out of the equation.\n\nAnd the interesting thing about that analogy, which is this point is not made either in the book or in David's paper, is that in a way, it's co-coextensive with what happens anyway, right? So, if you think about a corporation, right, the world we have created through like, you know, through hegemonic capitalism with like large corporations, for example, in many ways, large corporations, they are things that are more powerful than any one person in a way that they kind of like, they run under their own imperatives and with their own rules and with their own incentives and with their own dynamics, and that for many, they are so powerful that there is no one person that could kind of stop them. Right? So, we sort of have a model for what this would look like. It's just that, of course, you know, in the case of like large complex systems like the corporation, the interactions are slow because they're largely human mediated. It's like email, you know, or Slack, and, you know, kind of like the the dynam—everything is kind of like humans are the cogs in the wheel or the cogs in the machine. Sorry. Yes. But in the case of AI, it's going to happen at warp speed, right? I suppose it's an interesting time because I mean, just look at AlphaFold, for example. This technology can be used for revolutionizing science potentially, but there are so many downsides as well, potentially. I mean, what downsides do you think we need to be most cautious about socially? If you think about how many products work? So, of course, you know, kind of like firms advertise products, and um, they do so by branding those products, right? So, branding is a kind of—it's a way of trying to get us to engage with something a bit like as if it was a human, right? Where that something is maybe it's not the product itself, maybe it's the company, it's the brand, and you know, that is more or less successful. Imagine a world in which everything was like that, but it could actually talk back to you and it could simulate all of the kind of social and emotional types of interaction that we have with people that we care about. So, you know, the milk in your fridge is like your best friend, right? This is a very strange world in which, you know, of course that's a silly example. The milk in the fridge is never going to be your best friend. But, you know, kind of like there are, you know, as I mentioned earlier, there are already, you know, kind of large numbers of people who are engaging with AI in ways that are kind of like that mimic the sorts of interactions they have with other people. And this creates a whole bunch of vulnerabilities, and a lot of people have talked about like, you know, risks to mental health and so on. And we should be—we should be really aware of that, especially where, you know, vulnerable people or minors are concerned. But I think there's another issue which is talked about much less, and that is the the degree to which that will give the organizations that build these systems power over people. You talked about—you said that AI increases our agency, and I would actually—like, in a way, that is true, but I actually think that it's—it's—there's also a really powerful sense in which is the opposite is true, right? Just as, you know, kind of like access to social media gives you in theory access to lots and lots of information, and you know, kind of like that should be empowering, actually, most people's practical experience of it is that they spend a lot of time doing something that they think is a bit stupid and would rather be doing something else. Yes, I'm glad you brought that up. It's a weird phenomenon. This comes into the labor market disruptions. I think initially for some people, certainly now, if you fire up cursor and you can build a software business in a week, in that sense, it increases your agency, but actually, everybody else has this capability, and the the long-term or even the medium-term is it sequesters your agency. It takes your agency away massively, and and this is this is a huge problem. Yeah. I mean, I think that this is, you know, this is true. This is not a unique problem to AI, right? You know, kind of you could see like the trend of increasing organization in society, right? In a way, it liberates us in lots of ways, right? The things that you can do in a society which is organized collectively are much greater than things you can do on your own. Right? Your opportunity is enormously increased. But at the same time, in order for that society to function, it has to curtail what you can do, right? And I think you can see, you know, technology as the natural culmination of that process, right? You know, technology, it gives us freedoms which we wouldn't otherwise have, we do things we wouldn't otherwise do, and of course, there's an imperative to seize those opportunities, not at least because they're usually economically, you know, really beneficial, but it's like a kind of Faustian pact, right? When you buy into that, you lock yourself into the use of that technology, and you know, that plays out in all sorts of like trivial ways. Like, how good are you at making a fire from scratch without a box of matches? I don't know about you, but I wouldn't be able to do it, right? I'm locked in. This is like a basic thing that we need to survive, and I couldn't do it, right? So, I know I wonder whether this would be ailarated when we have a more um diffused, distributed AI. You know, you were kind of um alluding to Daniel Dennett's \"Counterfeit People\" article in the Atlantic, and I was lucky enough to interview him about that before he died, and um, you know, he was basically saying that um when when everyone starts talking, you know, you mentioned the milk, but maybe maybe the milk in the fridge will be an agent, everything will be an agent, and unfortunately, we start to see this weird behavior when we see any kind of interaction online, and it's it's so-called counterfeit people. So, you know, um, and we acquire—Yes, because we just stop participating because the world suddenly looks very strange to us. But I also see the opposite, which is that we become counterfeit people. So, if you look at the way people behave on LinkedIn and social media now, it's becoming far more robotic, and it's just almost the meaning of the entire system seems to be eroding. Yeah. Yeah. Absolutely. There is like—I mean, you know, you could call it like a crisis of authenticity, right? And I think you can see this broadly in society, like, you know, kind of because our modes of interaction become so stylized that we we lose that sense of authenticity, right? There are so many dependencies, you know, we always have to present ourselves as being like, you know, kind of in line with the party line. You just asked me something that I wasn't able to answer, right? You know, kind of like because I have other dependencies, like there is a—there is a loss of authenticity in our communications because in the in a complex world, we represent many interests, and that I think is a natural byproduct of our kind of like becoming part of the system, right? I love this—uh, my favorite metaphor for this um is, you know, I—I woke up in the middle of the night, and it just hit me one night, which is, have you—I don't know if you remember Superman 3. Superman 3 is a terrible movie, but there's this wonderful scene. So, I think there's a kind of giant computer that goes rogue in Superman 3. And there's this wonderful scene where there's this female character, and, you know, she's sort of the—the machine is just kind of like waking up, and she tries to—she's just sort of walking past it, and the machine kind of like sucks her in. And she—she gets kind of like stuck there. And then what the machine does is it gradually like kind of puts armor plating on her and replaces her eyes with lasers and basically turns her into a sort of like automaton. And it's a very compelling scene. I think I was like terrified by it as a child, which is probably why I remember it. But like that is a sort of metaphor for like, you know, what h—what is happening to us, right? You know, we're worried about the robots taking over or whatever. But in a way, it's more like us being sucked into the machine, right? We become part—just like that poor, you know, character, um, we get turned into—we get turned into something we are not by technology, and I don't think this is not a comment that is specifically about AI. I think this happens—this happens to every person who, you know, has to go to a press conference or every person who has to, you know, kind of like represent, you know, their organization or a broader group of people, you become part of that system, and it it erodes your authenticity, and in a way, it erodes your humanity.\n\nYes. Um, last time I came to interview, I—I—I went to Luciano Floridi directly afterwards, and his argument is kind of similar about us becoming ensconced into the infosphere, and it changes our ontology. Perhaps you're arguing more from an agentual point of view, but I think, you know, it's—it's—it's quite related. Well, I—I think, you know, kind of as a psychologist, we have dramatically underindexed on the extent to which what is good for us is actually about our agency, our control, and not about reward. So, you know, kind of like we have, of course, you know, economics, psychology, machine learning have all grown up with this notion that like utility maximization is like the fundamental framework for understanding behavior, and that's expressed, of course, most prominently in ML, in in ML through reinforcement learning. Um, but you know, kind of like, of course, like when you actually look at—and of course, you know, this is not to—everyone needs to be warm and have enough to eat, right? But once those basic needs are satisfied, like if you look—and even sometimes when they're not—if you look in development, and if you take a sideways view at a lot of kind of both healthy and abnormal psychology, what you can see is that what people really care about is control. People need to understand, and by control, I really mean formally, like your ability to have predictable influence on a system. So, in machine learning, this often gets quantified as like this wonderful notion of empowerment, right? But like the idea that, you know, what we want to maximize is the mutual information between our actions and kind of future states, for example, either immediate or delayed. Um, and um, that is agency, by the way. And that is that is agency. And I think that we, you know, kind of we really, really, you know, if you think of like kids, you know, kids—just two examples, you know, the extent to which kids will explore the world, you know, the extent to which they will take actions to try and understand, like, why if I tap that thing or why if I take my dinner and throw it on the floor, what's going to happen? Oh, look, I have control, or I cry. Oh, look, my dad's gonna come. Like, I have control. I can understand that system. Like, that's what they're doing, right? Right through to, you know, kind of like, you know, in adulthood forms or adolescence adulthood forms of pathological control, like too much control, like, you know, you can see OCD, compulsive disorder, as a need for too much control. So, anyway, I digress, but like control is really, really important, and I think we, when thinking about the impact of technology on our well-being, that conversation needs to be grounded in a robust understanding of how important it is to us to have a a predictable influence on our world. And what a lot of AI or a lot of technological penetration actually does is make our actions kind of unpredictable. It's like that. This is the frustration that happens whenever you interact with a website that doesn't quite work, or you know, you get a computer says no answer, or you know, two-factor authentication, but then there's no internet, and you're like, ah, it's like you've lost control. But that control you—in the systems that we evolved to—the the environment that we evolved for, that control is much more, you know, it's much more readily available. Isn't that fascinating? There—there have been studies—I'm—I'm sure you're familiar with this one where um, managers in an organization—this study was in the '70s or something like that—and they—they um had fewer rates of heart disease because they had more power, and and then the the underlings would would get disease much more regularly. And if you think about it with social media and even with these chatbot platforms, so this—this um, I interviewed the team that that built all the engagement hacking algorithms, and they were incredibly proud that they were, you know, their average session length was 90 minutes, and they were talking all about how they would do model merging and send, you know, send this response and this response and keep them hooked, keep them there for longer. And in a sense, that is—that's dopamine hacking is about giving random rewards, right? And and it's—it's—it's a disempowering thing along the lines you said. And that is that is the kind of modus operandi for all technology now. Yeah. Absolutely. Yeah. Variable reinforcement schedule is the most—most best way to train animals, including humans. And we are susceptible—the—the unpredictable nature of the reward engages us with the system, and what makes us come because we want to control the system, right? We want to know how do I make the reward come, and of course, if you can't, then you keep on trying and trying and trying. Yeah. I mean, you know, we live in a world in which the—people have a lot of liberty about like how they spend their time. And I think that's as it should be. You know, I don't—you know, I don't think we should—I don't think we should legislate against frivolity, right? You know, if people want to spend a lot of time on TikTok, collectively, I understand that that's bad. But, you know, kind of like it is also—we—we, for better or worse, live in a world in which that is permissible, or we live in a country at least in which that is permissible. Um, where I think we need to be cautious, you know, so—but so—so, you know, kind of what—what what I'm saying is that, you know, kind of that kind of hacking, you know, maybe it's undesirable, I might deem it undesirable, but, you know, collectively as a society, there are many things that are undesirable, you know, alcohol is also addictive, but, you know, I'm probably going to have a beer as soon as this is done, right? So, you know, kind of there—that we make those choices, but I think that there are vulnerabilities. There are people who are uniquely vulnerable where that kind of liberty to\n\n\nKind of a hack, if you like, spills over into something that can be really actively harmful and can lead, of course, to, you know, people to do, you know, to self-harm. And there have been tragic cases as well, as I'm sure you already, as I'm sure you know, in which, you know, people have even taken their own life under influence which was which came from an AI system with which they interacting in this kind of like companion mode.\n\nDo you think it makes sense to think of evolution as having a goal?\n\nUm, probably not. Right. So there's this great, you know, kind of like this great way of thinking about, um, there's a paper that I really like which, um, draws upon the analogy of the kind of like blind progress of evolution, right? That, you know, kind of it's a selection mechanism that is not teological, right? It doesn't have a purpose. It just happens. And, you know, kind of argues that, um, you know, kind of we should think of kind of, um, evolution training in neural networks in a similar way, right? That it's kind of like it's very blind.\n\nUm, and, you know, kind of like I think that, yeah, that the I I think that there is a fundamental difference between evolution and the way that optimization happens, put it that way. And we could learn a lot in thinking about neural networks from thinking about the purposeless optimization that happens in evolution. Basically, it's a really um interesting topic for me.\n\nI was speaking with Kenneth Stanley the other day, and he he's done a lot of work about open-endedness. And of course, Tim Tashel works with DeepMind. Yeah. In Tim Rocktäschel's paper with um Edward Hughes. Yeah. Yeah. The open-ended system. An open-ended system is one from the perspective of an observer that produces a sequence of events which are um learnable and novel. Yeah. Yes. Exactly. It's about learnability, isn't it? Yeah. Yeah. Um, Joel Lemon, have you have you had Joel Lemon on the show?\n\nYeah. So Joel has written really, really nicely about this. I mean, Yeah. So I largely share his view and very close to Tim and Ed's view, which is that, um, Yeah. So the the world is open-ended and optimizing for open-ended systems using kind of like well-specified kind of narrow optimization towards a narrow goal is just doomed to failure, right? And there is probably something really deep about the way the the purposeless selection that happens in evolution conferring robustness because it doesn't precisely optimize for this narrow goal, but rather what it creates is this like astonishing heterogeneity, right? And the optimization algorithms that we use are all completely opposite, right? They are basically tailored for homogeneity. Like heterogeneity is a bug, and that's why LLMs show mode collapse. It's why, you know, kind of like you get this kind of like, you know, this um platonic hypothesis, you know, the idea that we're gradually converging towards kind of like essentially one common shared set of representations, right? It's like Yeah. Yeah. Yeah. Evolution doesn't do that.\n\nKenneth wrote this wonderful paper called the um the fractured entangled representation hypothesis. Oh, I don't know that paper. So um with um with Joel, I'm not sure if Joel was was part of this, but he was on Why Greatness Cannot Be Planned. They did this thing called Pickreeder, and that was like Flickr, where it was supervised by a diverse source of Humans, and the Humans could pick interesting image generators, which were CPN compositional pattern producing networks, and you could create this fogyny, and they they speak about this concept called deception, which is that the stepping stones that lead somewhere interesting don't resemble the interesting thing. So Humans have this this kind of idea of what's interesting because we seem to know the world well, and with a few steps in the fogyny they they found these um pictures of butterflies and apples, and when you do parameter sweeps on the networks because they so abstractly understand the objects, the apple would actually get bigger. One one neuron would make it bigger, one neuron would make the stem swing. And if you train a neural network with stochastic gradient descent to do the same thing and you do parameter sweeps, it's just it's like spaghetti all over the place. So they'll hypothesis, and this this seems like an obvious thing to say. If we could have a sparse representation which mirrored the world, then the creative leaps, because the knowledge is evolvable, we could trust it with autonomy because it would do the right thing. Yeah, that's amazing.\n\nSo I don't know about this paper. It sounds like I should read it. I mean, the idea that, yeah, that you have these that it's difficult to get places because the interim states are not highly valuable. I mean, I guess this is like, you know, kind of you this is a very old argument. This is the basis of like Paley's watchmaker argument, right? It's like how did we ever get the eye? You couldn't possibly evolve that. It's just too complicated. But yeah, those gradients must be there, right? The gradients are there.\n\nI have to say, um, Professor Summerfield, the pros, the way that you've written this book is very impressive to me. It's one of the best written pieces of of writing I've ever seen. And it couldn't it occurred to me whether you were deliberately making it so creative as for it to be impossible to be mistaken for AI-generated content. Um, I I don't know whether this is may maybe I've I've you know my my standards are so low now because you know in shitification and all of that, but it it was remarkable. But were you were you thinking that were you sort of like leaning into the creativity a little bit?\n\nI love to write. I love to find new ways to explain things to convey ideas. So that's a it's for me it's a selfish pleasure. It didn't cross my mind uh that people might think that I had used ChatGPT to write the book, but I guess in hindsight that's a kind of very sensible way of thinking about it. But no, I yeah, it was all me.\n\nThat is my been an absolute honor. Thank you so much. Thank you.\n",
  "dumpedAt": "2025-07-21T18:43:25.925Z"
}