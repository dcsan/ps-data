{
  "episodeId": "BzVAqnO5DH8",
  "channelSlug": "@practicallyintelligent",
  "title": "E10: Decoding AI Hype: A Practical Guide to Discerning Fact from Fiction",
  "publishedAt": "2024-02-27T13:30:07.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 0.7,
      "duration": 9.019
    },
    {
      "lang": "en",
      "text": "Nathan thanks for coming back on hey",
      "offset": 6.799,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "thanks for having me awesome so we're",
      "offset": 9.719,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "gonna go through a few areas where you",
      "offset": 13.28,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "think folks reading research papers",
      "offset": 15.519,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "reading articles news on AI uh make a",
      "offset": 18.199,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "couple mistakes get caught up in the",
      "offset": 21.24,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "hype go uh with the first one um that we",
      "offset": 23.279,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "talked about which was uh the tendency",
      "offset": 26.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "to label models as better worse Etc",
      "offset": 29.24,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "without sort of context or domain so",
      "offset": 32.92,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "talk to me about about this one a little",
      "offset": 36.92,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "yeah yeah and I'll I'll add some context",
      "offset": 39.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "to that because when we originally",
      "offset": 41.28,
      "duration": 2.599
    },
    {
      "lang": "en",
      "text": "brought this up this for everyone",
      "offset": 42.6,
      "duration": 2.68
    },
    {
      "lang": "en",
      "text": "listening because when we first brought",
      "offset": 43.879,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "this up we were trying to decide like",
      "offset": 45.28,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "you know he's going to be on a second",
      "offset": 47.239,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "time like we don't want to repeat what",
      "offset": 48.44,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "are we going to talk about and then all",
      "offset": 50.199,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "of a sudden we start talking about some",
      "offset": 51.92,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "paper and then we on off on some tangent",
      "offset": 53.079,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "on like well what makes it better who's",
      "offset": 56.199,
      "duration": 2.761
    },
    {
      "lang": "en",
      "text": "to say it's better like what does that",
      "offset": 57.719,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "even mean and then that kind of led into",
      "offset": 58.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "our our first conversation so this is",
      "offset": 61.28,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "something on the minds of a lot of",
      "offset": 63.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "people it's like when when someone comes",
      "offset": 64.68,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "out and says oh we are beating this",
      "offset": 66.32,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "model we're slightly worse than this",
      "offset": 68.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "model and it's like and then people",
      "offset": 70.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "always ask me sonan have you tried",
      "offset": 72.4,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "whatever Gemini is it better than gp4",
      "offset": 74.68,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "and I'm like I can't really answer that",
      "offset": 77.439,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "in a sentence or less so this is the",
      "offset": 79.799,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "kind of question that we we get a lot so",
      "offset": 82.439,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "we're really curious to hear your",
      "offset": 84.6,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "perspective yeah I mean this is kind of",
      "offset": 86.799,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "timely we're recording the week of",
      "offset": 88.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "Gemini Ultra becoming",
      "offset": 90.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "available earlier this week seared into",
      "offset": 92.079,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "my brain was this hilarious tweet where",
      "offset": 94.399,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "like French law chal shal chal I don't",
      "offset": 97,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "know how to pronounce it in French it",
      "offset": 100.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "brutal rough embarrassing to my former",
      "offset": 101.6,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "former employer but he essentially gave",
      "offset": 104.2,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "a tweet that was like F2 is",
      "offset": 106.2,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "bad like everyone in Industry knows this",
      "offset": 109.04,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "model is bad they just trained it to get",
      "offset": 111.6,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "high B scores and it's like some people",
      "offset": 114.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "on the open source thing were sad and I",
      "offset": 117.439,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "was like this why is bitter lesson but",
      "offset": 119.119,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "I'm like I'm not surprised and it's like",
      "offset": 120.719,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "how do you tell this from doing this I",
      "offset": 123.36,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "think there's a lot of expert driven",
      "offset": 126.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "things like I follow synthetic data and",
      "offset": 129.56,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "Alignment methods whatever these are",
      "offset": 131.84,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "pretty closely so I've been kind of",
      "offset": 134,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "there's like a lot of there's a specific",
      "offset": 136.04,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "line of work there with like lima and",
      "offset": 137.519,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "then these five models which is saying",
      "offset": 139.239,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "like you can do more with less data",
      "offset": 140.8,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "which is kind of a pointer it's like",
      "offset": 143.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "whenever there's a",
      "offset": 145.8,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "big we did something different that goes",
      "offset": 147.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "against the kind of core truths of what",
      "offset": 150.519,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "makes deep learning work you should",
      "offset": 152.48,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "probably be skeptical it's like yes you",
      "offset": 153.879,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "can make a small model good but you",
      "offset": 155.8,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "probably have to narrow the scope of",
      "offset": 157.519,
      "duration": 2.761
    },
    {
      "lang": "en",
      "text": "what you want it to be good at it's like",
      "offset": 158.959,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "there's no free lunch in any of these",
      "offset": 160.28,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "things like like there's no free lunch",
      "offset": 161.68,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "in AI like you can't make a model",
      "offset": 163.68,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "smaller and better at everything so you",
      "offset": 165.879,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "could might be able to reduce the",
      "offset": 167.48,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "overall capacity by making it better at",
      "offset": 169.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "one thing so if anyone's trying to give",
      "offset": 172.08,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you the marketing of like we did",
      "offset": 174.04,
      "duration": 2.44
    },
    {
      "lang": "en",
      "text": "everything better than everyone else",
      "offset": 175.2,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "that's like kind of a clear answer if",
      "offset": 176.48,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "it's not as good",
      "offset": 178.879,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "and with the Gemini thing it's like I",
      "offset": 180.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "think it's pretty clear that if the",
      "offset": 181.84,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "discussion is happening if it's",
      "offset": 184.76,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "legitimately better or worse that",
      "offset": 186.04,
      "duration": 2.68
    },
    {
      "lang": "en",
      "text": "normally means that they're pretty",
      "offset": 187.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "similar it's pretty easy to tell what a",
      "offset": 188.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "model is actually just not good and I",
      "offset": 191.08,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "think Gemini's a little slower it's",
      "offset": 194.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "pretty clearly a bigger model behind the",
      "offset": 196.159,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "scenes",
      "offset": 197.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and that's a good like that's just kind",
      "offset": 199.28,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "of how it'll be for a while these models",
      "offset": 202.56,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "oscillate let's try to loop loop my",
      "offset": 204.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "thinking back to the original question",
      "offset": 207,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "it's like how do you know if a model is",
      "offset": 208.28,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "good when you're going to see a model",
      "offset": 209.48,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "you're going it's going to be",
      "offset": 211.599,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "accompanied by a bunch of scores and",
      "offset": 212.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "these numbers tend to mean less than",
      "offset": 214.92,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "people think because I think a lot of",
      "offset": 218,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "like mmu is a big Focus for people right",
      "offset": 220.84,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "now a lot of models that are being",
      "offset": 223.4,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "released today are in like this 1 to 15",
      "offset": 225.92,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "billion parameter range and mlu is like",
      "offset": 228.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "a multiple just thinking about the",
      "offset": 232.04,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "fundamentals what it is mlu is a",
      "offset": 233.36,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "multiple choice questioning thing these",
      "offset": 235.28,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "models that we're releasing the base",
      "offset": 238.519,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "models get anywhere from 15 to 50% and",
      "offset": 240.12,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "if you just do the basic logic of it if",
      "offset": 243.28,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "you're doing a four answer multiple",
      "offset": 245.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "choice question random is 25% so it's",
      "offset": 246.799,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "like it's not necessarily the same as",
      "offset": 249.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like error bar on an evaluation but if",
      "offset": 251.439,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you think about what the",
      "offset": 253.56,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "random margin is and what just adding a",
      "offset": 255.359,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "bit of noise would do to the answers if",
      "offset": 258.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "it could change it by 25% it's like",
      "offset": 260.759,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "really hard to look at these numbers and",
      "offset": 263.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "a lot of other instruction models have a",
      "offset": 265.24,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "similar problem which is people are",
      "offset": 266.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "comparing evaluations for the 10 to 20%",
      "offset": 268.199,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "range which is like are we sure that",
      "offset": 270.72,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "these low numbers actually even mean",
      "offset": 273.039,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "anything and it doesn't like if the",
      "offset": 274.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "numbers are both meaningless it doesn't",
      "offset": 277.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "matter if you beat them and then it kind",
      "offset": 278.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of goes into the whole conversation of",
      "offset": 280.919,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "contamination and stuff that we won't go",
      "offset": 282.68,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "down the rabbit hole of right now sure",
      "offset": 284.56,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "we'll say that for our third uh our",
      "offset": 286.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "third time together don't worry but it's",
      "offset": 288.919,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "just basic",
      "offset": 290.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "math well it's funny because when when",
      "offset": 292.32,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "you you started that by by talking about",
      "offset": 294.6,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "when when you see someone breaking a",
      "offset": 297,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "court Canada machine learning you know",
      "offset": 298.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "be skeptical but a lot of people don't",
      "offset": 301.479,
      "duration": 2.841
    },
    {
      "lang": "en",
      "text": "know those core tenants of machine",
      "offset": 303.039,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "learning and and in fact you kind of",
      "offset": 304.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "just said one which is whenever you're",
      "offset": 305.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "training any machine learning model you",
      "offset": 308.08,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "know Screw language models for a second",
      "offset": 309.759,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "even like training a decision Tree",
      "offset": 311.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "classifier on some classification data",
      "offset": 313.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "set the bare minimum the floor of any",
      "offset": 315.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "machine learning engineer's job is to",
      "offset": 318.96,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "beat the null model which is if it's a",
      "offset": 321.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "classification for example what would",
      "offset": 323.72,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "you get by guessing optimally the same",
      "offset": 325.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "thing over and over again like if the",
      "offset": 329.68,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "class is in balance and like 60% of them",
      "offset": 331.16,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "are are in one class you just guess that",
      "offset": 333.199,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "class over and over again you got 60% so",
      "offset": 335.479,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "you gotta at bare minimum beat 60% and",
      "offset": 338.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "in this case when you're talking about",
      "offset": 341.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "mlu you know solving a multiple choice",
      "offset": 342.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "question it's kind of the same principle",
      "offset": 345,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "which is well if you just kind of guess",
      "offset": 346.759,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "you're GNA get 25% so if we're not even",
      "offset": 349.88,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "beating consistently",
      "offset": 352.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "25% what is the point of looking at this",
      "offset": 354,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "model with like serious eyes yeah yeah I",
      "offset": 356.6,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "mean like I'm building a it's a fun it's",
      "offset": 360.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "it's even fun to look at this like I",
      "offset": 362.919,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "just added this to a research project",
      "offset": 364.44,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "that I'm building where the it's 50% so",
      "offset": 366.039,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "I was like okay added the line of Shame",
      "offset": 368.479,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "which is you do worse than a coin",
      "offset": 370.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "flip on on my little internal",
      "offset": 372.4,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "leaderboard which is like yeah it",
      "offset": 375.12,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "happens it's not easy to get signal",
      "offset": 377.56,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "always no it's not and to be fair again",
      "offset": 380.12,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "to be Exum be fair these are extremely",
      "offset": 382.72,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "high level numbers you know accuracy is",
      "offset": 384.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "you know is one metric coming back back",
      "offset": 387.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to the example of classification you got",
      "offset": 389.599,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "Precision recall F1 there's so many more",
      "offset": 391.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "ways to probe in and say hey look maybe",
      "offset": 393.319,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "the overall accuracy is here but our",
      "offset": 395.639,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "Precision is 90 and but our recall",
      "offset": 397.84,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "happens to be 20 or whatever it is and",
      "offset": 399.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and then they can make the case then to",
      "offset": 402.44,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "say is our model amazing at all things",
      "offset": 404.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "no but here are some applications in",
      "offset": 406.88,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "which these kinds of situations would",
      "offset": 409.039,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "actually be beneficial High Precision",
      "offset": 411.319,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "means it would be not the worst",
      "offset": 413.639,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "situation to use for you know",
      "offset": 415.919,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "Diagnostics capabilities because because",
      "offset": 417.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "when it says yes you can at least trust",
      "offset": 419.8,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "it uh and that kind of nuance tends to",
      "offset": 422.08,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "be lost a little bit right in this in",
      "offset": 424.96,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "this really hierarchy of where are we",
      "offset": 426.44,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "ranking all of these models you kind of",
      "offset": 428.879,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "lose the Nuance of well for what using",
      "offset": 430.879,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "the model to help teenagers write essays",
      "offset": 434.12,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "or using the model to help lawyers",
      "offset": 437.52,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "review uh law documents like what are we",
      "offset": 440.44,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "talking about when we say better and",
      "offset": 443.16,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "worse so I think a lot of that Nuance is",
      "offset": 444.72,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "not out the window per se but it's just",
      "offset": 447.52,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "secondary or tertiary or further down on",
      "offset": 449.72,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "the list of conversation topics yeah I",
      "offset": 452.919,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "mean to be to to wrap it up to like",
      "offset": 455.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "specific like some of the popular",
      "offset": 459.12,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "benchmarks like mlu and big bench hard",
      "offset": 460.599,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "or grade school math they have different",
      "offset": 463,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "ways of computing the score and you need",
      "offset": 465.8,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "to make sure that you're compare like",
      "offset": 469.44,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "these should be documented but there's",
      "offset": 471.12,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "like literally different ways of",
      "offset": 472.68,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "computing the number and then the number",
      "offset": 473.96,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "is what people copy so like we I had to",
      "offset": 475.639,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "do the I had to do the work of like",
      "offset": 478.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "tracking down how these different models",
      "offset": 480.52,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "computed their numbers and be like at",
      "offset": 482.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "least I at least I could say how they",
      "offset": 484.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "did it but it's not even fun when you're",
      "offset": 486.08,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "doing that again core tenent of math",
      "offset": 488.56,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "don't forget your units or else what are",
      "offset": 491.039,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "you talking about how do you compare",
      "offset": 493.24,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "these two",
      "offset": 494.879,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "things sorry a go what were you saying",
      "offset": 496.12,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "no no I was saying I just uniformly and",
      "offset": 499.199,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "this is like I don't know like there's",
      "offset": 502.319,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "certain news weeks where this is like",
      "offset": 504.159,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "50% of your news feed it's it's just",
      "offset": 505.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "literally this model was released some",
      "offset": 508.56,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "claimed to param account it's all",
      "offset": 510.12,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "performative nonsense and I almost",
      "offset": 511.199,
      "duration": 6.681
    },
    {
      "lang": "en",
      "text": "always filter this out um it is clearly",
      "offset": 513.479,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "driven by this PR news cycle where",
      "offset": 517.88,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "there's some product lead or engineering",
      "offset": 519.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "lead who wants to announce uh and and is",
      "offset": 521.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "put on a PR cycle like the way this",
      "offset": 524.44,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "mechanically works is you have some",
      "offset": 526,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "product launch and then marketing takes",
      "offset": 527.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "it over works with the pr firm they",
      "offset": 528.76,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "publish a bunch of news around it and",
      "offset": 530.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "try and um sort of get stuff out there",
      "offset": 532,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "but the other thing is now I feel like",
      "offset": 535.24,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "Nathan with like even these leader",
      "offset": 537.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "boards they've just gotten so gamified",
      "offset": 539.2,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "that we talked about we me we had um",
      "offset": 542,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "other folks talking about you know need",
      "offset": 544.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "for more modular you know benchmarking",
      "offset": 546.12,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "uh Etc it's uh it's like that midwidth",
      "offset": 549,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "Meme where like everyone looks at like",
      "offset": 551.519,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "so the right end looks at the",
      "offset": 553.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "leaderboard left end looks at the",
      "offset": 554.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "leaderboard and the middle is um or",
      "offset": 556.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "sorry the middle is and yeah exactly",
      "offset": 558.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it's actually just like playing with the",
      "offset": 561.16,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "data and looking at the model that's",
      "offset": 562.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "relevant for your tasks but it is a",
      "offset": 563.68,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "little bit one of those things where um",
      "offset": 565.92,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "I remember initially getting a little",
      "offset": 569.36,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "more suede when uh especially more so",
      "offset": 570.76,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "around when llama 2 came out when this",
      "offset": 573.959,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "was a little bit less of a thing now",
      "offset": 575.44,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "it's just become something I just",
      "offset": 577.64,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "completely ignore there's something",
      "offset": 578.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "that's released recently I wait for uh",
      "offset": 579.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "for wait for the dust to settle yeah",
      "offset": 582.839,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "it's normally safer to wait I mean",
      "offset": 584.76,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "there's a new model this week called",
      "offset": 586.279,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "like Smog 72b or something which is",
      "offset": 587.64,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "supposed to be this like it's like the",
      "offset": 590.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "top it's lit like the top of the hugging",
      "offset": 592.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "face leaderboard it's like an open model",
      "offset": 594.079,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "and I was like just going to wait like I",
      "offset": 596,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "don't I literally saw that on my like my",
      "offset": 598.76,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "phone when it PS up like the Google",
      "offset": 600.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "results it was like recommended articles",
      "offset": 602.399,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "I was like no wle for now please it's",
      "offset": 604.8,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "pretty much like if that's your leading",
      "offset": 608.399,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "claim of your model it's unlikely to be",
      "offset": 610.04,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "that that actually useful it's it's",
      "offset": 612.079,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "perfectly fine to have good scores but",
      "offset": 615.279,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "like most of the time these days when",
      "offset": 616.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "they lead with that you're like uh I've",
      "offset": 618.56,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "got better things to do so it's like",
      "offset": 621.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Street smarts versus book smarts okay",
      "offset": 623.959,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "book smarts is good and all but when you",
      "offset": 625.64,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "get out there and you got to start",
      "offset": 627.56,
      "duration": 2.6
    },
    {
      "lang": "en",
      "text": "talking to people day to day millions",
      "offset": 628.6,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "billions of people out there got to have",
      "offset": 630.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "some Street smarts I have kind of hot",
      "offset": 631.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "take that I even think chatbot arena is",
      "offset": 633.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "a little overfit to like chat arena is",
      "offset": 635.32,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "very good but we don't know the",
      "offset": 638.8,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "distribution of the prompts I have a",
      "offset": 639.959,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "guess that it's like a third code a",
      "offset": 641.839,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "third like role play and then like a",
      "offset": 644.839,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "third other stuff and like models that",
      "offset": 647.399,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "refuse weirdly are just going to get",
      "offset": 649.44,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "hammered which is probably why like",
      "offset": 650.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Claude does really badly and it's just",
      "offset": 652.36,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "like I guess opening eyes opening eyes",
      "offset": 655.12,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "obviously really good but like there's a",
      "offset": 657.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "lot of muddled stuff in between there",
      "offset": 659.079,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "which we don't really know how much the",
      "offset": 660.8,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "models like I have some data from them",
      "offset": 663.279,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "and I want to look into it but we don't",
      "offset": 665.399,
      "duration": 2.521
    },
    {
      "lang": "en",
      "text": "have the we don't have the way to",
      "offset": 666.68,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "classify the prompts yet but within a",
      "offset": 667.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "year or two it'll be pretty easy to be",
      "offset": 669.639,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "like these are the types of things",
      "offset": 671.36,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "people are asking in these",
      "offset": 672.639,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "conversational data sets I'm pretty sure",
      "offset": 673.839,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "there's some chapot Arena there's a data",
      "offset": 676.44,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "set on hugging face with a chapot Arena",
      "offset": 678.399,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "and I I remember using it for something",
      "offset": 680.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "and and thinking a very similar thing",
      "offset": 683.079,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "which is you know a lot of the times",
      "offset": 684.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "when you get one of those you know I",
      "offset": 686.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "can't answer that It generally just",
      "offset": 688.32,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "getss voted down because well hey I",
      "offset": 689.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "wanted you to answer it but that's not",
      "offset": 691.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "really up to you all the",
      "offset": 693.76,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "time uh AA I totally agree when you were",
      "offset": 695.8,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "talking about a lot of this PR this",
      "offset": 700.079,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "marketing hype and especially when",
      "offset": 702.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you're talking about llama especially",
      "offset": 704.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "companies like meta you know Microsoft",
      "offset": 705.56,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "like when they put out Google with",
      "offset": 708.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Gemini when you put out models it is an",
      "offset": 710.88,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "opportunity to you know make a name for",
      "offset": 714.2,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "yourself and say hey here's where we are",
      "offset": 716.959,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "on the map here's where we stand here's",
      "offset": 718.48,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "what we're doing and sometimes that can",
      "offset": 720.079,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "really get muddled in with well how",
      "offset": 723,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "actually useful is is the model or is",
      "offset": 725.36,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "this all just marketing that being said",
      "offset": 727.519,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "other institutions who have more intent",
      "offset": 730.76,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "behind those releases and and",
      "offset": 733.639,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "deployments they can have a lot of",
      "offset": 736.16,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "different intents and obviously I'm kind",
      "offset": 738,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "of coming back to Nathan here uh because",
      "offset": 739.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "you recently your institution Nathan was",
      "offset": 741.839,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "part of amazing team that recently open",
      "offset": 743.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "sourced one of one of the first if not",
      "offset": 746.199,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "the fully uh open- sourced llms do you",
      "offset": 748.6,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "want to tell us a little bit more about",
      "offset": 752.48,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "that yeah I mean we could talk about why",
      "offset": 754.24,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "evaluation it's hard too I think um",
      "offset": 756.959,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "there's a long story of essentially I",
      "offset": 760.12,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "see nothing that gets people scientists",
      "offset": 761.839,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "more nerd sniped than evaluation which",
      "offset": 763.68,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "is like these things that we're talking",
      "offset": 765.399,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "about so it's not just people that are",
      "offset": 766.68,
      "duration": 2.68
    },
    {
      "lang": "en",
      "text": "trying to follow this it's like people",
      "offset": 768.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "who are building these models it's",
      "offset": 769.36,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "definitely not the first open model but",
      "offset": 771,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "it's probably like the third or the",
      "offset": 772.639,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "fourth that follows in a few really",
      "offset": 773.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "important artifacts so like Bloom",
      "offset": 775.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "everyone knows about this like huge",
      "offset": 777.76,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "multi-organization open multilingual",
      "offset": 779.12,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "model that hugging phas kickstarted",
      "offset": 781.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "they're not the only ones involved and",
      "offset": 783.24,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "then Paia from a luor AI which is like",
      "offset": 784.92,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "pretty solid models at the time but not",
      "offset": 787.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "how models are used now so the biggest",
      "offset": 790.12,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "change in how people train models now is",
      "offset": 792.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "we train them for a lot more tokens so",
      "offset": 793.839,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "it's kind of hard to compare models from",
      "offset": 795.839,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "Pia to what ELO is and theno is like the",
      "offset": 798.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "start of a process I think compared to",
      "offset": 800.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "those those two other things kind of",
      "offset": 802.68,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "were one set and done ando's kind of",
      "offset": 804.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "being like okay we're going to really",
      "offset": 807.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "try to keep training and improving",
      "offset": 808.44,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "models in the open and keep releasing",
      "offset": 810.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "them and trying to have them be",
      "offset": 812.8,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "state-ofthe-art and the models are okay",
      "offset": 814.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "like they're not at M level they're a",
      "offset": 817.279,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "little below llama 2 so it actually like",
      "offset": 819.68,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "a we did a tokenization error in our",
      "offset": 821.959,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "llama 2 Val so the scores we reported",
      "offset": 825.199,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "for llama were slightly low and this",
      "offset": 827.279,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "should be updated on the blog post now",
      "offset": 828.68,
      "duration": 2.68
    },
    {
      "lang": "en",
      "text": "but like obviously we're not going to be",
      "offset": 830.32,
      "duration": 2.519
    },
    {
      "lang": "en",
      "text": "able to make noise about like we messed",
      "offset": 831.36,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "up our table a little bit but like",
      "offset": 832.839,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "essentially the issue for",
      "offset": 835.56,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "cut to to like for people that want to",
      "offset": 837.759,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "know what the weird things are is",
      "offset": 841.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "essentially it's like if you're asking a",
      "offset": 843.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "multiple choice question the Llama",
      "offset": 844.68,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "tokenizer was having an extra space",
      "offset": 846.72,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "before the answer so it expects question",
      "offset": 849.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "colon space answer and our code had",
      "offset": 851.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "question colon space space and that",
      "offset": 853.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "messes the error the valves up a couple",
      "offset": 856.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "percent and then that's enough to make",
      "offset": 858.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "it Soo was listed at the top but",
      "offset": 859.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "technically Lama 2 is the best and it's",
      "offset": 861.56,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "like okay like now our blog post",
      "offset": 863.639,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "is but like that's the type of thing",
      "offset": 865.759,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "that's determining these numbers of",
      "offset": 867.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "people comparing models and like yeah",
      "offset": 869.959,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "it's just really hard it's like not",
      "offset": 872.48,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "worth spending all of your days on it is",
      "offset": 874.079,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "extremely hard and I think I mean your",
      "offset": 877.079,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "approach even like very frankly Nathan",
      "offset": 879.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "like even even to come on and say oh",
      "offset": 881.44,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "yeah we perform slightly worse than uh",
      "offset": 883.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Mr Lama those and then you explain like",
      "offset": 885.24,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "well then here's how it happened then",
      "offset": 887.88,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "here's how you do it and that's not",
      "offset": 889.04,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "always the point and I think that's",
      "offset": 890.759,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "really my point which is it's not always",
      "offset": 892.279,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "the point to only release models when",
      "offset": 894.72,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "they're better than everyone else right",
      "offset": 897.56,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "because if you've never checked out um",
      "offset": 900.199,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "anyone listening if you haven't checked",
      "offset": 901.959,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "outo I recommend you do because it's not",
      "offset": 903.519,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "just downloading a model and trying it",
      "offset": 906.199,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "out and see what happens there's the",
      "offset": 907.72,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "eval uh framework there's the um there's",
      "offset": 909.639,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "the DPO framework there's all of the",
      "offset": 913.6,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "Frameworks all of the code all of the",
      "offset": 915.92,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "data which by the way as a Turk I do",
      "offset": 917.639,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "appreciate that it's called Doma the",
      "offset": 919.759,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "data set um everything's there and and",
      "offset": 921.519,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "again to Nathan's point they're really",
      "offset": 925.079,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "trying to make a point of this is how",
      "offset": 926.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "open source is really supposed to look",
      "offset": 928.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "like you know this this is what the",
      "offset": 930.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "process is meant to be and I think a lot",
      "offset": 932.72,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "of people respond really positively to",
      "offset": 934.88,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "that you know when I talk about it in my",
      "offset": 936.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "lectures you know and I show the GitHub",
      "offset": 938.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "everyone always says wow that's so much",
      "offset": 940.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and that's really just a short way of",
      "offset": 943,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "saying oh we're not used to this that's",
      "offset": 944.36,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "not really how we've been trained to",
      "offset": 946.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "think about open source so uh what's",
      "offset": 948.24,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "what's coming next then for foro and and",
      "offset": 951.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "for what you're all working",
      "offset": 954.6,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "on more models more modality is trying",
      "offset": 956.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "to be better it's like pretty simple",
      "offset": 959.199,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "we're trying to get more Compu we're",
      "offset": 961.48,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "trying to do more of the",
      "offset": 963.16,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "same it's like it's really like that's",
      "offset": 964.72,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "the thing that I think is when you see",
      "offset": 967.199,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "major projects you don't really know",
      "offset": 969.16,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "what's coming from them especially with",
      "offset": 970.48,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "academics it's like Pia is great it's",
      "offset": 971.92,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "like okay I know Lu AI is doing other",
      "offset": 973.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "great things now but it's like they're",
      "offset": 976.399,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "not doing like Pia 2 it's like yeah",
      "offset": 977.56,
      "duration": 2.839
    },
    {
      "lang": "en",
      "text": "we're gonna do Elmo 2 we're gonna do",
      "offset": 979.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Elmo 70b whatever and we've already like",
      "offset": 980.399,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "publicly said all these things yeah um",
      "offset": 983.199,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "we've talked a lot the model space and",
      "offset": 987.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and evaluation that for a while there's",
      "offset": 989.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "two uh conrete examples of discourse on",
      "offset": 991.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "how folks should evaluate papers that I",
      "offset": 994,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "thought we could walk through Nathan",
      "offset": 995.68,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "that both areas you're familiar with uh",
      "offset": 997.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "both kind of Laura versus Q Laura and",
      "offset": 999.399,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "then the D poo versus the DPO debate in",
      "offset": 1001.48,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "both instances I think there you know",
      "offset": 1004.279,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "just discussions on different mechanisms",
      "offset": 1006.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "for machine learning where I could read",
      "offset": 1008.199,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "luckily I have you know you two I can I",
      "offset": 1009.92,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "can text and different folks that I can",
      "offset": 1012.519,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "ask to explain this to me but for folks",
      "offset": 1014.759,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "that get caught up in those sorts of",
      "offset": 1016.56,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "stuff maybe we could use both of those",
      "offset": 1018,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "as examples of Nathan some uh maybe some",
      "offset": 1019.36,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "problematic stuff in the discourse and",
      "offset": 1023.199,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "then how uh if you were to go back and",
      "offset": 1025.4,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "how that those those new Cycles unfolded",
      "offset": 1028.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "how you would have uh you know stayed",
      "offset": 1030.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "grounded I think both are relevant one",
      "offset": 1032.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you know very relevant for rhf and then",
      "offset": 1034.76,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "Cur obviously because of AI 2's you know",
      "offset": 1036.6,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "connection to to that work there as well",
      "offset": 1039.36,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "so either or but just curious how you",
      "offset": 1041.28,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "would have navigated those news Cycles a",
      "offset": 1043.4,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "little differently and maintained",
      "offset": 1044.839,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "grounded during those I think they kind",
      "offset": 1046.12,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "of are played out the same which is like",
      "offset": 1048.96,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "there's been two methods one of which",
      "offset": 1052.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "has kind of been established from Big",
      "offset": 1054.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "players which is like instruction tuning",
      "offset": 1056.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "normal instruction tuning and Po and",
      "offset": 1058.679,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "then a new thing which is simpler to",
      "offset": 1061.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "implement or more efficient that a lot",
      "offset": 1064,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "of people are using and because it",
      "offset": 1065.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "generally is a trend of when a lot of",
      "offset": 1068.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "people use it people assume that it's",
      "offset": 1070.679,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "better and just because it's easy to use",
      "offset": 1072.16,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "that it is better which is kind of is",
      "offset": 1074.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "kind this kind of can go both ways so is",
      "offset": 1076.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "like like when talking this is kind of a",
      "offset": 1078.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "link is like when you see a paper if",
      "offset": 1080.4,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "there's actually code it's normally",
      "offset": 1081.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "better and if you skim the code for five",
      "offset": 1083.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "minutes you can normally tell if they",
      "offset": 1085.12,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "took this stuff seriously or not and",
      "offset": 1086.4,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "it's fine to take an academic project",
      "offset": 1088.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "seriously as an academic project but if",
      "offset": 1089.919,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "you're trying to make it a serious tool",
      "offset": 1091.88,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "that people trade models with it looks",
      "offset": 1093.48,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "really different like Cura is an",
      "offset": 1094.96,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "academic project and if you open that",
      "offset": 1096.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "repository you're like oh there's",
      "offset": 1098.679,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "Cuda Corals in this this is this is a",
      "offset": 1100.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "lot which is very different than like a",
      "offset": 1103.28,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "random rhf method that's like okay they",
      "offset": 1105.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "for forked something deleted the get",
      "offset": 1107.799,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "history and added three lines of code",
      "offset": 1110.08,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "which you also see but like it's a",
      "offset": 1113.08,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "pretty clear flag that one of those is",
      "offset": 1115.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "meant to have different types of",
      "offset": 1116.799,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "longevity and back to like Kor and DPO",
      "offset": 1118.36,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "like I expect there's still going to be",
      "offset": 1122.039,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "more people doing Cur especially on like",
      "offset": 1124.24,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "the long tail of ml a lot of people can",
      "offset": 1126.72,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "find tun models without it but people do",
      "offset": 1129.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "both and there's like a trickle of",
      "offset": 1131.88,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "results buried in papers as like Kor is",
      "offset": 1133.96,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "not quite as good if you can do the",
      "offset": 1136.32,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "other thing",
      "offset": 1137.52,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "but that's kind of fine and then DPO is",
      "offset": 1138.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the same thing which is like most rumors",
      "offset": 1140.919,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "and people are like DPO is actually not",
      "offset": 1143.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "quite as good and has these problems but",
      "offset": 1145.28,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "it'll move faster and iterate faster due",
      "offset": 1147.2,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "to it being available and it's just like",
      "offset": 1150.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "there's no ABS when there's an absolute",
      "offset": 1152.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it becomes very obvious is the thing and",
      "offset": 1154.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "there's normally not obvious results",
      "offset": 1156.919,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "these days yeah I I I love that take on",
      "offset": 1159,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the absolute right there's always a new",
      "offset": 1162.4,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "I I was about to say because I'm",
      "offset": 1164.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "actually teaching a reinforcement",
      "offset": 1165.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "learning class pretty coming up and I",
      "offset": 1167.32,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "will be using more I will most of my",
      "offset": 1170.6,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "examples when it comes to DPO versus Po",
      "offset": 1173.28,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "will be in proximal will be pop and the",
      "offset": 1175.84,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "reason when whenever someone asks me",
      "offset": 1179.159,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "this because i' I've had people come up",
      "offset": 1180.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "and ask me like in person like why are",
      "offset": 1182.12,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "you using Po and DPO exists and I was",
      "offset": 1184.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like a few reasons one it's pretty new",
      "offset": 1187.2,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "I'm still kind of figuring out like",
      "offset": 1189.64,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "where where it stands it's more it's",
      "offset": 1191.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "newer at least second and I this is the",
      "offset": 1192.64,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "point that that usually sticks which is",
      "offset": 1195.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "what if you don't have direct",
      "offset": 1197.88,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "preferences and I my one of my examples",
      "offset": 1199.72,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "is using like a sentiment classifier to",
      "offset": 1202.32,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "make summaries of from flant T5 more",
      "offset": 1204.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "neutral sounding so like if you don't",
      "offset": 1208.28,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "use more positive or negative words be",
      "offset": 1210.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "as neutral as possible and I use like a",
      "offset": 1212.4,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "sentiment uh classifier from hugging",
      "offset": 1214.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "face basically as the reward mechanism",
      "offset": 1216.6,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "just to see the difference to show",
      "offset": 1218.64,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "people this is what you can do when you",
      "offset": 1220.159,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "don't have direct preferences but you",
      "offset": 1221.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "have a model that you can trust to give",
      "offset": 1223.919,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "rewards and and that tends to stick more",
      "offset": 1226.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and again it all comes back to your",
      "offset": 1228.919,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "point Nathan which is people really it's",
      "offset": 1230.84,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "easier to think about things in not even",
      "offset": 1233.679,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "absolutes just ordinally like a is",
      "offset": 1236.32,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "better than B therefore forget a ever",
      "offset": 1238.84,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "existed B is everything until C exists",
      "offset": 1241.24,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "and then continue that train until you",
      "offset": 1244.159,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "know something something happens but",
      "offset": 1246.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it's not that easy right I I think you",
      "offset": 1248.919,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "know that that seems",
      "offset": 1250.88,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "fair yeah it's like I think that what it",
      "offset": 1254.039,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "manifests now is that there's a lot of",
      "offset": 1257.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "papers that use DPO and things like that",
      "offset": 1258.88,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "and it's it's this is definitely one of",
      "offset": 1261.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the harder ones in information diet is",
      "offset": 1263.559,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "just like figuring out how to be okay",
      "offset": 1265.6,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "with the fact that the distribution",
      "offset": 1268.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "you're sampling from is very biased and",
      "offset": 1270.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "like there's more papers because it's",
      "offset": 1272.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "more available but like quantity is a",
      "offset": 1274.36,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "bad like quantity is simultaneously a",
      "offset": 1277.36,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "good and a bad metric when there's",
      "offset": 1280.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "quantity of people doing exactly the",
      "offset": 1281.88,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "same thing that means the idea is",
      "offset": 1283.559,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "validated but just because there's like",
      "offset": 1285.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "more people in a space doesn't mean that",
      "offset": 1287.039,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it's necessarily better it's just like",
      "offset": 1289.159,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "gasty which a happens a lot right now",
      "offset": 1291.679,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "like there's so much to be gained by",
      "offset": 1295.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "being timely like there's a lot of",
      "offset": 1297.88,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "Financial and personal gain by being in",
      "offset": 1299.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "the right area which is a safe thing to",
      "offset": 1301.36,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "do but that doesn't mean that you have",
      "offset": 1303.159,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "to assume that it",
      "offset": 1304.76,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "is just definitively better it's just",
      "offset": 1306.2,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "safe for people to work in yeah I mean a",
      "offset": 1309.2,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "lot of this basic stuff to be more",
      "offset": 1311.76,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "conscientiousness going back to the kind",
      "offset": 1313.32,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "of model Point um but this it's funny I",
      "offset": 1314.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "feel like you would not trust a study if",
      "offset": 1317.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "it said cell phones caught cancer and",
      "offset": 1319.72,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "had a sample size of 12 the equivalent",
      "offset": 1321.12,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "of that is literally just scaming the",
      "offset": 1323.039,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "quality of like the reproducible code",
      "offset": 1325.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "like you can see the amount of time",
      "offset": 1328.12,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "someone um went and kind of published it",
      "offset": 1329.72,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "the other thing is I think there's um",
      "offset": 1332.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "something I do frequently that helps",
      "offset": 1334.88,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "specifically on some this stuff because",
      "offset": 1336.4,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "the model stuff I've just sort of",
      "offset": 1337.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "immediately filtered out and I'm less",
      "offset": 1339.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "technical than than than you are both",
      "offset": 1342.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "and I'm not uh not as familiar with a",
      "offset": 1343.799,
      "duration": 2.841
    },
    {
      "lang": "en",
      "text": "lot of stuff so I actually have to rely",
      "offset": 1345.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "on other people genuinely actually like",
      "offset": 1346.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Googled author names and see what like",
      "offset": 1349.08,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "they've submitted into prior conferences",
      "offset": 1350.72,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "Etc I do that too I feel bad it's it's",
      "offset": 1352.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "no it's not bad there's just so much",
      "offset": 1356.96,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "noise and I actually want to know but",
      "offset": 1358.48,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "it's crazy you have these substacks I",
      "offset": 1359.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "met a random substack owner who's doing",
      "offset": 1361.679,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "probably north of 10K a month and just",
      "offset": 1365.6,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "doing summaries of ml papers but 60% of",
      "offset": 1367.2,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "the papers don't have reproducible code",
      "offset": 1369.72,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "and another 30% are written by paper",
      "offset": 1371.48,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "that not you know published at at an I",
      "offset": 1373.159,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "clear at an icml Etc so just to add to",
      "offset": 1375.52,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "that I can't just doing that like added",
      "offset": 1378.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "double click has really it's a good",
      "offset": 1380.679,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "practice I think it's good to be like",
      "offset": 1383.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "it's you should be aware that sometimes",
      "offset": 1385.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "new things happen from other places but",
      "offset": 1388.2,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "it's good it's good to follow where work",
      "offset": 1390.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "is coming from from different things and",
      "offset": 1392.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "like I think different types of people",
      "offset": 1394.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "will follow different tracks of work",
      "offset": 1396.48,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "easier like I can obviously follow a",
      "offset": 1397.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "North American Paper easier than an",
      "offset": 1399.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Asian paper but some of these Asian",
      "offset": 1401.36,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "papers are releasing really good",
      "offset": 1403.24,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "artifacts and then we end up using them",
      "offset": 1404.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "anyways but it's just like there's some",
      "offset": 1405.96,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "time to like there and back to like",
      "offset": 1407.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "reading the code we're luckily coming to",
      "offset": 1409.44,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "a place at least if you're working in",
      "offset": 1411.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "like rlf or alignment where a good",
      "offset": 1412.919,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "litmus test is like if they have a demo",
      "offset": 1415.919,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "of the model and if they're willing to",
      "offset": 1417.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "put their model out there and like",
      "offset": 1419.64,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "people can talk to it it's really like",
      "offset": 1421.2,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "okay these people are much more serious",
      "offset": 1422.88,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "about what they're doing as because",
      "offset": 1425,
      "duration": 2.6
    },
    {
      "lang": "en",
      "text": "either they're going to be right or",
      "offset": 1426.6,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "they're going to get roasted but like",
      "offset": 1427.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "them getting roasted for having a bad",
      "offset": 1429.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "model is like still they're probably",
      "offset": 1430.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "going to improve a lot faster which that",
      "offset": 1432.64,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "change is huge then just kind of of",
      "offset": 1435.84,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "having random like large files on Google",
      "offset": 1438.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "Drive that you like no one's ever going",
      "offset": 1441.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to use it's like okay yeah I mean that",
      "offset": 1442.679,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "whole idea of like offline versus online",
      "offset": 1444.88,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "feedback is is all is all for me it's a",
      "offset": 1446.4,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "lot of product um engineering because",
      "offset": 1448.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the idea is you know when you build a",
      "offset": 1451.08,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "product you test it internally you get a",
      "offset": 1452.52,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "lot of offline feedback from people you",
      "offset": 1454.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "know at the company or or whatever it's",
      "offset": 1456,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "only when you put it out there you start",
      "offset": 1458.64,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "actually collecting feedback from real",
      "offset": 1460.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "people who are going to use it under",
      "offset": 1462.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "real circumstances that online feedback",
      "offset": 1463.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "that you can really start to understand",
      "offset": 1465.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "okay this is how people wanted to use",
      "offset": 1468.279,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "the model and hopefully you're logging",
      "offset": 1470.12,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "all that as well it all ends up back in",
      "offset": 1472.159,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "your your data set if you're training a",
      "offset": 1474.08,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "model or what have you but that that",
      "offset": 1475.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "notion of of putting it in front of",
      "offset": 1478.76,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "people and saying what about this is is",
      "offset": 1480.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "it can be quite useful now of course you",
      "offset": 1484.24,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "have to measure that with you making the",
      "offset": 1485.88,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "claim like this is the best thing you're",
      "offset": 1488.279,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "ever about to see here it is this",
      "offset": 1489.679,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "something that like Tech historically",
      "offset": 1491.48,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "had a problem with because ml is just",
      "offset": 1493.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "coming around to it which is realizing",
      "offset": 1495.52,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "like you need like like there's a Dev",
      "offset": 1497.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Advocate role which is like I do a lot",
      "offset": 1499.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of this work but not because it's like",
      "offset": 1501.88,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "what I'm compelled to do it's just kind",
      "offset": 1503.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "of like under Index right now as a lot",
      "offset": 1505.52,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "of people don't want to do the work of",
      "offset": 1507.559,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "like taking your work to somebody else",
      "offset": 1509.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "like I don't know if that's always been",
      "offset": 1512.08,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "a problem in Tech but that's really a",
      "offset": 1513.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "thing right now where a lot of labs and",
      "offset": 1515,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "good groups are not doing that work",
      "offset": 1518.44,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "which is like delivering it like they're",
      "offset": 1520.799,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "going to they're like make they're like",
      "offset": 1523.2,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "putting products into the world but",
      "offset": 1524.6,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "everyone's information diet is so effed",
      "offset": 1526.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "up that sometimes you need to go and",
      "offset": 1528.72,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "like literally put it in front of them",
      "offset": 1530.12,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "and be like this is my cool new thing",
      "offset": 1531.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "you must now try this and that's like",
      "offset": 1533.399,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "distribution channels and how that",
      "offset": 1535.799,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "controls people's AI diet diets and you",
      "offset": 1537.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "should defin like having people that you",
      "offset": 1540.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "trust is good like it doesn't need to be",
      "offset": 1542,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "me and like AK was the first person",
      "offset": 1543.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "getting big tweeting papers on this but",
      "offset": 1546.96,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "I think that like really people should",
      "offset": 1548.88,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "try to find smaller people than AK that",
      "offset": 1550.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "they trust for a specific domain that",
      "offset": 1553,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "they're interested in because you can't",
      "offset": 1554.679,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "follow everything in ml it's like you",
      "offset": 1556.32,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "should follow a few people somebody",
      "offset": 1557.799,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "that's good at pre-training and like",
      "offset": 1559.52,
      "duration": 2.6
    },
    {
      "lang": "en",
      "text": "just they don't have to be around",
      "offset": 1560.919,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "forever but like that type of diet does",
      "offset": 1562.12,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "give you an",
      "offset": 1564.48,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "edge yeah I think one thing that since",
      "offset": 1566.96,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "we're on the topic of improving",
      "offset": 1570.64,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "information died I think it is a it's a",
      "offset": 1571.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "big issue in the in the tech ecosystem",
      "offset": 1573.36,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "like even developer tooling you talk",
      "offset": 1577.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "about developer envel evangelist Nathan",
      "offset": 1578.52,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "like it's a very classic like develop it",
      "offset": 1580.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "looks great in this like quick demo I'm",
      "offset": 1582.799,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "doing on stage and like the minute you",
      "offset": 1584.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "have questions like I'm nowhere to be",
      "offset": 1585.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "seen Etc you get S to some form I had",
      "offset": 1587.24,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "this really really funny moment it's",
      "offset": 1590.159,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "head of an mL of a company that uh we",
      "offset": 1592,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "all know but uh he said something really",
      "offset": 1595.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "funny so we had a conference and he's",
      "offset": 1597.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "presenting on basically these different",
      "offset": 1598.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "ml topics and specifically more like",
      "offset": 1601.6,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "data engineering topics so like language",
      "offset": 1604.24,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "model infrastructure Etc he's Midway",
      "offset": 1605.88,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "through his presentation he's like and I",
      "offset": 1608.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "want to call out that none of the like",
      "offset": 1610.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "screenshots I've presented today are",
      "offset": 1613.08,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "actually from anyone technical they're",
      "offset": 1614.96,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "all from V firm's blog posts and so",
      "offset": 1616.96,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "everyone just started cracking up where",
      "offset": 1621.12,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "there is this weird thing in the",
      "offset": 1623,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "ecosystem in Tech where it's like it",
      "offset": 1624.159,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "tends to be that um you know we have you",
      "offset": 1626.24,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "know key you know different incentives",
      "offset": 1629.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "either portfolio companies Etc you know",
      "offset": 1631.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "we filter a lot of the feedback we don't",
      "offset": 1634.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "understand a lot of it and then we",
      "offset": 1636.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "disseminate it which creates a bunch of",
      "offset": 1637.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "uh positive you know effects in the",
      "offset": 1640.88,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "sense like people are more aware of",
      "offset": 1642.44,
      "duration": 2.839
    },
    {
      "lang": "en",
      "text": "certain topics now people I think are",
      "offset": 1643.84,
      "duration": 3.079
    },
    {
      "lang": "en",
      "text": "more interested in machine learning",
      "offset": 1645.279,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "we're having know a lot of great",
      "offset": 1646.919,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "discussions about this stuff but at the",
      "offset": 1648.52,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "same time has negative externalities as",
      "offset": 1649.799,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "well which is if you also don't have a",
      "offset": 1651.76,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "in the same way LMS are grounded Etc if",
      "offset": 1654.159,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "you don't have something in key experts",
      "offset": 1656.6,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "that you're grounding to you're going to",
      "offset": 1658.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "get just lost in the wind and so I think",
      "offset": 1659.919,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "there's a lot of that happening where",
      "offset": 1661.64,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "there's almost this funnel of",
      "offset": 1663,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "information hierarchy where if you don't",
      "offset": 1664.88,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "get it straight from you know I think",
      "offset": 1667.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "established technical sources and you're",
      "offset": 1669.399,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "just listen this H this happened in tech",
      "offset": 1670.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "for a long time where uh it's really",
      "offset": 1673.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "hard to I think parse through and you",
      "offset": 1675.919,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "get",
      "offset": 1677.36,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "really really mixed information so um",
      "offset": 1678.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "I'm generally staying off Twitter I'm",
      "offset": 1681.64,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "like along with you Nathan obviously and",
      "offset": 1683.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and texting you on I'm trying to find",
      "offset": 1685.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "four or five people I really really",
      "offset": 1687.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "trust and actually just go deep on on",
      "offset": 1689.039,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "their work uh versus and then if someone",
      "offset": 1691.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "else brings up a topic to me in",
      "offset": 1693.399,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "conversation and they're like oh you",
      "offset": 1695,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "should know about it that's generally",
      "offset": 1696.76,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "when I get interested in it versus um I",
      "offset": 1698.72,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "think just buying into every new topic",
      "offset": 1701.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that yeah there's a lot of benefit to",
      "offset": 1703.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "not being trying in the rat race right",
      "offset": 1705.2,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "now",
      "offset": 1707.24,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "you need to really think about it if",
      "offset": 1708.679,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "your incentives are to really follow all",
      "offset": 1710,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "the noise that's happening most people",
      "offset": 1711.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "don't speaking of the like hilariousness",
      "offset": 1714.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "of this and why it's so okay for people",
      "offset": 1716.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to be overwhelmed I was like I wasn't",
      "offset": 1718.6,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "logged into a browser other day and I",
      "offset": 1720.72,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "opened GitHub and even GitHub is like",
      "offset": 1722.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the world's leading AI powered developer",
      "offset": 1724.399,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "platform I was like what is their weird",
      "offset": 1727.2,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "ass like hugging face Logan on their",
      "offset": 1729.12,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "like website and it's like why does",
      "offset": 1733.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "everything have to be this right now so",
      "offset": 1735.799,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "that's what you see if you open GitHub",
      "offset": 1737.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in an incognito window it's just like",
      "offset": 1738.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "how do we end up here like why did",
      "offset": 1741.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "GitHub need to Rebrand because these",
      "offset": 1743.679,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "analyst reports you know like have you",
      "offset": 1745.84,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "seen these like uh there's like a bunch",
      "offset": 1747.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "of Quant Bots that'll like front run a",
      "offset": 1749.24,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "stock if it mentions AI more so now like",
      "offset": 1751.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "all these CFOs like CEOs are just trying",
      "offset": 1753.519,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "to drop AI as much as possible oh my God",
      "offset": 1756.12,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "the stock because they're like oh maybe",
      "offset": 1758.72,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "we're affiliated and correlate with",
      "offset": 1760.159,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "Nvidia and some you know algorithm and",
      "offset": 1761.64,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "it boost the stock so that's literally",
      "offset": 1764.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "happening now which is like look",
      "offset": 1766.159,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "I drop I hate making the comparison but",
      "offset": 1768.76,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "when you follow a really hyped up",
      "offset": 1771.84,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "technology from subhype to subhype to",
      "offset": 1774.519,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "subhype maybe like crypto it might lead",
      "offset": 1776.84,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "to some bad places right not saying it's",
      "offset": 1780,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "all going to collapse but the more",
      "offset": 1782.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "analogies you kind of find to those to",
      "offset": 1784.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "to crypto the more I I try to take some",
      "offset": 1787.2,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "pause because when crypto became huge",
      "offset": 1789.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and I I won't say crypto I'll say you",
      "offset": 1792.039,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "know block Tang Technologies funable",
      "offset": 1793.6,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "non-fungible tokens the whole ecosystem",
      "offset": 1795,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "when that ecosystem starts to get big",
      "offset": 1798.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "you you all of a sudden see a lot of new",
      "offset": 1800.88,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "people who are suddenly experts in the",
      "offset": 1802.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "topic who are deting information very",
      "offset": 1804.44,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "similar to kind of what you see today",
      "offset": 1806.679,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "and then you moved from subhype to",
      "offset": 1808.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "subhype meaning you know erc20 for",
      "offset": 1810.24,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "fungible coins um 721s for nfts and then",
      "offset": 1812.72,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "there were derivatives of nfts that",
      "offset": 1816.6,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "would make things nuances more easy and",
      "offset": 1818.519,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "then you get to this point where",
      "offset": 1822,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "everything's so inflated and then",
      "offset": 1823.6,
      "duration": 3.079
    },
    {
      "lang": "en",
      "text": "obviously you know there's a bit of a",
      "offset": 1825.039,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "collapse and",
      "offset": 1826.679,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "bad things happen but I'm not saying",
      "offset": 1827.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "we're on that path but you could you can",
      "offset": 1829.679,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "draw a lot of these Corel so there are",
      "offset": 1832,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "Pathways in which you know enough people",
      "offset": 1835.08,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "are are kind of acting this way where um",
      "offset": 1838.24,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "you know we have to be uh careful so",
      "offset": 1841.72,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "Nathan maybe you can help us out um by",
      "offset": 1844.48,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "giving us and our our listeners some",
      "offset": 1847.919,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "constructive advice on you know where",
      "offset": 1849.919,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "what are some of the top things we kind",
      "offset": 1853.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "of started talking about this already",
      "offset": 1854.919,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "with code and stuff but what are some of",
      "offset": 1856.32,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "the top things that you kind of browse",
      "offset": 1858.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "and look for uh just to give you some",
      "offset": 1860.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "initial signal of this is actually good",
      "offset": 1862.559,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "to dive into a little bit",
      "offset": 1864.679,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "more yeah I mean I don't think you",
      "offset": 1867.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "should be like me because I like",
      "offset": 1869.6,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "actively read Twitter to try to find",
      "offset": 1871.159,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "that like make sure I'm up to date",
      "offset": 1873.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "because I write and produce content on",
      "offset": 1875.039,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "this so there's like a pretty different",
      "offset": 1877.72,
      "duration": 7.64
    },
    {
      "lang": "en",
      "text": "thing and most of my information is",
      "offset": 1881.399,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "partitioned either into papers or like",
      "offset": 1885.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "model releases and I mostly only really",
      "offset": 1888.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "follow model releases that have weights",
      "offset": 1890.72,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "available which is mostly on hugging",
      "offset": 1893.159,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "face and like data sets available just",
      "offset": 1894.679,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "because all the other things if it's a",
      "offset": 1897.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "big tech company it's like a it's",
      "offset": 1898.48,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "covered by way more people so you don't",
      "offset": 1900.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you normally can wait and you're going",
      "offset": 1902.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to get the answer about inflection",
      "offset": 1903.44,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "Google whatever open AI new models like",
      "offset": 1905.88,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "yeah you should use them but you like",
      "offset": 1909.48,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "you making your own judgments based on",
      "offset": 1912,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "using the models is more important than",
      "offset": 1913.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "whatever valow scores they tend to give",
      "offset": 1915.399,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "VI it's like open AI was telling us",
      "offset": 1917.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "about AP exams when they released gp4",
      "offset": 1919.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "it's like they could have just been like",
      "offset": 1922,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this shit's real good should like this",
      "offset": 1923.48,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "yeah I like that's weird so then then",
      "offset": 1926.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "it's like papers and things like this",
      "offset": 1928.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "which",
      "offset": 1931.6,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "is a lot of okay it's coming to me as I",
      "offset": 1932.24,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "talk but like a lot of the papers you we",
      "offset": 1935.159,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "talked about basic things like the the",
      "offset": 1937.679,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the basic things we discussed like code",
      "offset": 1939.84,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "availability and basic quality um model",
      "offset": 1941.519,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "access and if there's an endpoint as",
      "offset": 1945.039,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "kind of the highest weights and then you",
      "offset": 1946.72,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "kind of look at to be what the core",
      "offset": 1949.159,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "experiments are and based on the scale",
      "offset": 1950.84,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "of the experiments and what like what",
      "offset": 1953.679,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "size of models they're training for most",
      "offset": 1956.08,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "NLP papers is pretty clear indicator",
      "offset": 1957.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "there should be a mental cut off at like",
      "offset": 1960.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "a billion parameter models and if they",
      "offset": 1961.88,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "don't crack that it's like it doesn't",
      "offset": 1963.559,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "mean that the paper is not technically",
      "offset": 1965.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "sound and not interesting but if you're",
      "offset": 1966.679,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "really trying to be on what The Cutting",
      "offset": 1968.96,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "Edge and it's going to drive models that",
      "offset": 1970.399,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "people are using like filtering to",
      "offset": 1971.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "papers that have larger models is",
      "offset": 1973.96,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "normally fine to start with because",
      "offset": 1975.44,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "there's plent of them right now and then",
      "offset": 1976.679,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "you should also kind of make this",
      "offset": 1979,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "technical leap of whether or not it's a",
      "offset": 1980.88,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "technical report or paper where papers",
      "offset": 1983,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "are designed to be opinionated and kind",
      "offset": 1985.32,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "of stake ground where technical reports",
      "offset": 1987.08,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "are trying to be like we just did this",
      "offset": 1988.96,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "thing so like the Zephyr model from",
      "offset": 1990.519,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "huging face is just like a technical",
      "offset": 1993,
      "duration": 2.679
    },
    {
      "lang": "en",
      "text": "report it's just like a list of things",
      "offset": 1994.399,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "that we did which is normally much less",
      "offset": 1995.679,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "opinionated but it also will have fewer",
      "offset": 1997.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "comparisons externally so you kind of",
      "offset": 1999.559,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "need to like mix and match between what",
      "offset": 2001.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "are the models doing or like what are",
      "offset": 2004.399,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "the kind of Vibes where where a a paper",
      "offset": 2006.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "especially one for a conference like",
      "offset": 2009.48,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "Nerfs or whatever like you need to tell",
      "offset": 2011.039,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "a story to get it in so you have to like",
      "offset": 2012.519,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "you can buy into the story if it's fun",
      "offset": 2015.639,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "but like you're kind of trying to",
      "offset": 2017.48,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "dissociate from all of that and just be",
      "offset": 2019.96,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "like what is the actual underpinning",
      "offset": 2022.559,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "truth here and that's not easy to do at",
      "offset": 2025.36,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "the end of the day it's all Vibes it",
      "offset": 2029.519,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "really it's all Vibes a thank you thank",
      "offset": 2031.279,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "you AA it's all",
      "offset": 2033.72,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "Vibes no but Nathan no I really",
      "offset": 2035.799,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "appreciate it because I look at like",
      "offset": 2038.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "figure quality and stuff like if they",
      "offset": 2040.639,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "had the time to make like an actual",
      "offset": 2042.799,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "pretty figure or have eror bars it's",
      "offset": 2044.48,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "just like is this clearly matte plot lid",
      "offset": 2046.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "with no further",
      "offset": 2049.079,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "design like these things are normally",
      "offset": 2050.919,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "pretty strongly correlated unless the",
      "offset": 2053.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "person has established a brand of like",
      "offset": 2055.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "just not doing anything and just like",
      "offset": 2057.48,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "but like you'll normally figure that out",
      "offset": 2059.639,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "pretty fast yeah well uh Nathan I think",
      "offset": 2061.879,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "as we wrap up I'll I'll",
      "offset": 2065.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "I'll do some plugs a little bit for for",
      "offset": 2067.399,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "you as well if any of our listeners out",
      "offset": 2069.32,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "there if you're looking for even more",
      "offset": 2071.28,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "content you want more of Nathan's",
      "offset": 2073.52,
      "duration": 3.079
    },
    {
      "lang": "en",
      "text": "content you should check out his",
      "offset": 2074.679,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "newsletter interconnects and he has his",
      "offset": 2076.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "own podcast for Tor AI I was just",
      "offset": 2078.599,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "listening to it this morning on the",
      "offset": 2080.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "waifu episode I'll leave it at that and",
      "offset": 2083.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "everyone else can take a listen for",
      "offset": 2085.24,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "themselves Nathan thank you so much for",
      "offset": 2086.96,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "for being on the show as always like it",
      "offset": 2089.359,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "is so nice to have you it is so great to",
      "offset": 2091.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "like bounce these ideas off of you and",
      "offset": 2093.679,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "talk with you um and and just going know",
      "offset": 2095.32,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "be with you in this space because it is",
      "offset": 2098.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "hard it is challenging everyone has",
      "offset": 2100.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "different incentives and none of that is",
      "offset": 2102.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "bad is just how do we figure out how to",
      "offset": 2105.24,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "do all this together without hurting",
      "offset": 2107.32,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "without hurting the field and without",
      "offset": 2109.92,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "hurting anyone so thank you so much",
      "offset": 2111.52,
      "duration": 4.78
    },
    {
      "lang": "en",
      "text": "Nathan yeah thanks for having",
      "offset": 2113.88,
      "duration": 8.579
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 2116.3,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "me",
      "offset": 2122.839,
      "duration": 3
    }
  ],
  "cleanText": "[Music]\nNathan, thanks for coming back on. Hey, thanks for having me. Awesome. So we're going to go through a few areas where you think folks reading research papers, reading articles, news on AI, uh, make a couple mistakes, get caught up in the Hype. Go uh, with the first one, um, that we talked about, which was uh, the tendency to label models as better, worse, et cetera, without sort of context or domain. So talk to me about about this one a little.\n\nYeah, yeah, and I'll I'll add some context to that because when we originally brought this up, this for everyone listening, because when we first brought this up, we were trying to decide like, you know, he's going to be on a second time, like, we don't want to repeat, what are we going to talk about? And then all of a sudden, we start talking about some paper, and then we on off on some tangent on like, well, what makes it better? Who's to say it's better? Like, what does that even mean? And then that kind of led into our our first conversation. So this is something on the minds of a lot of people. It's like, when when someone comes out and says, oh, we are beating this model, we're slightly worse than this model, and it's like, and then people always ask me, Sonan, have you tried whatever Gemini is? Is it better than GPT4? And I'm like, I can't really answer that in a sentence or less. So this is the kind of question that we we get a lot. So we're really curious to hear your perspective.\n\nYeah, I mean, this is kind of timely. We're recording the week of Gemini Ultra becoming available. Earlier this week seared into my brain was this hilarious tweet where like French law, chal, shal, chal, I don't know how to pronounce it in French. It brutal, rough, embarrassing to my former former employer, but he essentially gave a tweet that was like, F2 is bad. Like, everyone in Industry knows this model is bad. They just trained it to get high B scores. And it's like, some people on the open source thing were sad, and I was like, this, why is bitter lesson? But I'm like, I'm not surprised. And it's like, how do you tell this from doing this? I think there's a lot of expert driven things. Like, I follow synthetic data and Alignment methods, whatever these are, pretty closely. So I've been kind of there's like a lot of there's a specific line of work there with like Lima and then these five models, which is saying, like, you can do more with less data, which is kind of a pointer. It's like, whenever there's a big, we did something different that goes against the kind of core truths of what makes deep learning work, you should probably be skeptical. It's like, yes, you can make a small model good, but you probably have to narrow the scope of what you want it to be good at. It's like, there's no free lunch in any of these things, like, like there's no free lunch in AI. Like, you can't make a model smaller and better at everything. So you could might be able to reduce the overall capacity by making it better at one thing. So if anyone's trying to give you the marketing of like, we did everything better than everyone else, that's like kind of a clear answer if it's not as good.\n\nAnd with the Gemini thing, it's like, I think it's pretty clear that if the discussion is happening, if it's legitimately better or worse, that normally means that they're pretty similar. It's pretty easy to tell what a model is actually just not good. And I think Gemini's a little slower. It's pretty clearly a bigger model behind the scenes. And that's a good, like, that's just kind of how it'll be for a while. These models oscillate. Let's try to loop, loop my thinking back to the original question. It's like, how do you know if a model is good? When you're going to see a model, you're going, it's going to be accompanied by a bunch of scores, and these numbers tend to mean less than people think. Because I think a lot of like, MMLU is a big focus for people right now. A lot of models that are being released today are in like this 1 to 15 billion parameter range, and MMLU is like a multiple, just thinking about the fundamentals, what it is. MMLU is a multiple choice questioning thing. These models that we're releasing, the base models get anywhere from 15 to 50%. And if you just do the basic logic of it, if you're doing a four answer multiple choice question, random is 25%. So it's like, it's not necessarily the same as like error bar on an evaluation, but if you think about what the random margin is and what just adding a bit of noise would do to the answers, if it could change it by 25%, it's like really hard to look at these numbers. And a lot of other instruction models have a similar problem, which is people are comparing evaluations for the 10 to 20% range, which is like, are we sure that these low numbers actually even mean anything? And it doesn't, like, if the numbers are both meaningless, it doesn't matter if you beat them. And then it kind of goes into the whole conversation of contamination and stuff that we won't go down the rabbit hole of right now.\n\nSure, we'll save that for our third, uh, our third time together, don't worry. But it's just basic math.\n\nWell, it's funny because when when you you started that by by talking about when when you see someone breaking a court Canada machine learning, you know, be skeptical, but a lot of people don't know those core tenants of machine learning. And and in fact, you kind of just said one, which is whenever you're training any machine learning model, you know, screw language models for a second, even like training a decision tree classifier on some classification data set, the bare minimum, the floor of any machine learning engineer's job is to beat the null model, which is, if it's a classification, for example, what would you get by guessing optimally the same thing over and over again? Like, if the class is in balance and like 60% of them are are in one class, you just guess that class over and over again, you got 60%. So you gotta at bare minimum beat 60%. And in this case, when you're talking about MMLU, you know, solving a multiple choice question, it's kind of the same principle, which is, well, if you just kind of guess, you're going to get 25%. So if we're not even beating consistently 25%, what is the point of looking at this model with like serious eyes?\n\nYeah, yeah, I mean, like, I'm building a, it's a fun, it's even fun to look at this. Like, I just added this to a research project that I'm building where the it's 50%. So I was like, okay, added the line of shame, which is you do worse than a coin flip on on my little internal leaderboard, which is like, yeah, it happens. It's not easy to get signal always.\n\nNo, it's not. And to be fair, again, to be Exum, be fair, these are extremely high level numbers. You know, accuracy is, you know, is one metric, coming back back to the example of classification, you got precision, recall, F1. There's so many more ways to probe in and say, hey, look, maybe the overall accuracy is here, but our precision is 90, and but our recall happens to be 20 or whatever it is. And and then they can make the case then to say, is our model amazing at all things? No, but here are some applications in which these kinds of situations would actually be beneficial. High precision means it would be not the worst situation to use for, you know, diagnostics capabilities, because because when it says yes, you can at least trust it. Uh, and that kind of nuance tends to be lost a little bit, right, in this in this really hierarchy of where are we ranking all of these models? You kind of lose the nuance of, well, for what? Using the model to help teenagers write essays or using the model to help lawyers review uh, law documents, like, what are we talking about when we say better and worse? So I think a lot of that nuance is not out the window per se, but it's just secondary or tertiary or further down on the list of conversation topics.\n\nYeah, I mean, to be, to to wrap it up, to like specific, like some of the popular benchmarks, like MMLU and Big Bench Hard or grade school math, they have different ways of computing the score, and you need to make sure that you're compare, like, these should be documented, but there's like literally different ways of computing the number, and then the number is what people copy. So like, we, I had to do the, I had to do the work of like, tracking down how these different models computed their numbers and be like, at least I, at least I could say how they did it, but it's not even fun when you're doing that again. Core tenent of math, don't forget your units, or else what are you talking about? How do you compare these two things?\n\nSorry, a go, what were you saying?\n\nNo, no, I was saying, I just uniformly, and this is like, I don't know, like, there's certain news weeks where this is like 50% of your news feed. It's it's just literally this model was released, some claimed to param account, it's all performative nonsense, and I almost always filter this out. Um, it is clearly driven by this PR news cycle where there's some product lead or engineering lead who wants to announce uh, and and is put on a PR cycle. Like, the way this mechanically works is you have some product launch, and then marketing takes it over, works with the PR firm, they publish a bunch of news around it and try and um, sort of get stuff out there. But the other thing is now I feel like, Nathan, with like, even these leaderboards, they've just gotten so gamified that we talked about, we me, we had um, other folks talking about, you know, need for more modular, you know, benchmarking, uh, et cetera. It's uh, it's like that midwidth meme where like, everyone looks at like, so the right end looks at the leaderboard, left end looks at the leaderboard, and the middle is um, or sorry, the middle is, and yeah, exactly. It's actually just like playing with the data and looking at the model that's relevant for your tasks, but it is a little bit one of those things where um, I remember initially getting a little more swayed when uh, especially more so around when Llama 2 came out, when this was a little bit less of a thing. Now it's just become something I just completely ignore. There's something that's released recently, I wait for uh, for wait for the dust to settle.\n\nYeah, it's normally safer to wait. I mean, there's a new model this week called like Smog 72B or something, which is supposed to be this like, it's like the top, it's lit, like the top of the hugging face leaderboard. It's like an open model, and I was like, just going to wait. Like, I don't, I literally saw that on my like, my phone when it PS up, like the Google results. It was like recommended articles. I was like, no, wle for now, please. It's pretty much like, if that's your leading claim of your model, it's unlikely to be that that actually useful. It's it's perfectly fine to have good scores, but like, most of the time these days when they lead with that, you're like, uh, I've got better things to do. So it's like, Street smarts versus book smarts. Okay, book smarts is good and all, but when you get out there and you got to start talking to people day to day, millions, billions of people out there got to have some Street smarts. I have kind of hot take that I even think chatbot arena is a little overfit to, like, chat arena is very good, but we don't know the distribution of the prompts. I have a guess that it's like a third code, a third like role play, and then like a third other stuff. And like models that refuse weirdly are just going to get hammered, which is probably why like Claude does really badly, and it's just like, I guess, opening eyes, opening eyes obviously really good, but like, there's a lot of muddled stuff in between there, which we don't really know how much the models, like, I have some data from them and I want to look into it, but we don't have the, we don't have the way to classify the prompts yet, but within a year or two, it'll be pretty easy to be like, these are the types of things people are asking in these conversational data sets.\n\nI'm pretty sure there's some chatbot Arena, there's a data set on hugging face with a chatbot Arena, and I I remember using it for something and and thinking a very similar thing, which is, you know, a lot of the times when you get one of those, you know, I can't answer that. It generally just gets voted down because, well, hey, I wanted you to answer it, but that's not really up to you all the time.\n\nAA, I totally agree when you were talking about a lot of this PR, this marketing Hype, and especially when you're talking about Llama, especially companies like Meta, you know, Microsoft, like when they put out Google with Gemini, when you put out models, it is an opportunity to, you know, make a name for yourself and say, hey, here's where we are on the map, here's where we stand, here's what we're doing. And sometimes that can really get muddled in with, well, how actually useful is is the model or is this all just marketing? That being said, other institutions who have more intent behind those releases and and deployments, they can have a lot of different intents. And obviously, I'm kind of coming back to Dr. Nathan Lambert here, uh, because you recently, your institution, Nathan, was part of amazing team that recently open sourced one of one of the first, if not the fully uh, open-sourced LLMs. Do you want to tell us a little bit more about that?\n\nYeah, I mean, we could talk about why evaluation, it's hard, too. I think, um, there's a long story of essentially, I see nothing that gets people, scientists, more nerd sniped than evaluation, which is like these things that we're talking about. So it's not just people that are trying to follow this, it's like people who are building these models. It's definitely not the first open model, but it's probably like the third or the fourth that follows in a few really important artifacts. So like Bloom, everyone knows about this, like huge multi-organization open multilingual model that hugging face kickstarted. They're not the only ones involved. And then Paia from a luor AI, which is like pretty solid models at the time, but not how models are used now. So the biggest change in how people train models now is we train them for a lot more tokens. So it's kind of hard to compare models from Paia to what ELO is. And then ELO is like the start of a process, I think, compared to those, those two other things kind of were one set and done, and ELO's kind of being like, okay, we're going to really try to keep training and improving models in the open and keep releasing them and trying to have them be state-of-the-art. And the models are okay, like, they're not at M level, they're a little below Llama 2. So it actually like, a, we did a tokenization error in our Llama 2 Val, so the scores we reported for Llama were slightly low, and this should be updated on the blog post now, but like, obviously, we're not going to be able to make noise about like, we messed up our table a little bit, but like, essentially the issue for, cut to to like, for people that want to know what the weird things are, is essentially it's like, if you're asking a multiple choice question, the Llama tokenizer was having an extra space before the answer. So it expects question colon space answer, and our code had question colon space space, and that messes the error the valves up a couple percent, and then that's enough to make it Soo was listed at the top, but technically Llama 2 is the best, and it's like, okay, like now our blog post is, but like, that's the type of thing that's determining these numbers of people comparing models, and like, yeah, it's just really hard. It's like,\n\n\nNot worth spending all of your days on it is extremely hard, and I think, I mean, your approach, even like, very frankly, Dr. Nathan Lambert, like, even, even to come on and say, \"Oh yeah, we perform slightly worse than, uh, Mr. Lama those,\" and then you explain, \"Like, well, then here's how it happened, then here's how you do it,\" and that's not always the point. And I think that's really my point, which is, it's not always the point to only release models when they're better than everyone else, right? Because if you've never checked out, um, anyone listening, if you haven't checked out, I recommend you do, because it's not just downloading a model and trying it out and see what happens. There's the eval, uh, framework, there's the, um, there's the DPO framework, there's all of the frameworks, all of the code, all of the data, which, by the way, as a Turk, I do appreciate that it's called Doma, the data set. Um, everything's there. And, and again, to Dr. Nathan Lambert's point, they're really trying to make a point of, \"This is how open source is really supposed to look like.\" You know, \"This, this is what the process is meant to be.\" And I think a lot of people respond really positively to that. You know, when I talk about it in my lectures, you know, and I show the GitHub, everyone always says, \"Wow, that's so much.\" And that's really just a short way of saying, \"Oh, we're not used to this. That's not really how we've been trained to think about open source.\" So, uh, what's, what's coming next then for foro and and for what you're all working on?\n\nMore models, more modality is trying to be better. It's like, pretty simple. We're trying to get more compute, we're trying to do more of the same. It's like, it's really like that's the thing that I think is, when you see major projects, you don't really know what's coming from them, especially with academics. It's like, Pia is great. It's like, \"Okay, I know Lu AI is doing other great things now,\" but it's like, they're not doing like Pia 2. It's like, \"Yeah, we're gonna do Elmo 2, we're gonna do Elmo 70B,\" whatever, and we've already like publicly said all these things. Yeah. Um, we've talked a lot the model space and and evaluation that for a while. There's two, uh, conrete examples of discourse on how folks should evaluate papers that I thought we could walk through, Dr. Nathan Lambert, that both areas you're familiar with, uh, both kind of Laura versus Q Laura, and then the DPO versus the DPO debate. In both instances, I think there, you know, just discussions on different mechanisms for machine learning where I could read, luckily I have, you know, you two, I can, I can text and different folks that I can ask to explain this to me. But for folks that get caught up in those sorts of stuff, maybe we could use both of those as examples of, Dr. Nathan Lambert, some, uh, maybe some problematic stuff in the discourse, and then how, uh, if you were to go back and how that, those, those new cycles unfolded, how you would have, uh, you know, stayed grounded.\n\nI think both are relevant. One, you know, very relevant for RHF, and then Cura, obviously, because of AI's you know, connection to to that work there as well. So either or, but just curious how you would have navigated those news cycles a little differently and maintained grounded during those. I think they kind of are played out the same, which is like, there's been two methods, one of which has kind of been established from Big players, which is like instruction tuning, normal instruction tuning, and Po, and then a new thing, which is simpler to implement or more efficient that a lot of people are using. And because it generally is a trend of when a lot of people use it, people assume that it's better, and just because it's easy to use that it is better, which is kind of is kind this kind of can go both ways. So is like, like when talking, this is kind of a link is like, when you see a paper, if there's actually code, it's normally better, and if you skim the code for five minutes, you can normally tell if they took this stuff seriously or not. And it's fine to take an academic project seriously as an academic project, but if you're trying to make it a serious tool that people trade models with, it looks really different. Like Cura is an academic project, and if you open that repository, you're like, \"Oh, there's Cuda Corals in this, this is, this is a lot,\" which is very different than like a random RHF method that's like, \"Okay, they forked something, deleted the get history, and added three lines of code,\" which you also see. But like, it's a pretty clear flag that one of those is meant to have different types of longevity. And back to like Kor and DPO, like I expect there's still going to be more people doing Cur, especially on like the long tail of ml. A lot of people can find tune models without it, but people do both, and there's like a trickle of results buried in papers as like, \"Kor is not quite as good if you can do the other thing,\" but that's kind of fine. And then DPO is the same thing, which is like, most rumors and people are like, \"DPO is actually not quite as good and has these problems,\" but it'll move faster and iterate faster due to it being available. And it's just like, there's no ABS when there's an absolute, it becomes very obvious is the thing, and there's normally not obvious results these days.\n\nYeah, I, I, I love that take on the absolute. Right there's always a new. I, I was about to say, because I'm actually teaching a reinforcement learning class pretty coming up, and I will be using more, I will most of my examples when it comes to DPO versus Po will be in proximal, will be pop. And the reason, whenever someone asks me this, because I've had people come up and ask me, like, in person, like, \"Why are you using Po and DPO exists?\" And I was like, \"A few reasons. One, it's pretty new, I'm still kind of figuring out like, where, where it stands, it's more, it's newer at least.\" Second, and I, this is the point that that usually sticks, which is, \"What if you don't have direct preferences?\" And I, my one of my examples is using like a sentiment classifier to make summaries of from flant T5 more neutral sounding. So like, if you don't use more positive or negative words, be as neutral as possible, and I use like a sentiment, uh, classifier from hugging face, basically as the reward mechanism, just to see the difference, to show people, \"This is what you can do when you don't have direct preferences, but you have a model that you can trust to give rewards.\" And, and that tends to stick more. And again, it all comes back to your point, Dr. Nathan Lambert, which is, people really, it's easier to think about things in not even absolutes, just ordinally, like, \"A is better than B, therefore, forget A ever existed, B is everything until C exists,\" and then continue that train until, you know, something, something happens. But it's not that easy, right? I, I think you know, that that seems fair.\n\nYeah, it's like, I think that what it manifests now is that there's a lot of papers that use DPO and things like that, and it's, it's this is definitely one of the harder ones in information diet is just like figuring out how to be okay with the fact that the distribution you're sampling from is very biased. And like, there's more papers because it's more available, but like quantity is a bad, like quantity is simultaneously a good and a bad metric when there's quantity of people doing exactly the same thing. That means the idea is validated, but just because there's like more people in a space doesn't mean that it's necessarily better. It's just like, gassy, which a happens a lot right now. Like, there's so much to be gained by being timely, like there's a lot of financial and personal gain by being in the right area, which is a safe thing to do, but that doesn't mean that you have to assume that it is just definitively better. It's just safe for people to work in. Yeah, I mean, a lot of this basic stuff to be more conscientiousness, going back to the kind of model point, um, but this, it's funny, I feel like you would not trust a study if it said cell phones caught cancer and had a sample size of 12. The equivalent of that is literally just scaming the quality of like the reproducible code. Like, you can see the amount of time someone, um, went and kind of published it. The other thing is, I think there's, um, something I do frequently that helps specifically on some this stuff, because the model stuff I've just sort of immediately filtered out, and I'm less technical than than than you are both, and I'm not, uh, not as familiar with a lot of stuff. So I actually have to rely on other people genuinely, actually, like Googled author names and see what like they've submitted into prior conferences, etc. I do that too. I feel bad. It's, it's no, it's not bad. There's just so much noise, and I actually want to know, but it's crazy. You have these substacks. I met a random substack owner who's doing probably north of 10K a month and just doing summaries of ml papers, but 60% of the papers don't have reproducible code, and another 30% are written by paper that not, you know, published at at an I clear, at an icml, etc. So just to add to that, I can't just doing that, like added double click has really, it's a good practice. I think it's good to be like, it's you should be aware that sometimes new things happen from other places, but it's good, it's good to follow where work is coming from from different things. And like, I think different types of people will follow different tracks of work easier. Like, I can obviously follow a North American paper easier than an Asian paper, but some of these Asian papers are releasing really good artifacts, and then we end up using them anyways. But it's just like, there's some time to like, there and back to like reading the code, we're luckily coming to a place, at least if you're working in like rlf or alignment, where a good litmus test is like, if they have a demo of the model, and if they're willing to put their model out there, and like people can talk to it, it's really like, \"Okay, these people are much more serious about what they're doing,\" as because either they're going to be right or they're going to get roasted, but like them getting roasted for having a bad model is like, still they're probably going to improve a lot faster, which that change is huge, then just kind of of having random like large files on Google Drive that you like, no one's ever going to use. It's like, okay, yeah, I mean, that whole idea of like, offline versus online feedback is, is all, is all for me, it's a lot of product, um, engineering, because the idea is, you know, when you build a product, you test it internally, you get a lot of offline feedback from people you know, at the company or or whatever. It's only when you put it out there, you start actually collecting feedback from real people who are going to use it under real circumstances, that online feedback, that you can really start to understand, \"Okay, this is how people wanted to use the model,\" and hopefully you're logging all that as well. It all ends up back in your your data set if you're training a model or what have you. But that that notion of of putting it in front of people and saying, \"What about this?\" is, is it can be quite useful. Now, of course, you have to measure that with you making the claim, like, \"This is the best thing you're ever about to see, here it is.\" This something that like Tech historically had a problem with, because ml is just coming around to it, which is realizing, like, you need like, like there's a Dev Advocate role, which is like, I do a lot of this work, but not because it's like what I'm compelled to do, it's just kind of like under Index right now, as a lot of people don't want to do the work of like taking your work to somebody else. Like, I don't know if that's always been a problem in Tech, but that's really a thing right now, where a lot of labs and good groups are not doing that work, which is like delivering it, like they're going to, they're like make, they're like putting products into the world, but everyone's information diet is so effed up that sometimes you need to go and like literally put it in front of them and be like, \"This is my cool new thing, you must now try this.\" And that's like distribution channels and how that controls people's AI diet diets, and you should defin, like having people that you trust is good. Like, it doesn't need to be me, and like AK was the first person getting big tweeting papers on this, but I think that like really people should try to find smaller people than AK that they trust for a specific domain that they're interested in, because you can't follow everything in ml. It's like, you should follow a few people, somebody that's good at pre-training, and like, just they don't have to be around forever, but like that type of diet does give you an edge.\n\nYeah, I think one thing that, since we're on the topic of improving information died, I think it is a, it's a big issue in the in the tech ecosystem, like even developer tooling, you talk about developer envel evangelist, Dr. Nathan Lambert, like it's a very classic, like develop, it looks great in this like quick demo I'm doing on stage, and like the minute you have questions, like I'm nowhere to be seen, etc. You get S to some form. I had this really, really funny moment, it's head of an mL of a company that, uh, we all know, but, uh, he said something really funny. So we had a conference, and he's presenting on basically these different ml topics, and specifically more like data engineering topics, so like language model infrastructure, etc. He's Midway through his presentation, he's like, \"And I want to call out that none of the like screenshots I've presented today are actually from anyone technical, they're all from V firm's blog posts.\" And so everyone just started cracking up, where there is this weird thing in the ecosystem in Tech, where it's like, it tends to be that, um, you know, we have, you know, key, you know, different incentives, either portfolio companies, etc., you know, we filter a lot of the feedback, we don't understand a lot of it, and then we disseminate it, which creates a bunch of, uh, positive, you know, effects in the sense, like people are more aware of certain topics now, people I think are more interested in machine learning, we're having know a lot of great discussions about this stuff, but at the same time has negative externalities as well, which is, if you also don't have a, in the same way, LMS are grounded, etc., if you don't have something in key experts that you're grounding to, you're going to get just lost in the wind. And so I think there's a lot of that happening, where there's almost this funnel of information hierarchy, where if you don't get it straight from, you know, I think established technical sources, and you're just listen, this happened in tech for a long time, where, uh, it's really hard to, I think, parse through, and you get really, really mixed information. So, um, I'm generally staying off Twitter, I'm like along with you, Dr. Nathan Lambert, obviously, and and texting you on, I'm trying to find four or five people I really, really trust and actually just go deep on on their work, uh, versus, and then if someone else brings up a topic to me in conversation, and they're like, \"Oh, you should know about it,\" that's generally when I get interested in it, versus, um, I think just buying into every new topic that. Yeah, there's a lot of benefit to not being trying in the rat race right now. You need to really think about it if your incentives are to really follow all the noise that's happening. Most people don't. Speaking of the like, hilariousness of this and why it's so okay for people to be overwhelmed, I was like, I wasn't logged into a browser other.\n\n\nDay and I opened GitHub, and even GitHub is like the world's leading AI-powered developer platform.\nI was like, \"What is their weird ass, like, hugging face, Logan on their, like, website?\"\nAnd it's like, \"Why does everything have to be this right now?\"\nSo that's what you see if you open GitHub in an incognito window.\nIt's just like, \"How do we end up here?\nLike, why did GitHub need to rebrand?\"\nBecause these analyst reports, you know, like, have you seen these, like, uh, there's like a bunch of Quant Bots that'll like front-run a stock if it mentions AI more.\nSo now, like, all these CFOs, like, CEOs are just trying to drop AI as much as possible.\nOh my God, the stock, because they're like, \"Oh, maybe we're affiliated and correlate with Nvidia and some, you know, algorithm, and it boost the stock.\"\nSo that's literally happening now, which is like, look, I drop, I hate making the comparison, but when you follow a really hyped-up technology from subhype to subhype to subhype, maybe like crypto, it might lead to some bad places, right?\nNot saying it's all going to collapse, but the more analogies you kind of find to those to crypto, the more I try to take some pause because when crypto became huge, and I, I won't say crypto, I'll say, you know, block Tang Technologies, funable, non-fungible tokens, the whole ecosystem, when that ecosystem starts to get big, you, you all of a sudden see a lot of new people who are suddenly experts in the topic who are deting information very similar to kind of what you see today.\nAnd then you moved from subhype to subhype, meaning, you know, ERC20 for fungible coins, um, 721s for NFTs, and then there were derivatives of NFTs that would make things nuances more easy, and then you get to this point where everything's so inflated, and then obviously, you know, there's a bit of a collapse and bad things happen.\nBut I'm not saying we're on that path, but you could, you can draw a lot of these corel.\nSo there are pathways in which, you know, enough people are kind of acting this way where, um, you know, we have to be careful.\nSo, Nathan, maybe you can help us out, um, by giving us and our listeners some constructive advice on, you know, where, what are some of the top things we kind of started talking about this already with code and stuff, but what are some of the top things that you kind of browse and look for, uh, just to give you some initial signal of this is actually good to dive into a little bit more?\nYeah, I mean, I don't think you should be like me because I like actively read Twitter to try to find that, like, make sure I'm up to date because I write and produce content on this.\nSo there's like a pretty different thing, and most of my information is partitioned either into papers or like model releases, and I mostly only really follow model releases that have weights available, which is mostly on hugging face and like data sets available, just because all the other things, if it's a big tech company, it's like a, it's covered by way more people, so you don't, you normally can wait, and you're going to get the answer about inflection, Google, whatever, open AI, new models, like, yeah, you should use them, but you, like, you making your own judgments based on using the models is more important than whatever valow scores they tend to give.\nVI, it's like open AI was telling us about AP exams when they released GP4.\nIt's like, they could have just been like, \"This shit's real good.\"\nShould like this.\nYeah, I like that's weird.\nSo then, then it's like papers and things like this, which is a lot of, okay, it's coming to me as I talk, but like, a lot of the papers, you, we talked about basic things like the, the, the basic things we discussed, like code availability and basic quality, um, model access, and if there's an endpoint as kind of the highest weights, and then you kind of look at to be what the core experiments are, and based on the scale of the experiments and what, like, what size of models they're training for, most NLP papers is pretty clear indicator, there should be a mental cut off at like a billion parameter models, and if they don't crack that, it's like, it doesn't mean that the paper is not technically sound and not interesting, but if you're really trying to be on what the cutting edge and it's going to drive models that people are using, like filtering to papers that have larger models is normally fine to start with because there's plenty of them right now.\nAnd then you should also kind of make this technical leap of whether or not it's a technical report or paper, where papers are designed to be opinionated and kind of stake ground, where technical reports are trying to be like, \"We just did this thing.\"\nSo like the Zephyr model from hugging face is just like a technical report.\nIt's just like a list of things that we did, which is normally much less opinionated, but it also will have fewer comparisons externally, so you kind of need to like mix and match between what are the models doing or like what are the kind of vibes, where, where a paper, especially one for a conference like Nerfs or whatever, like you need to tell a story to get it in, so you have to like, you can buy into the story if it's fun, but like you're kind of trying to dissociate from all of that and just be like, \"What is the actual underpinning truth here?\"\nAnd that's not easy to do.\nAt the end of the day, it's all vibes.\nIt really, it's all vibes.\nA thank you, thank you.\nAA, it's all vibes.\nNo, but Nathan, no, I really appreciate it because I look at like figure quality and stuff, like if they had the time to make like an actual pretty figure or have error bars, it's just like, is this clearly matte plot lid with no further design?\nLike these things are normally pretty strongly correlated unless the person has established a brand of like just not doing anything and just like, but like you'll normally figure that out pretty fast.\nYeah, well, uh, Nathan, I think as we wrap up, I'll, I'll, I'll do some plugs a little bit for, for you as well.\nIf any of our listeners out there, if you're looking for even more content, you want more of Nathan's content, you should check out his newsletter, interconnects, and he has his own podcast for Tor AI.\nI was just listening to it this morning on the waifu episode.\nI'll leave it at that, and everyone else can take a listen for themselves.\nNathan, thank you so much for, for being on the show as always.\nLike, it is so nice to have you.\nIt is so great to like bounce these ideas off of you and talk with you, um, and and just going know, be with you in this space because it is hard.\nIt is challenging.\nEveryone has different incentives, and none of that is bad.\nIt's just how do we figure out how to do all this together without hurting, without hurting the field and without hurting anyone?\nSo thank you so much, Nathan.\nYeah, thanks for having me.\n[Music]\nMe.\n",
  "dumpedAt": "2025-07-21T18:43:25.804Z"
}