{
  "episodeId": "pe-aKzlLsrM",
  "channelSlug": "@practicallyintelligent",
  "title": "E8:  Navigating the New Frontier of Multimodal AI with Jacob Solawetz",
  "publishedAt": "2023-12-21T15:52:47.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 0.71,
      "duration": 6.14
    },
    {
      "lang": "en",
      "text": "hey everyone welcome back to practically",
      "offset": 7.359,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "intelligent today we're excited to",
      "offset": 9.44,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "welcome Jacob salwitz uh the CTO at rc.",
      "offset": 11,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "and former founding engineer at roof",
      "offset": 16.119,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "flow one of the leading companies in",
      "offset": 17.88,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "computer vision infrastructure we're",
      "offset": 19.439,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "going to talk to Jacob a bit about",
      "offset": 21.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "Trends in",
      "offset": 24.08,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "vision and how the evolution of vision",
      "offset": 25.679,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "trans formers and now uh multimodal",
      "offset": 29.599,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "architectures could be different than",
      "offset": 32.239,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "how LMS progressed or more of the same I",
      "offset": 35.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "think I really like Jacob's balance",
      "offset": 38.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "given he's now working on a company",
      "offset": 40.8,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "that's domain adapting LMS but has had",
      "offset": 42.039,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "years of experience working in making",
      "offset": 43.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "usable and functional and Deployable",
      "offset": 46.96,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "Vision models for various different use",
      "offset": 48.76,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "cases um I like his balance perspective",
      "offset": 50.92,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "on both so we're excited to have him on",
      "offset": 53.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "yeah no it's a great conversation we we",
      "offset": 56.48,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "we talk it's one of those episodes where",
      "offset": 58.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "we talk not just about the technological",
      "offset": 61.16,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "improvements but we're also really",
      "offset": 63.039,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "hitting on how those improvements end up",
      "offset": 64.519,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "affecting the interaction between users",
      "offset": 68.439,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "and Ai and I think that's really where",
      "offset": 71.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "people are excited about multimodal",
      "offset": 74.04,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "because it's it's really the future of",
      "offset": 75.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "how we're going to interact with these",
      "offset": 77.759,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "systems so I say we Jump Right",
      "offset": 79,
      "duration": 6.439
    },
    {
      "lang": "en",
      "text": "In hey Jacob how's it going going great",
      "offset": 82,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "how are you guys I'm doing great",
      "offset": 85.439,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "actually how are you I'm hoping you're",
      "offset": 87.84,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "over here when I do this I'm pretty",
      "offset": 89.479,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "thrilled I am on I am on the left side",
      "offset": 93.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "of the",
      "offset": 95.92,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "screen we could we could use uh the new",
      "offset": 96.799,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "emu editor please make that work or",
      "offset": 99.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "honestly make me look like an idiot it's",
      "offset": 102.079,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "also fine uh today we have Jacob on we",
      "offset": 103.759,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "are going to be talking pretty much all",
      "offset": 107.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "things multimodal in computer vision",
      "offset": 110.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "because not just because it is actively",
      "offset": 113,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "kind of the Hot Topic but because Jacob",
      "offset": 115.68,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "is actually one of the",
      "offset": 118.119,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "uh in my opinion at least one of the",
      "offset": 120.479,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "pioneering engineers in the modern",
      "offset": 121.759,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "computer vision space uh being the",
      "offset": 123.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "founding engineer of roof flow and just",
      "offset": 125.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "yesterday by the way this is breaking",
      "offset": 128.56,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "news yesterday I was giving a lecture",
      "offset": 130.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "for O'Reilly on the topic of GPT and one",
      "offset": 132.2,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "of the questions was did you see this",
      "offset": 136.12,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "new uh webcam GPT demo from roof flow",
      "offset": 137.92,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "and they sent me the GitHub blank I'm",
      "offset": 141.959,
      "duration": 2.841
    },
    {
      "lang": "en",
      "text": "like that's so funny I'm talking to the",
      "offset": 143.319,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "founding engineer tomorrow about this or",
      "offset": 144.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "about you know his work and what he's",
      "offset": 147.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "been up to so this is something people",
      "offset": 148.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "are talking about more and more so Jacob",
      "offset": 150.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "my first question to you to kind of open",
      "offset": 153.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "us all up to this space is can you give",
      "offset": 155.72,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "us kind of a brief history where have we",
      "offset": 159.04,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "been where are we now uh and then we'll",
      "offset": 162.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "get to where are we going but later on",
      "offset": 164.76,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "but where where have we been where are",
      "offset": 166.76,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "we now in computer vision and multi yeah",
      "offset": 168.159,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "yeah definitely I I think that's an",
      "offset": 170.879,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "exciting place to kick things off so um",
      "offset": 172.28,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "obviously you know everything in the AI",
      "offset": 175.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "world is moving forward right now it's a",
      "offset": 177.04,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "lot of rapid velocity but in CV the most",
      "offset": 179.44,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "exciting thing is multimodality which is",
      "offset": 182.04,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "you know bringing in the ability to have",
      "offset": 184.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "language understanding in combination",
      "offset": 187.239,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "with images and video in a way that",
      "offset": 189.48,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "we've never been able to do that before",
      "offset": 191.519,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "so kind of taking taking a a high Lev",
      "offset": 193.519,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "step back into that landscape as the",
      "offset": 196.879,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "history of CV was you know people were",
      "offset": 200.159,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "doing old school ml algorithms like 10",
      "offset": 202.56,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "years ago and working on processing",
      "offset": 205.159,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "pixels and then they eventually",
      "offset": 207.08,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "collapsed on the CN and and so we had",
      "offset": 208.599,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "you know convolutional neural networks",
      "offset": 211.28,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "and exciting uh models like YOLO come",
      "offset": 212.879,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "out and make a really big impact and",
      "offset": 216.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "YOLO and resnet was kind of the dominant",
      "offset": 218.28,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "models in CV for you know about uh you",
      "offset": 221.28,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "know from 5 years ago to about yeah",
      "offset": 225.56,
      "duration": 6.519
    },
    {
      "lang": "en",
      "text": "maybe like a year ago now when uh you",
      "offset": 229.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "know Transformers really started to make",
      "offset": 232.079,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "a big impact and start to set uh New",
      "offset": 234.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Heights in in benchmarks and so it",
      "offset": 237.239,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "there's kind of an interesting mixing of",
      "offset": 239.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "waters now where you have a lot of",
      "offset": 241.56,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "practical applications still running on",
      "offset": 243.599,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "CNN models and uh and a lot of new",
      "offset": 245.36,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "exciting applications coming out uh that",
      "offset": 248.56,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "are more General on uh with",
      "offset": 251,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "multimodality yeah no I'm I'm glad you",
      "offset": 254.12,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "brought up a lot of that history",
      "offset": 256.519,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "because uh users or users listeners will",
      "offset": 258.959,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "will know I I tend to be an expert in",
      "offset": 262.8,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "all things text based um and you know",
      "offset": 265.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "NLP but that doesn't mean I don't",
      "offset": 268.08,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "understand computer vision I don't know",
      "offset": 270.56,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the history of computer vision models",
      "offset": 271.8,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "and I think part of what makes it such a",
      "offset": 273.68,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "similar story a similar Arc and again",
      "offset": 276.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this will all kind of converge with",
      "offset": 278.919,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "multimodality is while the NLP",
      "offset": 280.24,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "researchers and practitioners were over",
      "offset": 282.56,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "here you know figuring out you know not",
      "offset": 284.479,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "figuring out but using attention",
      "offset": 287,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "mechanisms attaching them onto recurrent",
      "offset": 288.6,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "neural networks to make them a little",
      "offset": 291.039,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "bit better um and and then finally",
      "offset": 292.8,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "figuring out that hey maybe you know",
      "offset": 295.759,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "quote attention is all you need and the",
      "offset": 297.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "trans Transformer a very similar thing",
      "offset": 299.28,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "was happening in Vision honestly pretty",
      "offset": 301.4,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "much at the same time you see in the",
      "offset": 303.96,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "mid2 2016 2017 I think it was you at all",
      "offset": 306.56,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "if I I'll have to remember this but",
      "offset": 311,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "papers were already coming out with",
      "offset": 313.08,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "people attaching the attention mechanism",
      "offset": 314.52,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "to cnns to make better image captioning",
      "offset": 316.16,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "systems so we were all we were using the",
      "offset": 318.88,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "the primary engine of the Transformer",
      "offset": 322.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the attention mechanism even before the",
      "offset": 324.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Transformer came out in computer vision",
      "offset": 327,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and an NLP and when the Transformer",
      "offset": 329.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "comes out 2017 it's only preceded a few",
      "offset": 331.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "years later with the quote Vision",
      "offset": 334.68,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "Transformer in 2020 a paper that comes",
      "offset": 337,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "out of Google so we see that's also the",
      "offset": 339.52,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "same year that gpt3 comes out and that",
      "offset": 341.8,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "starts to get in the new so vision and",
      "offset": 344.44,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "and NLP have always been within you know",
      "offset": 347.96,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "two to five years of each other in the",
      "offset": 351.12,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "state of progress so NLP came out a",
      "offset": 353.8,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "little bit ahead just because open AI",
      "offset": 356.6,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "put that really nice user interface on",
      "offset": 358.72,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "top of their llm but more importantly",
      "offset": 360.4,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "and I think this kind of leads me to my",
      "offset": 362.919,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "next question to you is the data was",
      "offset": 364.199,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "already there with text text data is",
      "offset": 366.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "just stupid easy to find right on the",
      "offset": 370,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "open internet but well-labeled image",
      "offset": 372.24,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "data not so much so we had our a big",
      "offset": 375.759,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "Delta in in data set quality was with",
      "offset": 378.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "imag net from like half a decade to a",
      "offset": 381.24,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "decade ago at this point and that really",
      "offset": 383.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "spurned the idea of pre-trained networks",
      "offset": 386.639,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "like resnet but all convolutional so my",
      "offset": 388.8,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "my my first question now back to you is",
      "offset": 391.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "how do you kind of see those parallel",
      "offset": 395.52,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "tracks going and now that we're seeing",
      "offset": 397.44,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "this you know explosion of vision models",
      "offset": 400.52,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "like you you mentioned donut and you",
      "offset": 403,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "know Flamingo and vision Transformer in",
      "offset": 404.56,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "the last two to three years what does",
      "offset": 407.08,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "that signal about the state of computer",
      "offset": 409.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "vision compared to the state of like NLP",
      "offset": 411.319,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "with chat with chat GPT yeah definitely",
      "offset": 414.28,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "yeah I think that is kind of an",
      "offset": 417.12,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "interesting way to to see things is that",
      "offset": 418.24,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "a big thing was just the the prevalence",
      "offset": 420.759,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "of a huge Corpus of labeled data and the",
      "offset": 423.24,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "nice thing about that was because you",
      "offset": 426,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "know NLP pre-training routines were able",
      "offset": 427.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to just find out that next token",
      "offset": 429.84,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "prediction worked pretty well to kind of",
      "offset": 431.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "get a deeper semantic understanding",
      "offset": 433.479,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "which next pixel prediction never really",
      "offset": 435.599,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "seemed to pan out that way so uh that",
      "offset": 438.08,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that just happened to be you know a a",
      "offset": 440.919,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "nice artifact of the way that language",
      "offset": 442.8,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "carries semantic richness in a way that",
      "offset": 445.36,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "uh just image pixel maybe doesn't quite",
      "offset": 448.44,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "have I mean maybe if we had like",
      "offset": 451.52,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "infinite data of video streams of",
      "offset": 453.039,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "different you know next pixel in the",
      "offset": 455.16,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "next time time frame maybe it maybe it",
      "offset": 458.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "would have worked differently um so I I",
      "offset": 460.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "do think I do think that's interesting",
      "offset": 463.96,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "but I think yeah I think the interesting",
      "offset": 465.56,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "thing is that you know like NLP had all",
      "offset": 467.599,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "these really strong base models to to",
      "offset": 470.039,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "build things off of you know where",
      "offset": 472.96,
      "duration": 3.079
    },
    {
      "lang": "en",
      "text": "people were making all kinds of",
      "offset": 474.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "applications on top of Bert when you",
      "offset": 476.039,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "know that first you know pre pre-train",
      "offset": 477.919,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "and then fine-tune uh schemo was was",
      "offset": 479.639,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "introduced and vision had things you",
      "offset": 482.68,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "know you could pre-train off or you",
      "offset": 484.919,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "could fine-tune off the uh imag net",
      "offset": 486.72,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "backbones and you know you were getting",
      "offset": 489.84,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "some semantic richness from pre-training",
      "offset": 491.8,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "on on imag net but you didn't really",
      "offset": 494.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "have like a really rich base like we",
      "offset": 495.919,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "have now so now there's these really",
      "offset": 497.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "exciting new models you know like uh",
      "offset": 499.56,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "grounding Dino and Flamingo and you know",
      "offset": 502.039,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "some of these other other new models",
      "offset": 505.319,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "that are even coming out this week uh",
      "offset": 506.8,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "that or exciting bases to to be training",
      "offset": 508.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "from so it seems like there is going to",
      "offset": 511.319,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "be kind of like a you know a Cambrian",
      "offset": 512.88,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "explosion if you will of deep U Vision",
      "offset": 515.12,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "applications that are are built off",
      "offset": 518.56,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "these things and and not only that um I",
      "offset": 520.719,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "would say which is you know with the",
      "offset": 523.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "ability to do uh single shot and fuse",
      "offset": 525.92,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "shot prompting of these General CV",
      "offset": 528.76,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "models there's all kinds of new",
      "offset": 531.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "applications that can be built by",
      "offset": 533.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "developers that have that kind of",
      "offset": 534.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "General ability that language has been",
      "offset": 536.72,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "shown going to be you know making a lot",
      "offset": 538.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "a lot of you know exciting new new",
      "offset": 540.76,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "applications on top of that which which",
      "offset": 543,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "is really big you know if you don't have",
      "offset": 544.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "to spin up your own gpus and you don't",
      "offset": 545.92,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "have to figure out how to you know",
      "offset": 547.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "orchestrate you know 1,00 A1 100s in the",
      "offset": 550.04,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "cloud together to get a model out um you",
      "offset": 553.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "know that that that's going to speed up",
      "offset": 555.8,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "the pace of things quite a bit yeah um I",
      "offset": 557.44,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "can see it now the the the hit equal to1",
      "offset": 560.72,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "Dalmations 101 gpus I think it's going",
      "offset": 563.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "to be a big hit uh and AI can make the",
      "offset": 566.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "whole video eventually",
      "offset": 568.279,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "but it's actually I'm really glad you",
      "offset": 569.8,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "mentioned the the the F shot learning",
      "offset": 570.92,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "because uh that's actually for me almost",
      "offset": 574.279,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "a Perfect Analogy because the the",
      "offset": 576.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "original name of the paper for",
      "offset": 579.16,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "gpt3 was language models are F shot",
      "offset": 581.88,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "Learners right not introducing gpt3 it",
      "offset": 585.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "was language models are F shot Learners",
      "offset": 588.12,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "that paper introduced GPT where the",
      "offset": 590.72,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "authors opening eye were saying that",
      "offset": 593.6,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "where you get the most interesting work",
      "offset": 595.8,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "is through the fot learn learning and",
      "offset": 598.079,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "this is 2020 again two years before they",
      "offset": 600,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "focused on alignment so that you didn't",
      "offset": 603.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "need fuch shot learning anymore it just",
      "offset": 605.24,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "becomes um it it just becomes ask it a",
      "offset": 608.32,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "question get your answer so it's that",
      "offset": 611.64,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "Delta between we're seeing the promise",
      "offset": 613.519,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "to we've made it more user accessible",
      "offset": 616.32,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "and I think between there you get this",
      "offset": 618.88,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "explosion of research you know your came",
      "offset": 620.959,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "be an explosion of research and then it",
      "offset": 623.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "all kind of culminates in here's how you",
      "offset": 625.079,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "now interact with this this model uh",
      "offset": 627.399,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "does that is that you know that's how I",
      "offset": 630.36,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "see it at least o like what what do you",
      "offset": 632.24,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "think no I think it's seeing similar",
      "offset": 635.8,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "things I think one thing Jacob that your",
      "offset": 639.2,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "blog post actually from the cvpr",
      "offset": 642.079,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "conference up in Vancouver or this year",
      "offset": 644.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "touched on was there seem to be two",
      "offset": 646.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "research tracks which is um a lot of",
      "offset": 647.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "research being present is derivative of",
      "offset": 649.8,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "clip and essentially you know few shot",
      "offset": 651.399,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "learning from distilled clip models and",
      "offset": 654.519,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "newer applications of that uh barring",
      "offset": 657,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "from similar architectures and then",
      "offset": 658.8,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "there seems to be a separate path um",
      "offset": 660.36,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "from grounding dyo uh Florence um and a",
      "offset": 662.839,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "few other models that that that sonan",
      "offset": 666.2,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "has already mentioned so it's really",
      "offset": 667.76,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "interesting I think there's uh even with",
      "offset": 669.079,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "this cambrid explosion there tends to be",
      "offset": 672.6,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "two sort of trees and lineages from",
      "offset": 674.12,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "which research is is pres which is a",
      "offset": 676.88,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "little dis bit distinct on I think from",
      "offset": 679.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you know we basically had the seminal",
      "offset": 681.72,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "moment where we all realize oh GPT",
      "offset": 683.04,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "and this singular Transformer",
      "offset": 684.8,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "architecture can essentially be",
      "offset": 686.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "replicated for uh you know a thousand",
      "offset": 688.079,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "different things there seems to be more",
      "offset": 690.88,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "diversity Jacob and and uh and part of",
      "offset": 692.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "this is maybe the image use cases can be",
      "offset": 695.399,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "different um and multimodality has a",
      "offset": 697.079,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "variety of different data and use cases",
      "offset": 698.92,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "it can be applicable to but there seems",
      "offset": 701.44,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "to be more uh",
      "offset": 703.2,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "diversity um in in existing Vision",
      "offset": 705.959,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "models and architectures than than",
      "offset": 708.839,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "language yeah I'd say that definitely",
      "offset": 712.56,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "seems seems to be the case in in many",
      "offset": 714.639,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "regards and that you know if you think",
      "offset": 716.76,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "about language applications the chat",
      "offset": 718.76,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "interface is a pretty kind of dominant",
      "offset": 720.959,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "one where you just kind of put in",
      "offset": 722.72,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "language and then get language out and",
      "offset": 724,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "there's a lot lot of different uh",
      "offset": 725.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "applications that you can do with that",
      "offset": 728.04,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "whereas in Vision you know there's a lot",
      "offset": 729.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "more specificity that people are looking",
      "offset": 733.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "for um within identifying specific",
      "offset": 735.24,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "things within images and doing specific",
      "offset": 738,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "tasks with them um and so yeah so I",
      "offset": 739.92,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "actually think um if that that's kind of",
      "offset": 743.68,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "like a little bit of a segue what I",
      "offset": 746.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "think is is somewhat Limited in some of",
      "offset": 747.72,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "the multimodal models now compared to uh",
      "offset": 749.88,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "traditional CV techniques which is like",
      "offset": 752.959,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "for very specific operations of machines",
      "offset": 755.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and you know things where you need to be",
      "offset": 758.279,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "cutting very precisely or identifying an",
      "offset": 760.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "object's location um things are I think",
      "offset": 762.32,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "it's it's been shown even you know GPD",
      "offset": 766,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "4V doesn't really have that preciseness",
      "offset": 768.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "of being able to draw you know tight",
      "offset": 770.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "boxes or very close masks or or things",
      "offset": 772.56,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "like this that people are usually using",
      "offset": 775.44,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "uh you know traditional CV techniques",
      "offset": 778.04,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "for um which which I which I think is is",
      "offset": 779.959,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "is interesting in that language it seems",
      "offset": 783.079,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "like we can get it almost dead on now",
      "offset": 785.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "but uh Vision that still seems like some",
      "offset": 788.48,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "of that Precision in pixels is is still",
      "offset": 791,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "to come yeah I mean an image is worth a",
      "offset": 793.519,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "thousand words or in the in the words of",
      "offset": 796.92,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "Google an image is worth uh 16 by 16",
      "offset": 798.68,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "words I believe is the name of the paper",
      "offset": 801.959,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "for the vision Transformer or something",
      "offset": 803.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "like that um that I mean to me that",
      "offset": 805.279,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "makes a lot of sense the the user",
      "offset": 808.8,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "interface the practicality you know if",
      "offset": 811.76,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "you will of it all really seems to",
      "offset": 814.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "dominate",
      "offset": 816.839,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "because uh you know the chat interface",
      "offset": 818.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "is the dominant form to interact with",
      "offset": 820.399,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "llms but it's not the only way to",
      "offset": 821.959,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "interact with an llm right access to",
      "offset": 823.48,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "open source autoencoding models like",
      "offset": 826.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Bert mean you don't talk to it per se",
      "offset": 827.959,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "but you can still train it to do the",
      "offset": 830.48,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "task you want to do arguably for the",
      "offset": 832.279,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "most times cheaper and better at scale",
      "offset": 834.759,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "but it does does converge into this well",
      "offset": 837.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "this is how the consumer interacts with",
      "offset": 840.199,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "this product and here's how the",
      "offset": 842.56,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "developer might interact with this",
      "offset": 843.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "ecosystem and with vision toer point",
      "offset": 845.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it's almost like we're still finding it",
      "offset": 848.32,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "we still we're still figuring out what",
      "offset": 850.44,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "is that mainstream consumer path because",
      "offset": 852.6,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "we seem to have all these different ways",
      "offset": 856.8,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "that developers can do you know editing",
      "offset": 858.36,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "or masking or segmentation or just even",
      "offset": 861.399,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Flatout detection can be spun off into a",
      "offset": 864.279,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "billion dollar a company alone for the",
      "offset": 867.399,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "most part but we still don't know what",
      "offset": 870.759,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "that middle track is is it",
      "offset": 872.8,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "gbtv potentially is it all just a chat",
      "offset": 875.199,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "interface I hope not but maybe um but",
      "offset": 878.04,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "that we still are figuring that out um",
      "offset": 882,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "is that kind of how you see it Jacob or",
      "offset": 885.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "or is that totally I agree I I think",
      "offset": 887.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "yeah it's kind of the Wild West what the",
      "offset": 890.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "what that middle ground is going to be",
      "offset": 892.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "um I actually don't necessar I don't",
      "offset": 894.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "think I even have any speculations",
      "offset": 896.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "actually may maybe you guys me",
      "offset": 897.8,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "neither well me neither right because",
      "offset": 900.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you know we talk about multimodality and",
      "offset": 902.72,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "maybe this is the perfect segue um we",
      "offset": 904.519,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "talk about multimodality a lot and my",
      "offset": 906.68,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "experience I don't know about you two",
      "offset": 909.56,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "but my experience people will come to me",
      "offset": 910.8,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "and like what do you think about",
      "offset": 913.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "multimodality and then they'll follow up",
      "offset": 915.16,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "with you know like gptv like images and",
      "offset": 917.12,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "text together and I'm like and I have to",
      "offset": 920.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "kind of look at them and go yeah it's",
      "offset": 922.36,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "really exciting and don't forget",
      "offset": 924.16,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "multimodality one of the examp examples",
      "offset": 926.8,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "of multimodality is text and images but",
      "offset": 928.959,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "the term multimodality is so vague it",
      "offset": 932.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "literally just means any combination of",
      "offset": 934.92,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "two or more modes of data you can have a",
      "offset": 937.24,
      "duration": 6.839
    },
    {
      "lang": "en",
      "text": "a a model that knows audio and video",
      "offset": 941.319,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "only you can literally only talk to it",
      "offset": 944.079,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "but it produces videos that would be",
      "offset": 946.48,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "technically a multimodal model that does",
      "offset": 948.959,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "not require any quote texting depending",
      "offset": 951,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "on how you do the image processing but",
      "offset": 953.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that's something I have to kind of walk",
      "offset": 956.399,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "people up to so in in your mind I'm kind",
      "offset": 958.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "of curious about two things the where",
      "offset": 962.319,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "are we with",
      "offset": 964.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "multimodality as a field both from a",
      "offset": 966.12,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "kind of consumer standpoint and a",
      "offset": 970.079,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "research standpoint and maybe let's",
      "offset": 971.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "start with the research standpoint",
      "offset": 973.279,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "because I I'm more",
      "offset": 975.959,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "interested because research tends to",
      "offset": 978.199,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "kind of get ahead of consumers a little",
      "offset": 980.6,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "bit so where are we do you think in the",
      "offset": 983.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "research field of just kind of mult M IM",
      "offset": 986.279,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "modality in general mhm mhm yeah I mean",
      "offset": 988.8,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "I don't have maybe the best calibration",
      "offset": 992.48,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "on on the very cutting edge of this but",
      "offset": 995.519,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "it definitely seems it definitely makes",
      "offset": 998.44,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "sense if you if you think about just",
      "offset": 1000.279,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "kind of like if you're building a",
      "offset": 1002.24,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "general intelligence that this general",
      "offset": 1003.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "intelligence should be fed from many",
      "offset": 1005.24,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "different modes of of of data and so you",
      "offset": 1007.839,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "know the exciting thing with the",
      "offset": 1011.319,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "connection of text and images because",
      "offset": 1012.639,
      "duration": 2.521
    },
    {
      "lang": "en",
      "text": "those are the ones that are most",
      "offset": 1014.12,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "prevalent on the web is kind of an",
      "offset": 1015.16,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "exciting initial connection where we've",
      "offset": 1017.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "seen a lot of good progress coming in U",
      "offset": 1019.279,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "but I think there's definitely been a",
      "offset": 1022.16,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "lot of uh interesting research that",
      "offset": 1023.759,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "people have been doing with Transformers",
      "offset": 1025.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "to try to continue to figure out how can",
      "offset": 1027.16,
      "duration": 6.759
    },
    {
      "lang": "en",
      "text": "we create this unified interface between",
      "offset": 1029.64,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "uh you know whatever the data modality",
      "offset": 1033.919,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "is you know so an image is just you know",
      "offset": 1035.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "like what you said like a 16 by6 patch",
      "offset": 1038.76,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "of of sequences uh and uh and you know",
      "offset": 1041.72,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "maybe the way that audio manifests",
      "offset": 1045.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "itself and taste or all these other",
      "offset": 1047.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "different modalities are the same thing",
      "offset": 1050.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and you can get that all into the same",
      "offset": 1051.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "uh model which which I think is exciting",
      "offset": 1054.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and um I don't know is this does this",
      "offset": 1056.88,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "fall into what you were talking about",
      "offset": 1059.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "with the item poent generative network",
      "offset": 1060.44,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "is that in this lot of work or is it",
      "offset": 1062.76,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "yeah kind of I think um so before again",
      "offset": 1065.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "peek behind the curtains we talk before",
      "offset": 1068,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "the recording as well um Google released",
      "offset": 1069.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "a paper early November 2023 couple weeks",
      "offset": 1072.44,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "ago at this point uh two weeks ago at",
      "offset": 1075.52,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "this point right so long ago uh and and",
      "offset": 1077.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the paper was called IGN item potency uh",
      "offset": 1079.96,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "item potency generative networks and it",
      "offset": 1082.88,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "is to my knowledge and um you know",
      "offset": 1086.6,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "having read the paper and kind of walk",
      "offset": 1088.799,
      "duration": 2.921
    },
    {
      "lang": "en",
      "text": "through a little bit about what they're",
      "offset": 1090.559,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "talking about the idea is that maybe",
      "offset": 1091.72,
      "duration": 6.439
    },
    {
      "lang": "en",
      "text": "Transformers aren't you know kind of",
      "offset": 1096.4,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "pure Vision Transformers aren't",
      "offset": 1098.159,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "necessarily the only path forward here",
      "offset": 1100.76,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "right I still argue Transformers are not",
      "offset": 1103.44,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "the end of the story for NLP in general",
      "offset": 1105.919,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "they just are the biggest Delta that",
      "offset": 1108.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "we've had in a very long time but it's",
      "offset": 1109.72,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "not the end of the story or it very",
      "offset": 1112.52,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "likely is not computer vision is the",
      "offset": 1115.12,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "same and and even now we're talking",
      "offset": 1117.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "about all these different models not all",
      "offset": 1119.72,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "of them are technically pure",
      "offset": 1121.48,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Transformers or even pure Vision",
      "offset": 1122.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Transformers there's already so much",
      "offset": 1124.48,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "diversity as I think actually you were",
      "offset": 1126.96,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "talking about earlier in the",
      "offset": 1128.52,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "architecture so when Google puts out you",
      "offset": 1129.72,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "know a paper and I kind of nerded out a",
      "offset": 1132,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "little bit just because my masters is in",
      "offset": 1134.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "algebraic geometry so I'm I'm reading",
      "offset": 1135.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "words it's like manifolds and Target uh",
      "offset": 1138.32,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "Target manifolds in the uh in the",
      "offset": 1140.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "function you know item potency I'm like",
      "offset": 1142.52,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "oh I remember all these terms from intro",
      "offset": 1144.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "algebra in my master's class but like",
      "offset": 1147.039,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "that's kind of the point is like well",
      "offset": 1150,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "you know we're the research is talking",
      "offset": 1151.799,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "at this level of mathematical",
      "offset": 1154.039,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "rigorousness that is still trickling",
      "offset": 1157.48,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "down so it's always fun for me in way to",
      "offset": 1160.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "see like wow like this what an",
      "offset": 1162.64,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "interesting math function all the way to",
      "offset": 1164,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "oh right but Sable diffusion does it",
      "offset": 1166.52,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "this way and that's the most efficient",
      "offset": 1168.08,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "right now but here's where we are um and",
      "offset": 1169.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "that gap between the research and the",
      "offset": 1172.84,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "consumer is what I I like to think about",
      "offset": 1174.799,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "a lot uh and and kind of what becomes",
      "offset": 1176.72,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "adopted so I think that speaks to your",
      "offset": 1179.24,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "point though is well where's the data",
      "offset": 1180.84,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "where's the where's the use case and",
      "offset": 1182.4,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "where is the scalability",
      "offset": 1184.32,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "right yeah Jacob it's it's interesting I",
      "offset": 1187.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "think that son you're touching on",
      "offset": 1190.2,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "something really interesting which is",
      "offset": 1191.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "all this research until there was a",
      "offset": 1192.96,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "clear crystal clear uh consum use case",
      "offset": 1195.32,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "that made people aware of potential",
      "offset": 1199.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Downstream applications people weren't",
      "offset": 1201.64,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "really paying attention right and so",
      "offset": 1204.08,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "Jacob I'm I'm kind of curious right I",
      "offset": 1206.48,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "think in many ways multimodality it is",
      "offset": 1207.96,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "multi there are multiple different",
      "offset": 1209.72,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "applications of this people are familiar",
      "offset": 1211.679,
      "duration": 2.601
    },
    {
      "lang": "en",
      "text": "with the mid journey and visual",
      "offset": 1213.039,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "prompting",
      "offset": 1214.28,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "examples it'd be kind of interesting to",
      "offset": 1215.52,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "walk through given your background Ro",
      "offset": 1218.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "flow I'm asking this for people in LMS",
      "offset": 1220.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "what are the four main use cases for",
      "offset": 1222.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "llms in four years right and that I",
      "offset": 1225.48,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "think can help infrastructure startups",
      "offset": 1228,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "can help people conceptualize there's",
      "offset": 1229.44,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "co-pilots there's chat Bots there's",
      "offset": 1230.88,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "transcription you know there's a bunch",
      "offset": 1233.08,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "of different applications but there are",
      "offset": 1234.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "four to five really key ones I think it",
      "offset": 1236.799,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "might be interesting given you saw what",
      "offset": 1239.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "people were building with roof flow and",
      "offset": 1241.159,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "also seeing these different",
      "offset": 1243.88,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "architectures what are the four to five",
      "offset": 1244.96,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "main applications of multimodality that",
      "offset": 1247.6,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "you're you've already seen and are",
      "offset": 1250.919,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "seeing that has you really psyched about",
      "offset": 1253.36,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "that are kind of uh maybe just beyond",
      "offset": 1255.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "the kind of visual you know create an",
      "offset": 1257.799,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "image of uh you know a dog running",
      "offset": 1260,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "through a field or create my logo um",
      "offset": 1261.919,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "what are other use cases that you you're",
      "offset": 1264.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "pretty psyched about yeah yeah that's",
      "offset": 1267.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "really interesting so yeah so I guess",
      "offset": 1269.919,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "kind as you as you put there yeah maybe",
      "offset": 1272.44,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "with language models we feel like we've",
      "offset": 1274.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "kind of started to see the collapse of",
      "offset": 1277.159,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "uh the different different forms that",
      "offset": 1279.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that they would be utilized for um but",
      "offset": 1281.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "but yeah with with multimodal vision",
      "offset": 1284.2,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "models maybe it's it's not so clear yeah",
      "offset": 1286.4,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "and the nent applications are yeah the",
      "offset": 1289.559,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "visual prompting and so so you can chat",
      "offset": 1293.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "with the image or chat with the the",
      "offset": 1296.12,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "scene and then the um the image",
      "offset": 1298.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "generation so you can actually just",
      "offset": 1302.32,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "generate new images and and those two",
      "offset": 1304.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "seem to be kind of like the first uh",
      "offset": 1306.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "leaders in this um but yeah then",
      "offset": 1308.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Crossing that with my experience at at",
      "offset": 1310.44,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "roof flow I think is pretty interesting",
      "offset": 1312.32,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "so there um I mean it was predominantly",
      "offset": 1314.64,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "uh detection cases so um the the number",
      "offset": 1317.64,
      "duration": 6.519
    },
    {
      "lang": "en",
      "text": "one use case on roof Universe which has",
      "offset": 1321.32,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "you know some 400,000 models on it now",
      "offset": 1324.159,
      "duration": 6.361
    },
    {
      "lang": "en",
      "text": "is pothole detection so uh everybody",
      "offset": 1327.559,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "just wants to know if there's potholes",
      "offset": 1330.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "on the street that they're driving down",
      "offset": 1332.159,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "and everybody wants to know that",
      "offset": 1333.64,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "throughout the entire world um and and",
      "offset": 1335.679,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "you know it has the Civic uh you",
      "offset": 1339.48,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "know yeah exactly so um I mean I'm sure",
      "offset": 1342.559,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "people are still going to want to do",
      "offset": 1346.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "that one um but in terms of how",
      "offset": 1347.64,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "multimodality plays into that I think um",
      "offset": 1350.679,
      "duration": 6.681
    },
    {
      "lang": "en",
      "text": "you know I think the the biggest promise",
      "offset": 1354.32,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "of multimodality is to be able to",
      "offset": 1357.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "connect the you know AI understanding",
      "offset": 1360.039,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "layer that you have with the neural",
      "offset": 1363.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "network with with the real world so just",
      "offset": 1365.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "in the way you know that uh opening eye",
      "offset": 1368,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "release gpts with the really strong",
      "offset": 1370.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "promise of being able to orchestrate all",
      "offset": 1372.24,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "these apis that are operating you know",
      "offset": 1374.159,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "the web is if you can reach one level",
      "offset": 1376.919,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "lower and you're starting to operate you",
      "offset": 1379.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "know mechanical processes in the",
      "offset": 1381.799,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "physical world um that seems to be kind",
      "offset": 1383.32,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "of like the most promising thing about",
      "offset": 1385.76,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "about multimodal that you could have",
      "offset": 1388.559,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "which is like a a multimodal machine",
      "offset": 1390.12,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "that you could say just like you know I",
      "offset": 1392.279,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "want you to clean my bathroom floor and",
      "offset": 1395.2,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "it knows what the bathroom floor is it",
      "offset": 1397.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "knows where it is it goes over there and",
      "offset": 1399.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "it does does the task so I think that's",
      "offset": 1401.279,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "I think there's going to be a lot of",
      "offset": 1403.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "exciting merging of that through",
      "offset": 1405.24,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "multimodal is people that are working on",
      "offset": 1407.96,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "uh",
      "offset": 1410.679,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "multimodal combinations with with with",
      "offset": 1411.36,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "robotics um so if if there's someone out",
      "offset": 1414.039,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "there listening on the podcast right now",
      "offset": 1417.08,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "looking for a startup idea I think that",
      "offset": 1418.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that that one's pretty exciting I",
      "offset": 1420.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "completely agree I don't know if you all",
      "offset": 1422.919,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "saw the like deep mine rt2 model uh it",
      "offset": 1424.4,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "was it was super interesting um I was",
      "offset": 1428.159,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "chatting with a friend over at bosson",
      "offset": 1430.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "Dynamics um Jacob who was also talking",
      "offset": 1432.36,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "exactly about this which is literally",
      "offset": 1434.919,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "the entire field of Robotics has spent",
      "offset": 1437.52,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "so much time trying to encode semantic",
      "offset": 1440.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "understanding of physical space and",
      "offset": 1442.6,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "teach the robot the room is messy this",
      "offset": 1444.76,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "is what a you know paper cup looks like",
      "offset": 1447.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "Etc now go pick that up and the last",
      "offset": 1449.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "mile is literally been you know",
      "offset": 1453.36,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "programming that Hardware um to to you",
      "offset": 1454.64,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "know basically instructed to do specific",
      "offset": 1457.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "tasks um rt2 was quite interesting",
      "offset": 1460.2,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "because it was Deep Mind basically",
      "offset": 1462.52,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "showing exactly that which is if you",
      "offset": 1463.679,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "know what a poth hole is or if you know",
      "offset": 1465.6,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "what a um what messy is and can",
      "offset": 1468.2,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "deconstruct that from language to visual",
      "offset": 1472.52,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "examples you can instruct in you know",
      "offset": 1474.919,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "the physical world someone just say",
      "offset": 1478.36,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "someone go clean your room and just as a",
      "offset": 1479.919,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "human would a robot could understand and",
      "offset": 1481.399,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "decompose that into different tasks and",
      "offset": 1483.24,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "so I think even Beyond just like basic",
      "offset": 1485.76,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "option I I couldn't agree more I think",
      "offset": 1487.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "um and and maybe you you remember this",
      "offset": 1490.679,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "from the conference I think people were",
      "offset": 1492.64,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "most excited about um particularly",
      "offset": 1494.039,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "visual prompting for synthetic data use",
      "offset": 1496.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "cases to actually teach uh different you",
      "offset": 1498.559,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "know physical world examples uh to to",
      "offset": 1501.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "robots and and basically accelerate",
      "offset": 1504.039,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "their learning so I actually think that",
      "offset": 1505.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "subdomain is going to be uh going to be",
      "offset": 1508.559,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "a huge cases couldn't couldn't agree",
      "offset": 1511.159,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "more so coming and now that we're on the",
      "offset": 1516.919,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "topic of of you know squarely in in use",
      "offset": 1520.24,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "cases and practicality of multimodality",
      "offset": 1523.64,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "and I guess it's it's a big question but",
      "offset": 1526.039,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "and we've already started to answer it",
      "offset": 1529.12,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "but",
      "offset": 1530.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "how what kinds of kind of imminent use",
      "offset": 1531.52,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "cases do you see as as uh something more",
      "offset": 1535.76,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "more like untapped like auction and I",
      "offset": 1538.799,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "were talking about this the other day at",
      "offset": 1541.24,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "at a coffee shop we were talking about",
      "offset": 1542.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "use cases for multimodality and we kind",
      "offset": 1543.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "of came to a very similar conclusion",
      "offset": 1546.12,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "which we can think of ideas but is it",
      "offset": 1547.6,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "worth starting something now knowing",
      "offset": 1551.76,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "that the architecture is so in flux or",
      "offset": 1554.48,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "is it better to think more on what are",
      "offset": 1558.36,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "the use cases that are okay now but will",
      "offset": 1560.559,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "only become better and and kind of like",
      "offset": 1563.76,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "a race between what's the better idea",
      "offset": 1566.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and what is the actual model",
      "offset": 1568.6,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "architectures ready for today so what",
      "offset": 1571.32,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "kind of uh what what do you think are",
      "offset": 1574.799,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "like the biggest applications today that",
      "offset": 1577.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "can be solved that maybe people are are",
      "offset": 1579.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "just starting to get into mhm yeah",
      "offset": 1581.919,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "that's interesting so I think I guess",
      "offset": 1584.88,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "immediately what's coming to mind",
      "offset": 1587.88,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "there's no nothing like a really really",
      "offset": 1589.399,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "good like few single use cases that are",
      "offset": 1591.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "really coming to mind but I think",
      "offset": 1594.48,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "there's um a lot to be done so there",
      "offset": 1596.559,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "there's obviously still a lot of use",
      "offset": 1600.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "cases where you know your traditional CV",
      "offset": 1602.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "methods like detection segmentation",
      "offset": 1604.399,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "classification are going to be the best",
      "offset": 1606.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "thing you can do to get high accuracy",
      "offset": 1607.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "results and operate you know machines",
      "offset": 1609.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "with the efficiency that that uh we we",
      "offset": 1611.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "want to but there are a lot of",
      "offset": 1614.159,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "applications that you know a multimodal",
      "offset": 1616.12,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "model might be almost there that you can",
      "offset": 1618.84,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "just bet on you know in six to the 12",
      "offset": 1621.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "months that those models are just going",
      "offset": 1623.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "to get stronger and your your",
      "offset": 1625.679,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "application will end up becoming you",
      "offset": 1626.96,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "know a very useful thing um and you can",
      "offset": 1628.919,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "kind of ride the tides of of the the",
      "offset": 1631.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "fact that these General models are just",
      "offset": 1634.52,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "going to be getting a lot stronger um so",
      "offset": 1636.039,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "anything within those like couple first",
      "offset": 1638.799,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "use cases that we talked about with",
      "offset": 1641.679,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "visual prompting and and image gen",
      "offset": 1643.08,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "definitely seems like you know a lot of",
      "offset": 1645.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "exciting places to be building and the",
      "offset": 1648,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "other nice thing there too is you know",
      "offset": 1650.76,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "all the infra getting put up around it",
      "offset": 1652.48,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "so you can build on top of the shoulders",
      "offset": 1654.559,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "of giants for a lot of those",
      "offset": 1656.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "applications um it could be fun to kind",
      "offset": 1657.799,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "of ideate on what some of those",
      "offset": 1659.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "applications might be but um yeah cuz",
      "offset": 1661.24,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "like even I I'm like you know I have uh",
      "offset": 1664.039,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "I have blank cameras in my in my house",
      "offset": 1666.679,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "because my pets can be kind of",
      "offset": 1669.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "rambunctious when I'm gone uh and even I",
      "offset": 1671.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "was like Well Blink I can get access to",
      "offset": 1674.76,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "the API I can get images from my camera",
      "offset": 1676.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "I can run that through a thing I can",
      "offset": 1678.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "tell me what the cat is doing what the",
      "offset": 1680.399,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "dog is doing and it's like and then I'm",
      "offset": 1682.399,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "like well if I can do that then I can do",
      "offset": 1684.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this if I can do that then I can do this",
      "offset": 1687.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "and it feels like it's",
      "offset": 1689.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "almost it's really easy I think to come",
      "offset": 1690.919,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "up with all of these ideas but then it",
      "offset": 1693.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "becomes like this you know almost like",
      "offset": 1695.2,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "the diversity in architectures there's",
      "offset": 1696.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "this Paradox of choice which is like",
      "offset": 1698.6,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "okay but what's cool and what's",
      "offset": 1700.679,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "interesting what's interesting and",
      "offset": 1701.919,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "what's profitable what's profitable and",
      "offset": 1703.08,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "what's you know not quite there yet and",
      "offset": 1704.559,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "you have this really mult accessed",
      "offset": 1706.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "decision- making problem of where should",
      "offset": 1708.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "I be focusing my time but that kind of",
      "offset": 1710.88,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "leads to a bigger question which is like",
      "offset": 1713.799,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "the modern quote unquote chat GP expert",
      "offset": 1715.919,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "who is who is really just someone who is",
      "offset": 1720.24,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "uh really good at teaching and reading",
      "offset": 1722.559,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and writing and I was a prompt really",
      "offset": 1724.519,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "well um they can get in and kind of make",
      "offset": 1726.159,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "their fair share of Splash in the space",
      "offset": 1729.2,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "what does that look like in computer",
      "offset": 1731.88,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "vision like what what what does that",
      "offset": 1734.519,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "look like what is the um cuz I think the",
      "offset": 1735.919,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "big thing for me was always the avatars",
      "offset": 1738.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "right upload your face like dream Booth",
      "offset": 1740.84,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "all upload your face and we're going to",
      "offset": 1743,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "make you know chibi youu we're gonna",
      "offset": 1744.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "make uh Marvel you we're gonna make you",
      "offset": 1746.64,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "know Renaissance painting of you and it",
      "offset": 1749.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "was fun but then I saw like 50 of them",
      "offset": 1752.159,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "and I'm like okay we get it uh what are",
      "offset": 1754.96,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "some of those like other like fun and",
      "offset": 1758,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "interesting ideas or let me put ask you",
      "offset": 1761.159,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "a different way that's also leads to a",
      "offset": 1763.279,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "different potential issue that I",
      "offset": 1765.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "which is a paper that I read out of rice",
      "offset": 1768.2,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "um it was called like models go mad and",
      "offset": 1771.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "the acronym was like model autophagy",
      "offset": 1775.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "disorder the idea was they were looking",
      "offset": 1776.88,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "to data poisoning as these applications",
      "offset": 1779.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "keep cropping up that are making AI",
      "offset": 1781.96,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "generated",
      "offset": 1784.36,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "images it kind of floods the space the",
      "offset": 1785.44,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "open internet which as we all know",
      "offset": 1788.08,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "becomes the source material for a lot of",
      "offset": 1790.279,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "the next generation of AI models and",
      "offset": 1792.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "they showed that if you train AI models",
      "offset": 1794.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "on incre increasingly larger amounts of",
      "offset": 1796.84,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "synthetic images from previous",
      "offset": 1798.88,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "generations of models the models tend to",
      "offset": 1800.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "not get better but actually get worse in",
      "offset": 1803.399,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "quality over time and it becomes this",
      "offset": 1805.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "tricky issue of like well we have to",
      "offset": 1808.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "spend more time on data processing I",
      "offset": 1810.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "guess how do you see that cycle of",
      "offset": 1812.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "generating I mean the same thing for",
      "offset": 1814.88,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "text too but images specifically how do",
      "offset": 1816.12,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "you see that kind of self-feeding uh",
      "offset": 1818.6,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "self-filling prophecy and like feedback",
      "offset": 1820.88,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "loop",
      "offset": 1822.64,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "developing yeah that's interesting I",
      "offset": 1823.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "wasn't familiar with that paper that it",
      "offset": 1825.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "it uh it was a couple months ago",
      "offset": 1827.12,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "honestly just came to mind like Yeah",
      "offset": 1828.88,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "because it seems like it would be like",
      "offset": 1831,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "uh at least steady like it would just be",
      "offset": 1832.679,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "regurgitating upon itself and kind of",
      "offset": 1835.559,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "staying steady but if it's maybe you're",
      "offset": 1837.519,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "like losing resolution at every every",
      "offset": 1839.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "step it's always the way they describe",
      "offset": 1841.919,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it was the previous generations have",
      "offset": 1844.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "imperfections that later generations",
      "offset": 1846.399,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "kind of exploit and like make bigger so",
      "offset": 1848.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "like the problem of image generating",
      "offset": 1851.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "model giving me six fingers becomes like",
      "offset": 1853.44,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "eight fingers down the road it's like it",
      "offset": 1855.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "just kind of gets worse yeah yeah I mean",
      "offset": 1857.08,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "maybe that's too kind of like a",
      "offset": 1860.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "promising fact that we can have some",
      "offset": 1862.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "consolation in and that like we like us",
      "offset": 1864.279,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "humans still have something to do you",
      "offset": 1867.12,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "know we still need to create and",
      "offset": 1868.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "generate new content that's worthwhile",
      "offset": 1871.08,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "for for the the the models of tomorrow",
      "offset": 1873.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "to be learning from um which which I do",
      "offset": 1876.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "think is is an interesting fact about",
      "offset": 1878.72,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "you know the hoi thing which some people",
      "offset": 1880.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "feel like we're kind of like totally out",
      "offset": 1883,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "of a job but uh you know there's still a",
      "offset": 1884.48,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "lot of interesting things for for for us",
      "offset": 1886.639,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "to do you can always create content",
      "offset": 1889.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "that's it's there's solace in that I",
      "offset": 1891.96,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "think For Better or For Worse humans can",
      "offset": 1894.279,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "always create content whether people",
      "offset": 1896.639,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "want us to or not we'll be creating",
      "offset": 1899.2,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "content so he said as his listeners",
      "offset": 1900.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "turned off the",
      "offset": 1903.96,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "podcast um but you're you're raising a",
      "offset": 1905.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "great Point Jacob because you know with",
      "offset": 1909.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the SAG uh strike that just ended",
      "offset": 1911.72,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "recently a big point of that strike with",
      "offset": 1914.08,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "with you know screen actors and and",
      "offset": 1916.399,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "writers as well is AI generated content",
      "offset": 1917.96,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "and you know I'm not an expert in",
      "offset": 1921.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "economics I'm not an expert in in strike",
      "offset": 1924.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "philosophy and I do know that and",
      "offset": 1926.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "believe and know that AI is actively uh",
      "offset": 1929,
      "duration": 7.159
    },
    {
      "lang": "en",
      "text": "uh replacing some jobs but to your point",
      "offset": 1932.12,
      "duration": 6.439
    },
    {
      "lang": "en",
      "text": "the the fear around oh my God the AI is",
      "offset": 1936.159,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "here and it's already better than humans",
      "offset": 1938.559,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that's the point that I want people to",
      "offset": 1940.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "kind of forget it's like that's not the",
      "offset": 1942.639,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "argument the bad part isn't the AI is",
      "offset": 1944.32,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "better than humans the part is the AI is",
      "offset": 1946.84,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "actually not as good as humans but",
      "offset": 1949.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "companies still want to use them that's",
      "offset": 1951.36,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "the",
      "offset": 1953.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "problem uh and the answer isn't great",
      "offset": 1954.44,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "well then we'll wait for AI to get",
      "offset": 1957.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "better no the answer is what you said I",
      "offset": 1958.799,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "think which is humans will always need",
      "offset": 1961.08,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "to play a role otherwise humans are not",
      "offset": 1963.399,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "progressing we are not creating anything",
      "offset": 1966.559,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "new we are just relying on AI systems to",
      "offset": 1968.72,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "kind of cut paste put things together of",
      "offset": 1971.399,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "stuff we've already done which up till",
      "offset": 1973.96,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "now is a lot but it shouldn't be all of",
      "offset": 1976.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "what we've done so there's always going",
      "offset": 1979.039,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "to be this tricky conversation to have",
      "offset": 1981,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "and it's a lot of his economics a lot of",
      "offset": 1983.24,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "it's research and a lot of it is just",
      "offset": 1985.84,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "human nature and navigating all that but",
      "offset": 1988.24,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "I I like what you said very succinctly",
      "offset": 1991.44,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "which is what I'm saying very unusally",
      "offset": 1993.399,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "which is humans will always have a part",
      "offset": 1995,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to play and and and for me that's a",
      "offset": 1996.559,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "wonderful philosophy to kind of walk",
      "offset": 1999.08,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "away with from a lot of this",
      "offset": 2000.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "conversation do you do you think so yeah",
      "offset": 2001.72,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "definitely definitely good well you",
      "offset": 2005,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "heard it here first humans will always",
      "offset": 2007.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "have a part to play it's content",
      "offset": 2008.96,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "everyone the uh the",
      "offset": 2011.519,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "um one thing son you mentioned which is",
      "offset": 2014.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "humans will always have a part to play",
      "offset": 2017.24,
      "duration": 2.439
    },
    {
      "lang": "en",
      "text": "is that I think we're actually in the",
      "offset": 2018.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "middle of maybe the biggest upskilling",
      "offset": 2019.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "that we've had you know in technical",
      "offset": 2022.519,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Talent ever which is that everyone's",
      "offset": 2024.88,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "learning how to become a new developer",
      "offset": 2026.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "with LMS in this new interesting world",
      "offset": 2028.36,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "and Jacob something I think it's",
      "offset": 2030.679,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "interesting is we have this whole new",
      "offset": 2032.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "audience of folks that don't have a",
      "offset": 2034.32,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "backr in ml that are functionally",
      "offset": 2036,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "creating new applications and they've",
      "offset": 2037.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "running into challenges which are",
      "offset": 2038.76,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "obvious to those that you like sonan",
      "offset": 2041.279,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "with a background at NLP that hey this",
      "offset": 2043.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "is non-deterministic to create a data",
      "offset": 2045,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "pipeline you're going to have to",
      "offset": 2046.72,
      "duration": 2.6
    },
    {
      "lang": "en",
      "text": "structure your output hey it turns out",
      "offset": 2047.399,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "distilling these models is quite hard",
      "offset": 2049.32,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "and for you to get performance out of",
      "offset": 2050.919,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "that relative to cost you need to do",
      "offset": 2052.28,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "that so these distinct infrastructure",
      "offset": 2053.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "challenges that have popped up that",
      "offset": 2055.52,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "Engineers are dealing with with LMS and",
      "offset": 2057.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "trying to figure out for multimodality",
      "offset": 2059.079,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "I'd ask you what are people going to run",
      "offset": 2061.56,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "into when they when this starts uh",
      "offset": 2063.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "becoming more mature right given your",
      "offset": 2066,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "your your time at roof you've probably",
      "offset": 2067.839,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "seen this and you're also seeing stuff",
      "offset": 2069.28,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "come online maybe get abstracted away",
      "offset": 2070.639,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "what are the one or two surprises that",
      "offset": 2072.839,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "people will realize they'll have to deal",
      "offset": 2075.839,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "with uh obviously everyone's GPU poor so",
      "offset": 2077.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "not having enough resources the obvious",
      "offset": 2080.159,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "one but what may be uh interesting",
      "offset": 2081.839,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "challenges will developers have to face",
      "offset": 2084.72,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "as they learn how to develop",
      "offset": 2086.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "multi-mobile",
      "offset": 2087.8,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "applications yeah yeah that's awesome",
      "offset": 2090.2,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "well so I'm not officially still",
      "offset": 2092.48,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "affiliated with Robo flow but definitely",
      "offset": 2095.52,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "feels like you just teed me up for this",
      "offset": 2097.32,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "one so um one big thing about multimodal",
      "offset": 2099,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "uh computer vision models is they're",
      "offset": 2103.48,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "huge so you know like that's the same",
      "offset": 2104.96,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "thing with the GPD models and things",
      "offset": 2107.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "like that you know is like you you have",
      "offset": 2110.079,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "these huge models they have huge General",
      "offset": 2111.599,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "capacity and uh they're very talented at",
      "offset": 2113.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "many different things but the the",
      "offset": 2116.32,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "problem with that is that your inference",
      "offset": 2118.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "costs are ridiculous right so you have",
      "offset": 2120.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "to spend a ton of money to send all your",
      "offset": 2123.2,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "data through the GP is necessary to that",
      "offset": 2126.04,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "that you're going to need to infer",
      "offset": 2128.52,
      "duration": 2.839
    },
    {
      "lang": "en",
      "text": "through these models and that will be",
      "offset": 2129.92,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "quite costly um and so yeah like you",
      "offset": 2131.359,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "said it's like a lot of vision cases",
      "offset": 2134.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "you're actually inferring uh at a at a",
      "offset": 2136.599,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "rapid rate so um a big thing that row",
      "offset": 2139,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "does is like real time inference so",
      "offset": 2142.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "you're inferring almost like 30 frames a",
      "offset": 2143.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "second and there's no way that you're",
      "offset": 2145.96,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "going to bring you know 175 billion",
      "offset": 2147.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "parameter multimodal Vision model down",
      "offset": 2149.76,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "down to the edge so a project that roof",
      "offset": 2152.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "flow has been working on is uh this",
      "offset": 2155.24,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "project called Auto distill uh and autod",
      "offset": 2156.92,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "distill what it does is you can infer",
      "offset": 2159.04,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "through multimodal models and use them",
      "offset": 2160.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "to label supervision data sets and then",
      "offset": 2162.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "distill them down into base models like",
      "offset": 2165.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "detection and segmentation and",
      "offset": 2168.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "classification models uh that you can",
      "offset": 2169.44,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "then deploy and so those apis are all",
      "offset": 2171.8,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "very simple to use where you do the same",
      "offset": 2173.88,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "thing where you prompt them and you",
      "offset": 2175.92,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "quickly get a new smaller model off of",
      "offset": 2177.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "it which I think that's a really",
      "offset": 2179.72,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "exciting uh thing that people are going",
      "offset": 2180.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "to be doing with multimodal models is uh",
      "offset": 2182.96,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "take them",
      "offset": 2186.16,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "to seal them down into kind of like that",
      "offset": 2187.319,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "basic thing that you're trying to do and",
      "offset": 2189.16,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "then operate it more efficiently um and",
      "offset": 2190.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "in some cases too that you have it more",
      "offset": 2193.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "accurately too because you've been able",
      "offset": 2195.24,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "to supervise the data set and uh kind of",
      "offset": 2197.359,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "cons take the control back a little bit",
      "offset": 2200.319,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "um so definitely that kind of well",
      "offset": 2203.28,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "that's what people are going to be doing",
      "offset": 2206.52,
      "duration": 2.28
    },
    {
      "lang": "en",
      "text": "in a couple years right now with LMS",
      "offset": 2207.48,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "they're having the same challenges right",
      "offset": 2208.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "which is uh distilling those models",
      "offset": 2210.24,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "supervising and getting the right data",
      "offset": 2212.96,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "it actually kind of relates to the",
      "offset": 2214.839,
      "duration": 2.681
    },
    {
      "lang": "en",
      "text": "solving problem you're you're now",
      "offset": 2216.079,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "addressing and founding your new company",
      "offset": 2217.52,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Jacob so could you tell us a little bit",
      "offset": 2219.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "more about uh RC and what you all are up",
      "offset": 2220.52,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "to yeah yeah so RC is kind of after a",
      "offset": 2223.96,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "little bit of a similar routine where um",
      "offset": 2226.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "we're all about making specialized",
      "offset": 2229.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "language models that are operating uh",
      "offset": 2231.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "with inside of people's uh vpcs and so",
      "offset": 2233.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that their data can stay private and",
      "offset": 2236.8,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "they're working on specific use cases",
      "offset": 2238.48,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "with language models um so for example",
      "offset": 2240.2,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "you know certain people are using",
      "offset": 2242.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "language models to you know do things",
      "offset": 2244.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that we used to do like entity",
      "offset": 2247.4,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "extraction and like uh or you know",
      "offset": 2248.64,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "classification or things like that or um",
      "offset": 2251.2,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "different you know more like constrained",
      "offset": 2254.28,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "NLP tasks and I even do it all the time",
      "offset": 2256.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "today where I'll just be like okay well",
      "offset": 2258.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "I want to get this thing done what's the",
      "offset": 2260.359,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "easiest way to do it llama 70 billion",
      "offset": 2262.16,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "and send in a prompt and you know spin",
      "offset": 2265.119,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "up a ton of gpus and uh process those",
      "offset": 2267.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "those desires that I have but really you",
      "offset": 2270.24,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "know if you want to operate some of",
      "offset": 2272.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "these models at lower cost then",
      "offset": 2274.2,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "best thing to do is distill them down",
      "offset": 2277.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "focus on a domain or a task and then",
      "offset": 2279.359,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "kind of deploy a smaller model to do",
      "offset": 2282.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "those things so that's kind of the area",
      "offset": 2284.76,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "of uh of work that I'm working in now um",
      "offset": 2286.599,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "which is in a lot of ways similar in",
      "offset": 2289.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Spirit uh to the distillation of",
      "offset": 2291.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "multimodal models to a CV",
      "offset": 2294.48,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "model yeah no it's more the same it's",
      "offset": 2296.8,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "it's the right data and getting it into",
      "offset": 2299.56,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "a usable format that matches your use",
      "offset": 2301.319,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "case right so I think we're going to see",
      "offset": 2304,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "more and more of that so not I already",
      "offset": 2305.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "have talked to that as a theme so we'll",
      "offset": 2307.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "link to uh you know the company and your",
      "offset": 2309.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "all's product and and and the links but",
      "offset": 2311.119,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "Jacob thank you so much for taking time",
      "offset": 2314.24,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "this was super fun so thanks for coming",
      "offset": 2315.96,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "on we uh we really really appreciate",
      "offset": 2317.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "it yeah awesome yeah thanks for having",
      "offset": 2320.56,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "me on guys love love doing things like",
      "offset": 2323,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "this and yeah had a great time myself as",
      "offset": 2325.079,
      "duration": 8.361
    },
    {
      "lang": "en",
      "text": "well awesome we see you soon yep see you",
      "offset": 2327.64,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "guys",
      "offset": 2335.52,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "a",
      "offset": 2338.76,
      "duration": 2.839
    }
  ],
  "cleanText": "[Music]\nHey everyone, welcome back to Practically Intelligent. Today, we're excited to welcome Jacob Solawetz, the CTO at arcee.ai and former founding engineer at Roboflow, one of the leading companies in computer vision infrastructure. We're going to talk to Jacob a bit about trends in vision and how the evolution of vision transformers and now multimodal architectures could be different than how LLMs progressed, or more of the same. I think I really like Jacob's balance, given he's now working on a company that's domain adapting LLMs but has had years of experience working in making usable and functional and deployable vision models for various different use cases. Um, I like his balanced perspective on both, so we're excited to have him on.\n\nYeah, no, it's a great conversation. We, we, we talk, it's one of those episodes where we talk not just about the technological improvements, but we're also really hitting on how those improvements end up affecting the interaction between users and AI, and I think that's really where people are excited about multimodal because it's, it's really the future of how we're going to interact with these systems. So I say we jump right in.\n\nHey Jacob, how's it going?\n\nGoing great, how are you guys?\n\nI'm doing great, actually. How are you?\n\nI'm hoping you're over here when I do this. I'm pretty thrilled. I am on, I am on the left side of the screen. We could, we could use the new EMU editor, please make that work, or honestly, make me look like an idiot, it's also fine. Uh, today we have Jacob on, we are going to be talking pretty much all things multimodal in computer vision, because not just because it is actively kind of the hot topic, but because Jacob is actually one of the, uh, in my opinion at least, one of the pioneering engineers in the modern computer vision space, uh, being the founding engineer of Roboflow. And just yesterday, by the way, this is breaking news, yesterday I was giving a lecture for O'Reilly on the topic of GPT, and one of the questions was, did you see this new, uh, webcam GPT demo from Roboflow? And they sent me the GitHub blank. I'm like, that's so funny, I'm talking to the founding engineer tomorrow about this, or about, you know, his work and what he's been up to. So this is something people are talking about more and more. So Jacob, my first question to you to kind of open us all up to this space is, can you give us kind of a brief history, where have we been, where are we now, uh, and then we'll get to where are we going, but where, where have we been, where are we now in computer vision and multi?\n\nYeah, yeah, definitely. I, I think that's an exciting place to kick things off. So, um, obviously, you know, everything in the AI world is moving forward right now, it's a lot of rapid velocity, but in CV, the most exciting thing is multimodality, which is, you know, bringing in the ability to have language understanding in combination with images and video in a way that we've never been able to do that before. So kind of taking, taking a high-level step back into that landscape, as the history of CV was, you know, people were doing old school ML algorithms like 10 years ago and working on processing pixels, and then they eventually collapsed on the CNN, and so we had, you know, convolutional neural networks and exciting, uh, models like YOLO come out and make a really big impact, and YOLO and ResNet was kind of the dominant models in CV for, you know, about, uh, you know, from 5 years ago to about, yeah, maybe like a year ago now when, uh, you know, transformers really started to make a big impact and start to set, uh, new heights in, in benchmarks. And so it, there's kind of an interesting mixing of waters now where you have a lot of practical applications still running on CNN models and, uh, and a lot of new, exciting applications coming out, uh, that are more general on, uh, with multimodality.\n\nYeah, no, I'm, I'm glad you brought up a lot of that history because, uh, users or users, listeners will, will know, I, I tend to be an expert in all things text-based, um, and, you know, NLP, but that doesn't mean I don't understand computer vision. I don't know the history of computer vision models, and I think part of what makes it such a similar story, a similar arc, and again, this will all kind of converge with multimodality is, while the NLP researchers and practitioners were over here, you know, figuring out, you know, not figuring out, but using attention mechanisms, attaching them onto recurrent neural networks to make them a little bit better, um, and, and then finally figuring out that, hey, maybe, you know, quote, \"attention is all you need\" and the transformer, a very similar thing was happening in vision, honestly, pretty much at the same time. You see in the mid-2016, 2017, I think it was, you at all, if I, I'll have to remember this, but papers were already coming out with people attaching the attention mechanism to CNNs to make better image captioning systems. So we were all, we were using the, the primary engine of the transformer, the attention mechanism, even before the transformer came out in computer vision and NLP. And when the transformer comes out, 2017, it's only preceded a few years later with the quote, \"Vision Transformer\" in 2020, a paper that comes out of Google. So we see that's also the same year that GPT-3 comes out, and that starts to get in the news. So vision and, and NLP have always been within, you know, two to five years of each other in the state of progress. So NLP came out a little bit ahead just because OpenAI put that really nice user interface on top of their LLM, but more importantly, and I think this kind of leads me to my next question to you is, the data was already there with text. Text data is just stupid easy to find, right, on the open internet, but well-labeled image data, not so much. So we had our a big Delta in, in data set quality was with ImageNet from like half a decade to a decade ago at this point, and that really spurned the idea of pre-trained networks like ResNet, but all convolutional. So my, my, my first question now back to you is, how do you kind of see those parallel tracks going, and now that we're seeing this, you know, explosion of vision models, like you, you mentioned Donut and you know, Flamingo and Vision Transformer in the last two to three years, what does that signal about the state of computer vision compared to the state of like NLP with chat, with chat GPT?\n\nYeah, definitely. Yeah, I think that is kind of an interesting way to, to see things is that a big thing was just the, the prevalence of a huge corpus of labeled data. And the nice thing about that was because, you know, NLP pre-training routines were able to just find out that next token prediction worked pretty well to kind of get a deeper semantic understanding, which next pixel prediction never really seemed to pan out that way. So, uh, that, that just happened to be, you know, a, a nice artifact of the way that language carries semantic richness in a way that, uh, just image pixel maybe doesn't quite have. I mean, maybe if we had like infinite data of video streams of different, you know, next pixel in the next time time frame, maybe it, maybe it would have worked differently. Um, so I, I do think, I do think that's interesting, but I think, yeah, I think the interesting thing is that, you know, like NLP had all these really strong base models to, to build things off of, you know, where people were making all kinds of applications on top of BERT when, you know, that first, you know, pre-pre-train and then fine-tune, uh, schemo was, was introduced, and vision had things, you know, you could pre-train off or you could fine-tune off the, uh, ImageNet backbones, and you know, you were getting some semantic richness from pre-training on, on ImageNet, but you didn't really have like a really rich base like we have now. So now there's these really exciting new models, you know, like, uh, Grounding DINO and Flamingo and, you know, some of these other, other new models that are even coming out this week, uh, that are exciting bases to, to be training from. So it seems like there is going to be kind of like a, you know, a Cambrian explosion, if you will, of deep vision applications that are built off these things. And, and not only that, um, I would say, which is, you know, with the ability to do, uh, single shot and few shot prompting of these general CV models, there's all kinds of new applications that can be built by developers that have that kind of general ability that language has been shown going to be, you know, making a lot, a lot of, you know, exciting new, new applications on top of that, which, which is really big, you know, if you don't have to spin up your own GPUs and you don't have to figure out how to, you know, orchestrate, you know, 1,000 A100s in the cloud together to get a model out, um, you know, that, that, that's going to speed up the pace of things quite a bit.\n\nYeah, um, I can see it now, the, the, the hit, \"101 Dalmatians, 101 GPUs,\" I think it's going to be a big hit, uh, and AI can make the whole video eventually. But it's actually, I'm really glad you mentioned the, the, the few-shot learning because, uh, that's actually for me almost a perfect analogy because the, the original name of the paper for GPT-3 was \"Language Models are Few-Shot Learners,\" right? Not introducing GPT-3, it was \"Language Models are Few-Shot Learners.\" That paper introduced GPT where the authors opening eye were saying that where you get the most interesting work is through the few-shot learning, and this is 2020 again, two years before they focused on alignment so that you didn't need few-shot learning anymore, it just becomes, um, it, it just becomes ask it a question, get your answer. So it's that Delta between we're seeing the promise to we've made it more user accessible, and I think between there you get this explosion of research, you know, your Cambrian explosion of research, and then it all kind of culminates in, here's how you now interact with this, this model. Uh, does that, is that, you know, that's how I see it at least, or like, what, what do you think?\n\nNo, I think it's seeing similar things. I think one thing, Jacob, that your blog post actually from the CVPR conference up in Vancouver or this year touched on was, there seem to be two research tracks, which is, um, a lot of research being present is derivative of CLIP and essentially, you know, few-shot learning from distilled CLIP models and newer applications of that, uh, barring from similar architectures, and then there seems to be a separate path, um, from Grounding DINO, uh, Florence, um, and a few other models that, that, that someone has already mentioned. So it's really interesting, I think there's, uh, even with this Cambrian explosion, there tends to be two sort of trees and lineages from which research is, is present, which is a little bit distinct on, I think, from, you know, we basically had the seminal moment where we all realize, oh, GPT and this singular transformer architecture can essentially be replicated for, uh, you know, a thousand different things. There seems to be more diversity, Jacob, and, and, uh, and part of this is maybe the image use cases can be different, um, and multimodality has a variety of different data and use cases it can be applicable to, but there seems to be more, uh, diversity, um, in, in existing vision models and architectures than than language.\n\nYeah, I'd say that definitely seems, seems to be the case in, in many regards, and that, you know, if you think about language applications, the chat interface is a pretty kind of dominant one where you just kind of put in language and then get language out, and there's a lot, lot of different, uh, applications that you can do with that, whereas in vision, you know, there's a lot more specificity that people are looking for, um, within identifying specific things within images and doing specific tasks with them. Um, and so, yeah, so I actually think, um, if that, that's kind of like a little bit of a segue, what I think is, is somewhat limited in some of the multimodal models now compared to, uh, traditional CV techniques, which is like, for very specific operations of machines and, you know, things where you need to be cutting very precisely or identifying an object's location, um, things are, I think it's, it's been shown, even, you know, GPT-4V doesn't really have that preciseness of being able to draw, you know, tight boxes or very close masks or, or things like this that people are usually using, uh, you know, traditional CV techniques for, um, which, which I, which I think is, is interesting in that language, it seems like we can get it almost dead on now, but, uh, vision, that still seems like some of that precision in pixels is, is still to come.\n\nYeah, I mean, an image is worth a thousand words, or in the, in the words of Google, an image is worth, uh, 16 by 16 words, I believe is the name of the paper for the vision transformer or something like that. Um, that, I mean, to me, that makes a lot of sense, the, the user interface, the practicality, you know, if you will, of it all really seems to dominate, because, uh, you know, the chat interface is the dominant form to interact with LLMs, but it's not the only way to interact with an LLM, right? Access to open source autoencoding models like BERT mean you don't talk to it per se, but you can still train it to do the task you want to do, arguably for the most times cheaper and better at scale, but it does, does converge into this, well, this is how the consumer interacts with this product, and here's how the developer might interact with this ecosystem. And with vision, to your point, it's almost like we're still finding it, we still, we're still figuring out what is that mainstream consumer path, because we seem to have all these different ways that developers can do, you know, editing or masking or segmentation or just even flat-out detection can be spun off into a billion-dollar company alone for the most part, but we still don't know what that middle track is. Is it GPT-V potentially? Is it all just a chat interface? I hope not, but maybe, um, but that we still are figuring that out. Um, is that kind of how you see it, Jacob, or, or is that totally?\n\nI agree. I, I think, yeah, it's kind of the Wild West, what the, what that middle ground is going to be. Um, I actually don't necessarily, I don't think I even have any speculations, actually. Maybe you guys, me neither. Well, me neither, right? Because, you know, we talk about multimodality, and maybe this is the perfect segue, um, we talk about multimodality a lot, and my experience, I don't know about you two, but my experience, people will come to me and like, what do you think about multimodality? And then they'll follow up with, you know, like GPT-V, like images and text together, and I'm like, and I have to kind of look at them and go, yeah, it's really exciting, and don't forget, multimodality, one of the examples of multimodality is text and images, but the term multimodality is so vague, it literally just means any combination of two or more modes of data. You can have a, a, a model that knows audio and video only, you can literally only talk to it, but it produces videos, that would be technically a multimodal model that does not require any quote texting, depending on how you do the image processing, but that's something I have to kind of walk people up to. So in, in your mind, I'm kind of curious about two things, the, where are we with multimodality as a field, both from a kind of consumer standpoint and a research standpoint, and maybe let's start with the research standpoint, because I, I'm more interested because research tends to kind of get ahead of consumers a little bit. So where are we do?\n\n\nYou think in the research field of just kind of multimodal AI in general?\n\nMhm, mhm, yeah.\nI mean, I don't have maybe the best calibration on the very cutting edge of this, but it definitely seems, it definitely makes sense if you think about just kind of like, if you're building a general intelligence, that this general intelligence should be fed from many different modes of data.\nAnd so, you know, the exciting thing with the connection of text and images, because those are the ones that are most prevalent on the web, is kind of an exciting initial connection where we've seen a lot of good progress coming in.\nBut I think there's definitely been a lot of, uh, interesting research that people have been doing with Transformers to try to continue to figure out how can we create this unified interface between, uh, you know, whatever the data modality is, you know, so an image is just, you know, like what you said, like a 16 by 16 patch of sequences, uh, and, uh, and you know, maybe the way that audio manifests itself and taste or all these other different modalities are the same thing, and you can get that all into the same, uh, model, which, which I think is exciting.\nAnd, um, I don't know, is this, does this fall into what you were talking about with the item potent generative network?\nIs that in this lot of work, or is it?\nYeah, kind of.\nI think, um, so before, again, peek behind the curtains, we talk before the recording as well.\nUm, Google released a paper early November 2023, a couple weeks ago at this point, uh, two weeks ago at this point, right?\nSo long ago.\nUh, and, and the paper was called IGN, item potency, uh, item potency generative networks.\nAnd it is, to my knowledge, and, um, you know, having read the paper and kind of walked through a little bit about what they're talking about, the idea is that maybe Transformers aren't, you know, kind of pure Vision Transformers aren't necessarily the only path forward here, right?\nI still argue Transformers are not the end of the story for NLP in general.\nThey just are the biggest delta that we've had in a very long time, but it's not the end of the story, or it very likely is not.\nComputer vision is the same, and, and even now we're talking about all these different models, not all of them are technically pure Transformers or even pure Vision Transformers.\nThere's already so much diversity, as I think actually you were talking about earlier in the architecture.\nSo when Google puts out, you know, a paper, and I kind of nerded out a little bit just because my masters is in algebraic geometry, so I'm reading words, it's like manifolds and Target, uh, Target manifolds in the, uh, in the function, you know, item potency.\nI'm like, oh, I remember all these terms from intro algebra in my master's class.\nBut like, that's kind of the point is like, well, you know, we're the research is talking at this level of mathematical rigorousness that is still trickling down.\nSo it's always fun for me in a way to see like, wow, like this, what an interesting math function all the way to, oh, right, but Stable Diffusion does it this way, and that's the most efficient right now.\nBut here's where we are.\nUm, and that gap between the research and the consumer is what I like to think about a lot, uh, and, and kind of what becomes adopted.\nSo I think that speaks to your point, though, is, well, where's the data?\nWhere's the, where's the use case, and where is the scalability?\n\nRight, yeah, Jacob, it's, it's interesting.\nI think that, son, you're touching on something really interesting, which is all this research until there was a clear, crystal clear, uh, consum use case that made people aware of potential downstream applications, people weren't really paying attention, right?\nAnd so, Jacob, I'm, I'm kind of curious, right?\nI think in many ways, multimodality, it is multi, there are multiple different applications of this.\nPeople are familiar with the Midjourney and visual prompting examples.\nIt'd be kind of interesting to walk through, given your background, Roboflow, I'm asking this for people in LLMs, what are the four main use cases for LLMs in four years, right?\nAnd that, I think, can help infrastructure startups, can help people conceptualize.\nThere's co-pilots, there's chatbots, there's transcription, you know, there's a bunch of different applications, but there are four to five really key ones.\nI think it might be interesting, given you saw what people were building with Roboflow and also seeing these different architectures, what are the four to five main applications of multimodality that you're, you've already seen and are seeing that has you really psyched about, that are kind of, uh, maybe just beyond the kind of visual, you know, create an image of, uh, you know, a dog running through a field or create my logo, um, what are other use cases that you, you're pretty psyched about?\n\nYeah, yeah, that's really interesting.\nSo, yeah, so I guess kind of, as you, as you put there, yeah, maybe with language models, we feel like we've kind of started to see the collapse of, uh, the different, different forms that that they would be utilized for.\nUm, but, but yeah, with, with multimodal vision models, maybe it's, it's not so clear.\nYeah, and the nascent applications are, yeah, the visual prompting, and so, so you can chat with the image or chat with the scene, and then the, um, the image generation, so you can actually just generate new images.\nAnd, and those two seem to be kind of like the first, uh, leaders in this.\nUm, but yeah, then crossing that with my experience at Roboflow, I think is pretty interesting.\nSo there, um, I mean, it was predominantly, uh, detection cases, so, um, the the number one use case on Roboflow Universe, which has, you know, some 400,000 models on it now, is pothole detection.\nSo, uh, everybody just wants to know if there's potholes on the street that they're driving down, and everybody wants to know that throughout the entire world.\nUm, and, and, you know, it has the Civic, uh, you know, yeah, exactly.\nSo, um, I mean, I'm sure people are still going to want to do that one.\nUm, but in terms of how multimodality plays into that, I think, um, you know, I think the the biggest promise of multimodality is to be able to connect the, you know, AI understanding layer that you have with the neural network with, with the real world.\nSo just in the way, you know, that, uh, OpenAI released GPTs with the really strong promise of being able to orchestrate all these APIs that are operating, you know, the web, is if you can reach one level lower and you're starting to operate, you know, mechanical processes in the physical world, um, that seems to be kind of like the most promising thing about, about multimodal that you could have, which is like a, a multimodal machine that you could say, just like, you know, I want you to clean my bathroom floor, and it knows what the bathroom floor is, it knows where it is, it goes over there, and it does the task.\nSo I think that's, I think there's going to be a lot of exciting merging of that through multimodal is people that are working on, uh, multimodal combinations with, with, with robotics.\nUm, so if, if there's someone out there listening on the podcast right now looking for a startup idea, I think that that, that one's pretty exciting.\n\nI completely agree.\nI don't know if you all saw the like DeepMind RT2 model, uh, it was, it was super interesting.\nUm, I was chatting with a friend over at Boston Dynamics, um, Jacob, who was also talking exactly about this, which is literally the entire field of robotics has spent so much time trying to encode semantic understanding of physical space and teach the robot the room is messy, this is what a, you know, paper cup looks like, etc., now go pick that up.\nAnd the last mile is literally been, you know, programming that hardware, um, to, to, you know, basically instructed to do specific tasks.\nUm, RT2 was quite interesting because it was DeepMind basically showing exactly that, which is if you know what a pothole is, or if you know what a, um, what messy is, and can deconstruct that from language to visual examples, you can instruct in, you know, the physical world, someone just say, someone go clean your room, and just as a human would, a robot could understand and decompose that into different tasks.\nAnd so I think even beyond just like basic option, I couldn't agree more.\nI think, um, and, and maybe you, you remember this from the conference, I think people were most excited about, um, particularly visual prompting for synthetic data use cases to actually teach, uh, different, you know, physical world examples, uh, to, to robots and and basically accelerate their learning.\nSo I actually think that subdomain is going to be, uh, going to be a huge cases.\nCouldn't, couldn't agree more.\nSo coming and now that we're on the topic of, of, you know, squarely in use cases and practicality of multimodality, and I guess it's, it's a big question, but, and we've already started to answer it, but, how, what kinds of kind of imminent use cases do you see as, as, uh, something more, more like untapped?\nLike, auction and I were talking about this the other day at, at a coffee shop.\nWe were talking about use cases for multimodality, and we kind of came to a very similar conclusion, which we can think of ideas, but is it worth starting something now, knowing that the architecture is so in flux, or is it better to think more on what are the use cases that are okay now, but will only become better, and and kind of like a race between what's the better idea and what is the actual model architectures ready for today?\nSo what kind of, uh, what, what do you think are like the biggest applications today that can be solved that maybe people are, are just starting to get into?\n\nMhm, yeah, that's interesting.\nSo I think, I guess immediately what's coming to mind, there's no, nothing like a really, really good, like, few single use cases that are really coming to mind, but I think there's, um, a lot to be done.\nSo there, there's obviously still a lot of use cases where, you know, your traditional CV methods, like detection, segmentation, classification, are going to be the best thing you can do to get high accuracy results and operate, you know, machines with the efficiency that that, uh, we, we want to.\nBut there are a lot of applications that, you know, a multimodal model might be almost there that you can just bet on, you know, in six to 12 months that those models are just going to get stronger and your, your application will end up becoming, you know, a very useful thing, um, and you can kind of ride the tides of, of the fact that these general models are just going to be getting a lot stronger.\nUm, so anything within those like couple first use cases that we talked about with visual prompting and and image gen definitely seems like, you know, a lot of exciting places to be building.\nAnd the other nice thing there, too, is, you know, all the infra getting put up around it, so you can build on top of the shoulders of giants for a lot of those applications.\nUm, it could be fun to kind of ideate on what some of those applications might be, but, um, yeah, cuz like even I, I'm like, you know, I have, uh, I have blank cameras in my, in my house because my pets can be kind of rambunctious when I'm gone, uh, and even I was like, well, Blink, I can get access to the API, I can get images from my camera, I can run that through a thing, I can tell me what the cat is doing, what the dog is doing, and it's like, and then I'm like, well, if I can do that, then I can do this, if I can do that, then I can do this.\nAnd it feels like it's almost, it's really easy, I think, to come up with all of these ideas, but then it becomes like this, you know, almost like the diversity in architectures, there's this paradox of choice, which is like, okay, but what's cool and what's interesting, what's interesting and what's profitable, what's profitable and what's, you know, not quite there yet, and you have this really multi-accessed decision-making problem of where should I be focusing my time.\nBut that kind of leads to a bigger question, which is like, the modern quote unquote ChatGPT expert, who is, who is really just someone who is, uh, really good at teaching and reading and writing and I was a prompt really well, um, they can get in and kind of make their fair share of splash in the space.\nWhat does that look like in computer vision?\nLike, what, what, what does that look like?\nWhat is the, um, cuz I think the big thing for me was always the avatars, right?\nUpload your face, like DreamBooth, all upload your face and we're going to make, you know, chibi you, we're gonna make, uh, Marvel you, we're gonna make, you know, Renaissance painting of you.\nAnd it was fun, but then I saw like 50 of them, and I'm like, okay, we get it.\nUh, what are some of those like other like fun and interesting ideas, or let me put, ask you a different way that's also leads to a different potential issue that I, which is a paper that I read out of Rice, um, it was called like Models Go Mad, and the acronym was like Model Autophagy Disorder.\nThe idea was they were looking to data poisoning as these applications keep cropping up that are making AI generated images, it kind of floods the space, the open internet, which as we all know, becomes the source material for a lot of the next generation of AI models, and they showed that if you train AI models on increasingly larger amounts of synthetic images from previous generations of models, the models tend to not get better, but actually get worse in quality over time, and it becomes this tricky issue of like, well, we have to spend more time on data processing.\nI guess how do you see that cycle of generating, I mean, the same thing for text, too, but images specifically, how do you see that kind of self-feeding, uh, self-filling prophecy and like feedback loop developing?\n\nYeah, that's interesting.\nI wasn't familiar with that paper.\nThat it, it, uh, it was a couple months ago, honestly, just came to mind, like, Yeah, because it seems like it would be like, uh, at least steady, like, it would just be regurgitating upon itself and kind of staying steady, but if it's maybe you're like losing resolution at every, every step.\nIt's always the way they describe it was the previous generations have imperfections that later generations kind of exploit and like make bigger.\nSo like the problem of image generating model giving me six fingers becomes like eight fingers down the road.\nIt's like it just kind of gets worse.\nYeah, yeah.\nI mean, maybe that's too kind of like a promising fact that we can have some consolation in and that like we, like us humans still have something to do, you know, we still need to create and generate new content that's worthwhile for, for the, the models of tomorrow to be learning from, um, which, which I do think is is an interesting fact about, you know, the hoi thing, which some people feel like we're kind of like totally out of a job, but, uh, you know, there's still a lot of interesting things for, for, for us to do.\nYou can always create content that's, it's there's solace in that.\nI think, for better or for worse, humans can always create content, whether people want us to or not, we'll be creating content.\nSo he said as his listeners turned off the podcast.\nUm, but you're, you're raising a great point, Jacob, because, you know, with the SAG, uh, strike that just ended recently, a big point of that strike with, with, you know, screen actors and and writers as well, is AI generated content.\nAnd, you know, I'm not an expert in economics, I'm not an expert in in strike philosophy, and I do know that and believe and know that AI is actively, uh, uh, replacing some jobs, but to your point, the, the fear around, oh my God, the AI is here and it's already better than humans, that's the point that I want people to kind of forget.\nIt's like, that's not the argument.\nThe bad part isn't the AI is\n\n\nBetter than humans, the part is the AI is actually not as good as humans, but companies still want to use them.\nThat's the problem, uh, and the answer isn't great.\nWell, then we'll wait for AI to get better.\nNo, the answer is what you said, I think, which is humans will always need to play a role.\nOtherwise, humans are not progressing, we are not creating anything new, we are just relying on AI systems to kind of cut, paste, put things together of stuff we've already done, which up till now is a lot, but it shouldn't be all of what we've done.\nSo there's always going to be this tricky conversation to have, and it's a lot of his economics, a lot of it's research, and a lot of it is just human nature and navigating all that.\nBut I, I like what you said very succinctly, which is what I'm saying very unusually, which is humans will always have a part to play, and, and, and for me, that's a wonderful philosophy to kind of walk away with from a lot of this conversation.\nDo you, do you think so?\nYeah, definitely, definitely good.\nWell, you heard it here first, humans will always have a part to play.\nIt's content, everyone.\nThe, uh, the, um, one thing, Son, you mentioned, which is humans will always have a part to play, is that I think we're actually in the middle of maybe the biggest upskilling that we've had, you know, in technical talent ever, which is that everyone's learning how to become a new developer with LLMs in this new, interesting world.\nAnd Jacob, something I think it's interesting is we have this whole new audience of folks that don't have a background in ML that are functionally creating new applications, and they've running into challenges, which are obvious to those that you like Sonan with a background at NLP, that, hey, this is non-deterministic, to create a data pipeline, you're going to have to structure your output.\nHey, it turns out distilling these models is quite hard, and for you to get performance out of that relative to cost, you need to do that.\nSo these distinct infrastructure challenges that have popped up that engineers are dealing with with LLMs and trying to figure out for multimodality, I'd ask you, what are people going to run into when they, when this starts, uh, becoming more mature, right?\nGiven your, your, your time at Roboflow, you've probably seen this, and you're also seeing stuff come online, maybe get abstracted away.\nWhat are the one or two surprises that people will realize they'll have to deal with, uh, obviously everyone's GPU poor, so not having enough resources, the obvious one, but what may be, uh, interesting challenges will developers have to face as they learn how to develop multi-mobile applications?\nYeah, yeah, that's awesome.\nWell, so I'm not officially still affiliated with Roboflow, but definitely feels like you just teed me up for this one.\nSo, um, one big thing about multimodal, uh, computer vision models is they're huge.\nSo, you know, like that's the same thing with the GPD models and things like that, you know, is like you, you have these huge models, they have huge general capacity, and, uh, they're very talented at many different things, but the, the problem with that is that your inference costs are ridiculous, right?\nSo you have to spend a ton of money to send all your data through the GPUs necessary to that that you're going to need to infer through these models, and that will be quite costly.\nUm, and so, yeah, like you said, it's like a lot of vision cases, you're actually inferring, uh, at a, at a rapid rate.\nSo, um, a big thing that Roboflow does is like real-time inference, so you're inferring almost like 30 frames a second, and there's no way that you're going to bring, you know, 175 billion parameter multimodal vision model down, down to the edge.\nSo a project that Roboflow has been working on is, uh, this project called Auto Distill, uh, and Auto Distill, what it does is you can infer through multimodal models and use them to label supervision data sets and then distill them down into base models like detection and segmentation and classification models, uh, that you can then deploy.\nAnd so those APIs are all very simple to use, where you do the same thing where you prompt them and you quickly get a new, smaller model off of it, which I think that's a really exciting, uh, thing that people are going to be doing with multimodal models is, uh, take them to seal them down into kind of like that basic thing that you're trying to do and then operate it more efficiently.\nUm, and in some cases, too, that you have it more accurately, too, because you've been able to supervise the data set and, uh, kind of cons take the control back a little bit.\nUm, so definitely that kind of, well, that's what people are going to be doing in a couple years, right?\nNow with LLMs, they're having the same challenges, right?\nWhich is, uh, distilling those models, supervising and getting the right data.\nIt actually kind of relates to the solving problem you're, you're now addressing and founding your new company, Jacob.\nSo could you tell us a little bit more about, uh, arcee.ai and what you all are up to?\nYeah, yeah, so arcee.ai is kind of after a little bit of a similar routine where, um, we're all about making specialized language models that are operating, uh, with inside of people's, uh, VPCs and so that their data can stay private and they're working on specific use cases with language models.\nUm, so for example, you know, certain people are using language models to, you know, do things that we used to do, like entity extraction and like, uh, or, you know, classification or things like that, or, um, different, you know, more like constrained NLP tasks.\nAnd I even do it all the time today where I'll just be like, okay, well, I want to get this thing done, what's the easiest way to do it?\nLlama 70 billion and send in a prompt and, you know, spin up a ton of GPUs and, uh, process those, those desires that I have.\nBut really, you know, if you want to operate some of these models at lower cost, then best thing to do is distill them down, focus on a domain or a task, and then kind of deploy a smaller model to do those things.\nSo that's kind of the area of, uh, of work that I'm working in now, um, which is in a lot of ways similar in spirit, uh, to the distillation of multimodal models to a CV model.\nYeah, no, it's more the same, it's the right data and getting it into a usable format that matches your use case, right?\nSo I think we're going to see more and more of that.\nSo not, I already have talked to that as a theme, so we'll link to, uh, you know, the company and your all's product and, and, and the links.\nBut Jacob, thank you so much for taking time, this was super fun, so thanks for coming on.\nWe, uh, we really, really appreciate it.\nYeah, awesome, yeah, thanks for having me on, guys, love, love doing things like this, and yeah, had a great time myself as well.\nAwesome, we see you soon.\nYep, see you guys.\n",
  "dumpedAt": "2025-07-21T18:43:25.242Z"
}