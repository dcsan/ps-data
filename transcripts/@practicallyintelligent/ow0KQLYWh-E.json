{
  "episodeId": "ow0KQLYWh-E",
  "channelSlug": "@practicallyintelligent",
  "title": "E12: Data You Can Trust: Revolutionizing Data Preparation and Curation with Curtis Northcutt",
  "publishedAt": "2024-05-06T17:20:41.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 0.71,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "hey everyone welcome to another episode",
      "offset": 7.399,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "of practically intelligent today we have",
      "offset": 9.519,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "on Curtis northcut founder and CEO of",
      "offset": 11.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "cleanlab doai uh cleanlab is an",
      "offset": 13.88,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "automated no code Tool uh to curate and",
      "offset": 16.88,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "automate your labeling",
      "offset": 21,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "operations the uh company was founded by",
      "offset": 22.68,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "three PhD Founders uh out of MIT and",
      "offset": 25.68,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "today we're talking to Curtis about the",
      "offset": 29.96,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "history of uh data Ops and and data",
      "offset": 31.84,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "quality and Core Concepts in machine",
      "offset": 35.16,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "learning related to data labeling and",
      "offset": 37.44,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "how we actually think about scaling that",
      "offset": 40.239,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "and creating",
      "offset": 43.32,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "trustworthy uh models and data yeah MIT",
      "offset": 44.84,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "I've heard of them um so they're the the",
      "offset": 49.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "interview is is is quite fun because",
      "offset": 52.16,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "yeah to your point we we we come at this",
      "offset": 53.76,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "from a lot of different angles from you",
      "offset": 55.359,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "know core traditional machine learning",
      "offset": 56.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "all the way to what's the bottom line",
      "offset": 58.68,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "how much money can you actually save",
      "offset": 60.92,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "when you put these uh processes in place",
      "offset": 63.039,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "and uh I think we actually go we go to a",
      "offset": 67.24,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "lot of different directions in in a",
      "offset": 69.479,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "relatively short amount of time so um",
      "offset": 70.799,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "I'm pretty excited to to Jump Right In",
      "offset": 73.04,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "let's do",
      "offset": 76.2,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "it awesome Curtis thank you so much for",
      "offset": 78.36,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "for coming on yeah glad to be here I",
      "offset": 81.479,
      "duration": 7.881
    },
    {
      "lang": "en",
      "text": "wanted to start by grounding us in a",
      "offset": 85.32,
      "duration": 8.36
    },
    {
      "lang": "en",
      "text": "simple but very nuanced question what to",
      "offset": 89.36,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "you at clean lab is the difference",
      "offset": 93.68,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "between reliable and unreliable",
      "offset": 95.399,
      "duration": 7.921
    },
    {
      "lang": "en",
      "text": "data it's a good one um so reliable data",
      "offset": 98.36,
      "duration": 7.88
    },
    {
      "lang": "en",
      "text": "historically meant uh you have you need",
      "offset": 103.32,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "imputation which means you have some",
      "offset": 106.24,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "structured data set like a CSV file and",
      "offset": 108.119,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "it misses values so you have some blinks",
      "offset": 111.479,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "and that was considered unreliable and",
      "offset": 114.04,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "there's a lot of companies that have",
      "offset": 116.32,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "built what's called ETL extract",
      "offset": 117.6,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "transform load or elt depending on if",
      "offset": 119.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "it's on the cloud or done before the",
      "offset": 123,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "cloud and what they're basically doing",
      "offset": 124.52,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "is making sure that doesn't happen and",
      "offset": 126.719,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "making sure that data is reliable in the",
      "offset": 128.399,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "sense that it like exists and it's the",
      "offset": 130.239,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "right type and it's going to the right",
      "offset": 132.36,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "places at clean lab when we say reliable",
      "offset": 133.879,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "we mean it like what a human means so",
      "offset": 136.56,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "for example if you have an image and",
      "offset": 138.76,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "you're in a data set of animals and that",
      "offset": 140.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "image is not an animal that is not",
      "offset": 142.48,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "reliable and we would call that an",
      "offset": 144.44,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "outlier another example of unreliable",
      "offset": 146.36,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "data is something that is an images of",
      "offset": 148.959,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "let's say um cell phones and laptops and",
      "offset": 151.519,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "it's a picture of a laptop and it's",
      "offset": 154.92,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "labeled cell phone so that would be",
      "offset": 156.84,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "unreliably labeled meaning it just has",
      "offset": 158.879,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the wrong label and there's a bunch of",
      "offset": 160.959,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "these other things are text for example",
      "offset": 162.879,
      "duration": 6.681
    },
    {
      "lang": "en",
      "text": "that has pii issues or toxic language or",
      "offset": 165.64,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "inappropriate content or the wrong",
      "offset": 169.56,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "language so these are all examples of",
      "offset": 172,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "unreliable data that semantically the",
      "offset": 173.599,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "data is there it's the right type from",
      "offset": 176.239,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "like a syntactic structure it's all the",
      "offset": 178.8,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "rules are correct but now we're talking",
      "offset": 180.8,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "about when you actually get value as a",
      "offset": 182.879,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "business or a customer from that data",
      "offset": 184.68,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "you're not going to get the value you",
      "offset": 187.68,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "want because the actual data itself is",
      "offset": 189.2,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "unreliable from a semantic",
      "offset": 191.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "standpoint so you you you're touching on",
      "offset": 193.72,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "I mean on its on its face a relatively",
      "offset": 197.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "simple idea but but something that a lot",
      "offset": 199.36,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "of people tend to overlook which that",
      "offset": 201.08,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "which is that reliability to your point",
      "offset": 202.76,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "I it's not one thing and it's it's",
      "offset": 205.239,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "barely even two or three things it's the",
      "offset": 207.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "idea that can go in and Trust something",
      "offset": 209.28,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "it's the which is always like the other",
      "offset": 211.28,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "side of reliability if something is",
      "offset": 212.92,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "reliable you trust it and a clean lab it",
      "offset": 214.68,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "sounds like the the the main Vision here",
      "offset": 218.72,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "is to make sure look at their website",
      "offset": 221.08,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "right it's it's data that you can trust",
      "offset": 223.08,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "and and there's a lot of Dimensions to",
      "offset": 225.28,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "that so C can I'm I'm curious myself",
      "offset": 228.319,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "what are some concrete examples of of",
      "offset": 231.159,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "ways that you are making data actively",
      "offset": 234.28,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "more reliable if you want to give us an",
      "offset": 237.4,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "example",
      "offset": 239.239,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "yeah for sure um a lot of folks right",
      "offset": 240.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "now are fine-tuning llms and they would",
      "offset": 242.959,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "like the outputs of those llms to",
      "offset": 245.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "produce something that doesn't yell at",
      "offset": 248.519,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "the person or cuss them out or do",
      "offset": 251.2,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "something that's inappropriate so that's",
      "offset": 253.28,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "an example of an llm being unreliable",
      "offset": 255.48,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "the way that you make an llm more",
      "offset": 258.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "reliable is when you fine-tune that LM",
      "offset": 260.519,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "when you train it you train it on",
      "offset": 263,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "examples it's called instruction based",
      "offset": 265.88,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "tuning where you're basically find",
      "offset": 268.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "finetuning a model with both the",
      "offset": 269.68,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "examples of both the original prompt and",
      "offset": 272.68,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "then what you expect the response to be",
      "offset": 275.199,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "so what we would do is we'd run clean",
      "offset": 277.36,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "laab through all the responses of the",
      "offset": 278.919,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "fine-tuning data set and filter out all",
      "offset": 280.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the stuff that would be problematic like",
      "offset": 283.12,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "bad language pii email addresses URLs",
      "offset": 285.16,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "credit card numbers uh you know informal",
      "offset": 288.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "language uh inappropriate remarks and",
      "offset": 291.759,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "then when you now fine-tune your model",
      "offset": 294.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it knows not to do those things and so",
      "offset": 296.639,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "that's an example of how you can now",
      "offset": 299.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "have a model that produces more reliable",
      "offset": 301,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "output where reliable in this case just",
      "offset": 302.88,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "means it talks the way that you would",
      "offset": 305.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "like it to",
      "offset": 307.32,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "talk and something that you're implying",
      "offset": 308.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "there which I want to make extremely",
      "offset": 310.68,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "explicit for everybody which is reliable",
      "offset": 312.32,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "data I is not the end goal it's kind of",
      "offset": 315.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the starting point for Reliable models",
      "offset": 318.199,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "and reliable AI ecosystems right in in a",
      "offset": 321.36,
      "duration": 7.399
    },
    {
      "lang": "en",
      "text": "lot of ways having data you can trust by",
      "offset": 325.24,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "itself is often useless the whole point",
      "offset": 328.759,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "of that data was to be powering",
      "offset": 332,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "something bigger than the data than the",
      "offset": 334.24,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "the rows and columns itself and you know",
      "offset": 336.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "most of the time these days those are",
      "offset": 339.319,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "llms those are multimodal models so what",
      "offset": 341.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you're doing at clean laab is not just",
      "offset": 344.6,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "creating data you can trust but that's",
      "offset": 346.28,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "the foundation for models and therefore",
      "offset": 348.199,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "features based on those models are are",
      "offset": 351.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "going to be uh reliable themselves and I",
      "offset": 354.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "mean I think you kind of for me what",
      "offset": 357.28,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "really Rings true is a recent story",
      "offset": 359.88,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "about airic Canada chatbot right when",
      "offset": 361.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "when a when airic Canada chatbot",
      "offset": 363.68,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "promises a refund policy I believe it",
      "offset": 366.12,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "was like a refund policy that doesn't",
      "offset": 368.28,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "actually exist that model that to that",
      "offset": 370.56,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "person is unreliable and it's it's",
      "offset": 373.639,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "building that ecosystem so now it the",
      "offset": 376.919,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "idea Curtis that you've been working on",
      "offset": 380.36,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "this as as an entrepreneur uh is is you",
      "offset": 382.08,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "know pretty well known but before clean",
      "offset": 385.8,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "lab Ean the idea of reliability and and",
      "offset": 388.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "confidence was something that you",
      "offset": 391.28,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "focused on a lot um when you were",
      "offset": 392.639,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "getting your PhD at MIT can can you tell",
      "offset": 394.52,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "us a little bit about the inspiration",
      "offset": 396.96,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "like what what kind of drove you to this",
      "offset": 398.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "field to this industry like what's",
      "offset": 401.199,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "what's the story there 100% it was",
      "offset": 403.199,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "trying to change the world um",
      "offset": 406.8,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "fundamentally I wanted to democratize",
      "offset": 409.44,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "education um I think I would be remiss",
      "offset": 412.36,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "and I think the people listening to this",
      "offset": 415.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "would also want to know everything that",
      "offset": 417.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we're going to talk about is",
      "offset": 419.24,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "automated uh and that's very different",
      "offset": 421.28,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "you when you a lot of companies are like",
      "offset": 423.36,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "data you can trust and then they send",
      "offset": 424.919,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "your data off to the Philippines and",
      "offset": 426.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "then 50 people review it and then they",
      "offset": 429.16,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "send it back um that is not what we're",
      "offset": 431.039,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "talking about here so everything that",
      "offset": 433.52,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "we're going to talk about everything",
      "offset": 435.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "we've already talked about is systematic",
      "offset": 436.319,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "algorithmic with reliability quality",
      "offset": 439.4,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "scores added to every data point in a",
      "offset": 441.96,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "way that you can verify and actually",
      "offset": 444.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "show that Above This threshold here's",
      "offset": 446.479,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you know the probably approximately",
      "offset": 448.8,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "correct bounds that this is actually",
      "offset": 450.879,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "reliable data and below this threshold",
      "offset": 452.199,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you know you need to do whatever okay so",
      "offset": 454.56,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "with that in mind uh I got to MIT in",
      "offset": 456.599,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "2013 did my PhD there I worked with",
      "offset": 459.16,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "Isaac Chang um who's commonly known as",
      "offset": 462.479,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "the first person to ever build a working",
      "offset": 466.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "quantum computer so sometimes called the",
      "offset": 468.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "inventor of the quantum computer and",
      "offset": 471.56,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "what he really cared about was how do",
      "offset": 473.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "you take data signals from a quantum",
      "offset": 476.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "computer and be able to reliably",
      "offset": 478.919,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "understand what that quantum computer is",
      "offset": 482.28,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "doing and when you have atoms that are",
      "offset": 483.879,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "in different states how do you take",
      "offset": 486.479,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "measurements and velocities and particle",
      "offset": 488.4,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "speeds and how do you measure that in a",
      "offset": 490.8,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "way that's reliable at this time you",
      "offset": 492.879,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "know 1998 it was a two-bit quantum",
      "offset": 495.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "computer and they're constantly",
      "offset": 497.12,
      "duration": 2.519
    },
    {
      "lang": "en",
      "text": "increasing them but that's that was",
      "offset": 498.44,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "literally the task and the way that this",
      "offset": 499.639,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "was done is a combination of of",
      "offset": 502.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "tremendous engineering work but also",
      "offset": 504.759,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "systematic Theory that's provable and",
      "offset": 507.36,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "guaranteed um called Quantum information",
      "offset": 510.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Theory and I worked with Ike for eight",
      "offset": 512.599,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "years at MIT and what we developed was a",
      "offset": 515.64,
      "duration": 6.839
    },
    {
      "lang": "en",
      "text": "way that you could take that same Theory",
      "offset": 519.839,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "and apply it to arbitrary data because",
      "offset": 522.479,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "if you think about it a quantum computer",
      "offset": 525.399,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "is arbitrary information it's just a",
      "offset": 526.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "computer it doesn't care if the data is",
      "offset": 528.64,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "images it doesn't care if the data is",
      "offset": 530.839,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "audio or text and so that's one of our",
      "offset": 532.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "unique differentiations is we were able",
      "offset": 535.68,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "to invent an algorithm that is",
      "offset": 537.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "framework a framework of algorithms",
      "offset": 539.959,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "called confident learning that allows",
      "offset": 542.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "you to reliably and systematically and",
      "offset": 544.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "approvable way find errors and data",
      "offset": 546.839,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "automatically and fix them for any type",
      "offset": 549.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of data which is very unique you know",
      "offset": 551.92,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "you have self-driving car companies you",
      "offset": 554.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "fix image data you've got llm companies",
      "offset": 556.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "it's Text data but with clean laab it's",
      "offset": 558.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "it's any type of data and so the problem",
      "offset": 560.36,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "that I first wanted to solve was",
      "offset": 563.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "democratization of Education because I",
      "offset": 565.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "was working as the first research",
      "offset": 568,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "scientist at mitx which is a subset of",
      "offset": 569.519,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "edex a competitor of corsera if you've",
      "offset": 572.36,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "ever taken online courses like Andrew",
      "offset": 575.079,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "in's deep learning course and we needed",
      "offset": 576.959,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "to detect who was cheating or not so we",
      "offset": 579.36,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "could validate certificates so you've",
      "offset": 581.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "got all this Education data and you're",
      "offset": 583.399,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "trying to predict if someone's cheatah",
      "offset": 585,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "or not which is a label and it turned",
      "offset": 586.72,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "out that machine learning failed and so",
      "offset": 588.92,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "I talked to the smartest people I could",
      "offset": 591.32,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "find at MIT and people who had done",
      "offset": 592.88,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "machine learning for 20 30 years F like",
      "offset": 594.88,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "forefathers of the field I talked with",
      "offset": 597.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "Tommy akla who's uh you know one of the",
      "offset": 599.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "first inventors of some of the",
      "offset": 602,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "problemistic graphical model work and",
      "offset": 603.8,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "pushed svms and really ogs in the field",
      "offset": 605.88,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "and at that point it's now 2013 2014",
      "offset": 609.64,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "Machine learning did just did not work",
      "offset": 613.399,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "there was no actual reliable",
      "offset": 615.12,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "multiclassification algorithm that could",
      "offset": 616.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "actually train un erroneous data and so",
      "offset": 619.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "I spent the next like four to eight",
      "offset": 621.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "years developing the theory and",
      "offset": 624.279,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "algorithms that eventually turned into",
      "offset": 625.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "clean lab and now of course we've been",
      "offset": 627.56,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "building a business on it for you know",
      "offset": 629.64,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "about half a",
      "offset": 631.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "decade it's interesting Curtis because",
      "offset": 633.2,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "you started working on this uh and",
      "offset": 635.519,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "innovating um you know um before the",
      "offset": 637.8,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "Transformer era and during a time where",
      "offset": 641,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "um really this an anti idea of data",
      "offset": 644.839,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "curation was about throwing headcount",
      "offset": 648,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "and and essentially all about labels one",
      "offset": 651.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "thing I'm curious about is that's that's",
      "offset": 653.959,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "changing now right and companies",
      "offset": 656.44,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "organizations are making they get this",
      "offset": 658.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "concept even you know outside of the ml",
      "offset": 660.72,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "or of data being the new oil of creating",
      "offset": 662.68,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "a knowledge base that's proprietary of",
      "offset": 664.6,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "imbuing that into your Workforce",
      "offset": 667.279,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "enabling automation talk to us a little",
      "offset": 668.639,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "bit about how data curation and scalable",
      "offset": 671.32,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "data Creation in uh companies has",
      "offset": 676,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "changed over the last couple years I",
      "offset": 678.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "know you talked about automation but",
      "offset": 680.56,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "give us a little history lesson on you",
      "offset": 683,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "know scale came into this space you were",
      "offset": 685.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "innovating seeing what was happening",
      "offset": 687.839,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "there uh talks a little about the",
      "offset": 690.04,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "changes of the space and the context and",
      "offset": 691.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "eyes from one of your one of potentially",
      "offset": 693.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "your customers 100% so I'll first talk",
      "offset": 695.56,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "about how things have changed and then I",
      "offset": 698.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "can focus on a customer use case um I",
      "offset": 700.079,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "have a slide that I usually show for",
      "offset": 703.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "this um but I know that doesn't work for",
      "offset": 705.079,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "this this format um but it basically",
      "offset": 708.04,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "shows 2013 to 2016 how do we do data",
      "offset": 711,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "curation at Enterprises well um and it's",
      "offset": 714.399,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "worth noting I I did some kind of",
      "offset": 717.6,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "research contingent position or research",
      "offset": 719.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "scientist position or internship at",
      "offset": 721.8,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "Amazon uh NASA General Electric",
      "offset": 724.24,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "Microsoft Google and meta and Oculus",
      "offset": 727.959,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "research um and so I've done the Gambit",
      "offset": 731.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "I've seen a lot of these places and how",
      "offset": 733.8,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "they work and most of what I'll share is",
      "offset": 735.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "rhetoric from firsthand experience um",
      "offset": 737.279,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "and what what typically was done in data",
      "offset": 740.16,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "science teams and machine learning teams",
      "offset": 742.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "is a bunch of ad hoc Jupiter notebooks",
      "offset": 745.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "where you would basically write a bunch",
      "offset": 747.48,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "of rules to label things internally",
      "offset": 749.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "share it around get a bunch of people to",
      "offset": 751.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "do it then eventually people realize",
      "offset": 752.76,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "wait we're paying you know whatever",
      "offset": 754.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "salaries from 150 up to 400 something K",
      "offset": 756.639,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "in order to have research scientists",
      "offset": 760.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "label data maybe we can do this more",
      "offset": 762.16,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "efficiently and so that was like 100x",
      "offset": 764.399,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "cost and time and so 2016 uh Alex Wang",
      "offset": 767.079,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "has a great idea and uh you know to say",
      "offset": 771,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "hey look let's just have sort of a human",
      "offset": 774.44,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "labor force that's affordable and over",
      "offset": 776.72,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "be able to sort of ship data for AI and",
      "offset": 779.68,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "they can label it for you um but they're",
      "offset": 782.279,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "not experts and so if you're a",
      "offset": 784.399,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "self-driving car company and you have an",
      "offset": 785.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "image of a road and you know you don't",
      "offset": 787.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "even live in America it's difficult to",
      "offset": 789.279,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "know is that exactly a stoplight or a",
      "offset": 791,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "road and so and the way you deal with",
      "offset": 793.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that is you get 50 non-experts to all",
      "offset": 795.72,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "label something and come to consensus um",
      "offset": 797.88,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "and so there's a few issues with that",
      "offset": 800.639,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "but it's a good approach and it's and",
      "offset": 802.079,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "that's done very well right it provided",
      "offset": 803.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "real value um and it's a good approach",
      "offset": 805.56,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "the downside are you've got to pay a lot",
      "offset": 808.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "of people you have to distribute it out",
      "offset": 810.199,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "you have to send the data out to third",
      "offset": 812.839,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "parties um so it creates Data Trust on",
      "offset": 814.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "sort of the consensus do these 50 people",
      "offset": 817.399,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "actually agree on the light right label",
      "offset": 820.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "is it high quality can we trust it and",
      "offset": 822.32,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "also is there any way to do this without",
      "offset": 824.48,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "shipping the data out and also can we do",
      "offset": 825.88,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "it without paying 50 people to do it so",
      "offset": 828.279,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "what came after that was this concept of",
      "offset": 830.959,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "labeling functions and we saw that with",
      "offset": 832.92,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "companies like snorkel um and they had a",
      "offset": 835.079,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "really good idea which was like let's",
      "offset": 837.519,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "look at text didn't work so well for",
      "offset": 839.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "images but let's look at text and say",
      "offset": 841.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "look if we can write some function in",
      "offset": 843.44,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "Python if I can get an engineer I",
      "offset": 845.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "software developer to sit down and say I",
      "offset": 847.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "can map all of my data into labels just",
      "offset": 849.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "by writing software functions and we'll",
      "offset": 852.6,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "build software around that that then",
      "offset": 854.24,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "finds a a decorrelation among all those",
      "offset": 856.72,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "labels in order to say this is sort of",
      "offset": 859.759,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the best label for that data point based",
      "offset": 861.639,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "on all the rules you wrote um and that",
      "offset": 863.279,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "saves some time and cost that cut down",
      "offset": 865.36,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "on it increased the automation",
      "offset": 867.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the downside of that is what it produced",
      "offset": 869.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "is something that snorkel and companies",
      "offset": 871.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "like that themselves call weak labels so",
      "offset": 873.48,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "basically noisy guesses of labels but",
      "offset": 876.12,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "not high accurate high quality labels",
      "offset": 878.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "another downside is it required",
      "offset": 880.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Engineers to actually write the code to",
      "offset": 882.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "produce those and another downside is",
      "offset": 883.92,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "that it only worked for things where you",
      "offset": 886.199,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "could actually systematically label them",
      "offset": 887.759,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "uh like for example text where you can",
      "offset": 890.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "say an example would be um you know I",
      "offset": 892.24,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "want my wife to grab uh to make food for",
      "offset": 895.44,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "me or something and then it would say",
      "offset": 898.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "that the speaker is most likely uh a man",
      "offset": 900.519,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "or something or husband and of course",
      "offset": 903.72,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "that's a you know that can be wrong um",
      "offset": 906,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "you know but it basically you're just",
      "offset": 908.48,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "doing your best and you can see how that",
      "offset": 910.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "label could be wrong but it's still a",
      "offset": 912.12,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "labeling function and so that's an",
      "offset": 914.12,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "example so we got there and that was a",
      "offset": 916.32,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "way you could automate some some of the",
      "offset": 918.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "tasks and then where we are today is",
      "offset": 920.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "what we're doing is domain specific AI",
      "offset": 922.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "training that looks at these data sets",
      "offset": 925.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and is actually producing a label for",
      "offset": 927.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "you based on a small subset of labels",
      "offset": 930.12,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "but then going Way Beyond labeling so",
      "offset": 933.44,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "what I focused on was just labeling but",
      "offset": 935.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "actually most of the error is not just",
      "offset": 938.6,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "in the label it's in the data itself and",
      "offset": 940.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "so we extended that Beyond automated",
      "offset": 942.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "labeling and automated detection of",
      "offset": 944.72,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "Errors to outliers ambiguous data which",
      "offset": 946.639,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "means it confuses models uh pii issues",
      "offset": 949.8,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "ETC so I talked for a while I'd love to",
      "offset": 952.959,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "share a use case of this when if you",
      "offset": 955.36,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "guys want yeah before we get into a use",
      "offset": 957.48,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "case I I I I I do have one followup to",
      "offset": 960.36,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "that because the you're you're right I",
      "offset": 963.519,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "think there that the idea",
      "offset": 965.199,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of almost subjectiveness and kind of",
      "offset": 967.319,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "ambiguity and vagueness I I'll come back",
      "offset": 970.079,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "to your example of like I want you know",
      "offset": 972,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this person to make to make food for me",
      "offset": 973.6,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "well context is now going to be the",
      "offset": 976.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "greatest input here that you may totally",
      "offset": 978.639,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "be missing in in that in that text",
      "offset": 980.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "sample so in in in your philosophy or in",
      "offset": 982.959,
      "duration": 6.761
    },
    {
      "lang": "en",
      "text": "clean lab's philosophy is is clean lab",
      "offset": 986.079,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "an alternative to things like Gathering",
      "offset": 989.72,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "consensus or do you prefer that to",
      "offset": 991.88,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "almost work in in parallel or in in a",
      "offset": 994.079,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "pipeline where where clean lab maybe is",
      "offset": 996.759,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "is showing something as ambiguous and",
      "offset": 999.68,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "vague perhaps that's more of a short",
      "offset": 1001.92,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "list now for the actual domain experts",
      "offset": 1003.88,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "to take a look at it and and readjust it",
      "offset": 1007.279,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "to some process what's the philosophy",
      "offset": 1010.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "there between combining some of those",
      "offset": 1012.48,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "paradigms yeah any customer of any of",
      "offset": 1015.079,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "products you know that we've already",
      "offset": 1019,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "talked about any labeling product is a",
      "offset": 1020.24,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "great customer for clean lab because",
      "offset": 1022.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "what they can do is reduce the number of",
      "offset": 1024.439,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "annotators they need and then put",
      "offset": 1026.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "lowquality data into clean lab and",
      "offset": 1028.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "automate a lot of the time and cost and",
      "offset": 1031,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "so you can see it as a next step or you",
      "offset": 1033.72,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "can just feed the direct the data",
      "offset": 1036.199,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "directly into clean lab and then do a",
      "offset": 1037.76,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "few initial labels yourself and then let",
      "offset": 1041,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "our system iteratively get you there",
      "offset": 1042.959,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "either there Works uh but I think of it",
      "offset": 1045,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "more as any customer of a labeling",
      "offset": 1047.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "company is definitely a customer of",
      "offset": 1050.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "clean lab but not vice versa a lot of",
      "offset": 1051.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "our users they want to do they just want",
      "offset": 1053.76,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "to actually get the business value not",
      "offset": 1056.16,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "just label data makes sense all right",
      "offset": 1058.52,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "let's hear let's hear a use case you",
      "offset": 1060.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "know we are practically intelligent so",
      "offset": 1062.48,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "we want to make sure everyone has a",
      "offset": 1064.76,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "really clear use case so tell us how you",
      "offset": 1066.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "are you are actively helping uh or in",
      "offset": 1068.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "this use case yeah one thing that you",
      "offset": 1071.16,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "could search online today uh it's a Blog",
      "offset": 1073.44,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "I think called money talks and um it's",
      "offset": 1076.24,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "for a big Bank you've probably heard of",
      "offset": 1079.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "them PNC in America globally they're",
      "offset": 1080.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "called BBVA um they're one of the",
      "offset": 1083.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "largest financial institutions in the",
      "offset": 1085.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "world um and they posted on their",
      "offset": 1087.6,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "website uh not on ours um just to show",
      "offset": 1090.2,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "like where the source is coming from",
      "offset": 1093.52,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "that they were able to reduce the total",
      "offset": 1095.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "amount of spend and time uh in terms of",
      "offset": 1097.72,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "getting a financial predictive data set",
      "offset": 1100.799,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "to predict accurately uh what a",
      "offset": 1103.36,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "financial outcome would be like should",
      "offset": 1106.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you buy something or not uh is this a",
      "offset": 1107.64,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "good loan or not investment or not um",
      "offset": 1109.72,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "based on financial data and tex document",
      "offset": 1111.84,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "data they were able to reduce the total",
      "offset": 1113.919,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "number of uh time and cost by",
      "offset": 1115.96,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "98% uh that is an extreme example uh you",
      "offset": 1119.08,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "know the amount of principle of a big",
      "offset": 1123.08,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Bank like that is going to be pretty",
      "offset": 1124.559,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "high typically in the millions and so",
      "offset": 1126.2,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "reducing costs by 98% is a factor that I",
      "offset": 1128.6,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "would not promise your average person uh",
      "offset": 1132.44,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "but we are seeing time and cost",
      "offset": 1135.28,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "improvements between 70 and 80 % on",
      "offset": 1136.72,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "average 98% is uh you know of course I'm",
      "offset": 1139.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "sharing that because it's an exceptional",
      "offset": 1143.039,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "example by a massive organization um and",
      "offset": 1144.52,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "in addition to that and I think this is",
      "offset": 1148.039,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "the real kicker is after using clean",
      "offset": 1149.52,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "laab they also saw model Improvement by",
      "offset": 1152.559,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "over 20% so the accuracy on a heldout",
      "offset": 1155.159,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "test set for a financial task was",
      "offset": 1158.159,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "increased by 20% even though they spent",
      "offset": 1160.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "98%",
      "offset": 1163.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "less yeah and we'll we'll put a link to",
      "offset": 1165.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "it in the description of course and and",
      "offset": 1167.44,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "I if you when you listener uh actually",
      "offset": 1168.96,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "take a look at that post you you're",
      "offset": 1173.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "going to see basically what almost looks",
      "offset": 1175.6,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "like a like a duh moment like well of",
      "offset": 1177.4,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "course they had to build a training set",
      "offset": 1181,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and evaluation set train the model",
      "offset": 1183.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "there's a nice little graphic there of",
      "offset": 1185.48,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "you know not annotation and and and and",
      "offset": 1187.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "notifying things which is basically",
      "offset": 1190.559,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "proposing samples to be labeled that",
      "offset": 1192.12,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "that cycle that you see on on that uh",
      "offset": 1194.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "post is basically the cycle you'll see",
      "offset": 1197.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "on any machine learning or mlops course",
      "offset": 1200.28,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "right the idea of train the model you",
      "offset": 1202.88,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "have a data set you have to improve the",
      "offset": 1204.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "data set you train it again and you test",
      "offset": 1206.52,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "it so in in a lot of ways when I think",
      "offset": 1208.52,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "of a company like like clean laab I",
      "offset": 1210.799,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "think of well this has been this has",
      "offset": 1212.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "been what we were trying to do this",
      "offset": 1215,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "whole time and and it's only just now",
      "offset": 1216.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "frankly that with the Advent of",
      "offset": 1218.799,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "Transformer Technologies and much faster",
      "offset": 1221.28,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "processing and and cheaper compute that",
      "offset": 1223.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "we can",
      "offset": 1226.159,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "actually fulfill This Promise for a a",
      "offset": 1227.159,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "larger subset of people who have this",
      "offset": 1230.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "problem but never really had the",
      "offset": 1233.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "resources to solve it whether it was you",
      "offset": 1235.32,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "know someone who worked at the company",
      "offset": 1237.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "telling them they had to do it or you",
      "offset": 1239.12,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "know some kind of advisor kind of",
      "offset": 1241.28,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "intervening in the process so uh I I",
      "offset": 1243.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "think it's going to be almost like a a",
      "offset": 1246.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "shock to the system to see like how easy",
      "offset": 1248.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "um clean lab can can really make this",
      "offset": 1250.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and uh so I I I really love that use",
      "offset": 1253.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "case and you're right it's dramatic",
      "offset": 1254.88,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "because you know it's it's a really",
      "offset": 1256.44,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "great example but it also shows the",
      "offset": 1257.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "boundaries in which that you can help",
      "offset": 1260.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the upper boundaries of maybe not even",
      "offset": 1261.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "upper boundary to even go even higher",
      "offset": 1263.84,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "but it can be as dramatic as 97",
      "offset": 1265.64,
      "duration": 8.48
    },
    {
      "lang": "en",
      "text": "98% um change it can be that much",
      "offset": 1269.84,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "depending on who you are what you're",
      "offset": 1274.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "spending already and and what processes",
      "offset": 1275.76,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "you have in place so I I see that yes as",
      "offset": 1278.44,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "an extreme example but I I also see it",
      "offset": 1281.4,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "as a this could be you kind of example",
      "offset": 1283.6,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "whether you're as huge as a bank or as",
      "offset": 1286.279,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "small as a startup going through YC and",
      "offset": 1288.12,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "and and to that end let me ask you how",
      "offset": 1291.32,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "how does clean Labs work when you aren't",
      "offset": 1293.559,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "a giant Bank when you are a relatively",
      "offset": 1296.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "smaller company like what how does that",
      "offset": 1298.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "work that's a really great question so",
      "offset": 1300.48,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "another one of our our Enterprise",
      "offset": 1303.159,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "customers is Berkeley research group um",
      "offset": 1305,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "which if you haven't heard of them they",
      "offset": 1307.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "might sound like they're you know out of",
      "offset": 1309.4,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "Berkeley the university but this is",
      "offset": 1311.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "actually a pretty big company there 1100",
      "offset": 1312.88,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "employees um we classify them as one of",
      "offset": 1315.6,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "the larger on the SMB sale or on the",
      "offset": 1318.6,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "smaller on Enterprise scale they're",
      "offset": 1321.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "basically a uh Technical and digital",
      "offset": 1322.96,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "consulting firm what they do is work",
      "offset": 1326.12,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "with big legal clients um uh economic",
      "offset": 1328.2,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "cases all sorts of use cases like that",
      "offset": 1332.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "and they help them with ML and data",
      "offset": 1335.12,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "tasks so I'll give you an example say",
      "offset": 1337.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I'm a high-profile person I'm have I",
      "offset": 1339.24,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "have a big lawsuit coming up and this",
      "offset": 1341.159,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "lawsuit the case proceedings are going",
      "offset": 1343.52,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "to be made public for whatever legal",
      "offset": 1345.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "reason so some of my privileged and",
      "offset": 1347.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "private confidential documents will be",
      "offset": 1350.2,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "made public as part of the court case",
      "offset": 1351.88,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "for example Elon musk's tweets or uh",
      "offset": 1353.6,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "internal IP from a company when that",
      "offset": 1357.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "type of stuff happens these court cases",
      "offset": 1360.2,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "in terms of the diligence required to",
      "offset": 1362.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "look through those documents and make",
      "offset": 1364.48,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "sure that nothing that doesn't have to",
      "offset": 1366,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "be made confidential for the public is",
      "offset": 1368.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "not made confidential can be around a",
      "offset": 1370.4,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "million or more per day and we were able",
      "offset": 1372.76,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "to save this company Berkeley research",
      "offset": 1375.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "group and in terms of a legal case that",
      "offset": 1378.039,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "they were supporting one of their",
      "offset": 1379.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "clients on about 30 days off of the",
      "offset": 1380.919,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "Court proceedings so the amount of time",
      "offset": 1384.039,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "taken for them to an analyze the",
      "offset": 1386.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "documents and get the the lawsuit going",
      "offset": 1387.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "uh that we save them about a month and",
      "offset": 1390.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "so I'll let you do the math is can I",
      "offset": 1392.64,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "contribute you know every single aspect",
      "offset": 1394.88,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "of that month to us no they were using",
      "offset": 1396.919,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "our results and working quickly on their",
      "offset": 1399.4,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "side as well so somewhere savings",
      "offset": 1401.559,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "between you know 1 and 30 million",
      "offset": 1404.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "something like that and in addition to",
      "offset": 1406,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "that they were able to improve the model",
      "offset": 1408.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the accuracy of the model that was doing",
      "offset": 1410.559,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "privileged document detection and",
      "offset": 1412.24,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "confidential document detection um by",
      "offset": 1413.88,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "15% accuracy even though they're also",
      "offset": 1416.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "shaving off the time the reason I",
      "offset": 1419.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "brought that up is because the number of",
      "offset": 1421.159,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "documents was not that big so this",
      "offset": 1422.96,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "wasn't a massive company like a big bank",
      "offset": 1425.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "or a massive Fang Institute doing",
      "offset": 1427.32,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "hundreds of millions of data points",
      "offset": 1428.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "which we support by the way and that's",
      "offset": 1430.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "our bread and butter but they they're",
      "offset": 1432.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "actually more a boutique right where",
      "offset": 1434,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "their each document is complex and",
      "offset": 1435.919,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "complicated and we're supporting their",
      "offset": 1437.679,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "Ed cases that was on the thousands of",
      "offset": 1439.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "documents and they're not even complex",
      "offset": 1441.64,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "but they're also um you kind of hinted",
      "offset": 1444.2,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "at this they're very domain specific",
      "offset": 1446.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "right and that kind of comes back to the",
      "offset": 1448.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "idea the promise almost that you made",
      "offset": 1450.48,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "earlier of of of handling any data right",
      "offset": 1452.32,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "not just text not just images and not",
      "offset": 1455.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "even just text but text in the legal",
      "offset": 1458.039,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "field text in the financial field text",
      "offset": 1460.52,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "in the healthc care field what is your",
      "offset": 1462.4,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "personal or company vision",
      "offset": 1466.48,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "on on on on how to kind of create this",
      "offset": 1469.039,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "almost standard or maybe that's not even",
      "offset": 1472.36,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "the goal uh like how do you think about",
      "offset": 1474.559,
      "duration": 6.761
    },
    {
      "lang": "en",
      "text": "a system that can handle quote any kind",
      "offset": 1477.679,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "of data you know what are the main",
      "offset": 1481.32,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "difficulties and and what are the main",
      "offset": 1483.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "kind of uh through lines that go through",
      "offset": 1485.2,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "these these these different modes of",
      "offset": 1487.76,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "data yeah a lot of it was was technical",
      "offset": 1489.48,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "sin on um we did that work for like a",
      "offset": 1492.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "decade prior to the company so a lot of",
      "offset": 1495.52,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "that so all three of the founders were",
      "offset": 1497.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "did their phds in computer science at",
      "offset": 1500.039,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "MIT and I sometimes I'm nervous to share",
      "offset": 1501.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "that because while there's obviously",
      "offset": 1505.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "some validation that we've spent time",
      "offset": 1506.84,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "thinking about this uh and we might be",
      "offset": 1508.48,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "the right people to have built it",
      "offset": 1510.64,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "sometimes you hear that and you think",
      "offset": 1513.039,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "wow this is probably an academic thing",
      "offset": 1514.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and it's like no we're we're business",
      "offset": 1516.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "people like we're we are here to support",
      "offset": 1518.039,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "real value for Enterprise companies at",
      "offset": 1520.919,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "scale and we focused exclusively on that",
      "offset": 1523.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "task for several years um that that",
      "offset": 1525.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "being said a lot of the work really was",
      "offset": 1528.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "technical in the past and so what we",
      "offset": 1530.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "built was a way that you can not only",
      "offset": 1532.72,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "train any model and any type of data",
      "offset": 1534.96,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "which is commonly known as automl where",
      "offset": 1536.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "you basically just give it a data set",
      "offset": 1539.48,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "and then train any model but also how",
      "offset": 1541.24,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "can you find errors in any data set",
      "offset": 1543.279,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "regardless of the type um which is a",
      "offset": 1545.12,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "framework that I did my PhD on called",
      "offset": 1547.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "confident learning which we have now",
      "offset": 1549.88,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "extended into the full sort of Suite of",
      "offset": 1551.559,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "data Centric AI two bullet notes to make",
      "offset": 1554.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "on that is that we taught the First Data",
      "offset": 1557.279,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "Centric AI course it's it was at MIT and",
      "offset": 1559.84,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "you can find that um I'll put a link",
      "offset": 1563.159,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "I'll share a link so that you can share",
      "offset": 1565.32,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "it with listener yes please it's just DC",
      "offset": 1566.72,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "cal. mit.edu um and so that's one thing",
      "offset": 1570.48,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "is that we we've really spent a long",
      "offset": 1574.72,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "time finding a way that you can",
      "offset": 1576.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "generalize this to any data set prior to",
      "offset": 1577.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the company so this is a a m you know",
      "offset": 1579.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "over a decade Pursuit uh the second",
      "offset": 1582.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "thing is that as I mentioned the key and",
      "offset": 1584.679,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "core to making this technology work is",
      "offset": 1587.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "having the best automl in the world and",
      "offset": 1589.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "it's a lot of times you hear a small",
      "offset": 1592.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "company you know we're like between 30",
      "offset": 1594.84,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "and 40 people how can I say that we have",
      "offset": 1596.88,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "the best automl in the world like you",
      "offset": 1599.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "should doubt that and I would expect you",
      "offset": 1601.32,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "to doubt that and to which I would reply",
      "offset": 1603.679,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that the person who built Amazon's",
      "offset": 1606.399,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "automl it's which is called autog glue",
      "offset": 1609.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "on it's open source and so you can look",
      "offset": 1611.2,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "up who committed the most G GitHub",
      "offset": 1612.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "commits was yonas Mueller and he's our",
      "offset": 1615.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "chief science scientist and co-founder",
      "offset": 1617.679,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "at clean lab there you",
      "offset": 1619.24,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "go Curtis I wanted to we talked a",
      "offset": 1623.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "littleit about the history of uh data",
      "offset": 1625.919,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "curation and labeling fast forward to",
      "offset": 1628.72,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "2027 2028 you know a couple years from",
      "offset": 1631.32,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "now any predictions on things we're",
      "offset": 1633.64,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "going to be talking about then more in",
      "offset": 1635.279,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "this space whether it's you know example",
      "offset": 1636.88,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "synthetic data um you know training data",
      "offset": 1638.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "scarcity becoming more of a thing just",
      "offset": 1641.64,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "general topics that you're paying",
      "offset": 1643.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "attention to as a as a Forefront and",
      "offset": 1645.6,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "leader in this space um that your",
      "offset": 1647.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "customers are paying attention to that",
      "offset": 1649.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "you think we're going to hear more",
      "offset": 1650.48,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "about the future question is always good",
      "offset": 1652.679,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "right predict the future and then you",
      "offset": 1655.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "know 10 years we can play this and see",
      "offset": 1657.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "how wrong I was yeah but no quote this",
      "offset": 1658.919,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "if you're listening don't quote this",
      "offset": 1660.799,
      "duration": 6.041
    },
    {
      "lang": "en",
      "text": "yeah uh I would you know we can quote it",
      "offset": 1663.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "I'll do my best I would hope you don't",
      "offset": 1666.84,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "but but it's fine you know it's it's out",
      "offset": 1668.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "there so um I think there's going to be",
      "offset": 1670.159,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "a lot more multimodal work I think we're",
      "offset": 1672.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "going to see images being uh described",
      "offset": 1675.08,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "by text and text being described uh with",
      "offset": 1678.64,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "uh or being sort of supported with",
      "offset": 1683,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "images I think we're going to see more",
      "offset": 1684.6,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "tabular data combined with text Data a",
      "offset": 1686.159,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "lot more M multimodal so instead of it",
      "offset": 1688.72,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "being about sort of this like computer",
      "offset": 1691.32,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "vision where we just look at things I",
      "offset": 1693.64,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "think it'll be computer Vision Plus",
      "offset": 1695.76,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "statistical data and tabular data about",
      "offset": 1697.399,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "those routes and other statistics for",
      "offset": 1699.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "self-driving Mobility I think that we'll",
      "offset": 1702.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "see in the healthcare industry it won't",
      "offset": 1704.44,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "be just a prediction based on a medical",
      "offset": 1706.44,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "health record and text but also all the",
      "offset": 1708.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "tabular data of that patient prior and",
      "offset": 1710.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "also visual imagery data of you know",
      "offset": 1713.039,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "body scans x-rays combined into single",
      "offset": 1715.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "predictive workflows uh so that's one",
      "offset": 1718.559,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "thing I think we'll also see an",
      "offset": 1721.2,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "increased demand for uh speed of",
      "offset": 1723.399,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "innovation I think if you think if you",
      "offset": 1727.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "look at sort of what AI has done is it's",
      "offset": 1729.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "allowed us to create faster and I don't",
      "offset": 1732.519,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "think that's going to change which means",
      "offset": 1735.159,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "that I think what we should will start",
      "offset": 1737.679,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "hiring for and training for is not",
      "offset": 1739.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "someone to do for example what I did",
      "offset": 1742.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "which is know every detail of how all",
      "offset": 1744.72,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "the ml algorithms work but instead to",
      "offset": 1747.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "actually get really good at",
      "offset": 1750.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "understanding how to be creative and how",
      "offset": 1752.36,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "to be curious and how to push you know",
      "offset": 1754.96,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "plug with push buttons on an AI system",
      "offset": 1758.399,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and see what pops out how to how to",
      "offset": 1760.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "squeeze it and mold it and poke it and",
      "offset": 1763.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "see what comes out the other end I think",
      "offset": 1765.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "we'll find that people who think that",
      "offset": 1766.88,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "way who see life and AI as a sort of",
      "offset": 1768.76,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "bubble we can poke at and and see what",
      "offset": 1772.36,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "pops out instead of being forced to work",
      "offset": 1774.679,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "within the constraints of AI but instead",
      "offset": 1777.039,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "how we can mess with it to make it do",
      "offset": 1779.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "things it's never done before the people",
      "offset": 1781.64,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "who think that way will become the",
      "offset": 1784.08,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "leaders of the future versus people who",
      "offset": 1785.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "just know every detail of how to build",
      "offset": 1787.64,
      "duration": 2.279
    },
    {
      "lang": "en",
      "text": "these",
      "offset": 1789.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "things yeah now Innovation is definitely",
      "offset": 1789.919,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "uh feeling exponential right now I think",
      "offset": 1793.44,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "on that note of being uh curious Curtis",
      "offset": 1795.88,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "I uh happened to actually didn't know",
      "offset": 1799.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "this before the call but come across",
      "offset": 1801.279,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "clean Lab Studio and I think it's tough",
      "offset": 1802.84,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "when you're listening to this on a",
      "offset": 1804.64,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "podcast you're like get a feel you know",
      "offset": 1805.84,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "people are familiar with the sort of",
      "offset": 1807.799,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "workflow of uh essentially working",
      "offset": 1808.84,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "through um and improving uh your data",
      "offset": 1811.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "quality and labels but um it's a",
      "offset": 1814.399,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "phenomenal product it it is you know",
      "offset": 1816.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "essentially lets you try that for free",
      "offset": 1818.64,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "and also has like automatic deployment",
      "offset": 1820.48,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "out of the box and so would encourage",
      "offset": 1822.279,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "our listeners if uh you know they were",
      "offset": 1824.039,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "excited about the history maybe this",
      "offset": 1826.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "stuff Curtis talks out to to go uh check",
      "offset": 1827.2,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "it out it is of all the links we will",
      "offset": 1829.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "put in the description it'll be the",
      "offset": 1832.2,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "first one yeah for sure well but thanks",
      "offset": 1833.32,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "so much Curtis for coming on and and",
      "offset": 1837.12,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "really really appreciate you taking the",
      "offset": 1838.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "time yeah and thank you oay for for",
      "offset": 1839.84,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "adding that I if I if I may I'll add one",
      "offset": 1842.6,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "thing which is I tried really hard here",
      "offset": 1845.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "not to to like market and be like you",
      "offset": 1847.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "know buy this use this and I'm still not",
      "offset": 1850.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "going to do that what I'll say is that",
      "offset": 1852.24,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "the people who have have built this",
      "offset": 1854.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "thing they every single one of them",
      "offset": 1857.24,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "could have done tremendously good things",
      "offset": 1859.96,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "out in the world on their own and we",
      "offset": 1861.679,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "have an obligation at clean lab that if",
      "offset": 1864.24,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "we're going to build something that what",
      "offset": 1866.039,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "we do collectively as a team is at least",
      "offset": 1868.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "as good as what they would have done",
      "offset": 1870.519,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "independently on their own and we feel",
      "offset": 1872.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that every day at clean lab and so we",
      "offset": 1874.679,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "really do try to create something that",
      "offset": 1876.2,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "creates real value for people every day",
      "offset": 1878.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "it's it's bread and butter for us it's",
      "offset": 1879.799,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "what we care about amazing well Curtis",
      "offset": 1881.24,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "thanks so much uh for being on the show",
      "offset": 1884.639,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and we'll talk soon thanks yeah",
      "offset": 1886.84,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "appreciate you guys",
      "offset": 1889.519,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 1894.71,
      "duration": 4.149
    }
  ],
  "cleanText": "[Music]\nHey everyone, welcome to another episode of Practically Intelligent.\nToday we have on Curtis Northcutt, founder and CEO of CleanLab.ai.\nUh, CleanLab is an automated, no-code tool uh to curate and automate your labeling operations.\nThe uh company was founded by three PhD founders uh out of MIT, and today we're talking to Curtis about the history of uh data ops and and data quality and core concepts in machine learning related to data labeling and how we actually think about scaling that and creating trustworthy uh models and data.\nYeah, MIT, I've heard of them.\nUm, so they're the... the interview is is is quite fun because, yeah, to your point, we we we come at this from a lot of different angles, from, you know, core traditional machine learning all the way to what's the bottom line, how much money can you actually save when you put these uh processes in place?\nAnd uh, I think we actually go... we go to a lot of different directions in in a relatively short amount of time.\nSo, um, I'm pretty excited to to jump right in.\nLet's do it.\nAwesome, Curtis, thank you so much for for coming on.\nYeah, glad to be here.\nI wanted to start by grounding us in a simple but very nuanced question: what to you at CleanLab is the difference between reliable and unreliable data?\nIt's a good one.\nUm, so reliable data historically meant uh you have... you need imputation, which means you have some structured data set like a CSV file, and it misses values, so you have some blanks, and that was considered unreliable.\nAnd there's a lot of companies that have built what's called ETL, extract, transform, load, or ELT, depending on if it's on the cloud or done before the cloud, and what they're basically doing is making sure that doesn't happen and making sure that data is reliable in the sense that it like exists and it's the right type and it's going to the right places.\nAt CleanLab, when we say reliable, we mean it like what a human means.\nSo, for example, if you have an image and you're in a data set of animals and that image is not an animal, that is not reliable, and we would call that an outlier.\nAnother example of unreliable data is something that is an images of, let's say, um, cell phones and laptops, and it's a picture of a laptop and it's labeled cell phone, so that would be unreliably labeled, meaning it just has the wrong label.\nAnd there's a bunch of these other things are text, for example, that has PII issues or toxic language or inappropriate content or the wrong language.\nSo these are all examples of unreliable data that semantically the data is there, it's the right type from like a syntactic structure, it's all the rules are correct, but now we're talking about when you actually get value as a business or a customer from that data, you're not going to get the value you want because the actual data itself is unreliable from a semantic standpoint.\nSo you... you... you're touching on, I mean, on its... on its face, a relatively simple idea, but but something that a lot of people tend to overlook, which is that reliability, to your point, I... it's not one thing, and it's it's barely even two or three things.\nIt's the idea that can go in and trust something, it's the... which is always like the other side of reliability.\nIf something is reliable, you trust it.\nAnd at CleanLab, it sounds like the the the main vision here is to make sure... look at their website, right?\nIt's it's data that you can trust, and and there's a lot of dimensions to that.\nSo, C... can... I'm I'm curious myself, what are some concrete examples of of ways that you are making data actively more reliable?\nIf you want to give us an example.\nYeah, for sure.\nUm, a lot of folks right now are fine-tuning LLMs, and they would like the outputs of those LLMs to produce something that doesn't yell at the person or cuss them out or do something that's inappropriate.\nSo that's an example of an LLM being unreliable.\nThe way that you make an LLM more reliable is when you fine-tune that LM, when you train it, you train it on examples.\nIt's called instruction-based tuning, where you're basically fine-tuning a model with both the examples of both the original prompt and then what you expect the response to be.\nSo what we would do is we'd run CleanLab through all the responses of the fine-tuning data set and filter out all the stuff that would be problematic, like bad language, PII, email addresses, URLs, credit card numbers, uh, you know, informal language, uh, inappropriate remarks.\nAnd then when you now fine-tune your model, it knows not to do those things.\nAnd so that's an example of how you can now have a model that produces more reliable output, where reliable in this case just means it talks the way that you would like it to talk.\nAnd something that you're implying there, which I want to make extremely explicit for everybody, which is reliable data is not the end goal, it's kind of the starting point for reliable models and reliable AI ecosystems, right?\nIn in a lot of ways, having data you can trust by itself is often useless.\nThe whole point of that data was to be powering something bigger than the data than the the rows and columns itself, and you know, most of the time these days, those are LLMs, those are multimodal models.\nSo what you're doing at CleanLab is not just creating data you can trust, but that's the foundation for models and therefore features based on those models are are going to be uh reliable themselves.\nAnd I mean, I think you kind of... for me, what really rings true is a recent story about Air Canada chatbot, right?\nWhen when a... when Air Canada chatbot promises a refund policy, I believe it was like a refund policy that doesn't actually exist.\nThat model, that to that person, is unreliable, and it's it's building that ecosystem.\nSo now it... the idea, Curtis, that you've been working on this as as an entrepreneur, uh, is is you know, pretty well known, but before CleanLab, the idea of reliability and and confidence was something that you focused on a lot, um, when you were getting your PhD at MIT.\nCan can you tell us a little bit about the inspiration, like what what kind of drove you to this field, to this industry, like what's what's the story there?\n100%.\nIt was trying to change the world.\nUm, fundamentally, I wanted to democratize education.\nUm, I think I would be remiss, and I think the people listening to this would also want to know everything that we're going to talk about is automated, uh, and that's very different.\nYou... when you... a lot of companies are like, \"Data you can trust,\" and then they send your data off to the Philippines, and then 50 people review it, and then they send it back.\nUm, that is not what we're talking about here.\nSo everything that we're going to talk about, everything we've already talked about, is systematic, algorithmic, with reliability quality scores added to every data point in a way that you can verify and actually show that above this threshold, here's, you know, the probably approximately correct bounds that this is actually reliable data, and below this threshold, you know, you need to do whatever.\nOkay, so with that in mind, uh, I got to MIT in 2013, did my PhD there.\nI worked with Isaac Chang, um, who's commonly known as the first person to ever build a working quantum computer, so sometimes called the inventor of the quantum computer.\nAnd what he really cared about was how do you take data signals from a quantum computer and be able to reliably understand what that quantum computer is doing?\nAnd when you have atoms that are in different states, how do you take measurements and velocities and particle speeds, and how do you measure that in a way that's reliable?\nAt this time, you know, 1998, it was a two-bit quantum computer, and they're constantly increasing them, but that's that was literally the task.\nAnd the way that this was done is a combination of of tremendous engineering work, but also systematic theory that's provable and guaranteed, um, called quantum information theory.\nAnd I worked with Ike for eight years at MIT, and what we developed was a way that you could take that same theory and apply it to arbitrary data, because if you think about it, a quantum computer is arbitrary information.\nIt's just a computer.\nIt doesn't care if the data is images, it doesn't care if the data is audio or text.\nAnd so that's one of our unique differentiations is we were able to invent an algorithm that is framework, a framework of algorithms called confident learning that allows you to reliably and systematically and provable way find errors and data automatically and fix them for any type of data, which is very unique.\nYou know, you have self-driving car companies, you fix image data, you've got LLM companies, it's text data, but with CleanLab, it's it's any type of data.\nAnd so the problem that I first wanted to solve was democratization of education, because I was working as the first research scientist at MITx, which is a subset of edX, a competitor of Coursera, if you've ever taken online courses like Andrew in's deep learning course, and we needed to detect who was cheating or not, so we could validate certificates.\nSo you've got all this education data and you're trying to predict if someone's cheater or not, which is a label, and it turned out that machine learning failed.\nAnd so I talked to the smartest people I could find at MIT and people who had done machine learning for 20, 30 years, like forefathers of the field.\nI talked with Tommy Akla, who's uh, you know, one of the first inventors of some of the problemistic graphical model work and pushed SVMs and really OGs in the field, and at that point, it's now 2013, 2014, machine learning did just did not work.\nThere was no actual reliable multiclassification algorithm that could actually train on erroneous data.\nAnd so I spent the next like four to eight years developing the theory and algorithms that eventually turned into CleanLab, and now, of course, we've been building a business on it for, you know, about half a decade.\nIt's interesting, Curtis, because you started working on this uh and innovating, um, you know, um, before the Transformer era and during a time where um, really this an anti-idea of data curation was about throwing headcount and and essentially all about labels.\nOne thing I'm curious about is that's that's changing now, right?\nAnd companies, organizations are making... they get this concept, even you know, outside of the ML or of data being the new oil, of creating a knowledge base that's proprietary, of imbuing that into your workforce, enabling automation.\nTalk to us a little bit about how data curation and scalable data creation in uh companies has changed over the last couple years.\nI know you talked about automation, but give us a little history lesson on, you know, scale came into this space.\nYou were innovating, seeing what was happening there.\nUh, talks a little about the changes of the space and the context and eyes from one of your one of potentially your customers.\n100%.\nSo I'll first talk about how things have changed, and then I can focus on a customer use case.\nUm, I have a slide that I usually show for this, um, but I know that doesn't work for this this format, um, but it basically shows 2013 to 2016, how do we do data curation at Enterprises?\nWell, um, and it's worth noting, I I did some kind of research contingent position or research scientist position or internship at Amazon, uh, NASA, General Electric, Microsoft, Google, and Meta and Oculus research, um, and so I've done the gambit.\nI've seen a lot of these places and how they work, and most of what I'll share is rhetoric from firsthand experience.\nUm, and what what typically was done in data science teams and machine learning teams is a bunch of ad hoc Jupiter notebooks where you would basically write a bunch of rules to label things internally, share it around, get a bunch of people to do it, then eventually people realize, \"Wait, we're paying, you know, whatever salaries from 150 up to 400 something K in order to have research scientists label data.\nMaybe we can do this more efficiently.\"\nAnd so that was like 100x cost and time.\nAnd so 2016, uh, Alex Wang has a great idea and uh, you know, to say, \"Hey, look, let's just have sort of a human labor force that's affordable and over be able to sort of ship data for AI and they can label it for you,\" um, but they're not experts.\nAnd so if you're a self-driving car company and you have an image of a road and you know, you don't even live in America, it's difficult to know is that exactly a stoplight or a road?\nAnd so, and the way you deal with that is you get 50 non-experts to all label something and come to consensus.\nUm, and so there's a few issues with that, but it's a good approach, and it's and that's done very well, right?\nIt provided real value, um, and it's a good approach.\nThe downside are you've got to pay a lot of people, you have to distribute it out, you have to send the data out to third parties, um, so it creates Data Trust on sort of the consensus, do these 50 people actually agree on the light, right?\nLabel, is it high quality?\nCan we trust it?\nAnd also, is there any way to do this without shipping the data out?\nAnd also, can we do it without paying 50 people to do it?\nSo what came after that was this concept of labeling functions, and we saw that with companies like Snorkel, um, and they had a really good idea, which was like, \"Let's look at text,\" didn't work so well for images, but let's look at text and say, \"Look, if we can write some function in Python, if I can get an engineer, a software developer to sit down and say, I can map all of my data into labels just by writing software functions, and we'll build software around that that then finds a a decorrelation among all those labels in order to say this is sort of the best label for that data point based on all the rules you wrote,\" um, and that saves some time and cost, that cut down on it, increased the automation.\nThe downside of that is what it produced is something that Snorkel and companies like that themselves call weak labels, so basically noisy guesses of labels, but not high accurate, high quality labels.\nAnother downside is it required engineers to actually write the code to produce those, and another downside is that it only worked for things where you could actually systematically label them, uh, like for example, text where you can say an example would be, um, you know, \"I want my wife to grab uh to make food for me,\" or something, and then it would say that the speaker is most likely uh a man or something or husband, and of course, that's a, you know, that can be wrong, um, you know, but it basically you're just doing your best, and you can see how that label could be wrong, but it's still a labeling function.\nAnd so that's an example.\nSo we got there, and that was a way you could automate some some of the tasks.\nAnd then where we are today is what we're doing is domain-specific AI training that looks at these data sets and is actually producing a label for you based on a small subset of labels, but then going way beyond labeling.\nSo what I focused on was just labeling, but actually most of the error is not just in the label, it's in the data itself.\nAnd so we extended that beyond automated labeling and automated detection of errors to outliers, ambiguous data, which means it confuses models, PII issues, etc.\nSo I talked for a while.\nI'd love to share a use case of this when if you guys want.\nYeah, before we get into a use case, I I I I do have one follow-up to that because the you're right, I think there that the idea of almost subjectiveness and kind of ambiguity and vagueness, I I'll come back to your example of like, \"I want, you know, this person to make to make food for me,\" well, context is now going to be the greatest input here that you may totally be missing in in that in that text sample.\nSo in in in\n\n\nYour philosophy or in CleanLab's philosophy is CleanLab.\nAn alternative to things like gathering consensus, or do you prefer that to almost work in parallel or in a pipeline where CleanLab maybe is showing something as ambiguous and vague, perhaps that's more of a short list now for the actual domain experts to take a look at it and readjust it to some process?\nWhat's the philosophy there between combining some of those paradigms?\nYeah, any customer of any of products, you know, that we've already talked about, any labeling product is a great customer for CleanLab because what they can do is reduce the number of annotators they need and then put low-quality data into CleanLab and automate a lot of the time and cost.\nSo you can see it as a next step, or you can just feed the data directly into CleanLab and then do a few initial labels yourself and then let our system iteratively get you there either there works.\nUh, but I think of it more as any customer of a labeling company is definitely a customer of CleanLab, but not vice versa.\nA lot of our users, they want to do, they just want to actually get the business value, not just label data.\nMakes sense.\nAll right, let's hear, let's hear a use case.\nYou know, we are Practically Intelligent, so we want to make sure everyone has a really clear use case.\nSo tell us how you are actively helping, uh, or in this use case.\nYeah, one thing that you could search online today, uh, it's a blog, I think, called Money Talks, and um, it's for a big bank.\nYou've probably heard of them, PNC in America, globally they're called BBVA.\nUm, they're one of the largest financial institutions in the world, um, and they posted on their website, uh, not on ours, um, just to show like where the source is coming from, that they were able to reduce the total amount of spend and time, uh, in terms of getting a financial predictive data set to predict accurately, uh, what a financial outcome would be like, should you buy something or not, uh, is this a good loan or not, investment or not, um, based on financial data and text document data.\nThey were able to reduce the total number of, uh, time and cost by 98%.\nUh, that is an extreme example.\nUh, you know, the amount of principle of a big bank like that is going to be pretty high, typically in the millions, and so reducing costs by 98% is a factor that I would not promise your average person, uh, but we are seeing time and cost improvements between 70 and 80% on average.\n98% is, uh, you know, of course I'm sharing that because it's an exceptional example by a massive organization, um, and in addition to that, and I think this is the real kicker, is after using CleanLab, they also saw model improvement by over 20%.\nSo the accuracy on a held-out test set for a financial task was increased by 20% even though they spent 98% less.\nYeah, and we'll, we'll put a link to it in the description, of course.\nAnd and I, if you, when you, listener, uh, actually take a look at that post, you're going to see basically what almost looks like a, like a duh moment, like, well, of course they had to build a training set and evaluation set, train the model.\nThere's a nice little graphic there of, you know, not annotation and and and notifying things, which is basically proposing samples to be labeled.\nThat, that cycle that you see on, on that, uh, post is basically the cycle you'll see on any machine learning or MLOps course, right?\nThe idea of train the model, you have a data set, you have to improve the data set, you train it again, and you test it.\nSo in, in a lot of ways, when I think of a company like, like CleanLab, I think of, well, this has been, this has been what we were trying to do this whole time, and and it's only just now, frankly, that with the advent of Transformer Technologies and much faster processing and and cheaper compute that we can actually fulfill this promise for a larger subset of people who have this problem, but never really had the resources to solve it, whether it was, you know, someone who worked at the company telling them they had to do it, or you know, some kind of advisor kind of intervening in the process.\nSo, uh, I, I think it's going to be almost like a, a shock to the system to see like how easy, um, CleanLab can, can really make this.\nAnd, uh, so I, I, I really love that use case, and you're right, it's dramatic because, you know, it's, it's a really great example, but it also shows the boundaries in which that you can help, the upper boundaries of, maybe not even upper boundary, to even go even higher, but it can be as dramatic as 97, 98% um, change.\nIt can be that much, depending on who you are, what you're spending already, and and what processes you have in place.\nSo I, I see that, yes, as an extreme example, but I, I also see it as a, this could be you kind of example, whether you're as huge as a bank or as small as a startup going through YC.\nAnd and to that end, let me ask you, how, how does CleanLab work when you aren't a giant bank?\nWhen you are a relatively smaller company, like what, how does that work?\nThat's a really great question.\nSo another one of our, our Enterprise customers is Berkeley Research Group, um, which, if you haven't heard of them, they might sound like they're, you know, out of Berkeley, the university, but this is actually a pretty big company, there 1,100 employees.\nUm, we classify them as one of the larger on the SMB scale, or on the smaller on Enterprise scale.\nThey're basically a, uh, technical and digital consulting firm.\nWhat they do is work with big legal clients, um, uh, economic cases, all sorts of use cases like that, and they help them with ML and data tasks.\nSo I'll give you an example.\nSay I'm a high-profile person, I'm have, I have a big lawsuit coming up, and this lawsuit, the case proceedings are going to be made public for whatever legal reason.\nSo some of my privileged and private confidential documents will be made public as part of the court case, for example, Elon Musk's tweets or, uh, internal IP from a company.\nWhen that type of stuff happens, these court cases, in terms of the diligence required to look through those documents and make sure that nothing that doesn't have to be made confidential for the public is not made confidential, can be around a million or more per day.\nAnd we were able to save this company, Berkeley Research Group, and in terms of a legal case that they were supporting one of their clients on, about 30 days off of the court proceedings.\nSo the amount of time taken for them to analyze the documents and get the lawsuit going, uh, that we saved them about a month.\nAnd so I'll let you do the math.\nIs can I contribute, you know, every single aspect of that month to us?\nNo, they were using our results and working quickly on their side as well.\nSo somewhere savings between, you know, 1 and 30 million, something like that.\nAnd in addition to that, they were able to improve the model, the accuracy of the model that was doing privileged document detection and confidential document detection, um, by 15% accuracy, even though they're also shaving off the time.\nThe reason I brought that up is because the number of documents was not that big.\nSo this wasn't a massive company like a big bank or a massive Fang Institute doing hundreds of millions of data points, which we support, by the way, and that's our bread and butter, but they, they're actually more a boutique, right?\nWhere their each document is complex and complicated, and we're supporting their Ed cases.\nThat was on the thousands of documents, and they're not even complex, but they're also, um, you kind of hinted at this, they're very domain-specific, right?\nAnd that kind of comes back to the idea, the promise almost that you made earlier of of of handling any data, right?\nNot just text, not just images, and not even just text, but text in the legal field, text in the financial field, text in the healthcare field.\nWhat is your personal or company vision on, on, on, on how to kind of create this almost standard, or maybe that's not even the goal, uh, like how do you think about a system that can handle quote, any kind of data?\nYou know, what are the main difficulties and and what are the main kind of, uh, through lines that go through these, these, these different modes of data?\nYeah, a lot of it was, was technical, sin on, um, we did that work for like a decade prior to the company.\nSo a lot of that, so all three of the founders were did their PhDs in computer science at MIT, and I sometimes I'm nervous to share that because while there's obviously some validation that we've spent time thinking about this, uh, and we might be the right people to have built it, sometimes you hear that and you think, wow, this is probably an academic thing.\nAnd it's like, no, we're, we're business people, like, we're, we are here to support real value for Enterprise companies at scale, and we focused exclusively on that task for several years.\nUm, that, that being said, a lot of the work really was technical in the past, and so what we built was a way that you can not only train any model and any type of data, which is commonly known as AutoML, where you basically just give it a data set and then train any model, but also how can you find errors in any data set regardless of the type, um, which is a framework that I did my PhD on called Confident Learning, which we have now extended into the full sort of suite of data-centric AI.\nTwo bullet notes to make on that is that we taught the first Data-Centric AI course.\nIt's, it was at MIT, and you can find that, um, I'll put a link, I'll share a link so that you can share it with listeners.\nYes, please.\nIt's just dccal.mit.edu.\nUm, and so that's one thing is that we, we've really spent a long time finding a way that you can generalize this to any data set prior to the company.\nSo this is a, a m, you know, over a decade pursuit.\nUh, the second thing is that, as I mentioned, the key and core to making this technology work is having the best AutoML in the world.\nAnd it's a lot of times you hear a small company, you know, we're like between 30 and 40 people, how can I say that we have the best AutoML in the world?\nLike, you should doubt that, and I would expect you to doubt that, and to which I would reply that the person who built Amazon's AutoML, it's, which is called AutoGluon, on it's open source, and so you can look up who committed the most GitHub commits was Jonas Mueller, and he's our chief science scientist and co-founder at CleanLab.\nThere you go.\nCurtis, I wanted to, we talked a little bit about the history of, uh, data curation and labeling, fast forward to 2027, 2028, you know, a couple years from now, any predictions on things we're going to be talking about then, more in this space, whether it's, you know, example, synthetic data, um, you know, training data scarcity becoming more of a thing, just general topics that you're paying attention to as a, as a forefront and leader in this space, um, that your customers are paying attention to, that you think we're going to hear more about?\nThe future question is always good, right?\nPredict the future, and then, you know, 10 years, we can play this and see how wrong I was.\nYeah, but no, quote this.\nIf you're listening, don't quote this.\nYeah, uh, I would, you know, we can quote it, I'll do my best.\nI would hope you don't, but, but it's fine, you know, it's, it's out there.\nSo, um, I think there's going to be a lot more multimodal work.\nI think we're going to see images being, uh, described by text and text being described, uh, with, uh, or being sort of supported with images.\nI think we're going to see more tabular data combined with text data, a lot more multimodal.\nSo instead of it being about sort of this like computer vision where we just look at things, I think it'll be computer vision plus statistical data and tabular data about those routes and other statistics for self-driving mobility.\nI think that we'll see in the healthcare industry, it won't be just a prediction based on a medical health record and text, but also all the tabular data of that patient prior and also visual imagery data of, you know, body scans, x-rays, combined into single predictive workflows.\nUh, so that's one thing.\nI think we'll also see an increased demand for, uh, speed of innovation.\nI think if you think, if you look at sort of what AI has done is it's allowed us to create faster, and I don't think that's going to change, which means that I think what we should will start hiring for and training for is not someone to do, for example, what I did, which is know every detail of how all the ML algorithms work, but instead to actually get really good at understanding how to be creative and how to be curious and how to push, you know, plug with push buttons on an AI system and see what pops out, how to, how to squeeze it and mold it and poke it and see what comes out the other end.\nI think we'll find that people who think that way, who see life and AI as a sort of bubble we can poke at and and see what pops out, instead of being forced to work within the constraints of AI, but instead how we can mess with it to make it do things it's never done before, the people who think that way will become the leaders of the future versus people who just know every detail of how to build these things.\nYeah, now Innovation is definitely, uh, feeling exponential right now.\nI think on that note of being, uh, curious, Curtis, I, uh, happened to actually didn't know this before the call, but come across Clean Lab Studio, and I think it's tough when you're listening to this on a podcast, you're like, get a feel, you know, people are familiar with the sort of workflow of, uh, essentially working through, um, and improving, uh, your data quality and labels, but, um, it's a phenomenal product.\nIt, it is, you know, essentially lets you try that for free and also has like automatic deployment out of the box, and so would encourage our listeners if, uh, you know, they were excited about the history, maybe this stuff Curtis talks out, to go, uh, check it out.\nIt is, of all the links we will put in the description, it'll be the first one.\nYeah, for sure.\nWell, but thanks so much, Curtis, for coming on and and really, really appreciate you taking the time.\nYeah, and thank you, Oay, for, for adding that.\nI, if I, if I may, I'll add one thing, which is, I tried really hard here not to, to like market and be like, you know, buy this, use this, and I'm still not going to do that.\nWhat I'll say is that the people who have, have built this thing, they, every single one of them could have done tremendously good things out in the world on their own, and we have an obligation at CleanLab that if we're going to build something that what we do collectively as a team is at least as good as what they would have done independently on their own, and we feel that every day at CleanLab, and so we really do try to create something that creates real value for people every day.\nIt's, it's bread and butter for us, it's what we care about.\nAmazing.\nWell, Curtis, thanks so much, uh, for being on the show, and we'll talk soon.\nThanks.\nYeah, appreciate you guys.\n[Music]\n",
  "dumpedAt": "2025-07-21T18:43:26.471Z"
}