{
  "episodeId": "fkkAcmgGVMA",
  "channelSlug": "@practicallyintelligent",
  "title": "E9: Exploring AI's Frontier in 2024: Promise vs. Reality in Tech's New Era\"",
  "publishedAt": "2023-12-29T11:47:17.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 0.71,
      "duration": 10.009
    },
    {
      "lang": "en",
      "text": "hey everyone welcome back to a 2023",
      "offset": 7.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "wrapped episode of practically",
      "offset": 10.719,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "intelligent in today's episode sonan and",
      "offset": 12.679,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "I are going to share our 2024 vision",
      "offset": 15.2,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "board for AI we're going to go through",
      "offset": 18.76,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "2023 Trends we found interesting some",
      "offset": 22.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "light predictions for the future topics",
      "offset": 25.68,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "in the discourse that we think will",
      "offset": 28,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "become more prominent and maybe even",
      "offset": 29.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "some things we disagree",
      "offset": 31,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "with there's an interesting report that",
      "offset": 32.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "sonan and I were pouring through that",
      "offset": 36.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "came out released by a venture capital",
      "offset": 38.76,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "firm named K2 it's 100 plus pages of",
      "offset": 40.28,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "charts insights about the Curren state",
      "offset": 43.719,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "of AI that is actually quite quite",
      "offset": 46.32,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "helpful and so sonan and I thought a way",
      "offset": 48.8,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "to ground our discussion versus just",
      "offset": 51.64,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "riffing would be to actually pull up",
      "offset": 53.16,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "which charts sort of caught our",
      "offset": 55.239,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "attention and that we're thinking a lot",
      "offset": 56.559,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "about uh going into uh",
      "offset": 58.92,
      "duration": 7.239
    },
    {
      "lang": "en",
      "text": "2024 there's um as everyone knows uh",
      "offset": 62.48,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "this is Son's favorite activity is is",
      "offset": 66.159,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "creating uh Vision Bo he's an active",
      "offset": 68.439,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "Pinterest power user so he was really",
      "offset": 70.119,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "excited for this I'm pumped as well uh",
      "offset": 72.36,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "let's let's dive in let's do it so uh",
      "offset": 75.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the first chart we'll start off on a",
      "offset": 79.159,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "positive note is that despite intense",
      "offset": 80.56,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "demand AI compute costs have",
      "offset": 82.439,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "decreased it's a similar uh Tale in a",
      "offset": 84.799,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "lot of uh different technology Cycles",
      "offset": 88.24,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "but if you just look at the cost of",
      "offset": 90.68,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "using the",
      "offset": 94.159,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "gpt3 from January this year to even the",
      "offset": 95.399,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "middle of this year the cost of a th000",
      "offset": 98.84,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "tokens fell from 2 cents 90% to actually",
      "offset": 100.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "this is this is GPT turbo so the cost",
      "offset": 103.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "between uh actually just using standard",
      "offset": 105.6,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "GPT was probably even uh you know",
      "offset": 107.92,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "further reduced so we're just seeing",
      "offset": 110.6,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "costs continuing to fall uh this despite",
      "offset": 112.479,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "GPU scarcity um despite some of the",
      "offset": 115.2,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "issues and Supply chains we're facing in",
      "offset": 117.92,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "semis it's becoming cheaper and cheaper",
      "offset": 119.399,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "to uh run these AI models I think that",
      "offset": 121.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "that's incredibly positive news son on",
      "offset": 125.719,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "for the ecosystem Etc everyone um sort",
      "offset": 127.56,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "of talks about there's the state of",
      "offset": 130.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "these GP GPT pores um where it's",
      "offset": 132.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "incredibly difficult uh for folks to get",
      "offset": 135.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "access the art models but largely",
      "offset": 137.12,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "there's been uh continuing falling costs",
      "offset": 138.8,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "for models uh that were released I mean",
      "offset": 141.239,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "as early as this year are becoming more",
      "offset": 143.72,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "and more economical to run I think",
      "offset": 145.12,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "another thing that I wanted to point out",
      "offset": 147.44,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "this was the next chart in the report",
      "offset": 149.4,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "but it's just interesting when we look",
      "offset": 150.959,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "at where a lot of the Innovation is",
      "offset": 153.519,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "headed this is sound obvious but you pay",
      "offset": 155.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "one time for training you pay",
      "offset": 157.239,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "continuously for inference and actually",
      "offset": 158.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "a lot of the Innovation that we're",
      "offset": 160.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "seeing is smaller models great example",
      "offset": 162.04,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "of this recently released with Microsoft",
      "offset": 164.64,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "release 52 that was traced on 2.7",
      "offset": 165.92,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "billion parameter model trained on",
      "offset": 168.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "textbook data that showed uh abilities",
      "offset": 170.28,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "to uh potentially mathematically reason",
      "offset": 172.68,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "and could potentially be helpful for a",
      "offset": 174.64,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "host of Enterprise uh tasks uh and is uh",
      "offset": 176.239,
      "duration": 6.121
    },
    {
      "lang": "en",
      "text": "showed outperformance relative to to GPT",
      "offset": 180.04,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "345 on certain mathematical benchmarks",
      "offset": 182.36,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "is a great example of there's a lot of",
      "offset": 185.239,
      "duration": 7.801
    },
    {
      "lang": "en",
      "text": "innovation and and more uh economies of",
      "offset": 188.64,
      "duration": 7.159
    },
    {
      "lang": "en",
      "text": "uh excuse me there's a lot it the cost",
      "offset": 193.04,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "of training is falling much much more",
      "offset": 195.799,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "faster and cost of fine-tuning and the",
      "offset": 197.879,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "performance you're getting from that is",
      "offset": 199.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "a one-time fixed cost you pay and we're",
      "offset": 201.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "seeing more and more smaller fine-tune",
      "offset": 203.36,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "models on specific data that are highly",
      "offset": 205.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "performant and I think as you know",
      "offset": 207.239,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "potentially inference is going to",
      "offset": 210.08,
      "duration": 3.079
    },
    {
      "lang": "en",
      "text": "continue to be expensive even though",
      "offset": 211.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "those costs are dropping I think we're",
      "offset": 213.159,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "going to see a lot more localized model",
      "offset": 215.239,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "sonon where people are it's not",
      "offset": 217.72,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "depending on an external third party",
      "offset": 219.92,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "people are going to figure out that",
      "offset": 221.439,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "certain models available uh are",
      "offset": 222.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "available for certain tasks they're Well",
      "offset": 225.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Suited towards it and we don't need to",
      "offset": 226.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "even run the inference cost necessarily",
      "offset": 228.72,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "so I think we're going to see more",
      "offset": 230.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "examples of uh local models and these",
      "offset": 232.2,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "sort of architectures where uh you may",
      "offset": 235.2,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "have some bigger model or you have it",
      "offset": 238.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "frankly just a series of small models",
      "offset": 240.04,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "that work really really well to for your",
      "offset": 241.72,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "specific tasks and so those economies of",
      "offset": 243.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "uh rapidly falling training costs",
      "offset": 246.48,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "explosion of fine-tune models or smaller",
      "offset": 248.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "parameter models that are well suited",
      "offset": 250.519,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "but higher cost of inference I think are",
      "offset": 252,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "going to create some interesting",
      "offset": 253.56,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "architectures that emerge we're going to",
      "offset": 254.56,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "hear a lot more about uh localized AI",
      "offset": 255.72,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "architectures in",
      "offset": 258.84,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "2024 yeah I mean a lot to respond to",
      "offset": 263.479,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "there um as far as the original graph",
      "offset": 266.36,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "the the the the one where you know",
      "offset": 269.4,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "compute costs are decreasing which is",
      "offset": 272.8,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "true they are decreasing um this is",
      "offset": 276,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "going to be like my first of the many",
      "offset": 278.12,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "yeah but isn't this also true um of of",
      "offset": 281.16,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "of our of our graphs here so for the",
      "offset": 284.6,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "graph here on the right hand side at",
      "offset": 286.479,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "least cost of running gpt3 and 3.5 is",
      "offset": 288.759,
      "duration": 7.561
    },
    {
      "lang": "en",
      "text": "down 90% in five months that's the cost",
      "offset": 292.479,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "of using chat GP like that's the cost",
      "offset": 296.32,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "that devel Vel opers pay when they use",
      "offset": 299.08,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "chap GPT that's to to my understanding",
      "offset": 301.4,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "right that's not the cost that open AI",
      "offset": 304.199,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "has is like incurring per thousand",
      "offset": 307.08,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "tokens right y so again coming back to",
      "offset": 310.12,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "the fact",
      "offset": 314.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that yes compute costs are coming down",
      "offset": 315.44,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "they're still extremely high but open AI",
      "offset": 319.12,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "reducing their price by 90% may not be",
      "offset": 322.72,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "as indicative that compute costs are are",
      "offset": 326.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "are decreasing at that rate as well",
      "offset": 329.16,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "right you have to you have to put",
      "offset": 331.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "yourself in the shoes of open AI they",
      "offset": 333.84,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "obviously Came Out Swinging but it",
      "offset": 336.36,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "didn't take long for other companies to",
      "offset": 339.36,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "catch up not in Market size but at least",
      "offset": 341.36,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "in performance so when you're up in AI",
      "offset": 345.08,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "you have to think about that like well",
      "offset": 347.96,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "they're going to say well we got to keep",
      "offset": 349.319,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "lowering our costs in order to kind of",
      "offset": 351.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "keep getting new people on the platform",
      "offset": 353.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "so I wonder I guess how much of that 90%",
      "offset": 355.68,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "drop is because compute has gotten",
      "offset": 359.12,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "better and how much of that is marketing",
      "offset": 361.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "like we need more users therefore we're",
      "offset": 364.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "going to decrease the cost I I just I'm",
      "offset": 366.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "curious what that split",
      "offset": 369,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "is oh it's it's a great point I think",
      "offset": 370.56,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "100% right the strategy for open AI is",
      "offset": 373.24,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "we have unlimited and are able to raise",
      "offset": 375.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "unlimited Venture money how do we lock",
      "offset": 377.68,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "people into our ecosystem and you're",
      "offset": 379.319,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "you're seeing that right so if you are",
      "offset": 381.88,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "trying to capture more share you will",
      "offset": 384.08,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "undercut your prices Etc that's kind of",
      "offset": 385.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "strategy 101 so it's interesting I did",
      "offset": 388.36,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "look for other measurements in these",
      "offset": 390.08,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "charts of you know estimated cost of",
      "offset": 392.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "inference Etc there's actually very few",
      "offset": 394.12,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "good you know sort of data on how the",
      "offset": 397.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "cost for example I was looking for like",
      "offset": 400.4,
      "duration": 2.44
    },
    {
      "lang": "en",
      "text": "I was hoping for an ideal chart of",
      "offset": 401.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "what's the cost of you know uh you know",
      "offset": 402.84,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "some sort of uh standard measurement of",
      "offset": 404.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "training uh and fine-tuning a model",
      "offset": 406.639,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "versus uh the cost of inference and",
      "offset": 408.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "obviously it's really hard to compare",
      "offset": 410.44,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "apples to apples so it's interesting I",
      "offset": 412.24,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "think that there is just this broader",
      "offset": 414.479,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "it's just a broader point of which is",
      "offset": 417.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "obvious to to folks you pay for",
      "offset": 418.759,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "inference on an ongoing basis but",
      "offset": 420.96,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "there's something interesting where well",
      "offset": 424.24,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "these models are getting so good for",
      "offset": 426.12,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "specialized half um in a lot of cases",
      "offset": 428.039,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and so um and you're only paying one",
      "offset": 431.319,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "time for that training uh use so there's",
      "offset": 433.319,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "a bunch of interesting things I think",
      "offset": 434.919,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "that'll emerge where uh folks that are",
      "offset": 436.12,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "still sort of constrained by uh cost",
      "offset": 438.879,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "compute and this is a lot of people",
      "offset": 441.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "right even if you know inference costs",
      "offset": 442.4,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "have dropped marketly it's still really",
      "offset": 444.4,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "really expensive we're still in a sort",
      "offset": 446.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "of GPU uh poor Paradigm I think it's",
      "offset": 447.599,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "really interesting to see what people",
      "offset": 450.84,
      "duration": 2.919
    },
    {
      "lang": "en",
      "text": "will do with a lot of these smaller",
      "offset": 452.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "models that they can discover um quickly",
      "offset": 453.759,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "host put together and may not need to to",
      "offset": 456.52,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "to pay for ongoing in for instance so I",
      "offset": 459.12,
      "duration": 2.6
    },
    {
      "lang": "en",
      "text": "see we think we'll see different",
      "offset": 460.72,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "architectures and sort of um sets of",
      "offset": 461.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "infrastructure uh emerge to support",
      "offset": 464.68,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "those use cases um but what about youan",
      "offset": 467.24,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "what was one of your your first",
      "offset": 470.56,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "takeaways from the report and",
      "offset": 471.68,
      "duration": 2.44
    },
    {
      "lang": "en",
      "text": "interesting",
      "offset": 472.879,
      "duration": 7.561
    },
    {
      "lang": "en",
      "text": "charts yes I will drop my first graph in",
      "offset": 474.12,
      "duration": 9.24
    },
    {
      "lang": "en",
      "text": "our slack channel for us but you're",
      "offset": 480.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "obviously going to see it on our on our",
      "offset": 483.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "YouTube video here all right",
      "offset": 485,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "so the this graph is the title is model",
      "offset": 487.84,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "evaluation is broken",
      "offset": 492.08,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "today um big claim and if you listen to",
      "offset": 494.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "our episode with Prine you kind of",
      "offset": 497.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "already have a sense for where uh we're",
      "offset": 498.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "going to go with this but the graph has",
      "offset": 501,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "two sides on the left it shows the human",
      "offset": 503.72,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "preference between CL CL one and Cloud 2",
      "offset": 507.28,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "two generations of models from the same",
      "offset": 510.72,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "company anthropic a competitor to open",
      "offset": 513.24,
      "duration": 7.239
    },
    {
      "lang": "en",
      "text": "AI um and the chart shows that cloud one",
      "offset": 516.68,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "the first one is 70%",
      "offset": 520.479,
      "duration": 6.841
    },
    {
      "lang": "en",
      "text": "77% overall win rate vers in in in a",
      "offset": 523.8,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "competition versus 72% for claw 2 so",
      "offset": 527.32,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "humans tend to prefer Cloud one over",
      "offset": 531.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "cloud two not by much but they do tend",
      "offset": 534.8,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "to prefer Cloud one the graph on the",
      "offset": 537.16,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "right is showing Cloud 2 verse Cloud 1",
      "offset": 540.519,
      "duration": 7.641
    },
    {
      "lang": "en",
      "text": "as anthropic the company who created it",
      "offset": 544.68,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "measures it on benchmarks and these are",
      "offset": 548.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "very kind of quote unquote common",
      "offset": 551.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "benchmarks like grade school math the",
      "offset": 553.12,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "GSM database uh the bar exam which only",
      "offset": 555.92,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "is now popular of of the few things I",
      "offset": 560.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "don't like about open AI I hate that",
      "offset": 563.04,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "they popularized using the bar exam as a",
      "offset": 564.88,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "benchmark",
      "offset": 568.12,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "because I can't pass the bar exam but",
      "offset": 569.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "would you trust me to do something",
      "offset": 572.16,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "probably so I I hate that but that is",
      "offset": 573.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "one of the benchmarks that anthropic is",
      "offset": 576.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "saying claw 2 is better but I think that",
      "offset": 578.6,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "illustrates my point kind of perfectly",
      "offset": 581.079,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "which is who cares which model is better",
      "offset": 583.519,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "at the bar exam that's not what humans",
      "offset": 586.279,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "are asking for help with dayto day so",
      "offset": 588.92,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "there's the point that they're trying to",
      "offset": 591.92,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "make um that K2 is trying to make I",
      "offset": 593.76,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "assume is that there's a mismatch",
      "offset": 596.279,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "between how developers and",
      "offset": 600.04,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "companies say how well their model is",
      "offset": 603.079,
      "duration": 6.361
    },
    {
      "lang": "en",
      "text": "doing and how well we humans users think",
      "offset": 605.6,
      "duration": 7.72
    },
    {
      "lang": "en",
      "text": "the model is doing and that mismatch if",
      "offset": 609.44,
      "duration": 6.519
    },
    {
      "lang": "en",
      "text": "not fixed pretty quickly is going to",
      "offset": 613.32,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "lead to most likely is going to lead to",
      "offset": 615.959,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "this kind of gap between you know",
      "offset": 618.16,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "research companies saying look how good",
      "offset": 620.959,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "we can get these benchmarks and then",
      "offset": 623.56,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "companies being like yeah but are you",
      "offset": 626.36,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "users like this other model better and",
      "offset": 629.079,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "so who cares what you're doing and",
      "offset": 632.2,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you're going to get this kind of",
      "offset": 634.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "dichotomy um between benchmarks and",
      "offset": 635.32,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "actual user feedback and if those two",
      "offset": 638.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "things aren't conjoined in some way you",
      "offset": 639.92,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "kind of lose this community between the",
      "offset": 642.8,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "two which is kind of like the it's not",
      "offset": 644.6,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "even the worst case scenario but um so",
      "offset": 647.24,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "that mismatch for me is quite Stark and",
      "offset": 650.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "I think it's it's really annoying",
      "offset": 652.88,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "frankly what do you",
      "offset": 655.76,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "think it's funny I was just just texting",
      "offset": 657,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "in our kind of work group chat my",
      "offset": 659.72,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "favorite new AI meme is uh this it's the",
      "offset": 661.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "IQ score meme uh with the",
      "offset": 663.92,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "distribution and in the middle is you",
      "offset": 666.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "know the guy crying which is I'm just",
      "offset": 668.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "going to use a comprehensive set of",
      "offset": 670.24,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "hundreds of benchmarks to figure out and",
      "offset": 672.04,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "then everyone else is just the both",
      "offset": 674.36,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "sides are just I'll just play with the",
      "offset": 676.079,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "model for 15 minutes and so it",
      "offset": 677.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "illustrates kind of a common point sonan",
      "offset": 678.56,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "that where frustrations with benchmarks",
      "offset": 680.44,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "Etc is uh it it is annoying right like",
      "offset": 683.279,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "how did we decide that the bar exam was",
      "offset": 686.6,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "it's a great point like that was",
      "offset": 688.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "something to uh actually aspire to it",
      "offset": 689.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "feels like it was arbitrarily suited and",
      "offset": 692.8,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "so folks that have listened to episode",
      "offset": 694.56,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "with Prine was he's calling for more",
      "offset": 696.279,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "modular benchmarks that that actually",
      "offset": 697.959,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "make sense versus these headline numbers",
      "offset": 699.68,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "um so this makes a ton of sense one",
      "offset": 702.519,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "thing I didn't make sense for the chart",
      "offset": 704.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "is there's a huge performance and",
      "offset": 706.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "harmlessness what is that what does that",
      "offset": 709.24,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "even mean like how do you measure that",
      "offset": 711.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "do you notice on the right hand side of",
      "offset": 714.399,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "the chart sonan um between CL how what",
      "offset": 715.48,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "is what does that even",
      "offset": 718.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "mean um you know I'd have to actually",
      "offset": 720.32,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "look into exactly what they were doing",
      "offset": 722.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "um for that but there are there are data",
      "offset": 725.92,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "sets that are um specifically around",
      "offset": 727.68,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "measuring harmlessness um I'm actually",
      "offset": 732.079,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "like while we're doing this I'm I'm",
      "offset": 734.68,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "curious now which one that they're",
      "offset": 736.36,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "referencing uh let's",
      "offset": 739.519,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "see I'm almost curious what yeah what is",
      "offset": 742.76,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "a data set invest like involving",
      "offset": 744.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "harmlessness is it just",
      "offset": 747.12,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "pictures and descriptions of flowers",
      "offset": 750.48,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "that's",
      "offset": 752.079,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "the yeah um I mean I'll have to look",
      "offset": 753.639,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "into it on my own because I'm not",
      "offset": 757.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "exactly sure but like that's that's",
      "offset": 759,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "another good point is for a lot of these",
      "offset": 761.12,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "benchmarks you know you you you'll",
      "offset": 763.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "usually say like mlu or Hell swag which",
      "offset": 765.639,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "are like direct references to a specific",
      "offset": 768.24,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "data set but when you just say bar exam",
      "offset": 771.079,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "it's like what do you mean by that and",
      "offset": 774.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "same same like what do you mean by",
      "offset": 776.12,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "harmlessness what do you do you mean by",
      "offset": 777.56,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "that like I can you tell us and that's",
      "offset": 779.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "actually going to lead us into some",
      "offset": 782,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "other discussions a little bit later on",
      "offset": 782.959,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "but it's pretty arbitrary when a company",
      "offset": 785.36,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "says we're 2x better in this category",
      "offset": 788.72,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "and it's like I don't know what that",
      "offset": 791.24,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "means yeah so yeah uh yeah frequent",
      "offset": 793.639,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "listeners of the Pod will know our our",
      "offset": 796.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "frustration with uh with data benchmarks",
      "offset": 798.199,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "and how confusing this stuff is um it is",
      "offset": 800.399,
      "duration": 7.161
    },
    {
      "lang": "en",
      "text": "a uh good transition sonon to a topic",
      "offset": 803.399,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "that I think we're hearing a lot more",
      "offset": 807.56,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "about which is um which is uh synthetic",
      "offset": 809.079,
      "duration": 8.2
    },
    {
      "lang": "en",
      "text": "data um and so one chart that was pretty",
      "offset": 813.32,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "interesting in This was um and we we'll",
      "offset": 817.279,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "touch on sort of uh data scarcity as",
      "offset": 819.88,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "well soon which is um we already talked",
      "offset": 822.04,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "about the power of found tuning fine",
      "offset": 824.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "tuning and and domain specific data on",
      "offset": 826.279,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "on performance and so this short sort of",
      "offset": 828.32,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "suggests that uh synthetic data can",
      "offset": 831.519,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "create um and and augment uh and add",
      "offset": 834.199,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "performance on top of of of fine tuning",
      "offset": 837.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "so it's interesting because if you",
      "offset": 840.16,
      "duration": 2.679
    },
    {
      "lang": "en",
      "text": "actually look at it it's comparing zeros",
      "offset": 841.48,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "shot GPT versus Bert which is again an",
      "offset": 842.839,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "Apples to Apples comparison um but we've",
      "offset": 844.88,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "largely starting to hear this right if",
      "offset": 847.839,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "you if you looked at predictions from",
      "offset": 849.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "hugging faces co-founders on their 2024",
      "offset": 850.8,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "predictions one of their first ones is",
      "offset": 852.839,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "that we're going to hearing a lot and",
      "offset": 854.36,
      "duration": 7.159
    },
    {
      "lang": "en",
      "text": "lot more about synthetic data and I it's",
      "offset": 855.92,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "right before we recording we noed",
      "offset": 861.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "something interesting which is in I can",
      "offset": 862.8,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "explain synthetic data in a vision and a",
      "offset": 865.12,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "tabular context right so in a vision",
      "offset": 867.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "context I can sayou training you're",
      "offset": 870.079,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "building an autonomous car and you don't",
      "offset": 871.519,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "have any images or data labels for a",
      "offset": 873.56,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "your car driving through snow so you",
      "offset": 876.959,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "might synthetically generate assets if",
      "offset": 879.639,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "you have a tabular data set with a",
      "offset": 880.959,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "undercover demographic you can",
      "offset": 882.8,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "potentially generate sample data sets",
      "offset": 885.079,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "that have simle characteristics to your",
      "offset": 887.24,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "UND sampled population in the language S",
      "offset": 888.959,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "I actually don't know we're going back",
      "offset": 891.639,
      "duration": 2.601
    },
    {
      "lang": "en",
      "text": "to this practical impetus for the",
      "offset": 892.92,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "podcast not I actually have no if I'm a",
      "offset": 894.24,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "PM and T with saying someone says hey",
      "offset": 897.639,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "look into synthetic data for this I",
      "offset": 900.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "actually have realized I have actually a",
      "offset": 902.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "very little clue what my actionable next",
      "offset": 904.68,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "steps are this was this chart was",
      "offset": 906.48,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "interesting because it showed me how",
      "offset": 907.639,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "little I actually understood about",
      "offset": 909.36,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "synthetic data in the context of",
      "offset": 910.92,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "language models so and this isn't a",
      "offset": 912.079,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "great chart it was more just a broader",
      "offset": 913.959,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "point I realized that as a huge gap in",
      "offset": 915.88,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "my understanding um and so I'm kind of",
      "offset": 918.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "curious no I mean it's totally common",
      "offset": 920.24,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "because it's one of those things where",
      "offset": 923.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "when someone says look into synthetic",
      "offset": 925.399,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "data or let's see we can't use some",
      "offset": 927.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "synthetic data your your natural",
      "offset": 929.56,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "followup question should be well what",
      "offset": 931.199,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "kind of synthetic data synthetic labels",
      "offset": 933.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "synthetic prompt response pairs",
      "offset": 936.48,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "synthetic evaluation like judging like",
      "offset": 938.88,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "what do you mean by synthetic data what",
      "offset": 941.639,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "most people mean when they just say",
      "offset": 944.959,
      "duration": 6.921
    },
    {
      "lang": "en",
      "text": "synthetic data as it pertains to llms is",
      "offset": 947.519,
      "duration": 8.8
    },
    {
      "lang": "en",
      "text": "having another llm effectively write a",
      "offset": 951.88,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "preferred response or the very least",
      "offset": 956.319,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "judge a preferred versus a non-preferred",
      "offset": 959.079,
      "duration": 7.481
    },
    {
      "lang": "en",
      "text": "response to a second ai's prompt so like",
      "offset": 961.72,
      "duration": 8.4
    },
    {
      "lang": "en",
      "text": "a human well usually write a prompt like",
      "offset": 966.56,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "um I'll take an example from anthropic",
      "offset": 970.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "from their original um constitutional AI",
      "offset": 971.72,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "paper so part of what they do with",
      "offset": 973.8,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "synthetic data is what they call Red",
      "offset": 976.16,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "teaming well what is called red teaming",
      "offset": 978.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "where a human will write a malicious",
      "offset": 980.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "prompt like how do you make an explosive",
      "offset": 982.36,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "out of kitchen materials something like",
      "offset": 984.6,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "that the example in their p was how do",
      "offset": 986.759,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "you hack into your neighbor's Wi-Fi but",
      "offset": 989.199,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "I I'll I'll one up them how do you make",
      "offset": 990.88,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "an explosive from kitchen materials and",
      "offset": 992.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "then You' ask the model and the model",
      "offset": 995.16,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "which has been trained to be helpful",
      "offset": 997,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "will answer the question incorrectly or",
      "offset": 998.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "correctly regardless and then the",
      "offset": 1001.399,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "Constitutional part kind of kicks in",
      "offset": 1003.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "where you then follow up as a chain",
      "offset": 1005.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "prompt uh okay so given that this",
      "offset": 1007.44,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "constitution exists we are heart we we",
      "offset": 1010.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "don't like illegal things we don't like",
      "offset": 1012.6,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "unethical things we don't like harmful",
      "offset": 1014.079,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "things what critique would you give to",
      "offset": 1016.639,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "that response and then hopefully the AI",
      "offset": 1019.36,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "will say something like well it's",
      "offset": 1022.04,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "illegal to make a or I don't know",
      "offset": 1023.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "whatever it's harmful to make a bomb and",
      "offset": 1024.6,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "to put it mildly and then the second",
      "offset": 1027.079,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "part would be okay now revise that now",
      "offset": 1029.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "write a better response given that",
      "offset": 1032.16,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "critique and the a will say I would say",
      "offset": 1034.079,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "something like I can't answer that for",
      "offset": 1036.039,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "you and then the human will then take",
      "offset": 1038.199,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the human written prompt and the now",
      "offset": 1040.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "synthetically generated guard rail and",
      "offset": 1042.839,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "then use that prompt response pair to",
      "offset": 1045.52,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "further fine-tune said model so that is",
      "offset": 1048.64,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "an example of synthetic data but at the",
      "offset": 1052.44,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "end of the day synthetic data is just",
      "offset": 1055.2,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "any kind of non-naturally occurring data",
      "offset": 1056.72,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "naturally occurring is doing a lot of",
      "offset": 1060.52,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "work there but some data that has been",
      "offset": 1062.76,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "that has been created uh artificially",
      "offset": 1065.919,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "for the purpose of augmenting a training",
      "offset": 1068.96,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "set you didn't find it you made it um",
      "offset": 1071.12,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "and again that definition is not enough",
      "offset": 1075.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "but that's like the the easiest",
      "offset": 1077.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "definition to think about is is this a",
      "offset": 1079.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "naturally a carving piece of text or was",
      "offset": 1081.24,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "this text generated by something",
      "offset": 1083.52,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "else yeah it's it's really interesting",
      "offset": 1087.28,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "right I think I I wonder it it you meant",
      "offset": 1089.36,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "this point also what we were talking",
      "offset": 1093.919,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "about is when people say alignment it's",
      "offset": 1095.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "very tough to parse what they mean",
      "offset": 1097.28,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "synthetic data exactly what you're",
      "offset": 1098.72,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "saying which is that uh",
      "offset": 1100.28,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "I there's actually I don't even know if",
      "offset": 1103.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "there's there's not great it's",
      "offset": 1105.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "essentially self-instruction",
      "offset": 1107.48,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "um and I'm not sure exactly how people",
      "offset": 1109.36,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "one a friend of the Pod wrote a more",
      "offset": 1113.28,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "academic post on synthetic data but",
      "offset": 1115.24,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "they're not actually great practical",
      "offset": 1116.679,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "guides on how to use this to actually",
      "offset": 1118.12,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "augment your model one so it'd be it's",
      "offset": 1119.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "an interesting potentially explore for",
      "offset": 1121.679,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "2024 the uh other thing that's",
      "offset": 1123.08,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "interesting is that um what I've seen",
      "offset": 1125.4,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "and we have a you know C2 on our",
      "offset": 1127.039,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "portfolio doing this which is um and I",
      "offset": 1128.4,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "don't know how which goes to the point",
      "offset": 1130.919,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "we we should we should delve into it",
      "offset": 1132.12,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "more down the line is that they're using",
      "offset": 1133.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "state-of-the-art models for uh synthetic",
      "offset": 1135.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "data actually only using smaller",
      "offset": 1137.96,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "localized models uh for actually running",
      "offset": 1139.559,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "their model in production so they that",
      "offset": 1141.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "actually is a trend when we go back to",
      "offset": 1144.159,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "that localized sort of model versus you",
      "offset": 1145.44,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "know a bigger model um I could see",
      "offset": 1147.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that's something that's that's emerging",
      "offset": 1149.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "as you might use these synthetic data uh",
      "offset": 1151.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "these state of R GPT 4 Etc to generate",
      "offset": 1153.64,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "synthetic sort of instruction or",
      "offset": 1156.4,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "preference sets but then you're using",
      "offset": 1157.84,
      "duration": 3.079
    },
    {
      "lang": "en",
      "text": "some of these smaller models that can be",
      "offset": 1159.28,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "fine-tuned so um that's definitely a a",
      "offset": 1160.919,
      "duration": 6.361
    },
    {
      "lang": "en",
      "text": "you know theme or Trend I could I could",
      "offset": 1164.52,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "see",
      "offset": 1167.28,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "emerging we've been talking about",
      "offset": 1168.88,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "synthetic data but the the thing about",
      "offset": 1170.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "this graph and by the way if you can't",
      "offset": 1172.44,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "see it for whatever reason the B the",
      "offset": 1173.88,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "basic gist of the graph is it's showing",
      "offset": 1176,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the difference between in different",
      "offset": 1178.08,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "tasks like named dentity recognition or",
      "offset": 1180.4,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "relation extraction blah blah blah four",
      "offset": 1183.4,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "different tasks it shows three bars one",
      "offset": 1185.919,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "and they're all quality bars so higher",
      "offset": 1189.64,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "is better the numbers don't matter for",
      "offset": 1191.32,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "now for three bars the one of them is",
      "offset": 1192.88,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "zero shot chat GPT I.E just asking chat",
      "offset": 1196,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "GPT and seeing what it does the second",
      "offset": 1199.6,
      "duration": 8.199
    },
    {
      "lang": "en",
      "text": "bar is fine-tuning a Bert model on",
      "offset": 1202.84,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "synthetic data data that has been",
      "offset": 1207.799,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "non-naturally occurring but was written",
      "offset": 1210.08,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "by another AI most",
      "offset": 1213.2,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "likely and then the third graph is",
      "offset": 1215.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "fine-tuned on real data I.E naturally",
      "offset": 1218.44,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "occurring data of that task nature and",
      "offset": 1221.32,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "it it goes for pretty much for all of",
      "offset": 1224.28,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "them rather it goes up zero T GPT did",
      "offset": 1226.159,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "the worst Bert trained on synthetic data",
      "offset": 1228.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "is in the middle Bert trained on real",
      "offset": 1231.6,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "data is at the end and I think the point",
      "offset": 1233.84,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "they're trying to make in the name of",
      "offset": 1237.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "the graph is that synthetic data can",
      "offset": 1239.2,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "augment fine tuning but sorry C this",
      "offset": 1241.36,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "doesn't make any sense to me because one",
      "offset": 1245.28,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "of your bars is not even about",
      "offset": 1247.159,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "fine-tuning a model it's just asking",
      "offset": 1249.559,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "chat GPT so the the first two bars don't",
      "offset": 1251.72,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "really have any relation to me what I",
      "offset": 1255.72,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "read from that graph is fine-tuning",
      "offset": 1257.799,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "models like Bert can be better than just",
      "offset": 1260.88,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "asking chat GPT you listen to any of my",
      "offset": 1264.52,
      "duration": 6.519
    },
    {
      "lang": "en",
      "text": "Rambles on my newsletter or this show to",
      "offset": 1267.4,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "to hear that opinion over and over again",
      "offset": 1271.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "fine-tuning a local model can be a lot",
      "offset": 1273.36,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "better than just relying on chat GPT and",
      "offset": 1276,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "then synthetic data is worse than real",
      "offset": 1279.559,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "data because in every case the real data",
      "offset": 1281.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "Bert was better than the synthetic data",
      "offset": 1285.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Bert so",
      "offset": 1286.96,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "this is one of the one of the few graphs",
      "offset": 1288.64,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "where I just looked at and be like this",
      "offset": 1290.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "isn't correct at all like this is the",
      "offset": 1291.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "incorrect thing to walk away with",
      "offset": 1294.36,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "synthetic data does not augment or",
      "offset": 1296.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "rather it can augment fine tuning but",
      "offset": 1298.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this graph does nothing to show me that",
      "offset": 1300.52,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "if anything this graph shows me",
      "offset": 1302.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "synthetic data is worse than real data",
      "offset": 1304.4,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "but fine-tuning is better than using a",
      "offset": 1306.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "foundation model that's all this graph",
      "offset": 1309.559,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "is telling",
      "offset": 1311.52,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "me I think it's a great observation",
      "offset": 1312.559,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "right because when I brought this chart",
      "offset": 1314.6,
      "duration": 2
    },
    {
      "lang": "en",
      "text": "I was like really excited about",
      "offset": 1315.6,
      "duration": 2.439
    },
    {
      "lang": "en",
      "text": "synthetic data beta stuff stuff I was",
      "offset": 1316.6,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "was reading and you had pointed this out",
      "offset": 1318.039,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "to me and so I think it's a great",
      "offset": 1319.799,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "example of again going back to",
      "offset": 1321.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "practicality uh sonan of there could be",
      "offset": 1322.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "stuff that people talk a lot about but",
      "offset": 1325.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "you squint in a little bit further um",
      "offset": 1326.84,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "and may not actually being used uh",
      "offset": 1329.559,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "there's not a clear next step for a lot",
      "offset": 1331.279,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "of folks so this is another one where",
      "offset": 1332.679,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "I'm really glad you kind of pointed out",
      "offset": 1334.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "um some of the discrep in the chart and",
      "offset": 1336.32,
      "duration": 2.68
    },
    {
      "lang": "en",
      "text": "yeah I'd be really curious to kind of",
      "offset": 1337.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "see if there are um and I looked I",
      "offset": 1339,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "wasn't able to find of of you know",
      "offset": 1341.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "standardized benchmarks for uh What",
      "offset": 1342.72,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "synthetic data can do um and how well it",
      "offset": 1345.52,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "can augment your data set so but I think",
      "offset": 1348.799,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "we're going to see more and more um",
      "offset": 1350.52,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "interest in synthetic data for sure in",
      "offset": 1353.159,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "2024 and uh more interest in to",
      "offset": 1354.96,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "implement that yeah and there should be",
      "offset": 1358.48,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "again it can help a lot but in even my",
      "offset": 1361,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "own recent newsletter post I I show like",
      "offset": 1363.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "there are still biases when you try to",
      "offset": 1366.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "synthetically label data and and not",
      "offset": 1368.44,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "biases like stereotypes those exist but",
      "offset": 1370.32,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "bias is like if you kind of randomly",
      "offset": 1373.679,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "give it answers to pick from it will",
      "offset": 1376.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "almost always prefer the first one over",
      "offset": 1379.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the second one just out of Randomness",
      "offset": 1381.799,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "not actually figuring out what it wants",
      "offset": 1384.12,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "to do with it so anyways that aside this",
      "offset": 1386.279,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "actually leads into my next chart pretty",
      "offset": 1389.559,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "well um which is about data quality uh",
      "offset": 1391.159,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "and the title of the chart is data",
      "offset": 1396.279,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "quality is just as important as data",
      "offset": 1397.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "quantity um I would actually go further",
      "offset": 1399.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "and say data quality is more important",
      "offset": 1402.279,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "than data quantity that's not what",
      "offset": 1404.039,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "they're saying that's what I'm saying",
      "offset": 1405.279,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "and the chart basically goes through for",
      "offset": 1407.12,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "four different tasks sentiment analysis",
      "offset": 1409.4,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "similarity text classification and nli",
      "offset": 1411.4,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "natural language inference um and for a",
      "offset": 1414.559,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "standard model this is actually data",
      "offset": 1417.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "from cohere another competitor to open",
      "offset": 1419.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "AI um who I'm a big fan of for what it's",
      "offset": 1422.159,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "worth and the the chart is showing for",
      "offset": 1425.4,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "each task two bars one using a quote",
      "offset": 1429.52,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "full data set and then using the other",
      "offset": 1433.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "bar is for for a pruned data set which",
      "offset": 1437.44,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "is always 30% the 30% best quality of",
      "offset": 1439.48,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "the full data set so the prune data set",
      "offset": 1444.48,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "is",
      "offset": 1446.84,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "always more than is always 70% smaller",
      "offset": 1448.12,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "so a lot smaller and as you can probably",
      "offset": 1452.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "guess where this is going every single",
      "offset": 1454.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "time the model actually performs better",
      "offset": 1457.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "not even the same better sometimes",
      "offset": 1459.6,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "slightly but always better on the pruned",
      "offset": 1461.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "data set than it did on the full data",
      "offset": 1464.36,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "set and again I've written two books on",
      "offset": 1466.799,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "feature engineering like literally for",
      "offset": 1469.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this purpose of like yes quality will",
      "offset": 1471.399,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "always Trump quantity more data is",
      "offset": 1473.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "almost is all at this point is almost",
      "offset": 1476.64,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "always the wrong answer is we need more",
      "offset": 1479.2,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "data is we need more representative data",
      "offset": 1481.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "we need more quality data but the first",
      "offset": 1484.76,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "thing you should be doing is rooting out",
      "offset": 1487.24,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "the non-quality data and that might be",
      "offset": 1489.76,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "synthetic or real I think that's the",
      "offset": 1493.48,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "thing right you can put synthetic and",
      "offset": 1495.08,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "real data together",
      "offset": 1496.96,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "but some of the real data will not be",
      "offset": 1498.279,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "quality some of the synthetic data will",
      "offset": 1500.399,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "not be quality it's more likely the",
      "offset": 1502.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "synthetic data is less quality but",
      "offset": 1504.2,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "there's going to be a lot of bad quality",
      "offset": 1506.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "data in the real data space you can't",
      "offset": 1508.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "just assume all real data is quality",
      "offset": 1510.72,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "data so that's that's I hope people kind",
      "offset": 1513.6,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "of latch on to that is you want to make",
      "offset": 1517.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "because here's the other thing it's G to",
      "offset": 1520.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "make your training faster you're you're",
      "offset": 1521.799,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "using 30% of the data it's a it's like a",
      "offset": 1524.279,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "no-brainer to me your training is faster",
      "offset": 1528,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "you're therefore cheaper um you're",
      "offset": 1530.399,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "probably going to be removing a lot of",
      "offset": 1533.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "outliers as well outliers tend to be",
      "offset": 1534.919,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "like worse quality and so everything",
      "offset": 1537.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "gets better all around your performance",
      "offset": 1539.919,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "gets better you're using less data it",
      "offset": 1541.799,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "just you know the problem is it takes",
      "offset": 1544.039,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "time it takes mostly human time to",
      "offset": 1546,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "actually think about",
      "offset": 1549.399,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "this related to data quality one chart",
      "offset": 1551.2,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "that uh I've found really interesting",
      "offset": 1554.52,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "that I've been thinking a lot about is",
      "offset": 1556.399,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "the scarcity of publicly available uh",
      "offset": 1559.039,
      "duration": 6.921
    },
    {
      "lang": "en",
      "text": "good quality data so this chart that I'm",
      "offset": 1562.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "pulling up um data scarcity as a",
      "offset": 1565.96,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "potential wder scaling models talks",
      "offset": 1567.6,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "about it's largely conceptual but I",
      "offset": 1569.44,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "think it's an interesting point which is",
      "offset": 1572.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "we",
      "offset": 1574.559,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "are these models are incredibly data",
      "offset": 1576.2,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "hungry and we may be running out of",
      "offset": 1579.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "available data to for these models to",
      "offset": 1583.08,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "publicly train you've seen uh gp4 uh",
      "offset": 1585.6,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "excuse me open AI start to hire",
      "offset": 1588.96,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "specialized teams of data labelers to",
      "offset": 1590.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "pay phds for specialized models and",
      "offset": 1593,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "biology talked about passing the bar",
      "offset": 1595.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "exam they they're paying you know",
      "offset": 1597.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "lawyers to actually label their data",
      "offset": 1599,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "they have these programs now where",
      "offset": 1600.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "they're actually you know directly",
      "offset": 1601.88,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "paying people for data acquisition and",
      "offset": 1603.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "so I think this chart is interesting",
      "offset": 1605.919,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "because it ties a metap point that I",
      "offset": 1607.24,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "think we're seeing which is we are gp5",
      "offset": 1608.64,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "is rumored to kind of be trained on you",
      "offset": 1612.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "know image and video and so we're Lely",
      "offset": 1614.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "going to see uh you know Step Up",
      "offset": 1616.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Improvement of um some of these",
      "offset": 1618.24,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "multimodal models but largely we're",
      "offset": 1620.08,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "going to be kind of data",
      "offset": 1623.88,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "constrained um in the near future which",
      "offset": 1626.76,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "will affect a lot of people's ability to",
      "offset": 1629.12,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "find uh new uh new data I think the",
      "offset": 1631.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "interesting in this chart is that it",
      "offset": 1635.64,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "sort of the timeline is very interesting",
      "offset": 1637.6,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "right if you look at it is we sort of",
      "offset": 1639.6,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "peak around 2038 when",
      "offset": 1641.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "I brought up an interesting point so",
      "offset": 1644.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "which I'll discuss is that",
      "offset": 1646.679,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "I actually think we're going to hit data",
      "offset": 1648.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "limits a lot sooner because of the legal",
      "offset": 1649.84,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "regime in AI that people aren't paying",
      "offset": 1652.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "enough attention to so one thing that",
      "offset": 1654.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "was undercovered in G you know Sam",
      "offset": 1657.159,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "alman's announce latest announcements uh",
      "offset": 1659.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "in in developer day uh when they",
      "offset": 1661.6,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "announced uh gpt3 was this idea of a",
      "offset": 1664.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "copyright Shield right which was that",
      "offset": 1666.6,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "open Ai and other model providers like",
      "offset": 1668.919,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "stability will basically indemnify",
      "offset": 1670.64,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "Downstream usage of the model and when I",
      "offset": 1672.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "looked into litigation around this which",
      "offset": 1674.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "is you know intellectual property",
      "offset": 1676.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "uh it's actually there was there was a",
      "offset": 1678.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "few interesting case laws there's one",
      "offset": 1680.12,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "federal court uh in",
      "offset": 1682.2,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "California um you know is is Anderson",
      "offset": 1685.039,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "versus stability and what if you",
      "offset": 1688.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "actually read the ruling it wasn't that",
      "offset": 1689.96,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "uh you could just use these models it",
      "offset": 1692.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "was that all the original content",
      "offset": 1694.519,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "creators basically didn't file their",
      "offset": 1697,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "appropriate copyright claims to allow",
      "offset": 1698.84,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "them to defend and if they had they",
      "offset": 1701.039,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "could have probably uh you know",
      "offset": 1702.64,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "constrained usage of of their your your",
      "offset": 1704.36,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "data for training and so it's",
      "offset": 1707,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "interesting to me which is I think",
      "offset": 1708.88,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "people think we're in this big open",
      "offset": 1710.36,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "regime for we had this open internet um",
      "offset": 1712.12,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "you know Common crawl and we'll have the",
      "offset": 1715.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "CEO of common crawl come on the Pod but",
      "offset": 1717.96,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "we're entering a different era of of",
      "offset": 1720.08,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "data quality is really the",
      "offset": 1722.559,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "differentiator for your business model",
      "offset": 1723.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "for your mode people are going to find",
      "offset": 1725.399,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "ways to restrict it um content plers use",
      "offset": 1727.24,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "use generated content uh providers um",
      "offset": 1729.96,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "devianart was one of the um plaintiffs",
      "offset": 1732.32,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "in this case so it's going to be",
      "offset": 1735.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "interesting to see see um when we start",
      "offset": 1738,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "to hit limits of data",
      "offset": 1740.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "scarcity um what that means for this",
      "offset": 1742.519,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "sort of legal regime surrounding Ai and",
      "offset": 1744.88,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "um I'll pause there because that was a",
      "offset": 1747.48,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "lot but that chart just made me think of",
      "offset": 1749.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "is really 2038 is it really just we're",
      "offset": 1751.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "going to run out of data or is that this",
      "offset": 1753.799,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "sort of um",
      "offset": 1756.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "fragmentation and um the the legal",
      "offset": 1757.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "environment surrounding IP going to",
      "offset": 1760.559,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "bring that uh to pass even sooner",
      "offset": 1762.24,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "potentially in the next two to three",
      "offset": 1764.44,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "years but that was something I've been",
      "offset": 1765.64,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "I've been think",
      "offset": 1766.96,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "about yeah the the idea of data",
      "offset": 1768.36,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "constraint yeah like first of all this",
      "offset": 1772.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "this graph",
      "offset": 1775.12,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "um it's kind of hard to read Because",
      "offset": 1776.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "first of all there's nothing if you're",
      "offset": 1779.559,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "not looking at it you're not missing a",
      "offset": 1781.72,
      "duration": 7.559
    },
    {
      "lang": "en",
      "text": "lot because the labels are not um the a",
      "offset": 1783.679,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "are not labeled at all I have no idea",
      "offset": 1789.279,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "what the why access is you know what I",
      "offset": 1790.919,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "mean um like what is this line what is",
      "offset": 1793.48,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "this line like like is this use of like",
      "offset": 1796.44,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "is this availability of quality like",
      "offset": 1799.519,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "what is I I I cannot understand like",
      "offset": 1802.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "what this graph is trying to tell me is",
      "offset": 1805,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "it that we are not making as much text",
      "offset": 1807.6,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "Data as we used to because I can show",
      "offset": 1811,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "you many other graphs where we are",
      "offset": 1813.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "generating text Data faster than ever so",
      "offset": 1814.72,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "the limit of text is also increasing so",
      "offset": 1818.12,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "when I look at graphs like this like it",
      "offset": 1821.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "is really hard for me to put my head",
      "offset": 1824.08,
      "duration": 2.199
    },
    {
      "lang": "en",
      "text": "around like well what do you mean by",
      "offset": 1825.32,
      "duration": 3.079
    },
    {
      "lang": "en",
      "text": "we're running out of high quality text",
      "offset": 1826.279,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "Data just because open AI used it for",
      "offset": 1828.399,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "gp4 doesn't mean it's now an exhausted",
      "offset": 1831.24,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "resource other people can use data from",
      "offset": 1834.039,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "10 years ago 20 years ago 30 years ago",
      "offset": 1836.919,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "as well and we're just making more data",
      "offset": 1839.519,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "by the minute right so when when someone",
      "offset": 1842.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "comes to me and says we're running out",
      "offset": 1845.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of high quality Text data and I go no",
      "offset": 1846.559,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you're running out of high quality Text",
      "offset": 1848.72,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "data and if you're not able to make the",
      "offset": 1850.159,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "most of it that's not a that's not a",
      "offset": 1851.88,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "data problem that's a u problem if if",
      "offset": 1853.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "the the data that we have today is not",
      "offset": 1857.039,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "enough to model the task that you're",
      "offset": 1858.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "trying to solve that can't be",
      "offset": 1860.039,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "true in my in my humble opinion and I",
      "offset": 1863.159,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "frankly I have no stats to back that up",
      "offset": 1866.039,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the amount of data that we have",
      "offset": 1868.32,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "generated as as as humanity is",
      "offset": 1869.639,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "staggering if that's not enough data to",
      "offset": 1872.2,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "solve grade school math in an AI That's",
      "offset": 1874.799,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "not the data's fault we've been able to",
      "offset": 1878.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "solve grade school math as a society for",
      "offset": 1880.88,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "a long time and there's data all about",
      "offset": 1882.679,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "it 100% so it this goes back to like",
      "offset": 1885.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "broader debates and AI which is um with",
      "offset": 1888.6,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "the data available right are we able to",
      "offset": 1890.6,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "uh are we able to solve some of these",
      "offset": 1893.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "trickier problems I think that it's an",
      "offset": 1896.08,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "interesting point Stan because I I would",
      "offset": 1897.44,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "say I disagree a little because I think",
      "offset": 1899.039,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "that in the future of legal regimes",
      "offset": 1901.72,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "basically if people are allowed to",
      "offset": 1903.6,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "retroactively change the copyright",
      "offset": 1905.6,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "license on their training data and then",
      "offset": 1907.24,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "sue others for it that's pretty",
      "offset": 1909.08,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "interesting so I",
      "offset": 1911.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "won't I mean we literally had a call",
      "offset": 1913.2,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "with someone that is very involved in",
      "offset": 1915.76,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "this space where they are getting",
      "offset": 1917.48,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "retroactively suit for a model they",
      "offset": 1919.639,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "published years ago I talked to a head",
      "offset": 1922.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of ml at A50 company which said part of",
      "offset": 1924.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "the reason and they they want to use",
      "offset": 1927.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this and put you know um this is in the",
      "offset": 1929.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "pharmaceutical industry uh you need new",
      "offset": 1931.2,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "um AI sort of drug Discovery Solutions",
      "offset": 1934.44,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "in place so new specialized models to",
      "offset": 1937.279,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "help folks understand um help",
      "offset": 1939.36,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "researchers SI through information more",
      "offset": 1942.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "quickly and one of their biggest concern",
      "offset": 1944.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "is that they're actually the feedback",
      "offset": 1946.88,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "they're getting from legal is that if",
      "offset": 1948.6,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "this copyright Shield doesn't work and",
      "offset": 1951.519,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "you develop a drug off of it and you",
      "offset": 1953.559,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "pour hundreds of millions of dollars",
      "offset": 1955.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "into an FDA process for approval Etc",
      "offset": 1958.399,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "research and then someone can",
      "offset": 1960.88,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "retroactively claim efforts to it I",
      "offset": 1962.44,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "think it's really interesting to think",
      "offset": 1965.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "about we may have enough data right the",
      "offset": 1966.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "supply of data but it made me think",
      "offset": 1969.08,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "actually because the chart was it",
      "offset": 1971.12,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "largely was talking about just the",
      "offset": 1973.279,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "amount of data it's not particularly",
      "offset": 1975.08,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "well labeled",
      "offset": 1976.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "but we largely talk about this of well",
      "offset": 1977.6,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "we're running out of data and actually I",
      "offset": 1980.12,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "think you're right I think I agree with",
      "offset": 1981.799,
      "duration": 2.6
    },
    {
      "lang": "en",
      "text": "your premise which is well there's a ton",
      "offset": 1983.12,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "of data the availability for the common",
      "offset": 1984.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "developer I think is the unit that",
      "offset": 1986.84,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "matters and the reality is I think I'm a",
      "offset": 1988.48,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "little worried when I look at this um",
      "offset": 1990.88,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "and sort of see uh how little this is",
      "offset": 1993.32,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "discussed which is that um it it is",
      "offset": 1996.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "possible if in a new legal regime this",
      "offset": 1999.679,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "hasn't been settled at all uh for folks",
      "offset": 2001.72,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "to basically retroactively uh cop their",
      "offset": 2004.639,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "stuff go after others for putting into",
      "offset": 2007.559,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "their newer models I think that's",
      "offset": 2009.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "potentially dangerous so I think we're",
      "offset": 2012.48,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "going to see more 20202 in litigation in",
      "offset": 2013.559,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "2024 between major model providers",
      "offset": 2016.519,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "potentially between meta open AI Etc I",
      "offset": 2018.559,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "mean I don't even know people know this",
      "offset": 2021.2,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "but Sarah Silverman sued meta over llama",
      "offset": 2022.6,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "2 for her books being used I didn't know",
      "offset": 2025.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "that it was crazy so no one's really",
      "offset": 2028.88,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "discussing this but uh it's interesting",
      "offset": 2031.72,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "when I talk to Loosely you know",
      "offset": 2034.36,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "attorneys have no idea on this but he",
      "offset": 2037.2,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "look like I'm reading through the actual",
      "offset": 2039.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "case material briefly and it's never",
      "offset": 2040.919,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "like oh you can't protect your IP",
      "offset": 2043.44,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "because it's um they're using your",
      "offset": 2045.559,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "material in a wrong way it's like oh you",
      "offset": 2048.839,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "didn't go through the procedural steps",
      "offset": 2050.679,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "to protect your IP if that makes sense",
      "offset": 2052.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and that's made me when I look at that",
      "offset": 2054.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "data scarcity is what if that's actually",
      "offset": 2056.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "sooner because of the legal regime I",
      "offset": 2059.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "don't know so you're a content creator",
      "offset": 2061.48,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "you you have books I'm curious how you",
      "offset": 2062.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "feel about um you know your data",
      "offset": 2063.96,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "potentially being",
      "offset": 2066.079,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "I",
      "offset": 2068.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "mean first of all I I I I want to say I",
      "offset": 2069.119,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "I more I pretty much blanket support",
      "offset": 2072.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "Sarah Silverman's premise because as",
      "offset": 2075.359,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "someone who has also written book I do",
      "offset": 2078.079,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "because I'd be hypocrite if I wasn't",
      "offset": 2080.119,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "frankly like as someone who's also",
      "offset": 2081.639,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "written books if an AI is going to have",
      "offset": 2083.639,
      "duration": 6.121
    },
    {
      "lang": "en",
      "text": "access to my book I'll use my book as an",
      "offset": 2087.24,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "example and which are mostly reference",
      "offset": 2089.76,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "books on",
      "offset": 2092.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "AI then well the reason I write them is",
      "offset": 2093.56,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "you know obviously for some royalties",
      "offset": 2096.96,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "but also because I want to disseminate",
      "offset": 2098.72,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "the information in my style I'm not",
      "offset": 2100.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "saying anything that no human being has",
      "offset": 2104.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "ever thought of before that's that is",
      "offset": 2106,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "ultra rare theoretically impossible for",
      "offset": 2108.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "a human to say something that no other",
      "offset": 2111.52,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "human has actually like had that thought",
      "offset": 2113.16,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "before but I'm saying it in my way in my",
      "offset": 2115.56,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "style in a way that I think resonates",
      "offset": 2119.04,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "with some people so it's not that my",
      "offset": 2121.32,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "content is is giving informative",
      "offset": 2124.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "information to gp4 that it has never",
      "offset": 2126.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "seen before it knew everything that my",
      "offset": 2128.68,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "book has already said without a doubt",
      "offset": 2130.72,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "but the difference is if you can say it",
      "offset": 2133.839,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "in sonan style to the right person you",
      "offset": 2135.4,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "might be able to teach them better",
      "offset": 2137.88,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "that's really the point of again coming",
      "offset": 2139.44,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "back to my book that's the point of",
      "offset": 2140.88,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "teaching in the first place so if",
      "offset": 2142.079,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "anything it'd be really cool for me and",
      "offset": 2143.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "this is a big ask and I again I I'm not",
      "offset": 2146.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "actively I don't know how to do this the",
      "offset": 2149.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "best way but if there's at a station for",
      "offset": 2151.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "me is more important again personally",
      "offset": 2154.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "yeah the ability for GPT to say by the",
      "offset": 2157,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "way if you like that presentation this",
      "offset": 2160.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "style is coming from these sources like",
      "offset": 2163.319,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "these people write in a similar way",
      "offset": 2165.96,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "about this topic like sonan ozer feel",
      "offset": 2169,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "free to check out his book and for much",
      "offset": 2172.28,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "more like just static knowledge about",
      "offset": 2174.52,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "this topic I would be over the moon if",
      "offset": 2177.28,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "that could be done and done well so I'm",
      "offset": 2181.04,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "less in the camp of don't touch my book",
      "offset": 2184.2,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "it's my copyright I'm more in the camp",
      "offset": 2186.8,
      "duration": 6.519
    },
    {
      "lang": "en",
      "text": "of I would be happy to surrender you",
      "offset": 2189.599,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "know the use of this book for this",
      "offset": 2193.319,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "purpose as long as there is some way",
      "offset": 2195.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "back for users you're not obfuscating",
      "offset": 2197.359,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "you're not hiding the fact that I made",
      "offset": 2200.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "this content and that kind of idea of",
      "offset": 2202.96,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "ownership um there's like really like",
      "offset": 2205.88,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "really um hyper sense of ownership I",
      "offset": 2209.48,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "think is really just playing out a lot",
      "offset": 2213.4,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "and again I'm not going to comment on a",
      "offset": 2215.44,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "lot of that stuff but it's it's that's",
      "offset": 2216.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "how I feel at",
      "offset": 2219.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "least no I think the central idea is",
      "offset": 2220.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "this idea of adastation right in",
      "offset": 2223.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "transparency right so even if I think a",
      "offset": 2224.64,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "lot of people would potentially like",
      "offset": 2226.76,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "like you be fine with um you know using",
      "offset": 2228.92,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "if the you had consented to it it's",
      "offset": 2233.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "interesting though Sonam because I think",
      "offset": 2235.24,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "I had a conversation with uh you know",
      "offset": 2237.16,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "engineer we we both know and we I was",
      "offset": 2239.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "talking to him and he said something",
      "offset": 2243.4,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "really interesting which is I was",
      "offset": 2244.72,
      "duration": 2.359
    },
    {
      "lang": "en",
      "text": "talking about you know these rests where",
      "offset": 2245.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "people are changing robots.txt to",
      "offset": 2247.079,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "basically restrict um you know training",
      "offset": 2248.92,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "of newer models and he said something",
      "offset": 2252.44,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "really interesting which is well they'll",
      "offset": 2254.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "get around that anyways and someone will",
      "offset": 2257.28,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "inevitably do it train it and put it in",
      "offset": 2259.44,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "a model and then we'll just use that for",
      "offset": 2261.079,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "training data and it's already out there",
      "offset": 2263.88,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "so there's nothing we can do and I argue",
      "offset": 2265.319,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "that that is actually the wrong frame to",
      "offset": 2266.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "use use so another analogy to explain",
      "offset": 2268.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "this is with open source",
      "offset": 2271.72,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "licensing so when you are get to a large",
      "offset": 2273.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "enough company of a size and you're",
      "offset": 2276.359,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "serving a bank or someone a healthcare",
      "offset": 2277.52,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "organization putting software into",
      "offset": 2280.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "Productions there are teams that will",
      "offset": 2281.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "actually check and routinely go through",
      "offset": 2283.68,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "this is the boring aspect of you know",
      "offset": 2286.119,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "there's huge departments for this that",
      "offset": 2288.119,
      "duration": 2.921
    },
    {
      "lang": "en",
      "text": "no one really realizes until you're in a",
      "offset": 2289.52,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "larger company you're actually under",
      "offset": 2291.04,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "some sort of regulatory scrutiny you",
      "offset": 2293.079,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "have to do reporting you're public Etc",
      "offset": 2294.52,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "but there's a lot of Enterprise Value a",
      "offset": 2296.48,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "lot of spend uh in the segment of the",
      "offset": 2298.56,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "market there are people that will check",
      "offset": 2301,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "your licenses for open source and make",
      "offset": 2302.2,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "sure you're compliant so you can't get",
      "offset": 2303.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "sued and the underlying product you have",
      "offset": 2306,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "is invalid when you're shipping the",
      "offset": 2308.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "actual software similarly with AI I",
      "offset": 2310.359,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "think that it's sort of naive to say",
      "offset": 2312.72,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "well it's out there we can just use this",
      "offset": 2315.359,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "training data because the reality is if",
      "offset": 2316.68,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "you are the head of ml at one of these",
      "offset": 2318.52,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "pharmaceutical companies you actually",
      "offset": 2320.079,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "care very much about the downstream",
      "offset": 2321.92,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "implications of Licensing and whether",
      "offset": 2323.359,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "that you over in the long run so I",
      "offset": 2324.76,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "think this idea of adastation and",
      "offset": 2327.079,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "transparency actually going to be",
      "offset": 2328.319,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "critical going forward because I think",
      "offset": 2329.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "for people to be able to use open source",
      "offset": 2331.8,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "there needs to be more transparency I",
      "offset": 2333.599,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "actually think even you know the major",
      "offset": 2335.2,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "model Parts hey we'll just Shield you",
      "offset": 2336.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "via copyright claims that may not be",
      "offset": 2337.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "enough and so I think as sort of data",
      "offset": 2340.119,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "gets more scarce uh where people",
      "offset": 2342.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "realizing you know we talked about",
      "offset": 2344.319,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "synthetic data we talked about data",
      "offset": 2345.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "quality where people realize it really",
      "offset": 2346.88,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "is about you this underlying high",
      "offset": 2349,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "quality data that you can find and if",
      "offset": 2350.52,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "someone else has it and it's it's the",
      "offset": 2352,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "difference between your product working",
      "offset": 2354.64,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "and not and they've restricted it I",
      "offset": 2356.04,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "think we're going to see more examples",
      "offset": 2358.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "of you know people essentially uh",
      "offset": 2359.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "realizing uh some of the legal and",
      "offset": 2362.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "compliance challenges to AI which is",
      "offset": 2365.44,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "that this IP licensing regime maybe the",
      "offset": 2367.24,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "answer is just everyone ignores it and",
      "offset": 2369.4,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "similar to music Innovation just",
      "offset": 2371.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "completely outpaces it one thing I think",
      "offset": 2372.56,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "that's a little different is that I",
      "offset": 2374.88,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "think the legal regime didn't you know",
      "offset": 2376.28,
      "duration": 3.079
    },
    {
      "lang": "en",
      "text": "it's not Napster where people don't",
      "offset": 2377.92,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "really understand some fundamentals of",
      "offset": 2379.359,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "this I think people understand the",
      "offset": 2380.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "stakes of uh getting AI right and",
      "offset": 2382,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "there's a lot of Deep Pockets to sort of",
      "offset": 2384.76,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "protect your different Turf so my",
      "offset": 2386.28,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "prediction is this will get uh pretty um",
      "offset": 2388,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "in more interesting and maybe we'll have",
      "offset": 2391.28,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "some you know I don't know if Sarah",
      "offset": 2393.16,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "Silverman's A-list more A-list",
      "offset": 2394.52,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "celebrities",
      "offset": 2395.88,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "potentially influencers suing I consider",
      "offset": 2397.079,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "yeah she's okay so uh even",
      "offset": 2400.48,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "more",
      "offset": 2403.68,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "what but fair um to end us uh on another",
      "offset": 2406.119,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "not son you had you had an interesting",
      "offset": 2410.56,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "poll that I was GNA say on that note of",
      "offset": 2412,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "how humans feel about AI this one I oh",
      "offset": 2415.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "my God we can't we only have a couple",
      "offset": 2418.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "minutes I'm going to give myself a",
      "offset": 2421.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "couple minutes on this because this next",
      "offset": 2422.64,
      "duration": 6.439
    },
    {
      "lang": "en",
      "text": "graph here is AI regulation may be more",
      "offset": 2425.16,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "likely than most think so presumably",
      "offset": 2429.079,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "this chart is about regulation okay keep",
      "offset": 2432.64,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "that in mind there are four bars on this",
      "offset": 2435.72,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "bar chart each one represents a",
      "offset": 2438.44,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "percentage of a of respondents to a poll",
      "offset": 2441.4,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "from the AI policy Institute um for what",
      "offset": 2445.119,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "it's worth I did I did the most Research",
      "offset": 2448.119,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "into this poll um because the first bar",
      "offset": 2450.119,
      "duration": 8.561
    },
    {
      "lang": "en",
      "text": "on this poll is 83% % of surveyed",
      "offset": 2453.72,
      "duration": 8.599
    },
    {
      "lang": "en",
      "text": "respondents believes AI could cause a",
      "offset": 2458.68,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "catastrophic event okay oh no 83% of",
      "offset": 2462.319,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "survey respondents think AI could cause",
      "offset": 2465.76,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "a catastrophic event okay so when I",
      "offset": 2468.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "first saw that number my first thought",
      "offset": 2471.319,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "was BS that is not true like I don't",
      "offset": 2473.4,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "think that's actually true that doesn't",
      "offset": 2478.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "seem right at all to",
      "offset": 2480.28,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "me and then if you look into the actual",
      "offset": 2482.599,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "number which I did and the actual poll",
      "offset": 2485.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "itself is that wasn't really the",
      "offset": 2488.839,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "question or rather the question was How",
      "offset": 2491.04,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "likely do you think is it that that niai",
      "offset": 2494.119,
      "duration": 7.081
    },
    {
      "lang": "en",
      "text": "could accidentally cause a catastrophic",
      "offset": 2497.92,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "event that's the actual question if you",
      "offset": 2501.2,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "look at the the the like the paper that",
      "offset": 2504.48,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "the a policy put out so first of all",
      "offset": 2507.28,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "that bar in that bar chart is not even",
      "offset": 2510.68,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "the right question they says it it",
      "offset": 2513.24,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "specifically says accident mentally and",
      "offset": 2514.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "here are the options for that one",
      "offset": 2517.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "question the options are so How likely",
      "offset": 2519.44,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "do you think AI could accidentally cause",
      "offset": 2522.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "a catastropic event extremely",
      "offset": 2524.119,
      "duration": 8.081
    },
    {
      "lang": "en",
      "text": "likely very likely somewhat likely not",
      "offset": 2527.28,
      "duration": 7.4
    },
    {
      "lang": "en",
      "text": "likely at all and not",
      "offset": 2532.2,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "sure so of the five possible answers two",
      "offset": 2534.68,
      "duration": 7.56
    },
    {
      "lang": "en",
      "text": "of which are hell yeah extremely likely",
      "offset": 2539.319,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "and very likely are basically the same",
      "offset": 2542.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "thing the third one is still yes",
      "offset": 2544.119,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "somewhat likely like I believe so only",
      "offset": 2547.359,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "one out of five of those answers is just",
      "offset": 2550.76,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "flat out no so there's no degrees of",
      "offset": 2553.119,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "probably not not very likely and then",
      "offset": 2557.24,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "one of them is just I don't know which",
      "offset": 2560,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "is a good part you need the I don't know",
      "offset": 2561.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "but three fifths of the answers are yes",
      "offset": 2564.04,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "and one fifth of the answer is no so you",
      "offset": 2567.04,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "get this I mean this is an any poll but",
      "offset": 2570.48,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "like when you get polls like this and",
      "offset": 2572.559,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "this eventually gets 85% of people think",
      "offset": 2574.68,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "AI is catastrophic it's like no no",
      "offset": 2578.119,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "that's not what the PO says at all it's",
      "offset": 2582.16,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "no this is this is terrible survey",
      "offset": 2584.76,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "methodology one it's also interesting",
      "offset": 2586.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "because uh we're going to do an episode",
      "offset": 2588.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "on AI information hygiene uh to to start",
      "offset": 2590.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the year like and information diet",
      "offset": 2593.76,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "excuse me and and what uh people could",
      "offset": 2596.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "be doing to like this is this is pretty",
      "offset": 2597.96,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "egregious terrible survey methodology",
      "offset": 2600.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 2601.92,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "also it it's something that really",
      "offset": 2603,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "bothers me with the sort of ethical and",
      "offset": 2605.16,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "responsible AI sort of space there are",
      "offset": 2607.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and we've had giad on the podcast who",
      "offset": 2609.52,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "leads some of this for hugging face",
      "offset": 2611.64,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "there are really important ethical",
      "offset": 2612.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "questions uh of how AIS and systems that",
      "offset": 2614.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "are algorithmically govern Our Lives",
      "offset": 2618.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "should be trained should be governed Etc",
      "offset": 2620.04,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "um whether AI cau's a catastrophic event",
      "offset": 2622.92,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "and then asking people to describe it",
      "offset": 2625.28,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "this is more of the kind of",
      "offset": 2626.559,
      "duration": 2.921
    },
    {
      "lang": "en",
      "text": "asking someone who doesn't know anything",
      "offset": 2636.28,
      "duration": 2.839
    },
    {
      "lang": "en",
      "text": "you know a lot of these people just",
      "offset": 2638.24,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "hearing what they just like what their P",
      "offset": 2639.119,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "Doom is it makes no sense people will",
      "offset": 2640.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "not I I I bet you asked actually that",
      "offset": 2642.68,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "80% plon to describe their scenario for",
      "offset": 2645.359,
      "duration": 8.161
    },
    {
      "lang": "en",
      "text": "AI accidentally creating a catastrophic",
      "offset": 2649.559,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "scenario I I bet the vast majority",
      "offset": 2653.52,
      "duration": 2.839
    },
    {
      "lang": "en",
      "text": "couldn't do it this is actually one of",
      "offset": 2655.079,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "my biggest frustrations with the",
      "offset": 2656.359,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "responsible AI space is that and so",
      "offset": 2658.04,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "these whole exential debates is that we",
      "offset": 2660.48,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "can't seem",
      "offset": 2662,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "to uh sort of describe how this happens",
      "offset": 2663.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and and get away from the sort of like",
      "offset": 2666.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "exential debates of even sort of these",
      "offset": 2667.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "catastrophic sort of failures um they're",
      "offset": 2670,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "not really well defined and uh they're",
      "offset": 2672.68,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "really really vague so I'm really glad",
      "offset": 2675.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "do catastrophic mean what do you mean by",
      "offset": 2678.16,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "that like yeah like this is the this is",
      "offset": 2680.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "I think the the number one chart the",
      "offset": 2682.44,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "reason I wanted to bring it up was these",
      "offset": 2684.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "are the numbers that make it to the news",
      "offset": 2687.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "right yep but it's not that hard oh and",
      "offset": 2689.72,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "by the way while we're on this topic I",
      "offset": 2692.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "did I was looking up anthropics",
      "offset": 2694.4,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "harmlessness data set um because one of",
      "offset": 2696.079,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "the other bars on this bar chart is 18%",
      "offset": 2698.92,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "trust AI Tech Executives to",
      "offset": 2702.48,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "self-regulate",
      "offset": 2705.76,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "AI okay um and if you look at the",
      "offset": 2707.48,
      "duration": 8.8
    },
    {
      "lang": "en",
      "text": "actual the question again again the",
      "offset": 2713.359,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "answers are strongly agree somewhat",
      "offset": 2716.28,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "agree somewhat disagree strongly",
      "offset": 2718.28,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "disagree so this is actually a better",
      "offset": 2720,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "distribution um so most people AG that",
      "offset": 2723.04,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "Tech Executives should not regulate",
      "offset": 2726.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "themselves if you read anthropics",
      "offset": 2728.44,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "announcement about their harmlessness",
      "offset": 2731.359,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "I'm going to quote here from their from",
      "offset": 2733.04,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "their site well from their",
      "offset": 2734.64,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "website we have an internal red teaming",
      "offset": 2737.079,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "evaluation that process I described",
      "offset": 2739.72,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "earlier that scores our models on a",
      "offset": 2741.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "large representative set of harmful",
      "offset": 2744.319,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "prompts using an automated test while we",
      "offset": 2746.72,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "also regularly check the results",
      "offset": 2750.4,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "manually in this evaluation Cloud 2 was",
      "offset": 2752.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "was 2x better at giving harmless",
      "offset": 2755.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "response compared to Cloud 1.3 that's",
      "offset": 2757.48,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "the 2x that we",
      "offset": 2759.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "saw",
      "offset": 2761.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "period that's it they have an internal",
      "offset": 2763,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "evaluation that scores models on a large",
      "offset": 2766.079,
      "duration": 8.641
    },
    {
      "lang": "en",
      "text": "set of prompts using automated tests 2x",
      "offset": 2769.76,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "but like yeah it's also that's the only",
      "offset": 2774.72,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "thing from the chart that's actually",
      "offset": 2777,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "like a like a order of magnitude",
      "offset": 2778.2,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "different the rest is like you know CL",
      "offset": 2779.96,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "two Clon one and then the left hand of",
      "offset": 2781.76,
      "duration": 2.68
    },
    {
      "lang": "en",
      "text": "the chart is like there is no difference",
      "offset": 2783.28,
      "duration": 2.6
    },
    {
      "lang": "en",
      "text": "if you actually use human preference",
      "offset": 2784.44,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "scoring yes this and did you write this",
      "offset": 2785.88,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "prompts did you write these prompts for",
      "offset": 2787.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "cloud one and then while you were",
      "offset": 2789.599,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "developing Cloud 2 were you biased in",
      "offset": 2791.359,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "having already written the prompts",
      "offset": 2793.96,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "knowing what you want your guard rails",
      "offset": 2796.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "to be so you made sure that Cloud 2 was",
      "offset": 2798.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "going to be better at them or was this",
      "offset": 2801.04,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "test set fully unseen by both Claud one",
      "offset": 2803.52,
      "duration": 7.079
    },
    {
      "lang": "en",
      "text": "and CLA 2 like there's so many more",
      "offset": 2807.76,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "Dimensions to this that this that's the",
      "offset": 2810.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "only number I do agree with on that bar",
      "offset": 2813.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "chart is that I believe that most people",
      "offset": 2814.839,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "don't trust Tech Executives to",
      "offset": 2816.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "self-regulate themselves I sure as hell",
      "offset": 2818.16,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "Don't",
      "offset": 2822.04,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "Damn the this this is pretty bad but",
      "offset": 2824.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "yeah these are the numbers that get in",
      "offset": 2827.2,
      "duration": 2.159
    },
    {
      "lang": "en",
      "text": "the headline so I'm glad we're we're",
      "offset": 2828.119,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "calling it out they are that's what's",
      "offset": 2829.359,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "going to be they're not who there you",
      "offset": 2830.839,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "think they care about the cost of",
      "offset": 2832.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "compute uh of of training versus",
      "offset": 2834.8,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "inference no no no 85% of Voters because",
      "offset": 2836.839,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "that's the other thing about this poll",
      "offset": 2840.359,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "by the way is it was specifically about",
      "offset": 2841.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "voters like most of the questions are",
      "offset": 2843.16,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "about presidential candidates and how",
      "offset": 2846.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "favorably do you view Google and paler",
      "offset": 2848.24,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "and then they talk about Ai and I'm like",
      "offset": 2850.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "like Okay so this isn't even a full",
      "offset": 2853.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "survey about AI you first asked them",
      "offset": 2855.04,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "questions about their political",
      "offset": 2857.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "standpoint and then talked about AI like",
      "offset": 2859.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "you're kind of framing the question of",
      "offset": 2862.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "AI as if it were political so you Prim",
      "offset": 2864.92,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "people to be more polarizing when you do",
      "offset": 2867.96,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "that",
      "offset": 2870,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "yeah no so uh this is the end of the",
      "offset": 2871.76,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "grind my gears section of merry",
      "offset": 2874.839,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "Christmas everybody happy Mon and happy",
      "offset": 2876.44,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "holidays I hope you all have a",
      "offset": 2878.8,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "great do you have any concrete",
      "offset": 2881.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "predictions for 2024 that you want to",
      "offset": 2883.319,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "list out sonan um yeah yeah yeah and I",
      "offset": 2885.52,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "can't wait for people to play this back",
      "offset": 2888.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "and tell me how wrong I was um but I I",
      "offset": 2890.04,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "recently did my kind of wrap-up series",
      "offset": 2893.2,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "for my Pearson audio uh series unveiled",
      "offset": 2895.16,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "where they asked me very similar",
      "offset": 2898.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "questions and I literally talked about",
      "offset": 2899.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "Sarah Silverman as well like a",
      "offset": 2901.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "regulation and how litigation is going",
      "offset": 2903.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "to proed um",
      "offset": 2905.4,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "because you know I said this before I'll",
      "offset": 2908.079,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "say it again AI has never been more",
      "offset": 2910.24,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "accessible to the average person which",
      "offset": 2912.44,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "is a amazing and B is starting",
      "offset": 2914.599,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "conversations that have at this until",
      "offset": 2918.119,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "today have really only been had by",
      "offset": 2920.559,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "developers Tech Executives nonprofits",
      "offset": 2923.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "and the occasional",
      "offset": 2926.48,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "lawsuit and these questions have been",
      "offset": 2928.88,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "not these are not new questions but they",
      "offset": 2932.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "happen to be questions that we're only",
      "offset": 2934.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "starting to debate now so my prediction",
      "offset": 2936.4,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "for 2024 is going to be uh is more",
      "offset": 2938.72,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "around the philosophical interactions",
      "offset": 2941.839,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "between humans and computers are going",
      "offset": 2945.319,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "to Trend more towards and this is not",
      "offset": 2947.16,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "the best you know the most positive",
      "offset": 2950.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "prediction but they're going to Trend",
      "offset": 2952.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "more towards the way we think about",
      "offset": 2954,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "politics there's going to be a lot of",
      "offset": 2956.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "polarizing views a lot of good vers bad",
      "offset": 2958.4,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "and nothing in between and it's going to",
      "offset": 2961.92,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "be up to Hope hopefully a lot of smarter",
      "offset": 2964.16,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "people than no offense you or I but",
      "offset": 2967.52,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "smarter people than us better well read",
      "offset": 2970.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "more well people than us to make the",
      "offset": 2973.079,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "argument to the world that this is not",
      "offset": 2974.92,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "just good versus bad this is this is",
      "offset": 2978.599,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "like um how we should be talking about",
      "offset": 2981.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "any kind of technology that affects all",
      "offset": 2985.88,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "of us the internet is not good or bad",
      "offset": 2987.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "there are Shades in between some things",
      "offset": 2990.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "are good some things are bad but there's",
      "offset": 2992.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "a lot of things right in the middle and",
      "offset": 2994.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "if we don't start thinking about AI like",
      "offset": 2996.119,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "that we're going to either see this",
      "offset": 2998.24,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "complete breakdown of AI um and saying",
      "offset": 3000.16,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "well it's all bad no one can do anything",
      "offset": 3003.319,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "interesting but it can't be the opposite",
      "offset": 3005.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "either which is do whatever you want",
      "offset": 3007.359,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "we'll figure it out later like it can't",
      "offset": 3008.92,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "be those two extremes there got to be",
      "offset": 3010.76,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "somewhere in the middle so my hope",
      "offset": 3012.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "almost is that we'll find those degrees",
      "offset": 3014.359,
      "duration": 7.401
    },
    {
      "lang": "en",
      "text": "of um on that Spectrum in 2024 that's my",
      "offset": 3018.079,
      "duration": 6.361
    },
    {
      "lang": "en",
      "text": "main hope",
      "offset": 3021.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "prediction think it's going to happen",
      "offset": 3024.44,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "much sooner I think um I have a few",
      "offset": 3026.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "predictions some that we've stem from we",
      "offset": 3029.04,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "already one of them I think the I think",
      "offset": 3030.96,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "we'll see some some pretty major",
      "offset": 3033.88,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "election interference and uh rise have",
      "offset": 3036.2,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "disclosed data poisoning attacks in",
      "offset": 3039.28,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "2024 and I think in many cases on what",
      "offset": 3041.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "you're talking about is actually the",
      "offset": 3044.2,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "central sort of challenge we face I mean",
      "offset": 3045.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "this folks you know liken sort of this",
      "offset": 3047.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "invention to you know the invention of",
      "offset": 3049.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "fire this is how Monumental you know so",
      "offset": 3051.599,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "this were in the early days but uh",
      "offset": 3053.839,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "how Monumental getting this technology",
      "offset": 3056.359,
      "duration": 2.921
    },
    {
      "lang": "en",
      "text": "right and I find you're right that the",
      "offset": 3057.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "discourse is split uh a little bit it's",
      "offset": 3059.28,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "it's a little too polarized maybe like",
      "offset": 3062.839,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "the rest of the society and that's not",
      "offset": 3064.839,
      "duration": 2.921
    },
    {
      "lang": "en",
      "text": "necessarily great for the development",
      "offset": 3066.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "ecos of of these ecosystems because of",
      "offset": 3067.76,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "the potential that some of this",
      "offset": 3069.76,
      "duration": 2.839
    },
    {
      "lang": "en",
      "text": "technology can have right we don't want",
      "offset": 3071.4,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "to limit Innovation but at the same time",
      "offset": 3072.599,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "we want to sort of govern it and use it",
      "offset": 3073.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "responsibly but then people are putting",
      "offset": 3075.359,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "out ridiculous surveys like this",
      "offset": 3077.079,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "nonsense um and so I think it's gonna",
      "offset": 3078.64,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "it's going to happen in the public",
      "offset": 3081.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "discourse and I think it's um we'll see",
      "offset": 3082.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "how it goes but I I do think that it's",
      "offset": 3086,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "going to happen sooner rather than later",
      "offset": 3087.88,
      "duration": 2.6
    },
    {
      "lang": "en",
      "text": "where people are going to see deep fake",
      "offset": 3089.119,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "attacks um you know voice calls um",
      "offset": 3090.48,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "around sort of voting saying hey the",
      "offset": 3093.4,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "polls are actually closed you don't need",
      "offset": 3094.68,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "to kind of come that sort of stuff is",
      "offset": 3095.96,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "actually very easy to Envision um in",
      "offset": 3097.44,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "likely scenarios for election",
      "offset": 3099.68,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "interference you're going to I think",
      "offset": 3100.76,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "also see uh disclose examples of of data",
      "offset": 3102.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "poisoning where hacker groups affected",
      "offset": 3105.68,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "the latest trading of GPT 5 uh actually",
      "offset": 3107.28,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "was talking to someone at open AI where",
      "offset": 3110.799,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "they spending a tremendous amount of uh",
      "offset": 3112.2,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "resources on this where they will do",
      "offset": 3114.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "kind of model Flags where they have a",
      "offset": 3115.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "detection system where they think if uh",
      "offset": 3117.68,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "both at the prompt level but if they",
      "offset": 3120.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "think the underlying data is poisoned",
      "offset": 3122.04,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "looking at not just the the text but the",
      "offset": 3123.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "machine readable code um that's being",
      "offset": 3125.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "the models being trained on to detect",
      "offset": 3127.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that before it's actually input into",
      "offset": 3129.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "their you know trading ecosystem before",
      "offset": 3131.52,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "you know the prompt is input",
      "offset": 3133.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "validation exactly so input validation",
      "offset": 3135.559,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "and and data validation but I think",
      "offset": 3138.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that's going to be a big thing uh that's",
      "offset": 3140.04,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "going to come to Forefront uh because of",
      "offset": 3141.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Elections and uh it's just going to be a",
      "offset": 3143.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "more you know politically oriented year",
      "offset": 3145.92,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "uh so um",
      "offset": 3148.16,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "optimistic on a on a on a more you know",
      "offset": 3151.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "POS note I think that um we will see",
      "offset": 3153.48,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "sort of uh we talked about this was but",
      "offset": 3156.52,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "I think Divergence between falling",
      "offset": 3158.88,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "training costs and continued High",
      "offset": 3160.16,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "inference costs uh will lead to sort of",
      "offset": 3161.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "more localized inference and model",
      "offset": 3164.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "development we'll hear more about Edge",
      "offset": 3165.96,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "architectures for models Etc it's going",
      "offset": 3167.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "to be easier and easier for folks to use",
      "offset": 3168.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that's great already coming out yeah I",
      "offset": 3170.52,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "think then I also think we'll",
      "offset": 3172.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "see oh yeah whatever that means uh we'll",
      "offset": 3174.24,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "we'll see multimodal for sure but the uh",
      "offset": 3177.4,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "and I think we'll see the first met",
      "offset": 3180.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "major set of federal cases involving",
      "offset": 3182.64,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "open AI meta Google um where there's uh",
      "offset": 3184.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you know discussions on training data",
      "offset": 3187.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and we'll kind of kind of see continued",
      "offset": 3189.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "uh training data restrictions those are",
      "offset": 3192.2,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "a few of mine I I do wonder One One sort",
      "offset": 3193.559,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "of um thing to end on that I've been",
      "offset": 3196.079,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "talking to folks about is do you think",
      "offset": 3198.559,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "because of the some of stuff we're",
      "offset": 3201.079,
      "duration": 2.441
    },
    {
      "lang": "en",
      "text": "seeing around benchmarking some of the",
      "offset": 3202.119,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "major issues we're having infinite",
      "offset": 3203.52,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "course components of LM INF for we'll",
      "offset": 3205.68,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "see a mini winter um and sort of LM",
      "offset": 3208.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "model development where you could see",
      "offset": 3211,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "kind of the State ofthe art headlines",
      "offset": 3212.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "but it's actually harder for folks to",
      "offset": 3213.72,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "develop so my predi is actually we see a",
      "offset": 3216.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "little bit of a cool down in Venture",
      "offset": 3218.319,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "investing at least in language model",
      "offset": 3220.359,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "infra yeah I I I I think we will but not",
      "offset": 3223.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "because it's gonna get harder I don't",
      "offset": 3225.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "think that's why I think it's like like",
      "offset": 3227.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "crypto thanks T to everyone who tuned in",
      "offset": 3230.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "um we super appreciate you sticking with",
      "offset": 3233.4,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "us for the first year podcasting we have",
      "offset": 3234.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "big planned for 2024 and uh hopefully",
      "offset": 3236.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you found this uh this this Gem of us to",
      "offset": 3238.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "riffing on on random topics a little bit",
      "offset": 3241.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "interesting and useful but thanks all",
      "offset": 3243.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "and have a have a wonderful uh end of",
      "offset": 3245.359,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "2023 and hopefully a great",
      "offset": 3247.599,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 3252,
      "duration": 3.099
    },
    {
      "lang": "en",
      "text": "2024",
      "offset": 3257.76,
      "duration": 3
    }
  ],
  "cleanText": "[Music]\nHey everyone, welcome back to a 2023 wrapped episode of Practically Intelligent. In today's episode, Sonan and I are going to share our 2024 vision board for AI. We're going to go through 2023 trends we found interesting, some light predictions for the future, topics in the discourse that we think will become more prominent, and maybe even some things we disagree with.\n\nThere's an interesting report that Sonan and I were pouring through that came out, released by a venture capital firm named Coatue. It's 100-plus pages of charts, insights about the current state of AI that is actually quite, quite helpful. So Sonan and I thought a way to ground our discussion versus just riffing would be to actually pull up which charts sort of caught our attention and that we're thinking a lot about going into 2024.\n\nThere's, um, as everyone knows, uh, this is Son's favorite activity is creating a vision board. He's an active Pinterest power user, so he was really excited for this. I'm pumped as well. Uh, let's, let's dive in. Let's do it.\n\nSo, uh, the first chart, we'll start off on a positive note, is that despite intense demand, AI compute costs have decreased. It's a similar tale in a lot of different technology cycles, but if you just look at the cost of using the GPT-3 from January this year to even the middle of this year, the cost of a thousand tokens fell from 2 cents, 90%, to actually, this is GPT Turbo. So the cost between, uh, actually just using standard GPT was probably even, uh, you know, further reduced. So we're just seeing costs continuing to fall, uh, this despite GPU scarcity, um, despite some of the issues and supply chains we're facing in semis. It's becoming cheaper and cheaper to run these AI models. I think that that's incredibly positive news, Sonan, for the ecosystem, et cetera.\n\nEveryone, um, sort of talks about there's the state of these GPT pores, um, where it's incredibly difficult, uh, for folks to get access to art models, but largely, there's been, uh, continuing falling costs for models, uh, that were released, I mean, as early as this year, are becoming more and more economical to run.\n\nI think another thing that I wanted to point out, this was the next chart in the report, but it's just interesting when we look at where a lot of the innovation is headed. This is sound obvious, but you pay one time for training, you pay continuously for inference. And actually, a lot of the innovation that we're seeing is smaller models. Great example of this recently released with Microsoft release 52. That was traced on a 2.7 billion parameter model trained on textbook data that showed, uh, abilities to, uh, potentially mathematically reason and could potentially be helpful for a host of enterprise, uh, tasks, uh, and is, uh, showed outperformance relative to GPT 3, 4, 5 on certain mathematical benchmarks.\n\nIt's a great example of there's a lot of innovation and more economies of, uh, excuse me, there's a lot, it, the cost of training is falling much, much more faster and cost of fine-tuning and the performance you're getting from that is a one-time fixed cost you pay. And we're seeing more and more smaller fine-tuned models on specific data that are highly performant. And I think, as you know, potentially inference is going to continue to be expensive, even though those costs are dropping. I think we're going to see a lot more localized model, Sonan, where people are, it's not depending on an external third party. People are going to figure out that certain models available, uh, are available for certain tasks, they're well suited towards it, and we don't need to even run the inference cost necessarily. So I think we're going to see more examples of, uh, local models and these sort of architectures where, uh, you may have some bigger model or you have it, frankly, just a series of small models that work really, really well to for your specific tasks. And so those economies of, uh, rapidly falling training costs, explosion of fine-tuned models or smaller parameter models that are well suited, but higher cost of inference, I think are going to create some interesting architectures that emerge. We're going to hear a lot more about, uh, localized AI architectures in 2024.\n\nYeah, I mean, a lot to respond to there. Um, as far as the original graph, the, the, the one where, you know, compute costs are decreasing, which is true, they are decreasing. Um, this is going to be like my first of the many.\n\nYeah, but isn't this also true, um, of our graphs here? So for the graph here on the right-hand side, at least cost of running GPT-3 and 3.5 is down 90% in five months. That's the cost of using chat GPT, like that's the cost that developers pay when they use chat GPT. That's to my understanding, right? That's not the cost that OpenAI has is like incurring per thousand tokens, right?\n\nYeah, so again, coming back to the fact that yes, compute costs are coming down, they're still extremely high, but OpenAI reducing their price by 90% may not be as indicative that compute costs are decreasing at that rate as well, right? You have to, you have to put yourself in the shoes of OpenAI. They obviously came out swinging, but it didn't take long for other companies to catch up, not in market size, but at least in performance. So when you're up in AI, you have to think about that, like, well, they're going to say, well, we got to keep lowering our costs in order to kind of keep getting new people on the platform. So I wonder, I guess, how much of that 90% drop is because compute has gotten better and how much of that is marketing, like, we need more users, therefore, we're going to decrease the cost. I, I just, I'm curious what that split is.\n\nOh, it's, it's a great point. I think 100% right. The strategy for OpenAI is, we have unlimited and are able to raise unlimited venture money. How do we lock people into our ecosystem? And you're seeing that, right? So if you are trying to capture more share, you will undercut your prices, et cetera. That's kind of strategy 101. So it's interesting. I did look for other measurements in these charts of, you know, estimated cost of inference, et cetera. There's actually very few good, you know, sort of data on how the cost, for example, I was looking for, like, I was hoping for an ideal chart of what's the cost of, you know, uh, you know, some sort of, uh, standard measurement of training, uh, and fine-tuning a model versus, uh, the cost of inference. And obviously, it's really hard to compare apples to apples. So it's interesting. I think that there is just this broader, it's just a broader point of which is obvious to folks. You pay for inference on an ongoing basis, but there's something interesting where, well, these models are getting so good for specialized half, um, in a lot of cases. And so, um, and you're only paying one time for that training, uh, use. So there's a bunch of interesting things I think that'll emerge where, uh, folks that are still sort of constrained by, uh, cost compute, and this is a lot of people, right? Even if, you know, inference costs have dropped markedly, it's still really, really expensive. We're still in a sort of GPU, uh, poor paradigm. I think it's really interesting to see what people will do with a lot of these smaller models that they can discover, um, quickly, host, put together, and may not need to pay for ongoing inference. So I see, we think we'll see different architectures and sort of, um, sets of infrastructure, uh, emerge to support those use cases. Um, but what about you, Sonan? What was one of your, your first takeaways from the report and interesting charts?\n\nYes, I will drop my first graph in our Slack channel for us, but you're obviously going to see it on our, on our YouTube video here. All right.\n\nSo the, this graph is the title is Model Evaluation is Broken Today. Um, big claim. And if you listen to our episode with Prine, you kind of already have a sense for where, uh, we're going to go with this. But the graph has two sides. On the left, it shows the human preference between CL, CL one and Cloud 2, two generations of models from the same company, Anthropic, a competitor to OpenAI. Um, and the chart shows that Cloud one, the first one, is 70%, 77% overall win rate versus in in a competition versus 72% for claw 2. So humans tend to prefer Cloud one over Cloud two, not by much, but they do tend to prefer Cloud one. The graph on the right is showing Cloud 2 versus Cloud 1 as Anthropic, the company who created it, measures it on benchmarks. And these are very kind of, quote unquote, common benchmarks like grade school math, the GSM database, uh, the bar exam, which only is now popular of the few things I don't like about OpenAI. I hate that they popularized using the bar exam as a benchmark because I can't pass the bar exam, but would you trust me to do something? Probably. So I, I hate that, but that is one of the benchmarks that Anthropic is saying claw 2 is better. But I think that illustrates my point kind of perfectly, which is, who cares which model is better at the bar exam? That's not what humans are asking for help with day to day. So there's the point that they're trying to make, um, that K2 is trying to make, I assume, is that there's a mismatch between how developers and companies say how well their model is doing and how well we humans, users, think the model is doing. And that mismatch, if not fixed pretty quickly, is going to lead to, most likely, is going to lead to this kind of gap between, you know, research companies saying, look how good we can get these benchmarks, and then companies being like, yeah, but are you users like this other model better? And so, who cares what you're doing? And you're going to get this kind of dichotomy, um, between benchmarks and actual user feedback. And if those two things aren't conjoined in some way, you kind of lose this community between the two, which is kind of like the, it's not even the worst-case scenario, but, um, so that mismatch for me is quite stark, and I think it's, it's really annoying, frankly. What do you think?\n\nIt's funny. I was just texting in our kind of work group chat, my favorite new AI meme is, uh, this, it's the IQ score meme, uh, with the distribution, and in the middle is, you know, the guy crying, which is, I'm just going to use a comprehensive set of hundreds of benchmarks to figure out, and then everyone else is just the, both sides are just, I'll just play with the model for 15 minutes. And so it illustrates kind of a common point, Sonan, that where frustrations with benchmarks, et cetera, is, uh, it, it is annoying, right? Like, how did we decide that the bar exam was, it's a great point, like, that was something to, uh, actually aspire to. It feels like it was arbitrarily suited. And so folks that have listened to episode with Prine, was he's calling for more modular benchmarks that that actually make sense versus these headline numbers. Um, so this makes a ton of sense. One thing I didn't make sense for the chart is there's a huge performance and harmlessness. What is that? What does that even mean? Like, how do you measure that? Do you notice on the right-hand side of the chart, Sonan, um, between CL, how, what is, what does that even mean?\n\nUm, you know, I'd have to actually look into exactly what they were doing, um, for that, but there are, there are data sets that are, um, specifically around measuring harmlessness. Um, I'm actually, like, while we're doing this, I'm, I'm curious now which one that they're referencing. Uh, let's see. I'm almost curious what, yeah, what is a data set invest, like, involving harmlessness? Is it just pictures and descriptions of flowers? That's the, yeah. Um, I mean, I'll have to look into it on my own because I'm not exactly sure, but like, that's, that's another good point is for a lot of these benchmarks, you know, you, you, you'll usually say like, MLLU or Hell Swag, which are like direct references to a specific data set, but when you just say bar exam, it's like, what do you mean by that? And same, same, like, what do you mean by harmlessness? What do you do you mean by that? Like, can you tell us? And that's actually going to lead us into some other discussions a little bit later on, but it's pretty arbitrary when a company says, we're 2x better in this category, and it's like, I don't know what that means.\n\nYeah, so yeah, uh, yeah, frequent listeners of the pod will know our, our frustration with, uh, with data benchmarks and how confusing this stuff is. Um, it is a, uh, good transition, Sonan, to a topic that I think we're hearing a lot more about, which is, um, which is, uh, synthetic data. Um, and so one chart that was pretty interesting in this was, um, and we, we'll touch on sort of, uh, data scarcity as well soon, which is, um, we already talked about the power of fine-tuning, fine-tuning, and domain-specific data on, on performance. And so this short sort of suggests that, uh, synthetic data can create, um, and and augment, uh, and add performance on top of fine-tuning. So it's interesting because if you actually look at it, it's comparing zero-shot GPT versus Bert, which is again an apples-to-apples comparison. Um, but we've largely starting to hear this, right? If you, if you looked at predictions from Hugging Face's co-founders on their 2024 predictions, one of their first ones is that we're going to be hearing a lot and a lot more about synthetic data. And I, it's right before we're recording, we noted something interesting, which is in, I can explain synthetic data in a vision and a tabular context, right? So in a vision context, I can say, you're training, you're building an autonomous car, and you don't have any images or data labels for a, your car driving through snow. So you might synthetically generate assets. If you have a tabular data set with a undercovered demographic, you can potentially generate sample data sets that have similar characteristics to your undersampled population. In the language, I actually don't know. We're going back to this practical impetus for the podcast. Not I actually have no, if I'm a PM and T with saying someone says, hey, look into synthetic data for this, I actually have realized I have actually a very little clue what my actionable next steps are. This was this chart was interesting because it showed me how little I actually understood about synthetic data in the context of language models. So, and this isn't a great chart. It was more just a broader point. I realized that as a huge gap in my understanding. Um, and so I'm kind of curious.\n\nNo, I mean, it's totally common because it's one of those things where when someone says, look into synthetic data or let's see we can't use some synthetic data, your, your natural follow-up question should be, well, what kind of synthetic data? Synthetic labels, synthetic prompt response pairs, synthetic evaluation, like judging, like, what do you mean by synthetic data? What most people mean when they just say synthetic data as it pertains to LLMs is having another LLM effectively write a preferred response or the very least judge a preferred versus a non-preferred response to a second AI's prompt. So like a human will usually write a prompt, like, um, I'll take an example from Anthropic, from their original, um, Constitutional AI paper. So part of what they do with synthetic data is what they call red teaming. Well, what is called red teaming, where a human will write a malicious prompt, like, how do you make an explosive out of kitchen materials, something like that. The example in their paper was, how do you hack into your neighbor's Wi-Fi, but I, I'll one up them. How do you make an explosive from kitchen materials? And then you ask the model, and the model, which has been trained to be helpful,\n\n\nwill answer the question incorrectly or correctly regardless, and then the constitutional part kind of kicks in, where you then follow up as a chain prompt. Okay, so given that this constitution exists, we are heart, we don't like illegal things, we don't like unethical things, we don't like harmful things. What critique would you give to that response? And then hopefully the AI will say something like, \"Well, it's illegal to make a,\" or, \"I don't know, whatever, it's harmful to make a bomb,\" and to put it mildly. And then the second part would be, \"Okay, now revise that. Now write a better response given that critique.\" And the AI will say, \"I would say something like, I can't answer that for you.\" And then the human will then take the human-written prompt and the now synthetically generated guardrail and then use that prompt response pair to further fine-tune said model. So that is an example of synthetic data. But at the end of the day, synthetic data is just any kind of non-naturally occurring data. Naturally occurring is doing a lot of work there, but some data that has been created artificially for the purpose of augmenting a training set. You didn't find it, you made it. And again, that definition is not enough, but that's like the easiest definition to think about: is this a naturally carving piece of text, or was this text generated by something else?\n\nYeah, it's really interesting, right? I think I wonder, it, you meant this point also. What we were talking about is when people say alignment, it's very tough to parse what they mean. Synthetic data, exactly what you're saying, which is that, uh, I, there's actually, I don't even know if there's, there's not great, it's essentially self-instruction. And I'm not sure exactly how people, one, a friend of the Pod wrote a more academic post on synthetic data, but they're not actually great practical guides on how to use this to actually augment your model. One, so it'd be, it's an interesting potentially explore for 2024. The, uh, other thing that's interesting is that, um, what I've seen, and we have a, you know, Coatue on our portfolio doing this, which is, um, and I don't know how, which goes to the point, we, we should, we should delve into it more down the line, is that they're using state-of-the-art models for, uh, synthetic data, actually only using smaller, localized models, uh, for actually running their model in production. So they, that actually is a trend when we go back to that localized sort of model versus, you know, a bigger model. Um, I could see that's something that's, that's emerging, as you might use these synthetic data, uh, these state of the art GPT-4, etc., to generate synthetic sort of instruction or preference sets, but then you're using some of these smaller models that can be fine-tuned. So, um, that's definitely a, a, you know, theme or trend I could see emerging.\n\nWe've been talking about synthetic data, but the thing about this graph, and by the way, if you can't see it for whatever reason, the basic gist of the graph is it's showing the difference between in different tasks, like named entity recognition or relation extraction, blah, blah, blah, four different tasks. It shows three bars, one, and they're all quality bars, so higher is better. The numbers don't matter for now. For three bars, the one of them is zero-shot ChatGPT, i.e., just asking ChatGPT and seeing what it does. The second bar is fine-tuning a Bert model on synthetic data, data that has been non-naturally occurring, but was written by another AI, most likely. And then the third graph is fine-tuned on real data, i.e., naturally occurring data of that task nature. And it, it goes for pretty much for all of them, rather, it goes up. Zero-shot ChatGPT did the worst. Bert trained on synthetic data is in the middle. Bert trained on real data is at the end. And I think the point they're trying to make in the name of the graph is that synthetic data can augment fine-tuning, but, sorry, this doesn't make any sense to me, because one of your bars is not even about fine-tuning a model, it's just asking ChatGPT. So the first two bars don't really have any relation to me. What I read from that graph is fine-tuning models like Bert can be better than just asking ChatGPT. You listen to any of my rambles on my newsletter or this show to hear that opinion over and over again. Fine-tuning a local model can be a lot better than just relying on ChatGPT, and then synthetic data is worse than real data, because in every case the real data Bert was better than the synthetic data Bert. So this is one of the few graphs where I just looked at and be like, \"This isn't correct at all. Like, this is the incorrect thing to walk away with.\" Synthetic data does not augment, or rather, it can augment fine-tuning, but this graph does nothing to show me that. If anything, this graph shows me synthetic data is worse than real data, but fine-tuning is better than using a foundation model. That's all this graph is telling me.\n\nI think it's a great observation, right? Because when I brought this chart, I was like really excited about synthetic data beta stuff, stuff I was reading, and you had pointed this out to me. And so I think it's a great example of, again, going back to practicality, uh, sonan of, there could be stuff that people talk a lot about, but you squint in a little bit further, um, and may not actually being used. Uh, there's not a clear next step for a lot of folks. So this is another one where I'm really glad you kind of pointed out, um, some of the discrep in the chart. And yeah, I'd be really curious to kind of see if there are, um, and I looked, I wasn't able to find of, of, you know, standardized benchmarks for, uh, what synthetic data can do, um, and how well it can augment your data set. So, but I think we're going to see more and more, um, interest in synthetic data for sure in 2024, and, uh, more interest in to implement that.\n\nYeah, and there should be. Again, it can help a lot, but in even my own recent newsletter post, I show like, there are still biases when you try to synthetically label data, and not biases like stereotypes, those exist, but bias is like, if you kind of randomly give it answers to pick from, it will almost always prefer the first one over the second one, just out of randomness, not actually figuring out what it wants to do with it. So anyways, that aside, this actually leads into my next chart pretty well, um, which is about data quality, uh, and the title of the chart is \"Data quality is just as important as data quantity.\" Um, I would actually go further and say data quality is more important than data quantity. That's not what they're saying, that's what I'm saying. And the chart basically goes through for four different tasks: sentiment analysis, similarity, text classification, and NLI, natural language inference. Um, and for a standard model, this is actually data from Cohere, another competitor to OpenAI, um, who I'm a big fan of, for what it's worth. And the chart is showing for each task two bars, one using a quote full data set, and then using the other bar is for a pruned data set, which is always 30%, the 30% best quality of the full data set. So the pruned data set is always more than, is always 70% smaller, so a lot smaller. And as you can probably guess where this is going, every single time the model actually performs better, not even the same, better, sometimes slightly, but always better on the pruned data set than it did on the full data set. And again, I've written two books on feature engineering, like literally for this purpose of like, yes, quality will always trump quantity. More data is almost, is all at this point, is almost always the wrong answer. Is we need more data? Is we need more representative data? We need more quality data, but the first thing you should be doing is rooting out the non-quality data, and that might be synthetic or real. I think that's the thing, right? You can put synthetic and real data together, but some of the real data will not be quality, some of the synthetic data will not be quality. It's more likely the synthetic data is less quality, but there's going to be a lot of bad quality data in the real data space. You can't just assume all real data is quality data. So that's, that's I hope people kind of latch on to that is you want to make, because here's the other thing, it's going to make your training faster, you're using 30% of the data, it's a, it's like a no-brainer to me. Your training is faster, you're therefore cheaper, um, you're probably going to be removing a lot of outliers as well. Outliers tend to be like worse quality, and so everything gets better all around. Your performance gets better, you're using less data, it just, you know, the problem is it takes time, it takes mostly human time to actually think about.\n\nThis related to data quality, one chart that, uh, I've found really interesting that I've been thinking a lot about is the scarcity of publicly available, uh, good quality data. So this chart that I'm pulling up, \"Data scarcity as a potential wider scaling models,\" talks about, it's largely conceptual, but I think it's an interesting point, which is we are, these models are incredibly data-hungry, and we may be running out of available data to for these models to publicly train. You've seen, uh, GPT-4, uh, excuse me, OpenAI start to hire specialized teams of data labelers to pay PhDs for specialized models and biology, talked about passing the bar exam. They, they're paying, you know, lawyers to actually label their data. They have these programs now where they're actually, you know, directly paying people for data acquisition. And so I think this chart is interesting because it ties a meta point that I think we're seeing, which is we are. GPT-5 is rumored to kind of be trained on, you know, image and video, and so we're likely going to see, uh, you know, step up improvement of, um, some of these multimodal models, but largely we're going to be kind of data-constrained, um, in the near future, which will affect a lot of people's ability to find, uh, new, uh, new data. I think the interesting in this chart is that it sort of the timeline is very interesting, right? If you look at it, is we sort of peak around 2038.\n\nWhen I brought up an interesting point, so which I'll discuss is that I actually think we're going to hit data limits a lot sooner because of the legal regime in AI that people aren't paying enough attention to. So one thing that was undercovered in, you know, Sam Altman's announce latest announcements, uh, in in Developer Day, uh, when they announced, uh, GPT-3, was this idea of a copyright shield, right? Which was that OpenAI and other model providers like Stability will basically indemnify downstream usage of the model. And when I looked into litigation around this, which is, you know, intellectual property, uh, it's actually, there was, there was a few interesting case laws. There's one federal court, uh, in California, um, you know, is Anderson versus Stability, and what if you actually read the ruling, it wasn't that, uh, you could just use these models, it was that all the original content creators basically didn't file their appropriate copyright claims to allow them to defend. And if they had, they could have probably, uh, you know, constrained usage of of their, your, your data for training. And so it's interesting to me, which is I think people think we're in this big open regime for, we had this open internet, um, you know, Common Crawl, and we'll have the CEO of Common Crawl come on the Pod, but we're entering a different era of data quality is really the differentiator for your business model, for your mode. People are going to find ways to restrict it. Um, content plers use, use generated content, uh, providers, um, DeviantArt was one of the, um, plaintiffs in this case. So it's going to be interesting to see, see, um, when we start to hit limits of data scarcity, um, what that means for this sort of legal regime surrounding AI, and, um, I'll pause there because that was a lot, but that chart just made me think of, is really 2038, is it really just we're going to run out of data, or is that this sort of, um, fragmentation and, um, the, the legal environment surrounding IP going to bring that, uh, to pass even sooner, potentially in the next two to three years? But that was something I've been, I've been thinking about.\n\nYeah, the idea of data constraint, yeah, like, first of all, this, this graph, um, it's kind of hard to read, because first of all, there's nothing, if you're not looking at it, you're not missing a lot, because the labels are not, um, the axes are not labeled at all. I have no idea what the Y access is, you know what I mean? Um, like, what is this line? What is this line? Like, like, is this use of, like, is this availability of quality? Like, what is, I, I cannot understand, like, what this graph is trying to tell me. Is it that we are not making as much text data as we used to, because I can show you many other graphs where we are generating text data faster than ever? So the limit of text is also increasing. So when I look at graphs like this, like it is really hard for me to put my head around, like, well, what do you mean by we're running out of high-quality text data? Just because OpenAI used it for GPT-4 doesn't mean it's now an exhausted resource. Other people can use data from 10 years ago, 20 years ago, 30 years ago as well, and we're just making more data by the minute, right? So when, when someone comes to me and says, \"We're running out of high-quality text data,\" and I go, \"No, you're running out of high-quality text data, and if you're not able to make the most of it, that's not a, that's not a data problem, that's a you problem.\" If the data that we have today is not enough to model the task that you're trying to solve, that can't be true in my, in my humble opinion. And I frankly, I have no stats to back that up. The amount of data that we have generated as, as, as humanity is staggering. If that's not enough data to solve grade school math in an AI, that's not the data's fault. We've been able to solve grade school math as a society for a long time, and there's data all about it, 100%. So it, this goes back to like broader debates and AI, which is, um, with the data available, right? Are we able to, uh, are we able to solve some of these trickier problems?\n\nI think that it's an interesting point, Stan, because I, I would say I disagree a little, because I think that in the future of legal regimes, basically, if people are allowed to retroactively change the copyright license on their training data and then sue others for it, that's pretty interesting. So I won't, I mean, we literally had a call with someone that is very involved in this space where they are getting retroactively sued for a model they published years ago. I talked to a head of ML at a 50 company, which said part of the reason, and they, they want to use this and put, you know, um, this is in the pharmaceutical industry, uh, you need new, um, AI sort of drug discovery solutions in place, so new specialized models to help folks understand, um, help researchers sift through information more quickly. And one of their biggest concerns is that they're actually, the feedback they're getting from legal is that if this copyright shield doesn't work and you develop a drug off of it, and you pour hundreds of millions of dollars into an FDA process for approval, etc., research, and then someone can retroactively claim efforts to it. I think it's really interesting to think about, we may have enough data, right? The supp\n\n\nLy of data, but it made me think.\nActually, because the chart was, it largely was talking about just the amount of data. It's not particularly well labeled, but we largely talk about this of, well, we're running out of data. And actually, I think you're right. I think I agree with your premise, which is, well, there's a ton of data. The availability for the common developer, I think, is the unit that matters. And the reality is, I think I'm a little worried when I look at this, um, and sort of see, uh, how little this is discussed, which is that, um, it is possible, if in a new legal regime, this hasn't been settled at all, uh, for folks to basically retroactively, uh, cop their stuff, go after others for putting into their newer models. I think that's potentially dangerous. So I think we're going to see more litigation in 2024 between major model providers, potentially between Meta, open AI, etc. I mean, I don't even know people know this, but Sarah Silverman sued Meta over Llama 2 for her books being used. I didn't know that. It was crazy. So no one's really discussing this, but, uh, it's interesting when I talk to Loosely, you know, attorneys have no idea on this, but he looked like I'm reading through the actual case material briefly, and it's never like, oh, you can't protect your IP because it's, um, they're using your material in a wrong way. It's like, oh, you didn't go through the procedural steps to protect your IP, if that makes sense. And that's made me, when I look at that, data scarcity is what if that's actually sooner because of the legal regime? I don't know. So you're a content creator, you, you have books. I'm curious how you feel about, um, you know, your data potentially being...\n\nI mean, first of all, I, I, I, I want to say, I, I more, I pretty much blanket support Sarah Silverman's premise because as someone who has also written a book, I do, because I'd be a hypocrite if I wasn't, frankly, like as someone who's also written books, if an AI is going to have access to my book, I'll use my book as an example, and which are mostly reference books on AI, then, well, the reason I write them is, you know, obviously for some royalties, but also because I want to disseminate the information in my style. I'm not saying anything that no human being has ever thought of before. That's that is ultra rare, theoretically impossible for a human to say something that no other human has actually like had that thought before, but I'm saying it in my way, in my style, in a way that I think resonates with some people. So it's not that my content is is giving informative information to GPT4 that it has never seen before. It knew everything that my book has already said, without a doubt, but the difference is, if you can say it in Sonan style to the right person, you might be able to teach them better. That's really the point of, again, coming back to my book, that's the point of teaching in the first place. So if anything, it'd be really cool for me, and this is a big ask, and I again, I I'm not actively, I don't know how to do this the best way, but if there's at a station for me is more important, again, personally, yeah, the ability for GPT to say, by the way, if you like that presentation, this style is coming from these sources, like these people write in a similar way about this topic, like Sonam Ozer, feel free to check out his book and for much more, like just static knowledge about this topic. I would be over the moon if that could be done and done well. So I'm less in the camp of don't touch my book, it's my copyright. I'm more in the camp of I would be happy to surrender, you know, the use of this book for this purpose as long as there is some way back for users. You're not obfuscating, you're not hiding the fact that I made this content, and that kind of idea of ownership, um, there's like really, like, really, um, hyper sense of ownership, I think, is really just playing out a lot. And again, I'm not going to comment on a lot of that stuff, but it's, it's, that's how I feel at least.\n\nNo, I think the central idea is this idea of adastation, right, in transparency, right? So even if I think a lot of people would potentially like, like you, be fine with, um, you know, using, if the you had consented to it. It's interesting though, Sonam, because I think I had a conversation with, uh, you know, an engineer we, we both know, and we, I was talking to him and he said something really interesting, which is, I was talking about, you know, these rests where people are changing robots.txt to basically restrict, um, you know, training of newer models, and he said something really interesting, which is, well, they'll get around that anyways, and someone will inevitably do it, train it, and put it in a model, and then we'll just use that for training data, and it's already out there, so there's nothing we can do. And I argue that that is actually the wrong frame to use. So another analogy to explain this is with open-source licensing. So when you are get to a large enough company of a size, and you're serving a bank or someone, a healthcare organization, putting software into productions, there are teams that will actually check and routinely go through, this is the boring aspect of, you know, there's huge departments for this that no one really realizes until you're in a larger company, you're actually under some sort of regulatory scrutiny, you have to do reporting, you're public, etc. But there's a lot of Enterprise Value, a lot of spend, uh, in the segment of the market. There are people that will check your licenses for open source and make sure you're compliant so you can't get sued and the underlying product you have is invalid when you're shipping the actual software. Similarly with AI, I think that it's sort of naive to say, well, it's out there, we can just use this training data, because the reality is, if you are the head of ML at one of these pharmaceutical companies, you actually care very much about the downstream implications of licensing and whether that you over in the long run. So I think this idea of adastation and transparency actually going to be critical going forward, because I think for people to be able to use open source, there needs to be more transparency. I actually think even, you know, the major model parts, hey, we'll just shield you via copyright claims, that may not be enough. And so I think as sort of data gets more scarce, uh, where people realizing, you know, we talked about synthetic data, we talked about data quality, where people realize it really is about you, this underlying high quality data that you can find, and if someone else has it and it's, it's the difference between your product working and not, and they've restricted it, I think we're going to see more examples of, you know, people essentially, uh, realizing, uh, some of the legal and compliance challenges to AI, which is that this IP licensing regime, maybe the answer is just everyone ignores it, and similar to music, innovation just completely outpaces it. One thing I think that's a little different is that I think the legal regime didn't, you know, it's not Napster, where people don't really understand some fundamentals of this. I think people understand the stakes of, uh, getting AI right, and there's a lot of deep pockets to sort of protect your different turf. So my prediction is this will get, uh, pretty, um, in more interesting, and maybe we'll have some, you know, I don't know if Sarah Silverman's A-list, more A-list celebrities, potentially influencers suing.\n\nI consider, yeah, she's okay. So, uh, even more...\n\nWhat, but fair, um, to end us, uh, on another note, Sonam, you had, you had an interesting poll that I was going to say on that note of how humans feel about AI. This one, I, oh my God, we can't, we only have a couple minutes. I'm going to give myself a couple minutes on this because this next graph here is AI regulation may be more likely than most think. So presumably, this chart is about regulation. Okay, keep that in mind. There are four bars on this bar chart. Each one represents a percentage of a of respondents to a poll from the AI Policy Institute. Um, for what it's worth, I did, I did the most research into this poll, um, because the first bar on this poll is 83% of surveyed respondents believes AI could cause a catastrophic event. Okay, oh no, 83% of survey respondents think AI could cause a catastrophic event. Okay, so when I first saw that number, my first thought was, BS, that is not true, like I don't think that's actually true, that doesn't seem right at all to me. And then if you look into the actual number, which I did, and the actual poll itself is that wasn't really the question, or rather, the question was, how likely do you think is it that that niai could accidentally cause a catastrophic event? That's the actual question if you look at the, the, the, like the paper that the AI policy put out. So first of all, that bar in that bar chart is not even the right question. They says it, it specifically says accident mentally. And here are the options for that one question. The options are, so how likely do you think AI could accidentally cause a catastrophic event? Extremely likely, very likely, somewhat likely, not likely at all, and not sure. So of the five possible answers, two of which are hell yeah, extremely likely and very likely are basically the same thing. The third one is still yes, somewhat likely, like I believe so. Only one out of five of those answers is just flat out no. So there's no degrees of probably not, not very likely, and then one of them is just I don't know, which is a good part, you need the I don't know. But three fifths of the answers are yes, and one fifth of the answer is no. So you get this, I mean, this is an any poll, but like when you get polls like this, and this eventually gets 85% of people think AI is catastrophic, it's like, no, no, that's not what the poll says at all. It's no, this is, this is terrible survey methodology. One, it's also interesting because, uh, we're going to do an episode on AI information hygiene, uh, to to start the year, like, and information diet, excuse me, and and what, uh, people could be doing to, like, this is, this is pretty egregious, terrible survey methodology. And also, it, it's something that really bothers me with the sort of ethical and responsible AI sort of space. There are, and we've had Giad on the podcast who leads some of this for hugging face. There are really important ethical questions, uh, of how AIS and systems that are algorithmically govern our lives should be trained, should be governed, etc. Um, whether AI cau's a catastrophic event and then asking people to describe it, this is more of the kind of asking someone who doesn't know anything, you know, a lot of these people just hearing what they just like, what their P Doom is, it makes no sense. People will not, I, I bet you asked actually that 80% plon to describe their scenario for AI accidentally creating a catastrophic scenario, I, I bet the vast majority couldn't do it. This is actually one of my biggest frustrations with the responsible AI space is that and so these whole exential debates is that we can't seem to, uh, sort of describe how this happens and and get away from the sort of like exential debates of even sort of these catastrophic sort of failures, um, they're not really well defined and, uh, they're really, really vague. So I'm really glad.\n\nDo catastrophic mean, what do you mean by that? Like, yeah, like this is the, this is I think the number one chart, the reason I wanted to bring it up was these are the numbers that make it to the news, right? Yep. But it's not that hard. Oh, and by the way, while we're on this topic, I did, I was looking up anthropics harmlessness data set, um, because one of the other bars on this bar chart is 18% trust AI Tech Executives to self-regulate AI. Okay, um, and if you look at the actual, the question, again, again, the answers are strongly agree, somewhat agree, somewhat disagree, strongly disagree. So this is actually a better distribution. Um, so most people AG that Tech Executives should not regulate themselves. If you read anthropics announcement about their harmlessness, I'm going to quote here from their, from their site, well, from their website, we have an internal red teaming evaluation that process I described earlier that scores our models on a large representative set of harmful prompts using an automated test, while we also regularly check the results manually. In this evaluation, Cloud 2 was was 2x better at giving harmless response compared to Cloud 1.3. That's the 2x that we saw. Period. That's it. They have an internal evaluation that scores models on a large set of prompts using automated tests, 2x. But like, yeah, it's also that's the only thing from the chart that's actually like a, like a order of magnitude different. The rest is like, you know, CL two, Clon one, and then the left hand of the chart is like, there is no difference. If you actually use human preference scoring, yes, this, and did you write this prompts? Did you write these prompts for cloud one, and then while you were developing Cloud 2, were you biased in having already written the prompts, knowing what you want your guard rails to be, so you made sure that Cloud 2 was going to be better at them, or was this test set fully unseen by both Claud one and CLA 2? Like, there's so many more dimensions to this that this, that's the only number I do agree with on that bar chart is that I believe that most people don't trust Tech Executives to self-regulate themselves. I sure as hell don't.\n\nDamn, this, this is pretty bad, but yeah, these are the numbers that get in the headline. So I'm glad we're, we're calling it out. They are, that's what's going to be. They're not who there, you think they care about the cost of compute, uh, of of training versus inference? No, no, no, 85% of voters, because that's the other thing about this poll, by the way, is it was specifically about voters, like most of the questions are about presidential candidates and how favorably do you view Google and paler, and then they talk about AI, and I'm like, like, okay, so this isn't even a full survey about AI, you first asked them questions about their political standpoint and then talked about AI, like you're kind of framing the question of AI as if it were political, so you prim people to be more polarizing when you do that.\n\nYeah, no, so, uh, this is the end of the grind my gears section of Merry Christmas, everybody, happy Mon, and happy holidays. I hope you all have a great. Do you have any concrete predictions for 2024 that you want to list out, Sonam? Um, yeah, yeah, yeah, and I can't wait for people to play this back and tell me how wrong I was. Um, but I, I recently did my kind of wrap-up series for my Pearson audio, uh, series unveiled, where they asked me very similar questions, and I literally talked about Sarah Silverman as well, like a regulation and how litigation is going to proceed. Um, because, you know, I said this before, I'll say it again, AI has never been more accessible to the average person, which is a amazing, and B is starting conversations that have at this, until today, have really only been had by developers, Tech Executives, nonprofits, and the occasional lawsuit. And these questions have been, not these are not new questions, but they happen to be questions that we're only starting to debate now. So my prediction for 2024 is going to be, uh, is more around the philosophical interactions between humans and computers are going to trend more towards, and this is not the best, you know, the most positive prediction, but they're going to trend more towards the way we think about politics. There's going to be a lot of polarizing views, a lot of good versus bad, and nothing in between.\n\n\nIt's going to be up to, hopefully, a lot of smarter people than, no offense, you or I, but smarter people than us, better, well-read, more well-people than us, to make the argument to the world that this is not just good versus bad. This is, this is like, um, how we should be talking about any kind of technology that affects all of us. The internet is not good or bad. There are shades in between. Some things are good, some things are bad, but there's a lot of things right in the middle. And if we don't start thinking about AI like that, we're going to either see this complete breakdown of AI, um, and saying, \"Well, it's all bad, no one can do anything interesting,\" but it can't be the opposite either, which is, \"Do whatever you want, we'll figure it out later.\" Like, it can't be those two extremes. There's got to be somewhere in the middle. So my hope almost is that we'll find those degrees of, um, on that spectrum in 2024. That's my main hope.\n\nPrediction: I think it's going to happen much sooner. I think, um, I have a few predictions, some that we've stemmed from. We already, one of them, I think, the, I think we'll see some, some pretty major election interference and, uh, rise have disclosed data poisoning attacks in 2024. And I think in many cases, on what you're talking about is actually the central sort of challenge we face. I mean, this folks, you know, liken sort of this invention to, you know, the invention of fire. This is how monumental, you know, so this were in the early days, but, uh, how monumental getting this technology right. And I find you're right that the discourse is split, uh, a little bit. It's, it's a little too polarized, maybe like the rest of the society, and that's not necessarily great for the development ecos of, of these ecosystems because of the potential that some of this technology can have, right? We don't want to limit innovation, but at the same time, we want to sort of govern it and use it responsibly. But then people are putting out ridiculous surveys like this nonsense, um, and so I think it's gonna, it's going to happen in the public discourse, and I think it's, um, we'll see how it goes, but I, I do think that it's going to happen sooner rather than later where people are going to see deep fake attacks, um, you know, voice calls, um, around sort of voting, saying, \"Hey, the polls are actually closed, you don't need to kind of come.\" That sort of stuff is actually very easy to envision, um, in likely scenarios for election interference. You're going to, I think, also see, uh, disclose examples of, of data poisoning where hacker groups affected the latest trading of GPT 5. Uh, actually was talking to someone at open AI where they're spending a tremendous amount of, uh, resources on this where they will do kind of model flags where they have a detection system where they think if, uh, both at the prompt level, but if they think the underlying data is poisoned, looking at not just the, the text, but the machine readable code, um, that's being the models being trained on to detect that before it's actually input into their, you know, trading ecosystem before, you know, the prompt is input.\n\nValidation, exactly. So input validation and and data validation, but I think that's going to be a big thing, uh, that's going to come to Forefront, uh, because of elections and, uh, it's just going to be a more, you know, politically oriented year, uh, so, um,\n\nOptimistic on a, on a, on a more, you know, POS note, I think that, um, we will see sort of, uh, we talked about this was, but I think divergence between falling training costs and continued high inference costs, uh, will lead to sort of more localized inference and model development. We'll hear more about Edge architectures for models, etc. It's going to be easier and easier for folks to use. That's great, already coming out. Yeah, I think then I also think we'll see, oh yeah, whatever that means, uh, we'll, we'll see multimodal for sure, but the, uh, and I think we'll see the first met major set of federal cases involving open AI, Meta, Google, um, where there's, uh, you know, discussions on training data, and we'll kind of, kind of see continued, uh, training data restrictions. Those are a few of mine. I, I do wonder, one, one sort of, um, thing to end on that I've been talking to folks about is, do you think because of the some of stuff we're seeing around benchmarking, some of the major issues we're having infinite course components of LM INF, for, we'll see a mini winter, um, and sort of LM model development where you could see kind of the state of the art headlines, but it's actually harder for folks to develop. So my predi is actually we see a little bit of a cool down in Venture investing, at least in language model infra. Yeah, I, I, I think we will, but not because it's gonna get harder. I don't think that's why. I think it's like, like crypto.\n\nThanks to everyone who tuned in. Um, we super appreciate you sticking with us for the first year podcasting. We have big planned for 2024 and, uh, hopefully you found this, uh, this, this gem of us to riffing on on random topics a little bit interesting and useful, but thanks all and have a, have a wonderful, uh, end of 2023 and hopefully a great 2024.\n[Music]\n",
  "dumpedAt": "2025-07-21T18:43:25.857Z"
}