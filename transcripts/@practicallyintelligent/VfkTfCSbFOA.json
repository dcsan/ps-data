{
  "episodeId": "VfkTfCSbFOA",
  "channelSlug": "@practicallyintelligent",
  "title": "E7: The Power of Benchmarking in AI Progress with Praveen Paritosh",
  "publishedAt": "2023-12-01T19:09:04.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 0.71,
      "duration": 6.14
    },
    {
      "lang": "en",
      "text": "hey everyone welcome back to practically",
      "offset": 7,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "intelligent today we're excited to",
      "offset": 8.719,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "welcome Prine paros a former senior",
      "offset": 10.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "research scientist at Google and founder",
      "offset": 12.719,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and chair of the data perf research",
      "offset": 15.08,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "working group at mlc Commons we are",
      "offset": 17.439,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "going to chat with him this is a really",
      "offset": 20.519,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "wide raising ride ranging conversation",
      "offset": 23.4,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "about oh yeah how data benchmarking is",
      "offset": 25.96,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "evolved",
      "offset": 29.599,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "and how we should think about the",
      "offset": 30.519,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "evolving performance of llms on a",
      "offset": 31.92,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "holistic way we really really enjoyed",
      "offset": 34.92,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "this conversation it was fun we touched",
      "offset": 37.64,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "on a bunch of stuff um sonan I think",
      "offset": 40.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "what was your favorite part yeah I was",
      "offset": 43.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "about to say I think this is probably",
      "offset": 46.28,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "one so we usually you know a peek behind",
      "offset": 47.559,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the curtains we usually send our our",
      "offset": 49.399,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "guests an email before the recording",
      "offset": 51.239,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "just to say like here's what we want to",
      "offset": 54.44,
      "duration": 2.919
    },
    {
      "lang": "en",
      "text": "talk about you know what do you want to",
      "offset": 56.039,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "talk about we kind of figure out the",
      "offset": 57.359,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "general Arc of the episode I feel like",
      "offset": 59.199,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "this was I I was annoying him at a",
      "offset": 60.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "certain point because I just kept",
      "offset": 62.359,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "writing more and more questions that I",
      "offset": 64.199,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "had because in our initial introductions",
      "offset": 66,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "he just kind of wanted to cover so much",
      "offset": 68.88,
      "duration": 2.919
    },
    {
      "lang": "en",
      "text": "stuff and I was so excited about it",
      "offset": 70.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "because he were really um sinking on our",
      "offset": 71.799,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "our worldviews on this stuff so I think",
      "offset": 74.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "my favorite part is when we start to I",
      "offset": 76.4,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "think it's towards the end but we start",
      "offset": 78.88,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "to talk about the lessons learned from a",
      "offset": 79.88,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "computer engineering computer science",
      "offset": 83.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "standpoint in in talking about AI",
      "offset": 85.68,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "systems as if they were and they should",
      "offset": 88.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "be thought about this way not so",
      "offset": 91.96,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "different from any other computer",
      "offset": 93.88,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "engineering problem with the added",
      "offset": 95.84,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "benefit of this you know um machine",
      "offset": 98.399,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "learning capability so I think the",
      "offset": 101.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "parallels that we draw were really quite",
      "offset": 104.079,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "fun to talk about and I think really",
      "offset": 106.36,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "going to be useful for people to think",
      "offset": 107.96,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "about you know in the long term so i'",
      "offset": 110.119,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "I've rambled enough you're going to hear",
      "offset": 112.56,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "me ramble some more I say we just kind",
      "offset": 113.6,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "of Jump Right In let's do it well Prine",
      "offset": 115.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "thank you so much for being on the show",
      "offset": 119.119,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "this is uh really exciting I'm going to",
      "offset": 120.56,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "just jump right into things uh where do",
      "offset": 122.399,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "you see the current state of AI",
      "offset": 125.399,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "benchmarking and and and you know take",
      "offset": 128.319,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "that to wherever you want to go but uh I",
      "offset": 130.959,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "think our our listeners are going to be",
      "offset": 133.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "really curious about kind of the",
      "offset": 134.599,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "Practical applications of AI",
      "offset": 136.8,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "benchmarking and kind of how people",
      "offset": 138.08,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "approach it and what are some of the",
      "offset": 140.319,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "pitfalls that you're",
      "offset": 141.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "seeing thank you for having me uh it's",
      "offset": 143.36,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "such a pleasure and that's a great",
      "offset": 146.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "question benchmarking is",
      "offset": 147.72,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "you know particularly critical for the",
      "offset": 150.36,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "way we move the field forward so a",
      "offset": 153.04,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "shared Benchmark such as consider the",
      "offset": 155.28,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "first uh interesting Benchmark was Squad",
      "offset": 157.8,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "the Stanford question answering data set",
      "offset": 161.12,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "and that was a collection of a thousand",
      "offset": 163.599,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "questions that was extracted from",
      "offset": 166.599,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "Wikipedia using Mechanical Turk and",
      "offset": 168.319,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "turned into a question answer set and",
      "offset": 170.959,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "early research when lstm lstms came",
      "offset": 173.519,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "along and after that Transformers came",
      "offset": 176.159,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "along but people could test their",
      "offset": 178.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "question answering systems on Squad and",
      "offset": 181.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "report a metric and you could then build",
      "offset": 184.76,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "a table kind of a leaderboard uh where",
      "offset": 187.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you could see which algorithms were",
      "offset": 190.72,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "performing the best on that on that set",
      "offset": 192.36,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "and so suddenly it created this shared",
      "offset": 195.4,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "way in which the community could move",
      "offset": 198.68,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "forward on a problem now you know you",
      "offset": 201.08,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "can think about it as almost like a",
      "offset": 204.92,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "mechanism for the research community to",
      "offset": 207.879,
      "duration": 6.121
    },
    {
      "lang": "en",
      "text": "Hill Climb uh because now the accuracy",
      "offset": 210,
      "duration": 7.319
    },
    {
      "lang": "en",
      "text": "score on the squad test set is is an",
      "offset": 214,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "objective function is a metric and you",
      "offset": 217.319,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "can try to improve that you can see what",
      "offset": 219.239,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "methods what kind of training data what",
      "offset": 221.439,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "kinds of architecture give me higher",
      "offset": 224,
      "duration": 7.4
    },
    {
      "lang": "en",
      "text": "performance and likewise in uh Vision uh",
      "offset": 226.68,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "image net was such a important",
      "offset": 231.4,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "influential data set so the image net",
      "offset": 233.799,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "moment uh which was when Alex net but",
      "offset": 236.56,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "achieved high accuracy on a whole bunch",
      "offset": 240.2,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "of categories like thousands of",
      "offset": 242.439,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "categories of objects which was never",
      "offset": 243.959,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "done in computer vision before and that",
      "offset": 245.92,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "is what led to recognition by the",
      "offset": 248.079,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "touring Award of Yeshua Benjo Yan Leon",
      "offset": 250.879,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "and Jeff Hinton because that that",
      "offset": 253.959,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "demonstrated something remarkable had",
      "offset": 255.4,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "happened and the existence of these you",
      "offset": 257.519,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "know shared benchmarks allow the",
      "offset": 260.479,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "community to move forward but at the",
      "offset": 261.959,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "same time let's look at these examples",
      "offset": 263.88,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "we run into some problems so for the",
      "offset": 266.44,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "first squat uh uh data set was uh did",
      "offset": 268.4,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "not contain the way it was constructed",
      "offset": 272.479,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "it did not contain questions that",
      "offset": 275,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "couldn't be",
      "offset": 276.88,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "answered so for instance uh when asked",
      "offset": 278.039,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "the question what is Barack Obama's",
      "offset": 281.56,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "favorite",
      "offset": 283.16,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "color um the state-of-art algorithms",
      "offset": 284.199,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "that had cracked the squad Benchmark",
      "offset": 287.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "would very confidently say black and",
      "offset": 290.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "cite the Wikipedia article as a",
      "offset": 292.88,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "reference now the Wikipedia article has",
      "offset": 294.24,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "no mention of Obama's favorite color at",
      "offset": 296.6,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "all but but contains a color term",
      "offset": 298.479,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "repeated many times and such juristic",
      "offset": 301.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "worked when it was guaranteed the",
      "offset": 304.56,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "document contains an answer but that",
      "offset": 306.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "didn't work when the document didn't",
      "offset": 309.039,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "contain the answer so Squad 2.0 was",
      "offset": 310.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "released by the authors realized this",
      "offset": 313,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "problem and they added a bunch of",
      "offset": 315.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "unanswerable questions and that led the",
      "offset": 316.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "community to figure out there were two",
      "offset": 319.44,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "questions first determine if the",
      "offset": 321.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "document can answer the question and",
      "offset": 323.199,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "then find the answer to the question so",
      "offset": 325.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "such systems were then able to realize",
      "offset": 327.639,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "that one cannot answer what is Barack",
      "offset": 330.08,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "Obama's favorite color so as you can see",
      "offset": 332.16,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "as we change the benchmarks that changes",
      "offset": 334.36,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "the hill that the community is climbing",
      "offset": 338.28,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "the kind of components and capabilities",
      "offset": 341.12,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "you would need to build and so that's",
      "offset": 342.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "the you know role of Benchmark that the",
      "offset": 345.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "shared measures of progress like a",
      "offset": 348.319,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "compass for the research Community but",
      "offset": 350.52,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "at the same time you know those those",
      "offset": 352.84,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "are you know proxies right like we you",
      "offset": 355.28,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "cannot to take the whole universe of",
      "offset": 358.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "question answering and turned it into",
      "offset": 360.88,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "one particular Benchmark so what we've",
      "offset": 363.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "seen is proliferation of lots and lots",
      "offset": 365.919,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "of different benchmarks and typically",
      "offset": 368.24,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "now published results will contain you",
      "offset": 369.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "know performance on 10 different",
      "offset": 372.84,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "benchmarks and benchmarks themselves",
      "offset": 374.36,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "these days have become baskets of",
      "offset": 377.199,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "benchmarks so big bench and super glue",
      "offset": 378.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "then there some they contain you know",
      "offset": 381.28,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "dozens of other",
      "offset": 383.84,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "benchmarks uh so that's the direction of",
      "offset": 385.199,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "growth that the community has taken but",
      "offset": 387.479,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "even that is not enough because the",
      "offset": 389.84,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "systems are uh you know getting so",
      "offset": 393,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "powerful that they're able to you know",
      "offset": 395.8,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "saturate The Benchmark achieve a human",
      "offset": 398.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "level performance of The Benchmark very",
      "offset": 400.919,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "quickly so there's a famous analysis by",
      "offset": 402.36,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "D Keela who was at meta who built Diner",
      "offset": 404.479,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "bench and now is running contextual AI",
      "offset": 407.759,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "in which he shows this Benchmark",
      "offset": 410.479,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "saturation graph and what used to take",
      "offset": 412.24,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "years now takes months so each Benchmark",
      "offset": 415,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "becomes expires pretty pretty quickly so",
      "offset": 418.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "this is really an interesting point we",
      "offset": 420.479,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "find ourselves and the tools that we are",
      "offset": 422.16,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "throwing at it so there are some new",
      "offset": 423.919,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "ideas that people are exploring like",
      "offset": 425.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "adversarial approaches to proving such",
      "offset": 427.479,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "systems but it seems like you know the",
      "offset": 429.639,
      "duration": 6.921
    },
    {
      "lang": "en",
      "text": "bigger problem here is that we might",
      "offset": 432.879,
      "duration": 7.841
    },
    {
      "lang": "en",
      "text": "have grown outgrown this phase of using",
      "offset": 436.56,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "you know small crowdsource benchmarks as",
      "offset": 440.72,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "a way to measure",
      "offset": 443.199,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "performance um we need to figure out a",
      "offset": 444.599,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "way to turn this whole research program",
      "offset": 447.16,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "differentiable in a sense you know like",
      "offset": 449.599,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "that's the agenda right like as long as",
      "offset": 451.52,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "we can turn something into a hill that",
      "offset": 453.12,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "we can climb then we can use gradient",
      "offset": 455.4,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "descent and we can move forward",
      "offset": 457.56,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "incrementally so I feel like benchmarks",
      "offset": 459.52,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "give us this shared Compass but each one",
      "offset": 462.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "of these benchmarks that we have out",
      "offset": 464.919,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "there are limited and our flaws none of",
      "offset": 466.36,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "them point to the true north entirely",
      "offset": 468.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "they just give us hints in that",
      "offset": 470.639,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "direction and at this point we're at a",
      "offset": 472.319,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "point where we might need to think about",
      "offset": 475.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "some radically new ideas to to guide us",
      "offset": 476.759,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "because we need more precise compasses",
      "offset": 480.159,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "we we matured at that point of Building",
      "offset": 482.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Systems and Technology yeah no I there's",
      "offset": 484.8,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "a lot of great points in there and I I",
      "offset": 487.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "think I'll start with the the historical",
      "offset": 489.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "context well the modern historical",
      "offset": 491.28,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "context between talking about alexnet",
      "offset": 493.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "and imagenet um and and the squad data",
      "offset": 495.56,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "set because I remember working with",
      "offset": 498.599,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "Squad you know 1.0 and 2.0 uh even back",
      "offset": 500.72,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "you know years ago when before",
      "offset": 504.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "Transformers to your point in working",
      "offset": 506.479,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "with RNN and TMS and for even just",
      "offset": 508.44,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "talking about embeddings and text",
      "offset": 510.879,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "embeddings I would always use these",
      "offset": 512.959,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "kinds of data sets because to your point",
      "offset": 514.64,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "it was a way to not only feel connected",
      "offset": 517,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "to a greater community of this is what",
      "offset": 520.159,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "the researchers are using this is what",
      "offset": 522.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the real data scientists are using in my",
      "offset": 524.839,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "class you know the aspiring data",
      "offset": 526.88,
      "duration": 2.44
    },
    {
      "lang": "en",
      "text": "scientist this is what real data",
      "offset": 528.08,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "scientists are using this is the data",
      "offset": 529.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "set that we're going to do it does",
      "offset": 530.72,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "really ground students and and",
      "offset": 532.44,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "introductory level uh Engineers but then",
      "offset": 535.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "to your point at a certain point the",
      "offset": 538.16,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "community but not only the community the",
      "offset": 540.839,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "individual will outgrow that and and",
      "offset": 542.959,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "after a while you say well yes you know",
      "offset": 545.04,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "even recontextualizing the idea of",
      "offset": 547.839,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "question answering going from yes no to",
      "offset": 549.959,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "yes no non-answer or I don't know even",
      "offset": 552.76,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "Beyond then you can break that down into",
      "offset": 557.079,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "closed uh QA open QA General QA trivia",
      "offset": 558.8,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "QA which is one I see often and and and",
      "offset": 562.959,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "to your point even even more I was",
      "offset": 566,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "reading a paper today totally unrelated",
      "offset": 567.64,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "to NLP but to your point I got to a page",
      "offset": 569.6,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "where it was just 3/4 of the page was",
      "offset": 572.56,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "here's 10 benchmarks on the columns and",
      "offset": 575.68,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "here's 15 models on the rows and then",
      "offset": 578.279,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "theirs where bolded at the bottom and I",
      "offset": 581,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "was like oh my God this is just so much",
      "offset": 583.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to the parse and look at and I don't",
      "offset": 584.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "know what the takeaway is and a lot of",
      "offset": 587.32,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "the times it almost feels like marketing",
      "offset": 589.48,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "and I'll I'll I'll tell you what I mean",
      "offset": 592.079,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "by that a lot of the times I feel like",
      "offset": 593.68,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "I'm looking at this table and they go",
      "offset": 595.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "well we bolded our results but we've put",
      "offset": 597.64,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "the others here it's almost like when",
      "offset": 599.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you Google how do I you know",
      "offset": 601.279,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "alternatives to zoom 20 articles come up",
      "offset": 603.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "saying hi we're better than Zoom hi",
      "offset": 607.079,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "we're better than Zoom hi we're better",
      "offset": 608.6,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "than zoom and the idea is like well this",
      "offset": 610.079,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "is a competitive analysis if you looking",
      "offset": 612.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "for the best model we are going to show",
      "offset": 614.399,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "you a comparison and because the the",
      "offset": 617.44,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "person on the other end may not know",
      "offset": 619.88,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "what they're looking for it will come",
      "offset": 622.12,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "down to well theirs is bolded and",
      "offset": 624.64,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "clearly that number is slightly higher I",
      "offset": 626.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "as well use theirs so it becomes almost",
      "offset": 629.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "this this way of convincing others to",
      "offset": 631.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "use their open source model even though",
      "offset": 634.839,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "it might not be the best metric for the",
      "offset": 637.6,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "consumer trying to select an approach or",
      "offset": 640.76,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "a model so uh I guess given all that",
      "offset": 643.639,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "what kinds of radical Transformations do",
      "offset": 647.12,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "you think are are on the horizon or or",
      "offset": 651.079,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "just on the horizon and and like what",
      "offset": 654,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "what are what is your team working on in",
      "offset": 655.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "this space to try to alleviate some of",
      "offset": 658,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "these",
      "offset": 660.24,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "issues so I I'll take a you know a",
      "offset": 661.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "couple uh you know little tangents one",
      "offset": 664.639,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "one is that oh we we here are",
      "offset": 667.32,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "practically intelligent are are wild",
      "offset": 669.8,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "fans of tangents so please tangent away",
      "offset": 671.959,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "welcome to tangent air",
      "offset": 675.279,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "Airways um we might experience a little",
      "offset": 677.56,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "turbulence so what what you know one",
      "offset": 679.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "thing that first and foremost we haven't",
      "offset": 683.12,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "done as much is Benchmark the data",
      "offset": 684.72,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "itself so I've been working at ml",
      "offset": 687.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "Commons and started this working group",
      "offset": 689.399,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "called Data perf and we launched this uh",
      "offset": 691.079,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "you know half a dozen different",
      "offset": 693.959,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "challenges that just measure the quality",
      "offset": 695.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "of data not the quality of model and so",
      "offset": 697.8,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "that's one approach area that we've been",
      "offset": 700.32,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "exploring and you can learn more about",
      "offset": 702.88,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "it at data.org and we have an upcoming",
      "offset": 704.839,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "paper at newps uh in New Orleans in",
      "offset": 708.6,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "December that we'll be presenting about",
      "offset": 710.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "it it's a very large effort there's you",
      "offset": 713.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "know 60 different teams and",
      "offset": 715.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "organizations across Academia and",
      "offset": 717.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "corporations and what we did was we said",
      "offset": 719.36,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "you know all you can do as a participant",
      "offset": 722.8,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "think about like these leaderboards that",
      "offset": 724.76,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "we just talked about where there is a",
      "offset": 726.279,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "test set and you're trying to get a",
      "offset": 728.079,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "position on the leaderboard but instead",
      "offset": 729.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "by by changing your model by building a",
      "offset": 731.8,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "better model but instead what we did was",
      "offset": 733.48,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "we froze the model and we said all you",
      "offset": 735.68,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "can do is manipulate the data and can",
      "offset": 738.24,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "you get a position on the leaderboard by",
      "offset": 740.639,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "selecting sampling curating cleaning",
      "offset": 742.44,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "data in a way that produce has a better",
      "offset": 745.399,
      "duration": 7.081
    },
    {
      "lang": "en",
      "text": "performance so we change the focus on",
      "offset": 749.48,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "looking at data directly instead of you",
      "offset": 752.48,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "know thinking about model so that's like",
      "offset": 755.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "one area that we need to explore more",
      "offset": 756.76,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "and we are at the beginning of that we",
      "offset": 759.199,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "have right now built a platform and a",
      "offset": 761.04,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "community where one can come in and",
      "offset": 763.959,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "propose a new data Centric Challenge in",
      "offset": 766.959,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "a new domain and put it out there and",
      "offset": 768.76,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "it's not you know entirely you know",
      "offset": 772.12,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "automated uh it requires a little bit of",
      "offset": 774.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "human touch and engineering because",
      "offset": 777.72,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "these you know patterns are new um",
      "offset": 779.32,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "compared to like the type of things that",
      "offset": 782.199,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "kaggle for instance does so that's one",
      "offset": 783.839,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "area but I think that you know one",
      "offset": 787.04,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "picture that you started painting as",
      "offset": 789.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "well is that these benchmarks are",
      "offset": 791.56,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "proxies right these benchmarks are like",
      "offset": 793.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "little tests that tell us that we're",
      "offset": 795.76,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "moving in the right direction and we",
      "offset": 797.6,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "need them when we are beginning at the",
      "offset": 799.48,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "beginning of a process but what do the",
      "offset": 801.639,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "benchmarks really imply they imply a",
      "offset": 803.839,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "capability and you know those are like",
      "offset": 807.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "little tests of that capability just",
      "offset": 809.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "like you know even if you think about",
      "offset": 811.639,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "exams that we go through in like a",
      "offset": 813.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "school education or at in college these",
      "offset": 815.6,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "exams are a little test of whether we",
      "offset": 818.6,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "have learned something right and there",
      "offset": 821.639,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "are many ways to pass the exams in fact",
      "offset": 823.959,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "uh you know education researchers one of",
      "offset": 826.8,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "the biggest problems that they you know",
      "offset": 829.24,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "lose their sleep about is the figuring",
      "offset": 831.079,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "out the distinction between root",
      "offset": 834.399,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "learning and conceptual understanding",
      "offset": 835.92,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "and the goal of the educational system",
      "offset": 838.759,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "is to impart conceptual understanding so",
      "offset": 840.92,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "then you can have the capability to",
      "offset": 843.04,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "carry out a certain kind of",
      "offset": 845.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "task and the exams are these little",
      "offset": 847.079,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "proxies for that right and there are",
      "offset": 850.72,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "ways in which you know clever students",
      "offset": 853.16,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "can game the exams and there are entire",
      "offset": 854.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "institutions like Kaplan that can help",
      "offset": 857.759,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "you game these exams and you'll be",
      "offset": 860.44,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "better off if you took that and they",
      "offset": 862.839,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "don't really you know you can have an",
      "offset": 865.04,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "whole complex of exams and coaching and",
      "offset": 867.12,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "you know all of that but they are not",
      "offset": 869.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "entirely in the service of the true goal",
      "offset": 871.399,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "that we have of Education which is",
      "offset": 874.04,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "giving you the capability the competence",
      "offset": 876.32,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "and so we should remember that these",
      "offset": 879.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "benchmarks just like these tests are",
      "offset": 881.72,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "just you know these little indicators",
      "offset": 884.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "but what we want is competence I I want",
      "offset": 886.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "to give you a system that is competent",
      "offset": 888.32,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "at doing a certain kind of task right",
      "offset": 891.279,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "let's say let's consider the calculator",
      "offset": 893.32,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "right if you want to buy a calculator",
      "offset": 895.199,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "you want the expectation is that you",
      "offset": 897.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "know the addition multiplication",
      "offset": 900.32,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "division arithmetic that you want to",
      "offset": 901.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "do whatever number of digits the",
      "offset": 903.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "calculator can handle it'll give you",
      "offset": 905.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "correct answers every time so that's the",
      "offset": 907.639,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "competence that you want to expect now",
      "offset": 910.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "you know how would you test that right",
      "offset": 912.88,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "like with a test set any test set is",
      "offset": 914.639,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "going to be",
      "offset": 916.92,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "finite and might not be the best test",
      "offset": 917.959,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "set for like confirming 100% accuracy on",
      "offset": 920.399,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "all possible arithmetic questions that",
      "offset": 923.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the calculator can answer so in that",
      "offset": 926.079,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "such a case is we have almost a sound",
      "offset": 928.16,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "proof of why the calculator is correct",
      "offset": 931.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "so the way the systems and the circuits",
      "offset": 934.199,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "are designed is it's a proof of that",
      "offset": 935.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "competence so that's another way to say",
      "offset": 938.24,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "that you have competence right you could",
      "offset": 940.92,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "have uh you passed a multiple choice",
      "offset": 942.639,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "test you know you passed an interview uh",
      "offset": 945.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "you submitted a proof so these are all",
      "offset": 948.759,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "these different mechanisms so all we",
      "offset": 951.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "want to say is you know eventually you",
      "offset": 952.639,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "want to deploy it in some real world",
      "offset": 954.48,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "circumstance and it be able to you you",
      "offset": 956.279,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "know demonstrate the competence that it",
      "offset": 958.68,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "claimed that it has and so for instance",
      "offset": 960.319,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "uh I was at Google for 13 years and what",
      "offset": 963.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "witnessed the launch of some of these uh",
      "offset": 966.6,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "you know Transformers and the bird",
      "offset": 968.399,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "architectur these were built in house",
      "offset": 969.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "and the search uh you know ranking team",
      "offset": 972.199,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "search engineering team they were very",
      "offset": 975.36,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "careful in evaluating and testing these",
      "offset": 978.519,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "systems even though when they just do a",
      "offset": 981.6,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "did a first you know comparison on the",
      "offset": 983.68,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "Baseline metrics it performed as well as",
      "offset": 986.519,
      "duration": 6.041
    },
    {
      "lang": "en",
      "text": "the existing system but they were not",
      "offset": 990.16,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "convinced they they were worried and",
      "offset": 992.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "they poked and they tested the system",
      "offset": 994.92,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "and they found other weaknesses that the",
      "offset": 997.12,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "metric basically they realized the",
      "offset": 998.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "metric doesn't entirely capture once we",
      "offset": 1000.639,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "deploy it to billions of queres every",
      "offset": 1002.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "day all sorts of things will happen that",
      "offset": 1005.04,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "we are actually liable for and so they",
      "offset": 1007.279,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "were cautious and they spent like I",
      "offset": 1009.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "think upwards of two years in just",
      "offset": 1011.16,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "testing the system before deploying it",
      "offset": 1013.319,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "so that is the difference between you",
      "offset": 1015.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "know benchmark you know and metrics and",
      "offset": 1017.36,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "the competence and at some situations",
      "offset": 1019.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "when you are you know liable or Stakes",
      "offset": 1022.68,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "are high then it's the competence that",
      "offset": 1025.6,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "you want to care about at the end of the",
      "offset": 1027.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "day if you're working in healthcare then",
      "offset": 1029.439,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "you want FDA approval to demonstrate the",
      "offset": 1031.679,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "competence and so I think that we should",
      "offset": 1034.72,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "move more toward thinking about other",
      "offset": 1038.24,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "approaches to claim competence so right",
      "offset": 1041.039,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "now for instance there are papers that",
      "offset": 1044.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "are published about you know neural uh",
      "offset": 1045.88,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "networks language models uh abilities to",
      "offset": 1048.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "do arithmetic to continue with this",
      "offset": 1052.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "calculator example and most notably chat",
      "offset": 1054.28,
      "duration": 8.519
    },
    {
      "lang": "en",
      "text": "GPT GPT 3.5 was you know you know maybe",
      "offset": 1057.6,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "something like 70 80% accurate it was",
      "offset": 1062.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "actually reasonably accurate and it's",
      "offset": 1064.799,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "very impressive right like it wasn't",
      "offset": 1066.48,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "designed to do that and um then the gp4",
      "offset": 1067.919,
      "duration": 8.521
    },
    {
      "lang": "en",
      "text": "was actually 4% accurate so for some",
      "offset": 1073.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "reason that the changes and improvements",
      "offset": 1076.44,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "that made actually hurt its arithmetic",
      "offset": 1077.919,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "capability and then then some folks out",
      "offset": 1080.24,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "of China built a gigantic neural network",
      "offset": 1082.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "just focused on doing arithmetic and",
      "offset": 1085.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "they got to Almost 100%",
      "offset": 1087.559,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "accuracy and so you know I think that at",
      "offset": 1090.52,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "some point you know we might just want",
      "offset": 1095,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "proof like if you're doing you know",
      "offset": 1096.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "logic and reasoning and arithmetic in",
      "offset": 1099.84,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "these worlds there are actual proofs of",
      "offset": 1103,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "competence you don't need to be",
      "offset": 1106.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "empirical about it if I give you a",
      "offset": 1108.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "theorem with a proof then you have",
      "offset": 1109.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "absolute certainty that it is correct so",
      "offset": 1113.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "there are other mechanisms that are less",
      "offset": 1115.48,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "empirical that come with more sound",
      "offset": 1117.36,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "guarantees so we might want to think",
      "offset": 1119.76,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "about uh you know approaches like that",
      "offset": 1123.159,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "as we expand towards thinking about",
      "offset": 1126.559,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "capabilities not just performance on a",
      "offset": 1128.159,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "leaderboard got it I think one thing",
      "offset": 1131.96,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "that you and sonan are alluding to is",
      "offset": 1134.679,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "that engineers want to see how a",
      "offset": 1137.039,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "specific model",
      "offset": 1139.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "performs uh on their specific metric on",
      "offset": 1140.679,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "their specific tax when you talk about",
      "offset": 1143.76,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "competence each engineer may actually",
      "offset": 1145.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Define it uh quite differently I think",
      "offset": 1147.72,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "folks that you just very practical",
      "offset": 1151.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "question folks want to know what",
      "offset": 1153.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "competent on their specific uh data and",
      "offset": 1154.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "their specific M but that's very varied",
      "offset": 1157.2,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "and hard right so data freshness is more",
      "offset": 1158.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "apparent for student use cases then if",
      "offset": 1161.559,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "you're fi you're looking to fine-tune",
      "offset": 1163.36,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "data if you're looking on specific",
      "offset": 1164.799,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "problems robustness of your data set you",
      "offset": 1166.4,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "might be working for actually very",
      "offset": 1168.08,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "different data sets to augment your use",
      "offset": 1169.559,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "case uh than another and so I almost",
      "offset": 1171.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "want to take uh you know I'm a data",
      "offset": 1174.159,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "scientist or an ml engineer I uh you",
      "offset": 1177.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "know I'm looking at these specific high",
      "offset": 1180.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "level metrics that I'm used to and you",
      "offset": 1181.96,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "know for last decade you've been trained",
      "offset": 1183.6,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "to look at Precision recalls so in this",
      "offset": 1185.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "new Wild West Pine what is the advice",
      "offset": 1186.919,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "how do you even decompose such a varied",
      "offset": 1189.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "problem right we need to move in this",
      "offset": 1191.799,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "new Direction that's more intelligent uh",
      "offset": 1193.52,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "Beyond looking at this Bolden metric but",
      "offset": 1196.08,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "what is your advice to a data scientist",
      "offset": 1198.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that is looking to even understand and",
      "offset": 1200.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "people know the problem is more varied",
      "offset": 1202.44,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "but we still resort to uh you know just",
      "offset": 1204.039,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "looking at uh you know these uh these",
      "offset": 1207.159,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "sort of high level metrics so what how",
      "offset": 1209.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "do we decompose that problem of we're a",
      "offset": 1211.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "data scientist how do we uh how do we",
      "offset": 1213.28,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "compose a new framework for thinking",
      "offset": 1216.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "through uh thinking through data if",
      "offset": 1219.48,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "we're just a random data engineer",
      "offset": 1221.6,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "working on problem on a specific problem",
      "offset": 1222.88,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "try augment our data how do we how do we",
      "offset": 1225.32,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "approach",
      "offset": 1228.52,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "this right so where we are I I would say",
      "offset": 1230.48,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "that you know what you're asking amount",
      "offset": 1234.36,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "in data science terms amounts to asking",
      "offset": 1237.28,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "you know what is the Precision and",
      "offset": 1240.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "recall of my test set",
      "offset": 1241.48,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "itself right because I'm using a test",
      "offset": 1244.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "set to estimate the Precision and recall",
      "offset": 1247.28,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "of some model some system like the squad",
      "offset": 1250,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "is being used as a test set to evaluate",
      "offset": 1253.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the Precision and recall of some",
      "offset": 1256.28,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "question answering systems but then you",
      "offset": 1257.72,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "can also ask the meta question which is",
      "offset": 1260.32,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "also a data science question what is the",
      "offset": 1263.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Precision and recall of this test set",
      "offset": 1265.64,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "itself now as we see like if you look at",
      "offset": 1267.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Squad 2.0 given that it was missing",
      "offset": 1270.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "unanswerable questions so that's an",
      "offset": 1272.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "example of question",
      "offset": 1274.32,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "that is is not in the recall right like",
      "offset": 1276.799,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "so it has low recall because it's",
      "offset": 1281.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "missing a class of questions and then",
      "offset": 1282.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "there is other class of questions since",
      "offset": 1285.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Squad was studied in gr dep you know",
      "offset": 1286.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "questions about causality questions that",
      "offset": 1288.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "were for instance uh about non-factual",
      "offset": 1291.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "things because the data set was",
      "offset": 1294.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "constructed entirely on Wikipedia so by",
      "offset": 1295.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "by by definition all questions were",
      "offset": 1298.72,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "factual but if you look at the universe",
      "offset": 1300.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "of questions like a search engine gets",
      "offset": 1303,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "uh there's a significant amount of query",
      "offset": 1305.72,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "volume that contains the word should you",
      "offset": 1307.919,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "know should I do this or that and those",
      "offset": 1310.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "questions are not answered by a factual",
      "offset": 1312.36,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "Source like Wikipedia and you have to go",
      "offset": 1314.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to forums and you know other kinds of",
      "offset": 1316.4,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "opinions sources of opinions so the",
      "offset": 1318.48,
      "duration": 7.72
    },
    {
      "lang": "en",
      "text": "recall of this test set is not very high",
      "offset": 1321.72,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "so as a data scientist I would be",
      "offset": 1326.2,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "worried about what's missing in my test",
      "offset": 1327.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "set that because I'm making a claim",
      "offset": 1330,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "about a competence and if I say that it",
      "offset": 1332.36,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "this system can answer questions I",
      "offset": 1334.679,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "didn't say there was a footnote but not",
      "offset": 1336.24,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "uh non-factual ones but not the ones",
      "offset": 1339.52,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "that are unanswerable but not the ones",
      "offset": 1342.08,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "like if I am making that claim uh you",
      "offset": 1343.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "know I'm between the leap between what",
      "offset": 1347.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the test set captures and what the",
      "offset": 1349.159,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "phenomena or the competence I'm claiming",
      "offset": 1351.159,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "I should be very cognizant of that so I",
      "offset": 1353.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "would say that we must strive to figure",
      "offset": 1355.76,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "out what are these blind spots in our",
      "offset": 1357.84,
      "duration": 6.839
    },
    {
      "lang": "en",
      "text": "test sets uh of which between the gap",
      "offset": 1361.4,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "between you know what what the",
      "offset": 1364.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "competence claims and what we currently",
      "offset": 1366.159,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "have sampled in the test set and we need",
      "offset": 1368.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "to cover those areas so this",
      "offset": 1371.559,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "distributional mismatch between the you",
      "offset": 1373.96,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "know like often when real you know like",
      "offset": 1376.039,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "when one example was in fact uh an early",
      "offset": 1377.84,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "paper from Google where they showed",
      "offset": 1380.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "pretty strong results on diabetic",
      "offset": 1382.76,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "retinopathy and turns out that when",
      "offset": 1385.24,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "people actually deployed that system",
      "offset": 1387.919,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "then they there was the results were not",
      "offset": 1390.24,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "that good and it was a mismatch between",
      "offset": 1392.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "what was the actual real world sample",
      "offset": 1395.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and what sample was represented in the",
      "offset": 1397.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "test set so I think if we rely on the",
      "offset": 1399.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "methodology of test sets and benchmarks",
      "offset": 1402.44,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "then the test sets themselves are not",
      "offset": 1404.84,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "like ground truth and a representative",
      "offset": 1407.679,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "sample so test sets contain errors like",
      "offset": 1410.919,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "there was a study done by Curtis North",
      "offset": 1413.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "who is currently running clean lab and",
      "offset": 1416.2,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "he looked at you know 10 different most",
      "offset": 1419.12,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "cited data sets including imet and he",
      "offset": 1421.6,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "found that there were you know anywhere",
      "offset": 1423.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "from you know 3 to 10% errors in these",
      "offset": 1426.279,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "test set and when the he tried to fix",
      "offset": 1428.84,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "those errors um then the performance",
      "offset": 1431.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "changed so that you know rest net 18 was",
      "offset": 1434.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "doing better than than rest net 50 which",
      "offset": 1437.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "is a much more expensive model so that",
      "offset": 1438.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "makes you know begs the question so",
      "offset": 1441.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that's like a Precision error right and",
      "offset": 1442.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "what we previously talked about Squad",
      "offset": 1444.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "was like recall errors so we should",
      "offset": 1446.559,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "strive to measure quality of test sets",
      "offset": 1448.96,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "and improve the quality of those test",
      "offset": 1451.279,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "sets and we are beginning to figure out",
      "offset": 1452.919,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "in the work done with ML Commons some of",
      "offset": 1455.32,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "these mechanisms of attacking like this",
      "offset": 1458.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "adversarial uh approaches so one of the",
      "offset": 1460.4,
      "duration": 7.759
    },
    {
      "lang": "en",
      "text": "experiments um I ran uh with uh Laura",
      "offset": 1463.52,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "was this project and Kwang was this",
      "offset": 1468.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "project called cats forl where we",
      "offset": 1470.24,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "basically challenged participants to",
      "offset": 1472.32,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "submit images that would fool the",
      "offset": 1474.679,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "classifier so even though the classifier",
      "offset": 1478.64,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "had a performance of like 90% on the",
      "offset": 1481.039,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "overall data set from the same data set",
      "offset": 1484.6,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "they could sample images which the",
      "offset": 1487.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "classifier was getting wrong and which",
      "offset": 1489.52,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "chose some categories like uh you know",
      "offset": 1491.799,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "bus driver teacher uh um chop chop",
      "offset": 1494.36,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "sticks and I remember like we ended up",
      "offset": 1497.96,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "with we had 16,000 submissions we ended",
      "offset": 1500.559,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "up with a DAT data set of",
      "offset": 1502.399,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "10,000 on which we verified with human",
      "offset": 1504.159,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "labelers and in fact the machine was",
      "offset": 1507.039,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "getting it wrong so the in this test set",
      "offset": 1509,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the Precision was zero even though uh",
      "offset": 1511.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the state of art were performing at 0.9",
      "offset": 1514.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "on all of the standard test sets so this",
      "offset": 1516.12,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "was an adversarial approach and you know",
      "offset": 1518.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the kind of Errors we find was",
      "offset": 1520.799,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "interesting like an empty bus for",
      "offset": 1522.12,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "instance it would very confidently say",
      "offset": 1523.679,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "that there is a bus driver um or if",
      "offset": 1525.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "there is um",
      "offset": 1529.08,
      "duration": 7.839
    },
    {
      "lang": "en",
      "text": "uh there was a bowl of soup and you know",
      "offset": 1531.44,
      "duration": 7.64
    },
    {
      "lang": "en",
      "text": "there in rahen and it will be confident",
      "offset": 1536.919,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "that there's Chopsticks in the picture",
      "offset": 1539.08,
      "duration": 3.079
    },
    {
      "lang": "en",
      "text": "so there were these errors that were",
      "offset": 1540.72,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "like these kind of contextual",
      "offset": 1542.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "hallucinations but we discovered that by",
      "offset": 1543.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you know encouraging people to just",
      "offset": 1545.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "basically attack and this approach was",
      "offset": 1547.279,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "invented by Panos aerus at NYU in 2012",
      "offset": 1549.52,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "he built a system called beat the",
      "offset": 1553.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "machine where he it incentivized",
      "offset": 1555.08,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "mechanical tur workers to find an",
      "offset": 1557.32,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "example of hate speech that will fool",
      "offset": 1559.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "the system and if you fool the system",
      "offset": 1561.2,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "and subsequently will verified that you",
      "offset": 1564.159,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "were right that this was H speech then",
      "offset": 1565.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you got like 10 times more incentive",
      "offset": 1567.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "than if you the system recognized it so",
      "offset": 1569.88,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "there are these type of approaches that",
      "offset": 1571.919,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "we are exploring that are out there now",
      "offset": 1573.36,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "red teaming has become like a standard",
      "offset": 1575.48,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "you know testing methodology for",
      "offset": 1577.64,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "language",
      "offset": 1579.039,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "models awesome I again so many things to",
      "offset": 1582,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "dive into here I the I really love what",
      "offset": 1585.32,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "you just said specifically around the",
      "offset": 1588.6,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "idea of ground truth because in a lot of",
      "offset": 1590.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "people's experience working with data",
      "offset": 1594.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "that term it's almost like a term of art",
      "offset": 1596.24,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "these days to say like this is our",
      "offset": 1598.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "ground truth labeled data set right",
      "offset": 1599.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "everyone points to it and says this is",
      "offset": 1601.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the North Star we did it we found the",
      "offset": 1603.799,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "data but to your point what what that",
      "offset": 1605.64,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "kind of happen psychologically what what",
      "offset": 1608.279,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "happens is the more you say that the",
      "offset": 1609.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "more you kind of reinforce to yourself",
      "offset": 1611.84,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "that there there could be no fault in",
      "offset": 1613.44,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "our data it's the ground",
      "offset": 1615.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "truth and as soon as you start to prod",
      "offset": 1618.159,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "at it just a little bit and say well how",
      "offset": 1620.679,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "did you label it well it's a mix of Open",
      "offset": 1622.52,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "Source and some stuff we labeled in",
      "offset": 1624.48,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "house it's like oh has you know a",
      "offset": 1626,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "labeler who has been trained in your",
      "offset": 1628.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "framework gone over each and every one",
      "offset": 1630.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "of these data points no you start to",
      "offset": 1632.44,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "notice the cracks pretty quickly so I",
      "offset": 1635.159,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "really like that that that pushing back",
      "offset": 1638.08,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "on that idea that just because you call",
      "offset": 1640.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "something your ground truth does not",
      "offset": 1642.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "make it ground truth because if you",
      "offset": 1644.799,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "misrepresent or not misrepresent well",
      "offset": 1648.6,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "you could misrepresent but if you",
      "offset": 1650.679,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "mislabel data points you're just asking",
      "offset": 1651.919,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "for trouble so there are some approaches",
      "offset": 1654.12,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "you know quantitatively speaking that I",
      "offset": 1657.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "I personally really like uh there's this",
      "offset": 1659.279,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "one approach called I think area under",
      "offset": 1661.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "the margin ranking I believe which is",
      "offset": 1663.679,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "one approach to finding mislabeled data",
      "offset": 1666.44,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "and I think their example was actually I",
      "offset": 1669.76,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "think it was something like imet where",
      "offset": 1671.84,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "they were they were showing an example",
      "offset": 1673.399,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "of an image database where they were",
      "offset": 1675.08,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "finding mislabeled data as a",
      "offset": 1677.559,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "pre-processing step and that that idea",
      "offset": 1680.24,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "that working on your",
      "offset": 1683.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "data almost as much as if not more than",
      "offset": 1685.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "working on your model is something I I",
      "offset": 1688.96,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "personally am am extremely passionate",
      "offset": 1691,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "about um Eagle eagle-eyed listeners will",
      "offset": 1693,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "if you've ever read my books in one of",
      "offset": 1695.72,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "my books my first future engineering",
      "offset": 1698.76,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "book in the first chapter I I make a big",
      "offset": 1700.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "note and I remember this was like six",
      "offset": 1703.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "years seven years ago so my my publisher",
      "offset": 1705.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "were like why are you saying this I made",
      "offset": 1707.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "a point up front and saying this is not",
      "offset": 1709.679,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "a machine learning tuning book the point",
      "offset": 1712.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "of this book is I am going to only ever",
      "offset": 1715.12,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "use logistic regression I am setting",
      "offset": 1718.24,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "myself up right now like this is the",
      "offset": 1720.6,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "only model I'm allowing myself to use I",
      "offset": 1722.519,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "have to only find data uh performance",
      "offset": 1726.399,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "increments through data pre-processing",
      "offset": 1729.279,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "feature engineering Transformations",
      "offset": 1731.48,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "whatever it is selections so be it and",
      "offset": 1733.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that was the whole premise",
      "offset": 1736.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "uh and the point was to prove or at",
      "offset": 1738.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "least show that you can actually get",
      "offset": 1740.48,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "these boosts and performance by",
      "offset": 1743.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "manipulating only your data alone and",
      "offset": 1745.679,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and not even touching your models",
      "offset": 1748.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "parameters or at least the model",
      "offset": 1750.559,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "architecture uh now that being said all",
      "offset": 1753.159,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "of this again to your point comes back",
      "offset": 1755.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to well you got to trust the data and",
      "offset": 1757.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "not only do you have to trust the data",
      "offset": 1760.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "you have to trust that your data is",
      "offset": 1761.679,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "representative of the system you're",
      "offset": 1764.12,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "trying to model so coming back to",
      "offset": 1766.399,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "something you said earlier something I'm",
      "offset": 1768.159,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "personally very curious about being a",
      "offset": 1769.76,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "former mathematician how do you approach",
      "offset": 1771.96,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "the the concept of a proof in the world",
      "offset": 1775.72,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "of llms H how do you even uh think about",
      "offset": 1778.64,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "proving that your llm can solve a task",
      "offset": 1782.44,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "versus showing your llm can solve a task",
      "offset": 1785.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "using a data",
      "offset": 1788.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "set that's the question right yeah I",
      "offset": 1791.12,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "don't know we really we really that's",
      "offset": 1793.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that's the most interesting question at",
      "offset": 1796.679,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "this point that the field is facing",
      "offset": 1798.2,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "right this these benchmarks served us um",
      "offset": 1800.039,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "you know really well right so this began",
      "offset": 1803.519,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "in around",
      "offset": 1806.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "2010 and so the first",
      "offset": 1807.96,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "decade you know the benchmarks like",
      "offset": 1810.64,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "really allowed a lot of progress to",
      "offset": 1812.88,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "happen and a lot of people from all over",
      "offset": 1814.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the world to be able to work on the same",
      "offset": 1816.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "problem and you know and then we evolved",
      "offset": 1819.24,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "to like these basket of benchmarks and",
      "offset": 1822.6,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "that's like still you know like we're",
      "offset": 1824.64,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "like hobbling on the the crutches you",
      "offset": 1826.32,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "know like we're moving forward on this",
      "offset": 1828.519,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "but we're realizing that that's not",
      "offset": 1830.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "enough and like with llms you know it's",
      "offset": 1831.559,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "become even more challenging to compare",
      "offset": 1834.44,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "and test these systems so you",
      "offset": 1837.2,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "know I think that and it's also",
      "offset": 1840.72,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "challenging for you know one of the",
      "offset": 1843,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "things about Benchmark is that you can",
      "offset": 1844.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "do this kind of Rapid iterations you",
      "offset": 1846.32,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "know you can submit a new model and run",
      "offset": 1848.36,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "it and you know find how well you did",
      "offset": 1850.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "but this idea doesn't work very well",
      "offset": 1853.399,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "when you know each iteration cost tens",
      "offset": 1856.2,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "of millions of dollars to pre-train a",
      "offset": 1858.279,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "language model for instance so I think",
      "offset": 1860.799,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "that we need to think about collectively",
      "offset": 1863.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "as a field you know like how do we",
      "offset": 1865.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "measure progress because what benchmarks",
      "offset": 1868.44,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "are are these proxy estimates of",
      "offset": 1870.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "progress and you know we are so powerful",
      "offset": 1872.48,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "these things are so powerful and also so",
      "offset": 1875.88,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "expensive right so",
      "offset": 1877.399,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "monolithic",
      "offset": 1879.12,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "and so I feel at this point in time that",
      "offset": 1880.72,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "you know we might just need to",
      "offset": 1885.6,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "recognize that this monolithic approach",
      "offset": 1888.2,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "is not sufficient we need a more modular",
      "offset": 1891.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "approach and we need different",
      "offset": 1894.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "components that do different things that",
      "offset": 1897.48,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "we can test more clearly like what that",
      "offset": 1899.32,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "component promises so for instance you",
      "offset": 1901.6,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "know one of the most successful you know",
      "offset": 1904.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "the maybe the first killer app of",
      "offset": 1907.399,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "language models has been application to",
      "offset": 1909.32,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "uh internal Enterprise you know",
      "offset": 1913.159,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "information um access I would say like",
      "offset": 1915.88,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "mean in some sense for instance using",
      "offset": 1919.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "Vector databases and using retrival",
      "offset": 1921.639,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "augmented generation to index your",
      "offset": 1923.639,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "private documents your corporate",
      "offset": 1926.799,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "documents and then make them accessible",
      "offset": 1928.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "to you for in form of question answering",
      "offset": 1931.24,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "or chat or some some other form of",
      "offset": 1933.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "interface",
      "offset": 1935.639,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "now that is you know that that is like",
      "offset": 1937.48,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "you know I and my I think there's",
      "offset": 1941.799,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "probably at least a dozen companies that",
      "offset": 1943.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "I can think of that have like",
      "offset": 1945.2,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "well-funded you know uh you know",
      "offset": 1947.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "resources that are going after this",
      "offset": 1949.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "problem in the last you know 6 months",
      "offset": 1950.88,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "but it's really interesting to trace how",
      "offset": 1953.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "it happened so uh the first",
      "offset": 1955.32,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "demonstration uh in 2015 was of word Toc",
      "offset": 1958.12,
      "duration": 8.279
    },
    {
      "lang": "en",
      "text": "which was which did the you know magical",
      "offset": 1962.76,
      "duration": 8.159
    },
    {
      "lang": "en",
      "text": "thing that was king plus man minus woman",
      "offset": 1966.399,
      "duration": 7.481
    },
    {
      "lang": "en",
      "text": "equals Queen so it represented words as",
      "offset": 1970.919,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "vectors and was able to show that these",
      "offset": 1973.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "vectors contained enough semantics that",
      "offset": 1976.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "you could do this kind of arithmetic",
      "offset": 1978.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "that made common sense and in 2017 by",
      "offset": 1980.039,
      "duration": 6.841
    },
    {
      "lang": "en",
      "text": "2017 people had build Vector databases",
      "offset": 1983.639,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "because once it was clear that these",
      "offset": 1986.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "embeddings contain semantic information",
      "offset": 1988.679,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "that allowed people to to do that both",
      "offset": 1991.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "inside Google and outside",
      "offset": 1993.72,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "Google however you know the peak",
      "offset": 1996.159,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "interest in this technology began like",
      "offset": 1999.679,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "towards the end of last year early this",
      "offset": 2002.96,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "year uh after you know generative AI you",
      "offset": 2005.24,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "know the storm was kicked off by cat GPT",
      "offset": 2009.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "so it's really interesting and how that",
      "offset": 2012.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "is being used like most of the Magic in",
      "offset": 2014.6,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "the system these rag systems are",
      "offset": 2016.44,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "actually indexing your documents into",
      "offset": 2019.36,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "vectors and bringing them back to you",
      "offset": 2021.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "retrieval augmented generation and then",
      "offset": 2024.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "using the thin layer of language model",
      "offset": 2025.799,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "to craft you know the response for you",
      "offset": 2028.12,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "so what is happening is uh the llm is",
      "offset": 2031.399,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "acting one as a component and in this",
      "offset": 2034.76,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "overall system it's not the only thing",
      "offset": 2037.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that's doing the question answering",
      "offset": 2039.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "unlike the idea of just going to chbt",
      "offset": 2040.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "and getting you know your job done by",
      "offset": 2043.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "prompting it or fine-tuning it it's",
      "offset": 2045.279,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "actually an entire modular system that",
      "offset": 2048.56,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "contains index of your documents that's",
      "offset": 2051.44,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "one thing the other thing is the LM is",
      "offset": 2054.119,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "not at the",
      "offset": 2055.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "center you know it's almost a cernic",
      "offset": 2057.079,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "flip you know the LM is acting as an",
      "offset": 2059.48,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "interface and a lot of the magic is",
      "offset": 2062.679,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "happening with these embeddings in the",
      "offset": 2065.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "vector database and in the retrieval",
      "offset": 2067.079,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "process so I feel that this is just an",
      "offset": 2069.28,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "example of how things are going to look",
      "offset": 2073.04,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "like as we move forward as we move",
      "offset": 2075,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "forward we'll have many of these",
      "offset": 2077.159,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "different components that solve",
      "offset": 2078.639,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "different problems and we hook them up",
      "offset": 2080.04,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "and now we're not testing the monolithic",
      "offset": 2082.04,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "llm um but we're testing how well for",
      "offset": 2085.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "instance what is the Precision of",
      "offset": 2088.359,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "documents that this rag system retrieves",
      "offset": 2089.76,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "when I make a query that can be",
      "offset": 2092.879,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "independently evaluated just like search",
      "offset": 2094.52,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "engines where back in the day and the",
      "offset": 2096.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "third thing that this case study shows",
      "offset": 2098.48,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "is it's also how you know llms are",
      "offset": 2100.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "unlocking power of technologies that",
      "offset": 2104.599,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "were around so this technology for doing",
      "offset": 2106.76,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "embeddings and retrieval using Vector",
      "offset": 2110,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "database was around since 2017 but this",
      "offset": 2112.359,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "is what made it happen so I I feel like",
      "offset": 2115.16,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "maybe that's the shape of things to come",
      "offset": 2117.68,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "and many many more new components can be",
      "offset": 2119.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "added for precisely the type of things",
      "offset": 2122.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that llms are struggling at at this",
      "offset": 2124.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "point yeah and again I think we've said",
      "offset": 2125.8,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "this on the show dozens of times but my",
      "offset": 2128.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "my personal philosophy on",
      "offset": 2130.8,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "llms you know at a high level is that",
      "offset": 2132.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "they are exceptional reasoning machines",
      "offset": 2135.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "they are not the best thinking machines",
      "offset": 2137.04,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "right they are they are incredible at",
      "offset": 2139.64,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "being given you know insane amounts of",
      "offset": 2141.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "context and saying given these 20 Pages",
      "offset": 2144.64,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "answer this one question they're really",
      "offset": 2147.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "good at that kind of work but they're",
      "offset": 2149.079,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "not as good as coming back almost full",
      "offset": 2150.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "circle they're not as good as closed QA",
      "offset": 2153.4,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "you know not given the actual context to",
      "offset": 2156.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "answer this question that's where the",
      "offset": 2158.88,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "hallucinations tend to come in so to to",
      "offset": 2160.52,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "kind of again bring this full circle",
      "offset": 2163.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "when we're talking about Squad this is",
      "offset": 2165.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "very specifically an open book question",
      "offset": 2168.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "answering test right given context and a",
      "offset": 2170.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "question answer the question given the",
      "offset": 2172.76,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "context and rag is just the same thing",
      "offset": 2175.2,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "with uh with a vector database tacked on",
      "offset": 2179.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "well here's the question let me go ahead",
      "offset": 2181.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "and retrieve that let me look up in the",
      "offset": 2183.8,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "textbook real quick grab the context now",
      "offset": 2185.599,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "separate task given a question and a",
      "offset": 2189.04,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "context answer the question so you end",
      "offset": 2192.2,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "up with this modularity which is to a",
      "offset": 2194.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "developer you know almost music to their",
      "offset": 2196.8,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "ears because now I can test two things",
      "offset": 2199.2,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "and have a really good sense for where",
      "offset": 2201.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "things are breaking down in the pipeline",
      "offset": 2204.04,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "did is the document messed up does I'll",
      "offset": 2207,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "even add some more in is the chunking um",
      "offset": 2209.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "actually chunking up the information",
      "offset": 2212.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "appropriately is the embedding actually",
      "offset": 2215.04,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "embedding the semantic information from",
      "offset": 2217.839,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "our chunks correctly is our buy encoder",
      "offset": 2219.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "or whatever we're using for our",
      "offset": 2222.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "embedding actually matching things up",
      "offset": 2223.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "correctly are we retrieving the right",
      "offset": 2225.48,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "documents is the question and answering",
      "offset": 2227.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "system actually answering questions",
      "offset": 2229.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "given the right cont so you have this",
      "offset": 2231.319,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "chain of tasks that all end up with",
      "offset": 2233.44,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "someone ask a question and they get an",
      "offset": 2236.319,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "answer back but on the back end it's",
      "offset": 2237.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "it's a lot more steps happening and that",
      "offset": 2239.96,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "speaks to to kind of wrap it all up in a",
      "offset": 2242.359,
      "duration": 6.361
    },
    {
      "lang": "en",
      "text": "nice little bow this kind of this trend",
      "offset": 2245.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "we see of you know blank is all you need",
      "offset": 2248.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "I obviously you know coming from the the",
      "offset": 2251.44,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "fact that the Transformer paper is",
      "offset": 2253.839,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "called attention is all you need again",
      "offset": 2255.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "coming from a human standpoint it's",
      "offset": 2257.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "really appealing to say finally this AI",
      "offset": 2259.64,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "can do this is all we need but to the",
      "offset": 2263,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "real you know the production level",
      "offset": 2266.16,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "machine learning engineer they know well",
      "offset": 2267.599,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "the llm is one component of the 20",
      "offset": 2269.16,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "things that have to happen for our end",
      "offset": 2271.8,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "user to get their answer um so so in in",
      "offset": 2273.92,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "your words what is the what is the",
      "offset": 2277.04,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "reconciliation that has to happen",
      "offset": 2280.8,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "between where you know the blank is all",
      "offset": 2283.56,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "you need uh Trend and the actual",
      "offset": 2286.359,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "productionize system like what what has",
      "offset": 2290.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "to happen to get more people on the boat",
      "offset": 2292.16,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "of modularity testing and benchmarking",
      "offset": 2295,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "uh in in in in your",
      "offset": 2298.359,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "words I think it's really interesting I",
      "offset": 2301.079,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "mean if you I can SP speculate a little",
      "offset": 2303.88,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "bit about why we are here you know it",
      "offset": 2307.24,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "seems very obvious right what you were",
      "offset": 2309.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "saying moments ago every computer",
      "offset": 2311.2,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "scientist in the audience was probably",
      "offset": 2313.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "were vigorously nodding their heads",
      "offset": 2315.72,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "throughout it right we you know that's",
      "offset": 2317.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "what we how we we're taught to break a",
      "offset": 2319.599,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "problem down into smaller problems build",
      "offset": 2321.839,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "tests for those components hook those",
      "offset": 2324.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "components up and then do integration",
      "offset": 2326.68,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "and different people were responsible",
      "offset": 2328.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "and you could assemble a gigantic thing",
      "offset": 2331.599,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "out of such a process that's what the",
      "offset": 2333.319,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "software engineering is all about you",
      "offset": 2335.04,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "know as quickly as in your you know",
      "offset": 2337,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "first you know few classes you learn",
      "offset": 2339.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that you have to write small modular",
      "offset": 2341.44,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "functions that you can compose in so",
      "offset": 2343.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "many different ways and reuse of code",
      "offset": 2345.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "and you know having components that used",
      "offset": 2348.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "in different all of that so that's how",
      "offset": 2349.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we want to build systems that's where",
      "offset": 2351.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "computer scientists are taught to do",
      "offset": 2353.96,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "things and where we have is we have this",
      "offset": 2355.48,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "one very powerful thing and this thing",
      "offset": 2357.599,
      "duration": 7.601
    },
    {
      "lang": "en",
      "text": "the for instance you know llama too you",
      "offset": 2362.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "know like it there's no sub components",
      "offset": 2365.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in there you take it and then you can do",
      "offset": 2367.2,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "a few things on top of it you can prompt",
      "offset": 2369.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "it differently you can fine-tune it and",
      "offset": 2370.92,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "you get an answer so it kind of breaks",
      "offset": 2372.48,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "down like the typical you know computer",
      "offset": 2376.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "science you know setup and when you look",
      "offset": 2378.64,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "at go talk to people in Industry who are",
      "offset": 2381.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "trying to build you know serve a problem",
      "offset": 2383.48,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "solve a problem then you see that their",
      "offset": 2386.16,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "systems indeed do have components and",
      "offset": 2388.48,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "and so I feel like you know the first of",
      "offset": 2391.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "all I would say that we do need to you",
      "offset": 2394.28,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "you know turn this whole AI research",
      "offset": 2396.44,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "from this rocket science like approach",
      "offset": 2400.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "to computer science where we do have",
      "offset": 2403.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "components we do have modularity we do",
      "offset": 2405.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "have testing all of these features that",
      "offset": 2407.599,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "we know how to build robust systems",
      "offset": 2409.56,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "now you know why are we here I think",
      "offset": 2413.4,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "that this seems so obvious but I'll tell",
      "offset": 2416.88,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "you I think that there are people who",
      "offset": 2419.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "think that this is Blasphemous so when",
      "offset": 2421.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "in",
      "offset": 2425.56,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "2020 in New York uh right after yosua",
      "offset": 2427,
      "duration": 8.44
    },
    {
      "lang": "en",
      "text": "Benjo and the other true Trinity they",
      "offset": 2431.52,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "won the touring award they had a",
      "offset": 2435.44,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "panel with Daniel kanaman the guy who",
      "offset": 2438.64,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "wrote thinking fast and slow and they",
      "offset": 2441.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "were having a discussion about you know",
      "offset": 2443.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "system one system two and Daniel kanaman",
      "offset": 2445.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "brought to the table the point that",
      "offset": 2447.8,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "there are two different kind of",
      "offset": 2449,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "systems and you know system one is this",
      "offset": 2450.68,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "kind of fast automatic system uh and",
      "offset": 2454.2,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "system 2 is effortful and deliberate and",
      "offset": 2457.28,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "uses",
      "offset": 2459.68,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "symbols and the entire panel was",
      "offset": 2461,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "completely opposed to him Yoshua and",
      "offset": 2465.319,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "Jeff clearly said that you know it is",
      "offset": 2467.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "not a hybrid",
      "offset": 2471.52,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "system it is it's very important to them",
      "offset": 2473.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "that it's you know neurons neurons all",
      "offset": 2476.599,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "the way it's differentiable all the way",
      "offset": 2478.96,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "where symbols don't have that property",
      "offset": 2481.56,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "so this is a philosophical aesthetic you",
      "offset": 2484.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "know position that the leading",
      "offset": 2487.119,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "researchers have have and maybe this has",
      "offset": 2488.359,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "you know gone into the community and so",
      "offset": 2491.4,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "other researchers also bring this way of",
      "offset": 2494.44,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "thinking and this has been there in AI",
      "offset": 2496.319,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "before as well like you know if you look",
      "offset": 2498.88,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "at it at the beginning like 50 years ago",
      "offset": 2500.92,
      "duration": 6.439
    },
    {
      "lang": "en",
      "text": "or so in you know when uh back",
      "offset": 2503.72,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "propagation was invented early on there",
      "offset": 2507.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "was not enough compute for those methods",
      "offset": 2509.92,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "to do much well but on top of that",
      "offset": 2511.599,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Marvin Minsky had a proof that it can't",
      "offset": 2514.04,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "solve the exor problem and that resulted",
      "offset": 2516.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "in a whole bunch of research you know",
      "offset": 2519.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "field in setback for that field but Jeff",
      "offset": 2521.04,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "Hinton and other people like you know",
      "offset": 2524.319,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "really persisted for like 50 years and",
      "offset": 2526.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "continued working on it and then got to",
      "offset": 2529.599,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "a point where you know these things",
      "offset": 2531.24,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "actually showed like tremendous",
      "offset": 2533.319,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "capabilities that we hadn't seen before",
      "offset": 2534.72,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "likewise you know a few months ago uh",
      "offset": 2537.119,
      "duration": 6.681
    },
    {
      "lang": "en",
      "text": "one of the pioneers of AI Doug lenet uh",
      "offset": 2540.8,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "he died he passed away uh he was uh the",
      "offset": 2543.8,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "Builder of Psych uh and he was one of",
      "offset": 2548.319,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "the most brilliant stars coming from the",
      "offset": 2550.92,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "you know symbolic community of AI and",
      "offset": 2554.04,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "then he turned down job offers at",
      "offset": 2557.48,
      "duration": 2.839
    },
    {
      "lang": "en",
      "text": "Stanford and places like that to go",
      "offset": 2558.88,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "start a company because his vision was",
      "offset": 2560.319,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "that we need to build a repository of",
      "offset": 2562.839,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "all common sense knowledge in logical",
      "offset": 2565.599,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "representation that a machine can reason",
      "offset": 2568.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "with and so he kept chugging away at",
      "offset": 2570.839,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "that problem for 40 years with funding",
      "offset": 2572.96,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "of any anywhere between a few million",
      "offset": 2575.76,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "dollars from government and other",
      "offset": 2577.4,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "sources and sometimes more sometimes",
      "offset": 2578.92,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "less depending upon the cycle and I",
      "offset": 2580.68,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "think the system currently has like",
      "offset": 2584.119,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "something like you know 10 million",
      "offset": 2585.599,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "axioms about you know what happens when",
      "offset": 2587.68,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "it rains and you know what is a",
      "offset": 2590.04,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "celebrity all kinds of things and you",
      "offset": 2591.48,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "can do reasoning with that and like you",
      "offset": 2592.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "know like I just want to use this two",
      "offset": 2596.319,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "examples to show that you know AI has",
      "offset": 2597.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "been driven by people who are very very",
      "offset": 2599.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "you know",
      "offset": 2602.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "um you know",
      "offset": 2604.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the word that comes to my mind is",
      "offset": 2607.2,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "stubborn but you know they're driven and",
      "offset": 2608.52,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "they're willing to take a hypothesis",
      "offset": 2611.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "like really all the way I mean so and",
      "offset": 2612.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "then there was kind of a fight between",
      "offset": 2615.4,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "these neural and symbolic camps I was",
      "offset": 2617.119,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "giving a talk about this and uh somebody",
      "offset": 2618.88,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "pointed out that you know but yeah of",
      "offset": 2621.4,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "course these people are upset because",
      "offset": 2624.119,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "you know we kept them in the basement",
      "offset": 2627.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "you know like the idea was when the",
      "offset": 2629.559,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "symbolic methods were at its peak early",
      "offset": 2631,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "on then that was getting you know there",
      "offset": 2633.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "was the 198 expert system boom which",
      "offset": 2634.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "funded a lot of money brought in a lot",
      "offset": 2638,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "of money it was of similar scale",
      "offset": 2639.76,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "actually um maybe a little smaller but",
      "offset": 2641.839,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "um triple had 25,000 people in audience",
      "offset": 2645.48,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "which is similar to the size of neps",
      "offset": 2648.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "today and I'm told that there was a",
      "offset": 2650.16,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "champagne fountain at the 1985 Tria AI",
      "offset": 2652.72,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "um but it was at the same time there was",
      "offset": 2656.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "a similar Focus that it was all symbolic",
      "offset": 2659.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "so if you had something that had a d",
      "offset": 2662.4,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "data driven approach or component in it",
      "offset": 2664,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "then that didn't fit in because the",
      "offset": 2666.44,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "researchers had like that perspective as",
      "offset": 2668.119,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "well as I feel like you know you guys",
      "offset": 2671.44,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "maybe know better that I feel like the",
      "offset": 2673.2,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "investment Community also adopts a",
      "offset": 2675.119,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "similar focus on the dominant Paradigm",
      "offset": 2677.64,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "so it's hard to tell the story that are",
      "offset": 2680.88,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "so different from what the story other",
      "offset": 2683.68,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "people are telling so even though this",
      "offset": 2685.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "seems like this modularity going towards",
      "offset": 2686.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "a computer science like approach to",
      "offset": 2688.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "building these systems is pretty obvious",
      "offset": 2690.359,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "it's still a minority Approach at this",
      "offset": 2693,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "time in time in terms of like any",
      "offset": 2694.72,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "well-funded efforts using this",
      "offset": 2696.76,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "approach I I couldn't agree more I feel",
      "offset": 2701.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "like",
      "offset": 2704.559,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "every every few years we get obsessed",
      "offset": 2706.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "about the model as the unit of",
      "offset": 2709.4,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "innovation and then realize that",
      "offset": 2711.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "progress is mainly uh made by the",
      "offset": 2712.72,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "underlying data and systems that are the",
      "offset": 2715.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "core engines of allowing folks uh to",
      "offset": 2717,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "work with those underlying models and I",
      "offset": 2720.52,
      "duration": 2.599
    },
    {
      "lang": "en",
      "text": "think even in the investment sphere we",
      "offset": 2721.76,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "go through a lot of hype Cycles in and",
      "offset": 2723.119,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "around data",
      "offset": 2725.319,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "um because of that and and forgetting",
      "offset": 2727,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "that critical lesson I think another",
      "offset": 2729.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "thing um I think Pine I just wanted to",
      "offset": 2730.96,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "thank you so much for coming on and I",
      "offset": 2733,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "also wanted to to point out that uh you",
      "offset": 2734.44,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "mlcs is open source uh and uh data perf",
      "offset": 2736.8,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "is an awesome initiative I know a bunch",
      "offset": 2740.68,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "of uh you know open AI Etc has unlimited",
      "offset": 2742.44,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "budget to go curate Etc these data sets",
      "offset": 2744.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "and um you have an awesome chat uh from",
      "offset": 2747.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "icml that we'll link to about how folks",
      "offset": 2750.24,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "can get involved but um we really",
      "offset": 2751.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "appreciate you taking the time Pine and",
      "offset": 2753.72,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "thanks so much for coming on to",
      "offset": 2755.92,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "discuss thank you uh it was really fun I",
      "offset": 2759.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "want to just leave you with one message",
      "offset": 2762.4,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "if I if I have another moment of course",
      "offset": 2764,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "um you know I was thinking about an",
      "offset": 2766.2,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "analogy about this component idea for",
      "offset": 2768.04,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "language models um and I realized that",
      "offset": 2770.64,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "llms are like",
      "offset": 2774.359,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "salt you know salt is very important",
      "offset": 2776.079,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "it's a key ingredient like human",
      "offset": 2779.52,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "civilization has grown around places",
      "offset": 2781.16,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "where salt existed and it was very",
      "offset": 2783.16,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "important for us uh it's important for",
      "offset": 2785.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "our body to maintain",
      "offset": 2787.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "homeostasis uh it it makes food you know",
      "offset": 2789.44,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "uh tasty um and if you look at the",
      "offset": 2792.64,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "history of salt like the places the",
      "offset": 2796.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "actual places in the world like",
      "offset": 2798.52,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "Saltsburg in Austria saltel in Germany",
      "offset": 2799.64,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "the this same roote Sal for salt and",
      "offset": 2802.72,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "they were created around the wealth that",
      "offset": 2805.68,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "was created by salt and as the word",
      "offset": 2807.48,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "salary is from the same root Sal and at",
      "offset": 2811.2,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "some point in time you know it was",
      "offset": 2814.4,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "currency and so salt is very valuable",
      "offset": 2816.44,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "but at the same time I can buy a kilo of",
      "offset": 2820.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "salt for a dollar right salt is not",
      "offset": 2822.8,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "where the money is being made even",
      "offset": 2825.2,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "though it's so important and so critical",
      "offset": 2827.319,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "and so to me I feel like llms are that",
      "offset": 2829.4,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "useful what they are is a role as a",
      "offset": 2833.24,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "component the role as an interface the",
      "offset": 2835.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "role as enabling us to talk to things",
      "offset": 2837.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "instead of using structured complex",
      "offset": 2839.76,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "query mechanisms that is the solt like I",
      "offset": 2842.319,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "imagine a world in which they will be",
      "offset": 2846.04,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "part of every system that'll make it a",
      "offset": 2847.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "little fluent little more available to",
      "offset": 2849.28,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "us in terms of natural language which is",
      "offset": 2851.48,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "the human API which is our interface but",
      "offset": 2853.96,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "it is not the product it has got to be",
      "offset": 2858.119,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "put together with potatoes with fish we",
      "offset": 2860.559,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "need to figure that out and that's where",
      "offset": 2864.04,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "the really interesting stuff will happen",
      "offset": 2866.52,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "and that is what I call the system 2",
      "offset": 2868.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "hypothesis system 2 the system 2 solt",
      "offset": 2871.52,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "hypothesis so so you heard it here you",
      "offset": 2874.8,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "heard it here first uh and also if you",
      "offset": 2876.92,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "spill an llm on the table don't forget",
      "offset": 2879.119,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "to pick some up and throw it over your",
      "offset": 2880.8,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "shoulder for good luck I'm kidding but",
      "offset": 2882,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "that excellent analogy Prine thank you",
      "offset": 2885,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "so much for being on you you make a lot",
      "offset": 2887.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "of these frankly really difficult",
      "offset": 2889,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Concepts digestible and I think that",
      "offset": 2891.079,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "anyone who listened to this is going to",
      "offset": 2894.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "walk away just mind just all over the",
      "offset": 2896.72,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "place on like what they can be doing",
      "offset": 2900.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "better about not just their models but",
      "offset": 2901.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "their data and their infrastructure so",
      "offset": 2904.76,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Prine thank you so much for being on the",
      "offset": 2906.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "show again and uh uh we look forward to",
      "offset": 2907.76,
      "duration": 5.89
    },
    {
      "lang": "en",
      "text": "seeing you again hopefully thank",
      "offset": 2910.68,
      "duration": 9.129
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 2913.65,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "you",
      "offset": 2920.119,
      "duration": 3
    }
  ],
  "cleanText": "[Music]\nHey everyone, welcome back to practically intelligent.\nToday, we're excited to welcome Praveen Paritosh, a former senior research scientist at Google and founder and chair of the Data Perf research working group at MLC Commons.\nWe are going to chat with him.\nThis is a really wide-ranging conversation about, oh yeah, how data benchmarking has evolved and how we should think about the evolving performance of LLMs on a holistic way.\nWe really, really enjoyed this conversation.\nIt was fun.\nWe touched on a bunch of stuff.\nUm, Sonan, I think what was your favorite part?\nYeah, I was about to say, I think this is probably one, so we usually, you know, a peek behind the curtains, we usually send our our guests an email before the recording just to say, like, here's what we want to talk about, you know, what do you want to talk about?\nWe kind of figure out the general arc of the episode.\nI feel like this was, I, I was annoying him at a certain point because I just kept writing more and more questions that I had because in our initial introductions, he just kind of wanted to cover so much stuff and I was so excited about it because he were really um sinking on our our worldviews on this stuff.\nSo I think my favorite part is when we start to, I think it's towards the end, but we start to talk about the lessons learned from a computer engineering, computer science standpoint in in talking about AI systems as if they were and they should be thought about this way, not so different from any other computer engineering problem with the added benefit of this, you know, um, machine learning capability.\nSo I think the parallels that we draw were really quite fun to talk about, and I think really going to be useful for people to think about, you know, in the long term.\nSo I've rambled enough.\nYou're going to hear me ramble some more.\nI say we just kind of jump right in.\nLet's do it.\nWell, Prine, thank you so much for being on the show.\nThis is uh, really exciting.\nI'm going to just jump right into things.\nUh, where do you see the current state of AI benchmarking and and and you know, take that to wherever you want to go, but uh, I think our our listeners are going to be really curious about kind of the practical applications of AI benchmarking and kind of how people approach it and what are some of the pitfalls that you're seeing?\nThank you for having me.\nUh, it's such a pleasure.\nAnd that's a great question.\nBenchmarking is, you know, particularly critical for the way we move the field forward.\nSo a shared Benchmark, such as consider the first uh, interesting Benchmark was SQuAD, the Stanford question answering data set, and that was a collection of a thousand questions that was extracted from Wikipedia using Mechanical Turk and turned into a question answer set.\nAnd early research when LSTM, LSTMs came along and after that Transformers came along, but people could test their question answering systems on SQuAD and report a metric, and you could then build a table, kind of a leaderboard, uh, where you could see which algorithms were performing the best on that on that set.\nAnd so suddenly it created this shared way in which the community could move forward on a problem.\nNow, you know, you can think about it as almost like a mechanism for the research community to Hill Climb, uh, because now the accuracy score on the SQuAD test set is is an objective function, is a metric, and you can try to improve that.\nYou can see what methods, what kind of training data, what kinds of architecture give me higher performance.\nAnd likewise, in uh, vision, uh, ImageNet was such a important, influential data set.\nSo the ImageNet moment, uh, which was when AlexNet, but achieved high accuracy on a whole bunch of categories, like thousands of categories of objects, which was never done in computer vision before, and that is what led to recognition by the touring Award of Yeshua Benjo, Yan Leon, and Jeff Hinton, because that that demonstrated something remarkable had happened.\nAnd the existence of these, you know, shared benchmarks allow the community to move forward.\nBut at the same time, let's look at these examples, we run into some problems.\nSo for the first SQuAD, uh, uh, data set was, uh, did not contain, the way it was constructed, it did not contain questions that couldn't be answered.\nSo for instance, uh, when asked the question, what is Barack Obama's favorite color, um, the state-of-the-art algorithms that had cracked the SQuAD Benchmark would very confidently say black and cite the Wikipedia article as a reference.\nNow, the Wikipedia article has no mention of Obama's favorite color at all, but but contains a color term repeated many times, and such juristic worked when it was guaranteed the document contains an answer, but that didn't work when the document didn't contain the answer.\nSo SQuAD 2.0 was released by the authors, realized this problem, and they added a bunch of unanswerable questions, and that led the community to figure out there were two questions: first, determine if the document can answer the question, and then find the answer to the question.\nSo such systems were then able to realize that one cannot answer what is Barack Obama's favorite color.\nSo as you can see, as we change the benchmarks, that changes the hill that the community is climbing, the kind of components and capabilities you would need to build.\nAnd so that's the, you know, role of Benchmark, that the shared measures of progress, like a compass for the research community, but at the same time, you know, those, those are, you know, proxies, right?\nLike we, you cannot to take the whole universe of question answering and turned it into one particular Benchmark.\nSo what we've seen is proliferation of lots and lots of different benchmarks, and typically now published results will contain, you know, performance on 10 different benchmarks, and benchmarks themselves these days have become baskets of benchmarks, so Big Bench and SuperGLUE, then there some, they contain, you know, dozens of other benchmarks.\nUh, so that's the direction of growth that the community has taken, but even that is not enough because the systems are, uh, you know, getting so powerful that they're able to, you know, saturate the Benchmark, achieve a human level performance of the Benchmark very quickly.\nSo there's a famous analysis by D. Keela, who was at Meta, who built DinerBench and now is running contextual AI, in which he shows this Benchmark saturation graph, and what used to take years now takes months.\nSo each Benchmark becomes expires pretty, pretty quickly.\nSo this is really an interesting point we find ourselves and the tools that we are throwing at it.\nSo there are some new ideas that people are exploring, like adversarial approaches to proving such systems, but it seems like, you know, the bigger problem here is that we might have grown outgrown this phase of using, you know, small crowdsource benchmarks as a way to measure performance.\nUm, we need to figure out a way to turn this whole research program differentiable in a sense, you know, like that's the agenda, right?\nLike as long as we can turn something into a hill that we can climb, then we can use gradient descent and we can move forward incrementally.\nSo I feel like benchmarks give us this shared compass, but each one of these benchmarks that we have out there are limited and our flaws.\nNone of them point to the true north entirely, they just give us hints in that direction, and at this point, we're at a point where we might need to think about some radically new ideas to to guide us because we need more precise compasses.\nWe, we matured at that point of building systems and technology.\nYeah, no, I, there's a lot of great points in there, and I, I think I'll start with the the historical context, well, the modern historical context between talking about AlexNet and ImageNet, um, and and the SQuAD data set, because I remember working with SQuAD, you know, 1.0 and 2.0, uh, even back, you know, years ago when before Transformers, to your point, in working with RNN and TMS, and for even just talking about embeddings and text embeddings, I would always use these kinds of data sets because to your point, it was a way to not only feel connected to a greater community of this is what the researchers are using, this is what the real data scientists are using, in my class, you know, the aspiring data scientist, this is what real data scientists are using, this is the data set that we're going to do.\nIt does really ground students and and introductory level uh, engineers, but then to your point, at a certain point, the community, but not only the community, the individual will outgrow that, and and after a while, you say, well, yes, you know, even recontextualizing the idea of question answering, going from yes, no to yes, no, non-answer or I don't know, even beyond, then you can break that down into closed uh, QA, open QA, general QA, trivia QA, which is one I see often, and and and to your point, even even more, I was reading a paper today, totally unrelated to NLP, but to your point, I got to a page where it was just 3/4 of the page was, here's 10 benchmarks on the columns and here's 15 models on the rows and then theirs where bolded at the bottom, and I was like, oh my God, this is just so much to the parse and look at, and I don't know what the takeaway is, and a lot of the times it almost feels like marketing, and I'll I'll I'll tell you what I mean by that.\nA lot of the times I feel like I'm looking at this table and they go, well, we bolded our results, but we've put the others here.\nIt's almost like when you Google how do I, you know, alternatives to Zoom, 20 articles come up saying, hi, we're better than Zoom, hi, we're better than Zoom, hi, we're better than Zoom, and the idea is like, well, this is a competitive analysis.\nIf you looking for the best model, we are going to show you a comparison, and because the the person on the other end may not know what they're looking for, it will come down to, well, theirs is bolded and clearly that number is slightly higher, I as well use theirs.\nSo it becomes almost this, this way of convincing others to use their open source model, even though it might not be the best metric for the consumer trying to select an approach or a model.\nSo uh, I guess given all that, what kinds of radical transformations do you think are are on the horizon or or just on the horizon and and like what what are what is your team working on in this space to try to alleviate some of these issues?\nSo I, I'll take a, you know, a couple uh, you know, little tangents.\nOne, one is that, oh, we, we here are practically intelligent, are are wild fans of tangents, so please tangent away.\nWelcome to tangent Airways.\nUm, we might experience a little turbulence.\nSo what, what, you know, one thing that first and foremost, we haven't done as much is Benchmark the data itself.\nSo I've been working at MLC Commons and started this working group called Data Perf, and we launched this uh, you know, half a dozen different challenges that just measure the quality of data, not the quality of model.\nAnd so that's one approach area that we've been exploring, and you can learn more about it at data.org, and we have an upcoming paper at NeurIPS uh, in New Orleans in December that we'll be presenting about it.\nIt's a very large effort.\nThere's, you know, 60 different teams and organizations across academia and corporations, and what we did was we said, you know, all you can do as a participant, think about like these leaderboards that we just talked about, where there is a test set and you're trying to get a position on the leaderboard, but instead by by changing your model, by building a better model, but instead what we did was we froze the model and we said, all you can do is manipulate the data and can you get a position on the leaderboard by selecting, sampling, curating, cleaning data in a way that produce has a better performance.\nSo we change the focus on looking at data directly instead of, you know, thinking about model.\nSo that's like one area that we need to explore more, and we are at the beginning of that.\nWe have right now built a platform and a community where one can come in and propose a new data centric challenge in a new domain and put it out there, and it's not, you know, entirely, you know, automated, uh, it requires a little bit of human touch and engineering because these, you know, patterns are new, um, compared to like the type of things that Kaggle, for instance, does.\nSo that's one area, but I think that you know, one picture that you started painting as well is that these benchmarks are proxies, right?\nThese benchmarks are like little tests that tell us that we're moving in the right direction, and we need them when we are beginning at the beginning of a process, but what do the benchmarks really imply?\nThey imply a capability, and you know, those are like little tests of that capability, just like, you know, even if you think about exams that we go through in like a school education or at in college, these exams are a little test of whether we have learned something, right?\nAnd there are many ways to pass the exams.\nIn fact, uh, you know, education researchers, one of the biggest problems that they, you know, lose their sleep about is the figuring out the distinction between root learning and conceptual understanding, and the goal of the educational system is to impart conceptual understanding, so then you can have the capability to carry out a certain kind of task, and the exams are these little proxies for that, right?\nAnd there are ways in which, you know, clever students can game the exams, and there are entire institutions like Kaplan that can help you game these exams, and you'll be better off if you took that, and they don't really, you know, you can have an whole complex of exams and coaching and, you know, all of that, but they are not entirely in the service of the true goal that we have of education, which is giving you the capability, the competence.\nAnd so we should remember that these benchmarks, just like these tests, are just, you know, these little indicators, but what we want is competence.\nI, I want to give you a system that is competent at doing a certain kind of task, right?\nLet's say, let's consider the calculator, right?\nIf you want to buy a calculator, you want the expectation is that you know the addition, multiplication, division, arithmetic that you want to do, whatever number of digits the calculator can handle, it'll give you correct answers every time.\nSo that's the competence that you want to expect.\nNow, you know, how would you test that, right?\nLike with a test set, any test set is going to be finite and might not be the best test set for like confirming 100% accuracy on all possible arithmetic questions that the calculator can answer.\nSo in that such a case is, we have almost a sound proof of why the calculator is correct.\nSo the way the systems and the circuits are designed is it's a proof of that competence.\nSo that's another way to say that you have competence, right?\nYou could have uh, you passed a multiple choice test, you know, you passed an interview, uh, you submitted a proof.\nSo these are all these different mechanisms.\nSo all we want to say is, you know, eventually you want to deploy it in some real world circumstance and it be able to you, you know, demonstrate the competence that it claimed that it has.\nAnd so for instance, uh, I was at Google for 13 years and what witnessed the launch of some of these uh, you know, Transformers and the bird architecture.\nThese were built in house and the search uh, you know, ranking team, search engineering team, they were very careful in evaluating and testing these systems, even though when they just do a did a first, you know, comparison on the baseline metrics, it performed as well as the existing system, but they were not convinced.\nThey, they were worried and they poked and they tested the system and they found other weaknesses that the metric basically, they realized the metric doesn't entirely capture once we deploy it to billions of queries every day, all sorts of things will happen that we are actually liable for, and so they were cautious and they spent like, I think upwards of two\n\n\nYears in just testing the system before deploying it.\nSo that is the difference between, you know, benchmark, you know, and metrics and the competence.\nAnd at some situations when you are, you know, liable or stakes are high, then it's the competence that you want to care about at the end of the day.\nIf you're working in healthcare, then you want FDA approval to demonstrate the competence.\nAnd so I think that we should move more toward thinking about other approaches to claim competence.\nSo right now, for instance, there are papers that are published about, you know, neural, uh, networks, language models, uh, abilities to do arithmetic, to continue with this calculator example.\nAnd most notably, chat GPT, GPT 3.5 was, you know, you know, maybe something like 70, 80% accurate.\nIt was actually reasonably accurate, and it's very impressive, right?\nLike, it wasn't designed to do that.\nAnd, um, then the GP4 was actually 4% accurate.\nSo for some reason, that the changes and improvements that made actually hurt its arithmetic capability.\nAnd then, then some folks out of China built a gigantic neural network just focused on doing arithmetic, and they got to almost 100% accuracy.\nAnd so, you know, I think that at some point, you know, we might just want proof.\nLike, if you're doing, you know, logic and reasoning and arithmetic in these worlds, there are actual proofs of competence.\nYou don't need to be empirical about it.\nIf I give you a theorem with a proof, then you have absolute certainty that it is correct.\nSo there are other mechanisms that are less empirical that come with more sound guarantees.\nSo we might want to think about, uh, you know, approaches like that as we expand towards thinking about capabilities, not just performance on a leaderboard.\nGot it.\nI think one thing that you and Sonan are alluding to is that engineers want to see how a specific model performs, uh, on their specific metric, on their specific tax.\nWhen you talk about competence, each engineer may actually define it, uh, quite differently.\nI think folks that you just very practical question, folks want to know what competent on their specific, uh, data and their specific M, but that's very varied and hard, right?\nSo data freshness is more apparent for student use cases, then if you're fi, you're looking to fine-tune data, if you're looking on specific problems, robustness of your data set, you might be working for actually very different data sets to augment your use case, uh, than another.\nAnd so I almost want to take, uh, you know, I'm a data scientist or an ML engineer.\nI, uh, you know, I'm looking at these specific high-level metrics that I'm used to, and you know, for last decade, you've been trained to look at precision recalls.\nSo in this new Wild West, Pine, what is the advice?\nHow do you even decompose such a varied problem, right?\nWe need to move in this new direction that's more intelligent, uh, beyond looking at this Bolden metric, but what is your advice to a data scientist that is looking to even understand, and people know the problem is more varied, but we still resort to, uh, you know, just looking at, uh, you know, these, uh, these sort of high-level metrics.\nSo what, how do we decompose that problem of we're a data scientist, how do we, uh, how do we compose a new framework for thinking through, uh, thinking through data if we're just a random data engineer working on problem on a specific problem, try augment our data, how do we, how do we approach this, right?\nSo where we are, I, I would say that, you know, what you're asking amount in data science terms amounts to asking, you know, what is the precision and recall of my test set itself, right?\nBecause I'm using a test set to estimate the precision and recall of some model, some system, like the SQuAD is being used as a test set to evaluate the precision and recall of some question answering systems.\nBut then you can also ask the meta question, which is also a data science question, what is the precision and recall of this test set itself?\nNow, as we see, like, if you look at SQuAD 2.0, given that it was missing unanswerable questions, so that's an example of question that is not in the recall, right?\nLike, so it has low recall because it's missing a class of questions.\nAnd then there is other class of questions since SQuAD was studied in gr dep, you know, questions about causality, questions that were, for instance, uh, about non-factual things because the data set was constructed entirely on Wikipedia.\nSo by, by, by definition, all questions were factual, but if you look at the universe of questions, like a search engine gets, uh, there's a significant amount of query volume that contains the word should, you know, should I do this or that, and those questions are not answered by a factual source like Wikipedia, and you have to go to forums and, you know, other kinds of opinions, sources of opinions.\nSo the recall of this test set is not very high.\nSo as a data scientist, I would be worried about what's missing in my test set that because I'm making a claim about a competence.\nAnd if I say that it, this system can answer questions, I didn't say there was a footnote, but not, uh, non-factual ones, but not the ones that are unanswerable, but not the ones, like if I am making that claim, uh, you know, I'm between the leap between what the test set captures and what the phenomena or the competence I'm claiming, I should be very cognizant of that.\nSo I would say that we must strive to figure out what are these blind spots in our test sets, uh, of which between the gap between, you know, what, what the competence claims and what we currently have sampled in the test set, and we need to cover those areas.\nSo this distributional mismatch between the, you know, like often when real, you know, like when one example was in fact, uh, an early paper from Google where they showed pretty strong results on diabetic retinopathy, and turns out that when people actually deployed that system, then they, there was the results were not that good, and it was a mismatch between what was the actual real world sample and what sample was represented in the test set.\nSo I think if we rely on the methodology of test sets and benchmarks, then the test sets themselves are not like ground truth and a representative sample.\nSo test sets contain errors, like there was a study done by Curtis North, who is currently running Clean Lab, and he looked at, you know, 10 different most cited data sets, including ImageNet, and he found that there were, you know, anywhere from, you know, 3 to 10% errors in these test set.\nAnd when the, he tried to fix those errors, um, then the performance changed, so that, you know, rest net 18 was doing better than than rest net 50, which is a much more expensive model.\nSo that makes, you know, begs the question.\nSo that's like a precision error, right?\nAnd what we previously talked about SQuAD was like recall errors.\nSo we should strive to measure quality of test sets and improve the quality of those test sets.\nAnd we are beginning to figure out in the work done with ML Commons, some of these mechanisms of attacking, like this adversarial, uh, approaches.\nSo one of the experiments, um, I ran, uh, with, uh, Laura was this project, and Kwang was this project called Cats Forl, where we basically challenged participants to submit images that would fool the classifier.\nSo even though the classifier had a performance of like 90% on the overall data set from the same data set, they could sample images which the classifier was getting wrong and which chose some categories like, uh, you know, bus driver, teacher, uh, um, chop chop sticks.\nAnd I remember like we ended up with, we had 16,000 submissions, we ended up with a DAT data set of 10,000 on which we verified with human labelers, and in fact, the machine was getting it wrong.\nSo the in this test set, the precision was zero, even though, uh, the state of art were performing at 0.9 on all of the standard test sets.\nSo this was an adversarial approach, and you know, the kind of errors we find was interesting, like an empty bus, for instance, it would very confidently say that there is a bus driver, um, or if there is, um, uh, there was a bowl of soup and, you know, there in rahen, and it will be confident that there's chopsticks in the picture.\nSo there were these errors that were like these kind of contextual hallucinations, but we discovered that by, you know, encouraging people to just basically attack, and this approach was invented by Panos Ierus at NYU in 2012.\nHe built a system called Beat the Machine, where he it incentivized mechanical tur workers to find an example of hate speech that will fool the system.\nAnd if you fool the system and subsequently will verified that you were right, that this was H speech, then you got like 10 times more incentive than if you the system recognized it.\nSo there are these type of approaches that we are exploring that are out there now.\nRed teaming has become like a standard, you know, testing methodology for language models.\nAwesome.\nI again, so many things to dive into here.\nI, the, I really love what you just said specifically around the idea of ground truth, because in a lot of people's experience working with data, that term, it's almost like a term of art these days to say like, this is our ground truth labeled data set, right?\nEveryone points to it and says, this is the North Star, we did it, we found the data.\nBut to your point, what, what that kind of happen psychologically, what, what happens is the more you say that, the more you kind of reinforce to yourself that there, there could be no fault in our data, it's the ground truth.\nAnd as soon as you start to prod at it just a little bit and say, well, how did you label it?\nWell, it's a mix of open source and some stuff we labeled in house.\nIt's like, oh, has you know, a labeler who has been trained in your framework gone over each and every one of these data points?\nNo, you start to notice the cracks pretty quickly.\nSo I really like that, that, that pushing back on that idea that just because you call something your ground truth does not make it ground truth, because if you misrepresent or not misrepresent, well, you could misrepresent, but if you mislabel data points, you're just asking for trouble.\nSo there are some approaches, you know, quantitatively speaking, that I, I personally really like.\nUh, there's this one approach called, I think, area under the margin ranking, I believe, which is one approach to finding mislabeled data.\nAnd I think their example was actually, I think it was something like ImageNet, where they were, they were showing an example of an image database where they were finding mislabeled data as a pre-processing step.\nAnd that, that idea that working on your data almost as much as if not more than working on your model is something I, I personally am, am extremely passionate about.\nUm, eagle, eagle-eyed listeners will, if you've ever read my books, in one of my books, my first future engineering book, in the first chapter, I, I make a big note, and I remember this was like six years, seven years ago, so my, my publisher were like, why are you saying this?\nI made a point up front and saying, this is not a machine learning tuning book.\nThe point of this book is I am going to only ever use logistic regression.\nI am setting myself up right now, like, this is the only model I'm allowing myself to use.\nI have to only find data, uh, performance increments through data pre-processing, feature engineering, transformations, whatever it is, selections, so be it.\nAnd that was the whole premise, uh, and the point was to prove or at least show that you can actually get these boosts and performance by manipulating only your data alone and and not even touching your models parameters or at least the model architecture.\nUh, now that being said, all of this again, to your point, comes back to, well, you got to trust the data, and not only do you have to trust the data, you have to trust that your data is representative of the system you're trying to model.\nSo coming back to something you said earlier, something I'm personally very curious about, being a former mathematician, how do you approach the the concept of a proof in the world of LLMs?\nH, how do you even, uh, think about proving that your LLM can solve a task versus showing your LLM can solve a task using a data set?\nThat's the question, right?\nYeah, I don't know, we really, we really, that's, that's the most interesting question at this point that the field is facing, right?\nThis, these benchmarks served us, um, you know, really well, right?\nSo this began in around 2010, and so the first decade, you know, the benchmarks like really allowed a lot of progress to happen and a lot of people from all over the world to be able to work on the same problem and, you know, and then we evolved to like these basket of benchmarks, and that's like still, you know, like we're like hobbling on the the crutches, you know, like we're moving forward on this, but we're realizing that that's not enough.\nAnd like with LLMs, you know, it's become even more challenging to compare and test these systems.\nSo, you know, I think that, and it's also challenging for, you know, one of the things about benchmark is that you can do this kind of rapid iterations, you know, you can submit a new model and run it and, you know, find how well you did, but this idea doesn't work very well when, you know, each iteration cost tens of millions of dollars to pre-train a language model, for instance.\nSo I think that we need to think about collectively as a field, you know, like how do we measure progress, because what benchmarks are are these proxy estimates of progress, and you know, we are so powerful, these things are so powerful and also so expensive, right?\nMonolithic.\nAnd so I feel at this point in time that, you know, we might just need to recognize that this monolithic approach is not sufficient.\nWe need a more modular approach, and we need different components that do different things that we can test more clearly, like what that component promises.\nSo for instance, you know, one of the most successful, you know, the maybe the first killer app of language models has been application to, uh, internal Enterprise, you know, information, um, access.\nI would say like, mean, in some sense, for instance, using Vector databases and using retrival augmented generation to index your private documents, your corporate documents, and then make them accessible to you for in form of question answering or chat or some some other form of interface.\nNow that is, you know, that that is like, you know, I and my, I think there's probably at least a dozen companies that I can think of that have like well-funded, you know, uh, you know, resources that are going after this problem in the last, you know, 6 months.\nBut it's really interesting to trace how it happened.\nSo, uh, the first demonstration, uh, in 2015 was of Word To Vec, which was which did the, you know, magical thing that was king plus man minus woman equals Queen.\nSo it represented words as vectors and was able to show that these vectors contained enough semantics that you could do this kind of arithmetic that made common sense.\nAnd in 2017, by 2017, people had build Vector databases because once it was clear that these embeddings contain semantic information that allowed people to to do that both inside Google and outside Google.\nHowever, you know, the peak interest in this technology began like towards the end of last year, early this year, uh, after, you know, generative AI, you know, the storm was kicked off by cat GPT.\nSo it's really interesting and how that is being used, like most of the magic in the system, these rag systems are actually indexing your documents into vectors and bringing them back to you, retrieval augmented generation, and then using the thin layer of language model to craft, you know, the response for you.\nSo what is happening is, uh, the LLM is acting one as a component, and in this overall system, it's not the only thing that's doing the question answering, unlike the idea of just going to chbt and getting, you know, your job done by prompting it or fine-tuning it, it's actually an entire modular system that contains index of your documents, that's one thing.\nThe other thing is the LM is not at the center, you know, it\n\n\nIt's almost a CERNIC flip.\nYou know, the LLM is acting as an interface, and a lot of the magic is happening with these embeddings in the vector database and in the retrieval process.\nSo I feel that this is just an example of how things are going to look like as we move forward.\nAs we move forward, we'll have many of these different components that solve different problems, and we hook them up.\nAnd now we're not testing the monolithic LLM, um, but we're testing how well, for instance, what is the precision of documents that this RAG system retrieves when I make a query?\nThat can be independently evaluated, just like search engines were back in the day.\nAnd the third thing that this case study shows is it's also how, you know, LLMs are unlocking the power of technologies that were around.\nSo this technology for doing embeddings and retrieval using vector database was around since 2017, but this is what made it happen.\nSo I, I feel like maybe that's the shape of things to come, and many, many more new components can be added for precisely the type of things that LLMs are struggling at at this point.\nYeah, and again, I think we've said this on the show dozens of times, but my, my personal philosophy on LLMs, you know, at a high level, is that they are exceptional reasoning machines.\nThey are not the best thinking machines, right?\nThey are, they are incredible at being given, you know, insane amounts of context and saying, given these 20 pages, answer this one question.\nThey're really good at that kind of work, but they're not as good as coming back, almost full circle.\nThey're not as good as closed QA, you know, not given the actual context to answer this question.\nThat's where the hallucinations tend to come in.\nSo to, to kind of again bring this full circle, when we're talking about SQuAD, this is very specifically an open book question answering test, right?\nGiven context and a question, answer the question given the context.\nAnd RAG is just the same thing with, uh, with a vector database tacked on.\nWell, here's the question, let me go ahead and retrieve that, let me look up in the textbook real quick, grab the context, now separate task, given a question and a context, answer the question.\nSo you end up with this modularity, which is to a developer, you know, almost music to their ears, because now I can test two things and have a really good sense for where things are breaking down in the pipeline.\nDid is the document messed up?\nDoes, I'll even add some more in, is the chunking, um, actually chunking up the information appropriately?\nIs the embedding actually embedding the semantic information from our chunks correctly?\nIs our buy encoder or whatever we're using for our embedding actually matching things up correctly?\nAre we retrieving the right documents?\nIs the question and answering system actually answering questions given the right context?\nSo you have this chain of tasks that all end up with someone ask a question and they get an answer back, but on the back end, it's, it's a lot more steps happening.\nAnd that speaks to, to kind of wrap it all up in a nice little bow, this kind of, this trend we see of, you know, blank is all you need.\nI, obviously, you know, coming from the, the fact that the Transformer paper is called Attention is All You Need, again, coming from a human standpoint, it's really appealing to say, finally, this AI can do this, is all we need.\nBut to the real, you know, the production level machine learning engineer, they know, well, the LLM is one component of the 20 things that have to happen for our end user to get their answer.\nUm, so, so in, in your words, what is the, what is the reconciliation that has to happen between where, you know, the blank is all you need, uh, trend and the actual productionized system?\nLike, what, what has to happen to get more people on the boat of modularity, testing, and benchmarking, uh, in, in, in your words?\nI think it's really interesting.\nI mean, if you, I can speculate a little bit about why we are here.\nYou know, it seems very obvious, right?\nWhat you were saying moments ago, every computer scientist in the audience was probably were vigorously nodding their heads throughout it, right?\nWe, you know, that's what we, how we, we're taught to break a problem down into smaller problems, build tests for those components, hook those components up, and then do integration, and different people were responsible, and you could assemble a gigantic thing out of such a process.\nThat's what the software engineering is all about.\nYou know, as quickly as in your, you know, first, you know, few classes, you learn that you have to write small modular functions that you can compose in so many different ways and reuse of code and, you know, having components that used in different all of that.\nSo that's how we want to build systems.\nThat's where computer scientists are taught to do things.\nAnd where we have is, we have this one very powerful thing, and this thing, the, for instance, you know, Llama 2, you know, like it, there's no sub components in there.\nYou take it, and then you can do a few things on top of it, you can prompt it differently, you can fine-tune it, and you get an answer.\nSo it kind of breaks down like the typical, you know, computer science, you know, setup.\nAnd when you look at, go talk to people in industry who are trying to build, you know, serve a problem, solve a problem, then you see that their systems indeed do have components.\nAnd, and so I feel like, you know, the first of all, I would say that we do need to, you know, turn this whole AI research from this rocket science like approach to computer science, where we do have components, we do have modularity, we do have testing, all of these features that we know how to build robust systems.\nNow, you know, why are we here?\nI think that this seems so obvious, but I'll tell you, I think that there are people who think that this is blasphemous.\nSo when in 2020 in New York, uh, right after Yoshua Bengio and the other true Trinity, they won the Turing Award, they had a panel with Daniel Kahneman, the guy who wrote Thinking, Fast and Slow, and they were having a discussion about, you know, system one, system two, and Daniel Kahneman brought to the table the point that there are two different kind of systems, and you know, system one is this kind of fast, automatic system, uh, and system two is effortful and deliberate and uses symbols.\nAnd the entire panel was completely opposed to him.\nYoshua and Jeff clearly said that, you know, it is not a hybrid system.\nIt is, it's very important to them that it's, you know, neurons, neurons all the way, it's differentiable all the way, where symbols don't have that property.\nSo this is a philosophical, aesthetic, you know, position that the leading researchers have, have, and maybe this has, you know, gone into the community, and so other researchers also bring this way of thinking.\nAnd this has been there in AI before as well, like, you know, if you look at it at the beginning, like 50 years ago or so, in, you know, when, uh, back propagation was invented early on, there was not enough compute for those methods to do much well.\nBut on top of that, Marvin Minsky had a proof that it can't solve the XOR problem, and that resulted in a whole bunch of research, you know, field in setback for that field.\nBut Jeff Hinton and other people like, you know, really persisted for like 50 years and continued working on it and then got to a point where, you know, these things actually showed like tremendous capabilities that we hadn't seen before.\nLikewise, you know, a few months ago, uh, one of the pioneers of AI, Doug Lenat, uh, he died, he passed away.\nUh, he was, uh, the builder of Cyc, uh, and he was one of the most brilliant stars coming from the, you know, symbolic community of AI, and then he turned down job offers at Stanford and places like that to go start a company because his vision was that we need to build a repository of all common sense knowledge in logical representation that a machine can reason with.\nAnd so he kept chugging away at that problem for 40 years with funding of any anywhere between a few million dollars from government and other sources and sometimes more, sometimes less, depending upon the cycle.\nAnd I think the system currently has like something like, you know, 10 million axioms about, you know, what happens when it rains and, you know, what is a celebrity, all kinds of things, and you can do reasoning with that.\nAnd like, you know, like I just want to use these two examples to show that, you know, AI has been driven by people who are very, very, you know, um, you know, the word that comes to my mind is stubborn, but, you know, they're driven and they're willing to take a hypothesis like really all the way.\nI mean, so, and then there was kind of a fight between these neural and symbolic camps.\nI was giving a talk about this and, uh, somebody pointed out that, you know, but yeah, of course, these people are upset because, you know, we kept them in the basement.\nYou know, like the idea was when the symbolic methods were at its peak early on, then that was getting, you know, there was the 198 expert system boom, which funded a lot of money, brought in a lot of money.\nIt was of similar scale actually, um, maybe a little smaller, but, um, Triple had 25,000 people in audience, which is similar to the size of NEPS today.\nAnd I'm told that there was a champagne fountain at the 1985 Tria AI, um, but it was at the same time there was a similar focus that it was all symbolic.\nSo if you had something that had a data driven approach or component in it, then that didn't fit in because the researchers had like that perspective as well.\nAs I feel like, you know, you guys maybe know better that I feel like the investment community also adopts a similar focus on the dominant paradigm.\nSo it's hard to tell the story that are so different from what the story other people are telling.\nSo even though this seems like this modularity going towards a computer science like approach to building these systems is pretty obvious, it's still a minority approach at this time in terms of like any well-funded efforts using this approach.\nI couldn't agree more.\nI feel like every, every few years we get obsessed about the model as the unit of innovation and then realize that progress is mainly, uh, made by the underlying data and systems that are the core engines of allowing folks, uh, to work with those underlying models.\nAnd I think even in the investment sphere, we go through a lot of hype cycles in and around data, um, because of that and and forgetting that critical lesson.\nI think another thing, um, I think Praveen, I just wanted to thank you so much for coming on, and I also wanted to to point out that, uh, MLCS is open source, uh, and, uh, Data Perf is an awesome initiative.\nI know a bunch of, uh, you know, OpenAI, etc., has unlimited budget to go curate, etc., these data sets, and, um, you have an awesome chat, uh, from ICML that we'll link to about how folks can get involved.\nBut, um, we really appreciate you taking the time, Praveen, and thanks so much for coming on to discuss.\nThank you.\nUh, it was really fun.\nI want to just leave you with one message if I, if I have another moment, of course.\nUm, you know, I was thinking about an analogy about this component idea for language models, um, and I realized that LLMs are like salt.\nYou know, salt is very important.\nIt's a key ingredient.\nLike human civilization has grown around places where salt existed, and it was very important for us.\nUh, it's important for our body to maintain homeostasis.\nUh, it, it makes food, you know, uh, tasty.\nUm, and if you look at the history of salt, like the places, the actual places in the world, like Salzburg in Austria, Saltel in Germany, the this same root Sal for salt, and they were created around the wealth that was created by salt.\nAnd as the word salary is from the same root Sal, and at some point in time, you know, it was currency.\nAnd so salt is very valuable, but at the same time, I can buy a kilo of salt for a dollar, right?\nSalt is not where the money is being made, even though it's so important and so critical.\nAnd so to me, I feel like LLMs are that useful.\nWhat they are is a role as a component, the role as an interface, the role as enabling us to talk to things instead of using structured complex query mechanisms.\nThat is the salt.\nLike I imagine a world in which they will be part of every system that'll make it a little fluent, a little more available to us in terms of natural language, which is the human API, which is our interface, but it is not the product.\nIt has got to be put together with potatoes, with fish.\nWe need to figure that out, and that's where the really interesting stuff will happen, and that is what I call the system 2 hypothesis, system 2, the system 2 salt hypothesis.\nSo, so you heard it here, you heard it here first, uh, and also, if you spill an LLM on the table, don't forget to pick some up and throw it over your shoulder for good luck.\nI'm kidding, but that excellent analogy, Praveen, thank you so much for being on.\nYou, you make a lot of these frankly really difficult concepts digestible, and I think that anyone who listened to this is going to walk away just mind just all over the place on like what they can be doing better about not just their models, but their data and their infrastructure.\nSo Praveen, thank you so much for being on the show again, and, uh, uh, we look forward to seeing you again, hopefully.\nThank you.\n[Music]\nYou.\n",
  "dumpedAt": "2025-07-21T18:43:26.470Z"
}