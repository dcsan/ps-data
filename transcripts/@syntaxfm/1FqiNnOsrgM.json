{
  "episodeId": "1FqiNnOsrgM",
  "channelSlug": "@syntaxfm",
  "title": "MCP Explained | What, Why and How",
  "publishedAt": "2025-07-01T11:00:03.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "In this video, we're talking all about",
      "offset": 0.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "MC key or model context protocol. Talk",
      "offset": 1.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "about what it is, why it's needed, how",
      "offset": 4.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to build your own servers, how to",
      "offset": 6.72,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "integrate with existing ones, how to",
      "offset": 8.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "debug them, and everything in between.",
      "offset": 9.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "That sounds good to you, let's dive in.",
      "offset": 12.4,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "My name is CJ. Welcome to Syntax.",
      "offset": 14.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 18.28,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "Now, before we talk about MCP, let's",
      "offset": 20.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "take a step back and just talk about how",
      "offset": 22.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "LLMs work. Now, if you're already",
      "offset": 24.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "familiar with all of this stuff, go",
      "offset": 26.56,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "ahead and skip ahead. You can see the",
      "offset": 28.16,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "timestamps in the description. But for",
      "offset": 29.359,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "all of this, including LLMs and MCP, we",
      "offset": 31.679,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "can think about things in terms of",
      "offset": 34.719,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "input, some process or blackbox, and",
      "offset": 36.399,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "some output. And the world of",
      "offset": 39.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "programming is like this as well. And a",
      "offset": 40.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "simple example of this is an AD",
      "offset": 43.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "function. So add we can think of as our",
      "offset": 45.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "black box. Our inputs might be two",
      "offset": 47.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "numbers. So let's say we pass two and",
      "offset": 49.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "two into this add black box. And then",
      "offset": 51.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the output of this would be four. Now",
      "offset": 53.52,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "add is predefined, right? we we know how",
      "offset": 55.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "to add two numbers together. It's",
      "offset": 58.719,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "mathematical. We can basically take any",
      "offset": 60.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "two numbers and add them together.",
      "offset": 61.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "There's a very specific algorithm for",
      "offset": 63.6,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "doing that. We can also think of a black",
      "offset": 65.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "box that has a more interesting process.",
      "offset": 67.119,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "So for example, a text predictor. So",
      "offset": 69.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "let's say we have this black box called",
      "offset": 71.84,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "text predictor. It takes input which is",
      "offset": 73.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "text and spits out text as output. And",
      "offset": 75.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "one example might be if we pass in Mary",
      "offset": 78.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "had a little, we might expect that the",
      "offset": 80.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "text predictor responds with lamb. uh",
      "offset": 82.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "because Mary had a little lamb is pretty",
      "offset": 84.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "common uh in the English language. Now,",
      "offset": 86.32,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "what actually happens inside of this",
      "offset": 88.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "text predictor, we don't know. Um we",
      "offset": 89.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "could come up with ways of creating a",
      "offset": 91.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "text predictor that isn't an LLM. We",
      "offset": 93.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "could come up with like a list of word",
      "offset": 95.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "pairings and say like 80% of the time",
      "offset": 97.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "when the words Mary and little appear in",
      "offset": 100.159,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "a sentence, lamb is likely the next word",
      "offset": 102.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "to occur. Like we could come up with our",
      "offset": 105.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "own algorithm for that. But LLMs are",
      "offset": 106.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "basically this with a much more complex",
      "offset": 108.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "process to come up with them. And it's",
      "offset": 111.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "not a specific algorithm. So the way we",
      "offset": 113.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "create an LLM is also through this input",
      "offset": 116,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "output process. So in this case the",
      "offset": 117.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "blackbox is training. The input is going",
      "offset": 120,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "to be some training data and the output",
      "offset": 122.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "is going to be the LLM itself. Now this",
      "offset": 125.119,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "training data in a lot of cases might be",
      "offset": 127.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "question answer pairs. So it might be a",
      "offset": 129.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "million different sets of questions and",
      "offset": 131.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "answers and we build out a neural",
      "offset": 133.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "network based on those questions and",
      "offset": 135.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "answers. And we built out this large",
      "offset": 137.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "language model that given some question",
      "offset": 139.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "will output a seemingly correct answer",
      "offset": 141.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "based on all of the data that it was",
      "offset": 144.4,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "trained on. But it's interesting to see",
      "offset": 145.76,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "that even the creation of an LLM is an",
      "offset": 147.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "input output process. Now once we have",
      "offset": 148.879,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "an LLM, it works exactly that way. So",
      "offset": 150.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "given some user input, it spits out some",
      "offset": 152.319,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "output and it actually is a text",
      "offset": 155.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "prediction model. So, as much as we",
      "offset": 157.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "might think that LLMs are smart or doing",
      "offset": 159.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "more than than what they actually are",
      "offset": 162.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "doing, for the most part, they're just",
      "offset": 164.56,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "predicting the next piece of text, the",
      "offset": 166.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "next token in any given sequence. And it",
      "offset": 168.879,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "actually turns out that if your training",
      "offset": 171.599,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "data is good enough and large enough and",
      "offset": 172.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "general enough, you actually can get an",
      "offset": 174.72,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "LLM that can work in most cases and seem",
      "offset": 177.44,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "like it's actually pretty smart to be",
      "offset": 180.879,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "able to uh answer questions or or give",
      "offset": 182.879,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "facts about certain things. Now, when",
      "offset": 185.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you're interacting with an LLM in a tool",
      "offset": 186.879,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "like ChatGBT or Cloud Desktop or even",
      "offset": 188.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like cursor ID or VS Code with GitHub",
      "offset": 191.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Copilot, there's actually a lot more",
      "offset": 193.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that goes into this user input that is",
      "offset": 194.8,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "eventually passed to that LLM. And it",
      "offset": 196.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "looks kind of like this. So, you",
      "offset": 198.879,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "typically have some kind of system",
      "offset": 200.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "prompt that you don't have access to,",
      "offset": 201.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "but the owners of this LLM service,",
      "offset": 203.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "whether it's OpenAI or Google or",
      "offset": 205.44,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "Anthropic, they've come up with some",
      "offset": 208.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "kind of system prompt that makes sure",
      "offset": 210.239,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "that the output it generates aligns with",
      "offset": 211.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "maybe their ideals. Maybe it adds some",
      "offset": 214.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "safety guards. Maybe it has a specific",
      "offset": 216.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "personality. And so this system prompt",
      "offset": 219.44,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "is going to to describe that. If you use",
      "offset": 221.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "a tool like chat GBT or cloud desktop,",
      "offset": 222.959,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you know that sometimes it lets you save",
      "offset": 224.959,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "preferences like I want the LLM to",
      "offset": 226.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "always output the most succinct answer",
      "offset": 229.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "always or I don't want you to always",
      "offset": 231.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "agree with me. You should push back. So",
      "offset": 233.68,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "with tools like chat GBT and and cloud",
      "offset": 235.28,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "desktop, you add those in your user",
      "offset": 237.439,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "preferences and then those are sent",
      "offset": 238.799,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "along to the LLM in every single message",
      "offset": 240.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that you send to it. The other aspect of",
      "offset": 242.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "this that gives us this answer response",
      "offset": 244,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "flow is your chat history is included in",
      "offset": 246.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "this when sending it to the LLM. And",
      "offset": 249.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "then finally, you have the actual user",
      "offset": 251.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "prompt. So that's the question you just",
      "offset": 253.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "asked or the follow-up question or",
      "offset": 254.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "whatever you just typed in, that's going",
      "offset": 256.72,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "to be the last thing included in what",
      "offset": 258.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "gets sent to the LLM. And so all of that",
      "offset": 260.239,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "gets wrapped up together, passed to the",
      "offset": 262.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "LLM, and then we get some output. In",
      "offset": 263.919,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "this case, it's going to be the response",
      "offset": 265.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "to the question or the follow-up that",
      "offset": 267.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you just sent. Now the one thing to note",
      "offset": 269.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "about this whole process is this LLM is",
      "offset": 271.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "standalone. It doesn't have access to",
      "offset": 273.6,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the internet or to the outside world.",
      "offset": 276.08,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "Basically it was trained once created",
      "offset": 277.759,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "and now all of your interactions with it",
      "offset": 280.639,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "are just with this black box. It has no",
      "offset": 282.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "way of of reaching out and getting new",
      "offset": 284.479,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "data. It's a snapshot in time based on",
      "offset": 286.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "all of the data that it was trained on.",
      "offset": 288.4,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "And when we interact with it, we're",
      "offset": 289.919,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "interacting with that snapshot. So",
      "offset": 291.28,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "there's no connection to the internet.",
      "offset": 293.04,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "Now, to get around this, we can actually",
      "offset": 294.639,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "insert another thing into this context",
      "offset": 296.479,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "that we're sending to the LLM along with",
      "offset": 298.479,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "the user's latest prompt. In this case,",
      "offset": 300.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "we'll send a list of available tools.",
      "offset": 302.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "And so, these are all things that the",
      "offset": 304.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "LLM could potentially invoke if it",
      "offset": 306.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "thinks it needs to perform an action or",
      "offset": 308.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "needs to go get more data. Essentially,",
      "offset": 311.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "every single call to the LLM, it knows",
      "offset": 313.36,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "what tools are available. An example of",
      "offset": 315.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "this might be let's say we have a tool",
      "offset": 317.759,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "available called get weather and we have",
      "offset": 319.919,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "another tool available called get",
      "offset": 322.4,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "coordinates and in this context window",
      "offset": 324.639,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "we say those two tools are available",
      "offset": 327.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "when you call them you specifically need",
      "offset": 330.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "to pass in latitude longitude to get the",
      "offset": 332,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "weather and then for the get coordinates",
      "offset": 333.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "tool you need to pass in a place name",
      "offset": 335.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "and so all of that information about",
      "offset": 337.36,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "those tools and how to call them is",
      "offset": 338.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "included here and let's say the user's",
      "offset": 340.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "prompt is what's the current weather in",
      "offset": 341.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Denver Colorado part of the system",
      "offset": 343.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "prompt here is will say you can call",
      "offset": 345.44,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "these tools if you believe it has",
      "offset": 347.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "information that you might need. And so",
      "offset": 349.759,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "the LLM is going to think on this. It's",
      "offset": 351.36,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "going to see all of that context window.",
      "offset": 352.88,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "It's going to see the available tools.",
      "offset": 354.08,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "It's going to see the fact that it can",
      "offset": 355.52,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "call tools. It's going to see the user's",
      "offset": 356.72,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "input, which is what is the current",
      "offset": 358.479,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "weather in Denver, Colorado. And it",
      "offset": 359.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "might decide, hm, I know that I was",
      "offset": 361.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "trained on past data. The user wants",
      "offset": 363.36,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "very relevant, up-to-date information,",
      "offset": 365.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and I have tools available that I can",
      "offset": 367.759,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "call. First, let's actually call the get",
      "offset": 369.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "coordinates tool because I want to be",
      "offset": 371.68,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "able to call the get weather tool, but I",
      "offset": 373.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "need some coordinates first. So it might",
      "offset": 374.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "actually output, hey, I would like to",
      "offset": 376.56,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "call the get coordinates tool for",
      "offset": 378.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Denver, Colorado. And that's literally",
      "offset": 381.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "all it outputs. After that, it's done.",
      "offset": 382.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "But this output here says call this tool",
      "offset": 384.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "with the input Denver, Colorado. From",
      "offset": 387.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "there, the host application like chat",
      "offset": 388.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "GBT or cloud desktop or cursor. They",
      "offset": 390.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "will see that tool call and now they'll",
      "offset": 393.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "actually make the call. And so the tool",
      "offset": 394.639,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "itself can reach out to the internet.",
      "offset": 396.88,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "And the tool can be thought of as",
      "offset": 398.319,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "something that has inputs and outputs.",
      "offset": 399.759,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "And so in this case, the input is",
      "offset": 401.28,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "Denver, Colorado. The tool is get",
      "offset": 402.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "coordinates. It's going to call some web",
      "offset": 404.479,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "API that geoloccates things. So given",
      "offset": 406.24,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "the name of a place, it can come back",
      "offset": 408.56,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "with latitude longitude and its output",
      "offset": 409.759,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "are going to be the latitude longitude",
      "offset": 411.68,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "of Denver, Colorado. From there, we can",
      "offset": 413.199,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "now send all of that back into the LLM.",
      "offset": 415.039,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "So the tool output here will have the",
      "offset": 416.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "latitude longitude of Colorado. And in",
      "offset": 418.319,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "this case, the same user input of what",
      "offset": 420.639,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "is the current weather in Denver,",
      "offset": 423.039,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "Colorado. But now the LLM will",
      "offset": 424.319,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "potentially see, oh, uh, I have the",
      "offset": 426.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "coordinates and I want to know the",
      "offset": 428.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "weather. So maybe I'll make another tool",
      "offset": 430.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "call that will actually give me the",
      "offset": 432.8,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "weather based on some coordinates. So",
      "offset": 434.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "its output would actually be a tool call",
      "offset": 435.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "and then that will call the tool that",
      "offset": 438.08,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "will reach out to the API get the",
      "offset": 440,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "weather specifically for those",
      "offset": 441.599,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "coordinates and then all of that will",
      "offset": 442.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "again be included and finally the LLM",
      "offset": 444.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "will see okay I have the coordinates I",
      "offset": 447.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "have the weather forecast in my tool",
      "offset": 448.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "output and the user just asks what's the",
      "offset": 450.24,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "current weather in Denver Colorado.",
      "offset": 452.24,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "Okay, I think I can answer that question",
      "offset": 453.759,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "without calling any other tools. And",
      "offset": 455.199,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "then it will just answer the user to say",
      "offset": 456.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "what the weather is based on the the",
      "offset": 458.479,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "fact that it just got that weather",
      "offset": 460.4,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "forecast from that tool. And so when",
      "offset": 461.68,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "you're sitting at home talking to chat",
      "offset": 463.28,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "GPT or anything else, this process is",
      "offset": 464.639,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "just happening over and over and over.",
      "offset": 466.479,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "Every single time you send a new message",
      "offset": 468.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "in that chat window, this whole process",
      "offset": 470.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "is happening where if you have any tools",
      "offset": 472,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "available and you just ask the AI for",
      "offset": 474.4,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "something that it thinks it should",
      "offset": 476.72,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "invoke the tool for, it's going to",
      "offset": 477.759,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "invoke that tool. And then when the tool",
      "offset": 478.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "result comes back, that whole context of",
      "offset": 480.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "your conversation, the tool response,",
      "offset": 482.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "your latest question is all going to get",
      "offset": 484.24,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "passed back into the LLM. So it's this",
      "offset": 485.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "this loop where this context window here",
      "offset": 487.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "kind of just grows and grows as you chat",
      "offset": 490.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "with that LLM more and more. Now this is",
      "offset": 491.759,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "the current state of things.",
      "offset": 493.52,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "Essentially, if an LLM wants to have",
      "offset": 494.96,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "more up-to-date information, it needs to",
      "offset": 497.199,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "call these tools and all of the various",
      "offset": 499.199,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "tools like ChatGpt and Claude and VS",
      "offset": 500.72,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "Code and Cursor and all of these other",
      "offset": 503.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "things that can talk to LLMs have",
      "offset": 504.479,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "implemented a flow like this. Now, this",
      "offset": 506.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "is where MCP comes into play, which is",
      "offset": 508.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the model context protocol because",
      "offset": 510.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "there's lots of different LLMs. There's",
      "offset": 513.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "lots of different clients that we can",
      "offset": 515.12,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "use to talk to LLMs and MCP was",
      "offset": 517.44,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "essentially an effort to standardize how",
      "offset": 520.719,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "these host applications and LLMs can",
      "offset": 523.279,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "talk to these various tools that are",
      "offset": 526.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "available. So, the model context",
      "offset": 528.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "protocol specification defines how an",
      "offset": 530.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "MCP client or host application can talk",
      "offset": 533.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "to an MCP server. talks about the kind",
      "offset": 535.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "of things an MCP server can expose like",
      "offset": 538.08,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "tools or prompts or resources and",
      "offset": 540.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "basically all of this is defined in a",
      "offset": 542.959,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "standardized way so that any application",
      "offset": 545.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "whether it's chat GPT or claude or",
      "offset": 548.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "cursor or VS code which in this case are",
      "offset": 550.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "going to be the MCP clients can all",
      "offset": 553.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "implement this way of talking to these",
      "offset": 555.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "servers and then regardless of who",
      "offset": 557.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "defined that server any one of these",
      "offset": 559.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "client applications can start to talk to",
      "offset": 561.519,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "it and this essentially opens up a whole",
      "offset": 563.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "world of connecting LLMs to the internet",
      "offset": 564.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and data sources and all of the stuff",
      "offset": 567.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that it doesn't have access to that is",
      "offset": 569.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like the most up-to-date information or",
      "offset": 571.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the most relevant information about a",
      "offset": 573.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "specific user or a specific company. Now",
      "offset": 575.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "these LLMs can get access to that",
      "offset": 577.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "information in a standardized way. Now I",
      "offset": 579.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "actually developed a tool for getting",
      "offset": 581.04,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the weather based on a location and",
      "offset": 582.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "let's see it in action. So I'm just",
      "offset": 584.959,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "going to say what is the weather like",
      "offset": 586.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "right now? And because I set up Cloud",
      "offset": 590.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Desktop with access to this MC MCP tool,",
      "offset": 592.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you'll see that it first responds and",
      "offset": 595.12,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "says, &quot;I'd be happy to help you check",
      "offset": 596.56,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "the current weather to get accurate",
      "offset": 598,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "weather information for your area.&quot; I'll",
      "offset": 599.519,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "need to know your location. Could you",
      "offset": 601.279,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "tell me what city, state, or country",
      "offset": 602.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you're in? So, because I made these",
      "offset": 604.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "tools available, Cloud Desktop sees,",
      "offset": 606.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "okay, I have a tool I can call, which is",
      "offset": 608.32,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "get weather, but that requires",
      "offset": 609.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "coordinates. Coordinates require",
      "offset": 610.959,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "location. So, the user asks me a very",
      "offset": 612.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "general question. I need to know where",
      "offset": 615.2,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "they are. So, I'm going to tell them,",
      "offset": 616.64,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "hey, I'm in Denver, Colorado. And we",
      "offset": 617.839,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "should see now that it has the context",
      "offset": 619.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "it needs, it's going to make a request",
      "offset": 620.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "out to the tool that I set up. So I have",
      "offset": 622.88,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "this tool available called get",
      "offset": 624.48,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "coordinates. And I'm just going to click",
      "offset": 625.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "allow once. And you can see that it",
      "offset": 627.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "called that tool with the place Denver,",
      "offset": 629.279,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "Colorado. And then from there, it got",
      "offset": 631.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the coordinates. Now it can call get",
      "offset": 634.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "weather and pass those in. So you can",
      "offset": 635.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "see that these client applications can",
      "offset": 637.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "call multiple tools back to back and",
      "offset": 639.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "they can feed information from one tool",
      "offset": 641.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "called to another. So in this case, got",
      "offset": 643.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the coordinates. It's going to pass that",
      "offset": 644.959,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "to get weather. And now we can say the",
      "offset": 646.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "current weather in Denver, Colorado is",
      "offset": 648.64,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "looking quite nice. It's 79° Fahrenheit,",
      "offset": 650,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "mostly clear skies, humidity of 43%,",
      "offset": 653.519,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "etc. So each of these actually reached",
      "offset": 656.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "out to my tool, my tool called various",
      "offset": 659.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "APIs to get that data. All of that was",
      "offset": 660.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "put into the context and now Claude has",
      "offset": 663.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "everything it needs to answer in a",
      "offset": 665.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "grounded way than not hallucinate about",
      "offset": 667.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "what the current weather is. And you can",
      "offset": 669.519,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "see for get coordinates, my tool",
      "offset": 670.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "literally just responds with some JSON",
      "offset": 672.959,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "data. So I'm using the nomenatim API",
      "offset": 675.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "which is from open street map. Basically",
      "offset": 677.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "given a place it'll give you back a list",
      "offset": 678.8,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "of place results that include latitude",
      "offset": 681.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and longitude. So that's one tool call",
      "offset": 683.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "and it responded with that. And then get",
      "offset": 685.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "weather. I'm actually using the pirate",
      "offset": 687.44,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "weather API and it accepts latitude",
      "offset": 689.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "longitude. There's several different",
      "offset": 692.399,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "types you can pass in like do you want",
      "offset": 693.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the current weather, the daily forecast,",
      "offset": 695.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the hourly forecast, the minutely",
      "offset": 697.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "forecast and you can also pass in units.",
      "offset": 699.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "You can see this responded with",
      "offset": 701.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Fahrenheit because I'm in the US and",
      "offset": 703.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that's what we use. But it also accepts",
      "offset": 704.88,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "other units like SI and it would respond",
      "offset": 707.04,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "in Celsius. And then you can see the",
      "offset": 708.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "actual response is just this JSON object",
      "offset": 710.959,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that has the current forecast for",
      "offset": 713.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Denver. And this is the data we got back",
      "offset": 715.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "from the pirate weather API. So you can",
      "offset": 717.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "see how basically making these tools",
      "offset": 719.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "available to a client application allows",
      "offset": 721.839,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "it to be grounded in the current time",
      "offset": 724.48,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "and place and what the user is talking",
      "offset": 728,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "about and not just hallucinate things.",
      "offset": 730.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Now reading this model context protocol",
      "offset": 732.16,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "spec can be a little bit dense at times.",
      "offset": 734.639,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "But I want to reassure you that creating",
      "offset": 737.519,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "tools and MCP servers is fairly easy",
      "offset": 739.279,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "especially if you just use their SDK.",
      "offset": 742.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "And so you can see here that there's",
      "offset": 744.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "SDKs for many different languages. I",
      "offset": 745.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "specifically work in the world of",
      "offset": 748,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "JavaScript and TypeScript. So I just use",
      "offset": 749.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the TypeScript SDK. And even just",
      "offset": 750.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "looking at their readme, you can see how",
      "offset": 753.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "easy it is to set up these MCP servers.",
      "offset": 755.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "And so this defines a server. You",
      "offset": 758.079,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "register some tools. You define what",
      "offset": 760.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that tool takes in as input. And then",
      "offset": 762.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "you have a function that will get called",
      "offset": 764.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "whenever that tool is invoked. And this",
      "offset": 766.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "function can do anything. It can talk to",
      "offset": 768.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "an API. It can talk to a database. And",
      "offset": 770.399,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "so it's this easy to create tools. And",
      "offset": 772.399,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "then what gets a little bit trickier is",
      "offset": 775.839,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "how you actually expose these MCP",
      "offset": 777.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "servers. And so in the default example",
      "offset": 779.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "here, it's just using the standard IO",
      "offset": 781.36,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "server. And that means that this tool",
      "offset": 783.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "whenever it's called is just running",
      "offset": 785.839,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "directly on your machine. There is a way",
      "offset": 787.279,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "for you to define a remote server. So",
      "offset": 789.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that's a that is an MCP server hosted in",
      "offset": 791.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the cloud and then anytime a host",
      "offset": 793.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "application wants to invoke those tools,",
      "offset": 795.68,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "it will actually make requests to your",
      "offset": 797.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "deployed server. that gets a little bit",
      "offset": 799.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "trickier because you do need to know how",
      "offset": 801.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "to deploy that and potentially set",
      "offset": 802.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "things up with server sent events or",
      "offset": 804.32,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "with streaming HTTP. But again, there",
      "offset": 806.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "are SDKs that make that much simpler.",
      "offset": 808.079,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "So, aside from all of the spec and",
      "offset": 810.399,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "protocol descriptions and and everything",
      "offset": 812.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "else that gets into the nitty-gritty, at",
      "offset": 814.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the end of the day, as someone making",
      "offset": 816.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "MCP servers, really all you have to do",
      "offset": 818.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "is learn about the specific SDK for the",
      "offset": 820.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "language that you're familiar with and",
      "offset": 822.24,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "then also learn a little bit about the",
      "offset": 823.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "SDKs that have been defined to help you",
      "offset": 825.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "set up a remote server if that's the",
      "offset": 827.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "path you want to go down for your MCP",
      "offset": 829.12,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "server. Now, let's see my specific",
      "offset": 831.12,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "weather tool to see how I set all of",
      "offset": 832.399,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "this up. The codes itself are fairly",
      "offset": 833.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "simple. I just have an entry point which",
      "offset": 834.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "actually creates the MCP server. And",
      "offset": 836.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "from here we register all of the",
      "offset": 839.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "available tools and then expose it over",
      "offset": 842,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "standard io. And then to register a tool",
      "offset": 844.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "you pass in a name. In this case the",
      "offset": 846.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "name of the tool is get coordinates. You",
      "offset": 848.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "can give it a title and then a",
      "offset": 850.079,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "description. Now I found with the",
      "offset": 851.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "description you can kind of give some",
      "offset": 853.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "hints as to when the host application",
      "offset": 855.12,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "should call this tool. So here we have",
      "offset": 858.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "get the coordinates of a given place",
      "offset": 861.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "typically the user's location. if you",
      "offset": 863.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "don't know the user's location, ask them",
      "offset": 865.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "for it before calling this tool. And so",
      "offset": 867.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "we saw that happen inside of Cloud",
      "offset": 869.279,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "Desktop. It was like, wait, I want to",
      "offset": 870.72,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "call that tool, but where are you? I",
      "offset": 872.079,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "said Denver, Colorado. And then it was",
      "offset": 873.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "able to call this tool and it passed in",
      "offset": 875.519,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "an input. And so for tool, you can",
      "offset": 877.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "define the input schema. And this is",
      "offset": 879.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "what data needs to be passed to this",
      "offset": 881.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "tool. Now, in this case, we're using zod",
      "offset": 883.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "to say that when you call this tool,",
      "offset": 885.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "you'll pass in place and place is a",
      "offset": 886.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "string. You can see in the description,",
      "offset": 888.8,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "I also provided some examples of places",
      "offset": 890.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "so that way the LLM could potentially",
      "offset": 893.279,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "even reformat the user's input to look",
      "offset": 895.199,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "more like what we're expecting. And then",
      "offset": 898.24,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "that's what's going to be passed in",
      "offset": 900.399,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "here. So all of this is the setup. It's",
      "offset": 901.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "the tool name, the description.",
      "offset": 903.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "Basically, this is what is going to be",
      "offset": 905.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "exposed to the LLM in any prompt that a",
      "offset": 906.959,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "user types in to let them know that this",
      "offset": 909.199,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "tool is available. And then we can pass",
      "offset": 911.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "in a callback function. And this",
      "offset": 912.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "callback function is going to get access",
      "offset": 914.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to that input. So you can see here that",
      "offset": 916.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "it exactly corresponds to the input",
      "offset": 918.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "schema. And so when the LLM calls this",
      "offset": 921.12,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "tool, it's going to pass in a place and",
      "offset": 922.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "it figures out what that is, right?",
      "offset": 924.639,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Based on the user's prompt or their text",
      "offset": 926,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "or their input, it's going to figure out",
      "offset": 928.079,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "what to pass into our function here. And",
      "offset": 929.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "from there, we can do the work. In this",
      "offset": 931.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "case, I'm calling an API. So like I",
      "offset": 933.68,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "mentioned earlier, we're just calling",
      "offset": 935.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "the Nanatim Open Street Map API. It",
      "offset": 936.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "accepts a place name, responds with",
      "offset": 938.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "JSON, and in this case, I'm just sending",
      "offset": 941.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the response exactly back. Now,",
      "offset": 943.44,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "depending on the tool that you're",
      "offset": 945.199,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "building, instead of just sending back",
      "offset": 946.32,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "JSON data, you could reformat this as",
      "offset": 947.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "like markdown. But for these purposes,",
      "offset": 949.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the LLM is actually really good at just",
      "offset": 952,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "parsing that JSON data that it gets back",
      "offset": 953.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "and it's able to use that in further",
      "offset": 955.759,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "tool calls. So, we literally just",
      "offset": 957.279,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "stringify that data we got back from the",
      "offset": 958.56,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "place search API. And so then the LM can",
      "offset": 960.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "now use that coordinate data as further",
      "offset": 963.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "context for other prompts or in this",
      "offset": 964.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "case tool calls. Because we saw earlier",
      "offset": 967.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "after it got the coordinates, then it",
      "offset": 969.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "called the get weather endpoint. And so",
      "offset": 971.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "similar idea, we give it a tool name. We",
      "offset": 973.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "give it a title. And for the",
      "offset": 974.88,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "description, I also give it some hints",
      "offset": 976.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "that say if you don't have the latitude",
      "offset": 977.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and longitude, you can use the get",
      "offset": 979.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "coordinates tool to get them. So I'm",
      "offset": 981.44,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "basically letting it know, hey, call",
      "offset": 982.88,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "this other tool if you want to call this",
      "offset": 984.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "tool. And then this also accepts in the",
      "offset": 985.759,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "type. So you can ask for multiple. So",
      "offset": 988.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "you can ask for the current weather,",
      "offset": 989.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "hourly, daily, or minutely. And it can",
      "offset": 991.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "be any combination of these. And then",
      "offset": 993.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you also pass in the units. Now in this",
      "offset": 995.839,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "case, when it called the tool, it",
      "offset": 997.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "probably inferred that my local was",
      "offset": 999.199,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "English. And so it just passed in the",
      "offset": 1001.44,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "units as US. But you can see here on",
      "offset": 1002.959,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "input, we're going to get access to the",
      "offset": 1004.959,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "latitude, longitude, what types of",
      "offset": 1007.279,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "weather they're asking for, and then the",
      "offset": 1009.519,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "units that we should respond with. And",
      "offset": 1010.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "then again, we just call an API. So if",
      "offset": 1012.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "you look at my get weather function, I'm",
      "offset": 1015.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "specifically talking to pirate weather.",
      "offset": 1017.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "I have an API key set up. So that gets",
      "offset": 1018.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "passed in. We pass in the latitude,",
      "offset": 1020.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "longitude, and units. And then we get",
      "offset": 1022.32,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "back the data. And then from there,",
      "offset": 1024.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "whatever the LLM asks for. So if it",
      "offset": 1025.839,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "wanted current, hourly, daily or minute",
      "offset": 1027.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "or any combination of those, we include",
      "offset": 1029.199,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that in the response and then again just",
      "offset": 1031.12,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "respond with the JSON which gets",
      "offset": 1033.039,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "stringified. So these are fairly simple",
      "offset": 1035.439,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "tools and when you're first getting",
      "offset": 1037.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "started out with MCP, this is kind of",
      "offset": 1038.959,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the way you can think about things.",
      "offset": 1040.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "They're really just guided API",
      "offset": 1042.319,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "connectors, right? um they can get much",
      "offset": 1044.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "more complex than this and of course you",
      "offset": 1047.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "could have a function that itself calls",
      "offset": 1048.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "multiple APIs and gathers data for",
      "offset": 1050.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "multiple services but on the service",
      "offset": 1052,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "level and when you're just getting",
      "offset": 1053.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "started this is one way to think about",
      "offset": 1054.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "how to build out these tools which is",
      "offset": 1057.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "define how the LLM can structure data to",
      "offset": 1058.799,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "call this API and then you write the",
      "offset": 1062,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "code to actually call that API now the",
      "offset": 1063.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "next thing is how is this thing actually",
      "offset": 1065.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "running so here we're using the standard",
      "offset": 1067.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "IO server transport you can see we're",
      "offset": 1069.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "just importing that in from the SDK and",
      "offset": 1070.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "then we're starting the server up Now",
      "offset": 1072.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "when we configure this inside of cloud",
      "offset": 1075.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "desktop we actually just tell it that it",
      "offset": 1076.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "should start this by running this",
      "offset": 1079.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "TypeScript file with Node.js. So in",
      "offset": 1081.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "cloud desktop if you press command comma",
      "offset": 1083.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "and you head to your developer settings",
      "offset": 1086.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you can see that I have a couple of",
      "offset": 1088.48,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "tools set up. And if you click on edit",
      "offset": 1089.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "config that will actually show you where",
      "offset": 1091.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "on your computer is that config file so",
      "offset": 1093.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "that you can set all of these things up.",
      "offset": 1095.36,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "And so if I open this JSON file with",
      "offset": 1096.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "cursor, you can see first of all it has",
      "offset": 1098.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "an MCP servers section. And then inside",
      "offset": 1100.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "of there, we can set up each of our MCP",
      "offset": 1102.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "servers. And for the git weather server,",
      "offset": 1104.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "I tell it that the command it needs to",
      "offset": 1106.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "use is node. Now, usually you can just",
      "offset": 1108.16,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "specify node right here or python or",
      "offset": 1110.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "however you typically would run your",
      "offset": 1112.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "program, but in my case, I wanted it to",
      "offset": 1114.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "use a specific version of node and I use",
      "offset": 1116.4,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "nvm. So I gave it the full path to that",
      "offset": 1118,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "executable. So essentially when cloud",
      "offset": 1119.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "desktop wants to start up this server,",
      "offset": 1121.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "it's going to use this node command and",
      "offset": 1123.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "then it's going to pass in the argument",
      "offset": 1125.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of the file that it needs to run. And so",
      "offset": 1126.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "whenever cloud desktop starts up, it",
      "offset": 1128.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "literally runs Node.js with this file",
      "offset": 1130.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and that's just running as a background",
      "offset": 1133.2,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "process that's going to be able to",
      "offset": 1134.72,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "output data over standard IO. I also",
      "offset": 1136.08,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "gave it the current working directory",
      "offset": 1137.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "because this needs an API key, but ended",
      "offset": 1139.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "up actually just having to specify my",
      "offset": 1141.679,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "API key directly. So for any MCP server",
      "offset": 1143.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "that you're setting up in this way, you",
      "offset": 1146.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "can also pass in environment variables.",
      "offset": 1147.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "And in this case, I pass in my pirate",
      "offset": 1149.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "weather API key. And when it's running",
      "offset": 1151.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "this program, it'll have access to that",
      "offset": 1153.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "environment variable. So right now, this",
      "offset": 1155.039,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "is somewhat manual and cumbersome. Uh",
      "offset": 1156.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "but I'm okay with this because I'm a",
      "offset": 1159.28,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "developer. I know how to work inside of",
      "offset": 1160.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "JSON files. Um and for the servers that",
      "offset": 1161.679,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "I develop, I'm very likely just going to",
      "offset": 1164.32,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "set them up this way, especially if I",
      "offset": 1166.16,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "only need to access them on my computer.",
      "offset": 1167.679,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "Now, another way you might set up or",
      "offset": 1169.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "configure tools is to just use npx. So",
      "offset": 1170.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "if these are published to npm, you can",
      "offset": 1172.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "actually just specify the name of an npm",
      "offset": 1175.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "package and this will run it without",
      "offset": 1177.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "having to manually point it to a",
      "offset": 1180.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "directory or anything like that. So this",
      "offset": 1182.32,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "is another way of of getting MCP servers",
      "offset": 1183.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "set up is you can just pull them",
      "offset": 1185.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "directly from npm. Similarly, if you",
      "offset": 1186.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "find one on GitHub and you want to run",
      "offset": 1189.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "it locally, you could clone it down into",
      "offset": 1190.799,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "a folder and then set it up in a similar",
      "offset": 1192.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "way to what I'm doing here. But",
      "offset": 1194.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "basically whenever cloud desktop starts",
      "offset": 1195.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "up, it sees that these MCP servers need",
      "offset": 1198,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to be run and it will actually spin up",
      "offset": 1200.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "these terminals in the background and",
      "offset": 1202.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "then write to standard in and read from",
      "offset": 1204.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "standard out in order to communicate",
      "offset": 1207.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "with this process that's running. And so",
      "offset": 1208.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this is the the simplest form of MCP.",
      "offset": 1210.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "These are running directly on my",
      "offset": 1212.4,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "machine. That's the other thing to keep",
      "offset": 1213.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "in mind here is when I prompt claude",
      "offset": 1214.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "that actually goes off to Anthropic and",
      "offset": 1217.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "talks to their APIs and which interfaces",
      "offset": 1219.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "with their LLM with which makes this",
      "offset": 1221.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "response here. But when it needs to call",
      "offset": 1223.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "tools, if they're just set up as local",
      "offset": 1225.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "tools, it's literally just talking to a",
      "offset": 1227.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "process that's running on my machine.",
      "offset": 1229.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "But there are other types of tools that",
      "offset": 1230.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "can actually be exposed over the web.",
      "offset": 1232.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "And one example of this is the currency",
      "offset": 1234.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "conversion model context protocol server",
      "offset": 1237.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that Westboss wrote. And his code is",
      "offset": 1239.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "completely open source. It's on GitHub.",
      "offset": 1241.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "And in order to talk to it, he actually",
      "offset": 1244.159,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "has a hosted server at",
      "offset": 1246.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "currency-mcp.westboss.com.",
      "offset": 1247.679,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "And so if anyone wants to add this, it's",
      "offset": 1250.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "actually much easier. you can actually",
      "offset": 1252.559,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "just point it directly at his hosted",
      "offset": 1253.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "server. So, let me do this right now.",
      "offset": 1255.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "I'm going to add it to my Cloud Desktop",
      "offset": 1257.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "config. And typically, I've found I need",
      "offset": 1259.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to completely restart Cloud Desktop to",
      "offset": 1261.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "make sure that it picks up all of those",
      "offset": 1263.52,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "changes. Now, I tried just using these",
      "offset": 1264.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "settings exactly for Cloud Desktop, but",
      "offset": 1266.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "I ran into a bunch of issues, but I did",
      "offset": 1268.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "find this gist which talks about how to",
      "offset": 1270.72,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "use Cloud MCP with NVM, which is a node",
      "offset": 1272.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "version manager. And so they have a few",
      "offset": 1276.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "different things you can do with your",
      "offset": 1278.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "shell configuration to make sure that",
      "offset": 1280.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this works. So I got all of that working",
      "offset": 1282.559,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "and I created a special command called",
      "offset": 1284.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "PNPM for cloud. So this specifically",
      "offset": 1287.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "chooses the right version and then here",
      "offset": 1289.919,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "we're using DLX and it can then run this",
      "offset": 1292.4,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "MCP remote command with that server URL.",
      "offset": 1295.919,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "So with all of that now cloud desktop",
      "offset": 1298.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "has the tool and I can say something",
      "offset": 1301.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "like convert 25 USD to yen. Of course,",
      "offset": 1303.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "you can see Cloud Desktop figured out,",
      "offset": 1306.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "hey, I need to call that tool. So, we're",
      "offset": 1308.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "going to allow it. It calls Wes's tool,",
      "offset": 1310.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "which actually reaches out over the web",
      "offset": 1312.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "to his deployed server, gives back a",
      "offset": 1314.88,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "response. You can see that he's just",
      "offset": 1316.96,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "responding with some JSON data here, and",
      "offset": 1318.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "then it's able to say, &quot;Hey, 25 USD is",
      "offset": 1319.919,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "about 3600 Japanese yen.&quot; Now, I'll link",
      "offset": 1322.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "all of the resources I found for setting",
      "offset": 1325.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "up these remote servers inside of Cloud",
      "offset": 1327.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Desktop. But one of the things to note",
      "offset": 1329.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "here is this MCP remote tool. So this is",
      "offset": 1331.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "just a tool that lives on npm. And",
      "offset": 1334.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "essentially you can take any remote",
      "offset": 1336.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "server and turn it into a local server.",
      "offset": 1338.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "And right now this is what's needed if",
      "offset": 1341.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you want to do this more developeresque",
      "offset": 1342.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "setup of there's a server somewhere.",
      "offset": 1344.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Maybe you're working with a tool that",
      "offset": 1346.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "doesn't support remote URLs. MCP remote",
      "offset": 1347.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "basically turns it into a standard IO",
      "offset": 1350.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "tool. But let's take a look at the",
      "offset": 1352.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "actual code that Wes had to write to",
      "offset": 1353.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "make this a remotely deployed server. So",
      "offset": 1355.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "if you look in the entry point file",
      "offset": 1357.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "here, he's actually using MCP agent",
      "offset": 1358.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "which comes from the Cloudflare agents",
      "offset": 1361.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "SDK. So his server is actually deployed",
      "offset": 1363.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "to Cloudflare that makes these tools",
      "offset": 1366.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "available over the web. Now the code for",
      "offset": 1368.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "initializing a server is very similar to",
      "offset": 1370.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "our standard IO server. You can see here",
      "offset": 1372.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "that they register tools, they create an",
      "offset": 1373.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "instance of the server, but then",
      "offset": 1376.159,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "specifically in order to expose it over",
      "offset": 1377.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "the web, this Cloudflare worker whenever",
      "offset": 1379.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it receives an incoming request can",
      "offset": 1381.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "connect to that client, whether it was",
      "offset": 1383.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "coming over server sentent events or",
      "offset": 1386.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "just over the HTTP protocol and then",
      "offset": 1387.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "respond accordingly. But all of the",
      "offset": 1390.159,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "nitty-gritty details of talking over",
      "offset": 1393.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "that protocol are handled by the SDK.",
      "offset": 1394.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "And so that's really another takeaway",
      "offset": 1397.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "from developing these tools. We're kind",
      "offset": 1398.96,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "of at a point where you don't really",
      "offset": 1400.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "have to worry about the specifics of the",
      "offset": 1401.84,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "protocol as long as you're using an SDK.",
      "offset": 1404.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Writing the tools themselves is fairly",
      "offset": 1408.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "simple. You can see Wes is just calling",
      "offset": 1410.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "out to some APIs given the input and",
      "offset": 1412.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "just registering these tools here. But",
      "offset": 1415.12,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "then all of the protocol stuff is",
      "offset": 1416.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "handled by the SDK itself. And this is",
      "offset": 1418.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "one thing to think about if you are",
      "offset": 1420.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "going to be creating a remote MCP server",
      "offset": 1421.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "for people to use. You're going to be",
      "offset": 1424.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "paying for that server bandwidth, right?",
      "offset": 1426.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "So Wes absolutely is paying the monthly",
      "offset": 1428.08,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "bill for this on Cloudflare to run these",
      "offset": 1430.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "commands in the cloud. Now for some",
      "offset": 1433.039,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "users it's easier to set up because they",
      "offset": 1434.88,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "don't have to like download the whole",
      "offset": 1436.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "repo and like host it locally. Um and",
      "offset": 1437.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this is probably the way you want to go",
      "offset": 1440,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "especially if you maybe have some secret",
      "offset": 1441.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "sauce that you don't want to just expose",
      "offset": 1443.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "in the tool directly, right? Because if",
      "offset": 1444.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "people are just cloning down your repo,",
      "offset": 1446.48,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "they have access to all of the tools",
      "offset": 1447.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "source code. But if you're hosting it in",
      "offset": 1449.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the cloud, anything that happens",
      "offset": 1451.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "whenever a tool is called could do much",
      "offset": 1454.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "more secret things, right? It could talk",
      "offset": 1456.64,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "to a database that maybe you don't want",
      "offset": 1458.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "to expose the the password for or",
      "offset": 1459.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "whatever else. But in this case, Wes is",
      "offset": 1461.52,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "just reaching out to a third party API.",
      "offset": 1463.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Nothing crazy, but you could follow this",
      "offset": 1465.279,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "format if you want to kind of hide",
      "offset": 1467.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "what's happening in the tool call and",
      "offset": 1470.559,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "not just have it run on the user's local",
      "offset": 1472.24,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "machine. Now, when you're building out",
      "offset": 1473.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "your MCP server locally, you're going to",
      "offset": 1475.039,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "want to test it somehow, and it's pretty",
      "offset": 1477.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "cumbersome to restart your client every",
      "offset": 1480.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "single time you make changes to your",
      "offset": 1482.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "server to see it in action. And this is",
      "offset": 1484.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "where the model context protocol",
      "offset": 1486.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "inspector can help you out. So",
      "offset": 1488.559,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "essentially you can run this command in",
      "offset": 1491.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the folder where you're developing your",
      "offset": 1494,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "tool and it will give you a web",
      "offset": 1496,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "dashboard where you can actually invoke",
      "offset": 1497.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "your tools with various arguments. So",
      "offset": 1499.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "for instance I have this other tool",
      "offset": 1502,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "which I've been working on which gets",
      "offset": 1503.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "web search results from duck.go. But if",
      "offset": 1504.96,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "I want to run this and debug it, I can",
      "offset": 1507.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "do npx model context protocol/insspector",
      "offset": 1509.279,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "node and then the name of the file. Now,",
      "offset": 1512.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this will just spin up a local server.",
      "offset": 1515.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "If I head to that URL, I get a nice",
      "offset": 1516.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "little dashboard and then I can connect",
      "offset": 1519.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "to the server. And this is just",
      "offset": 1521.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "essentially connecting to it via",
      "offset": 1524,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "standard IO. So, it's spinning up that",
      "offset": 1525.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "process in the background. And now all",
      "offset": 1527.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "of the things that a client application",
      "offset": 1530.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "like cursor or cloud desktop would do to",
      "offset": 1532.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "interact with that tool, we can do from",
      "offset": 1535.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "this web dashboard. So, for one, we can",
      "offset": 1536.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "list the available tools. And you can",
      "offset": 1538.4,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "see that I have two tools. I have list",
      "offset": 1540.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "search results and get URL contents. So",
      "offset": 1541.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "for instance, I can call list search",
      "offset": 1544.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "results, pass in a search term, and this",
      "offset": 1546,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "is going to search duck.go. So let's",
      "offset": 1547.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "search for reverse string in JavaScript.",
      "offset": 1549.52,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "This will run my tool. And you can see",
      "offset": 1553.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "my tool responds with those search",
      "offset": 1555.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "results that came back from duck.go. And",
      "offset": 1556.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "so as you're building out these tools,",
      "offset": 1558.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "this is going to be one of the easiest",
      "offset": 1561.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "ways to make sure that your tools are",
      "offset": 1562.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "outputting what's expected and test them",
      "offset": 1564.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "with various types of input as well.",
      "offset": 1566.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Now, another tool I made available is",
      "offset": 1568.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "called get URL contents. And so this",
      "offset": 1570,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "essentially just takes in a URL, fetches",
      "offset": 1572.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "that page, converts it to markdown, and",
      "offset": 1574.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "then responds with the markdown and some",
      "offset": 1576.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "metadata about the page. So you can see",
      "offset": 1578.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "if I pass this Geeks forge Geeks uh URL",
      "offset": 1580.32,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "into my tool, it actually pulls back the",
      "offset": 1583.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "description of the page and then all of",
      "offset": 1585.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "the content of the page as markdown. And",
      "offset": 1587.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "then this could further be used as",
      "offset": 1590.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "context whenever an LLM is trying to",
      "offset": 1592.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "respond to a user's question. Now, if",
      "offset": 1595.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "your tool isn't a standard IO tool, they",
      "offset": 1596.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "do support testing out SSE servers or",
      "offset": 1598.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "streaming HTTP. So, even if you're",
      "offset": 1601.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "running them locally, you can connect",
      "offset": 1604.4,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "here and do things like list tools and",
      "offset": 1605.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "make tool calls. And so, like I said,",
      "offset": 1607.6,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "this is great for testing things out",
      "offset": 1609.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "before you actually add them into any",
      "offset": 1610.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "host application. Now, after debugging",
      "offset": 1612.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that tool, I can use it, for instance,",
      "offset": 1614.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "inside of Cloud. And personally, I've",
      "offset": 1616,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "been liking using my integration instead",
      "offset": 1619.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "of using the built-in web one because",
      "offset": 1621.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it's smart enough to basically choose",
      "offset": 1623.279,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "which of the pages it wants to get the",
      "offset": 1625.6,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "source for and and it's a whole lot",
      "offset": 1627.039,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "faster. So, for instance, if I say",
      "offset": 1628.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "search the web or how to reverse a",
      "offset": 1629.919,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "string in JavaScript, it should call my",
      "offset": 1632.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "web search tool. So, it's going to list",
      "offset": 1635.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "those duck.go search results. I'm going",
      "offset": 1636.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "to always allow it. How to reverse a",
      "offset": 1638.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "string JavaScript methods. And then you",
      "offset": 1639.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "can see that it got the list of results,",
      "offset": 1641.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "but it's like, all right, I need more",
      "offset": 1644.4,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "detailed information. And so now it's",
      "offset": 1645.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "specifically going to make a request for",
      "offset": 1647.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "one of those search results. And so",
      "offset": 1648.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "typically this is actually the kind of",
      "offset": 1652.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "question that LLMs are good at answering",
      "offset": 1653.84,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "without tools. But this now grounds its",
      "offset": 1656.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "answer in relevant results that it",
      "offset": 1660.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "retrieved from the web. Like let's try",
      "offset": 1662.88,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "another prompt like um what are the most",
      "offset": 1665.12,
      "duration": 8.96
    },
    {
      "lang": "en",
      "text": "foundational novels in science fiction?",
      "offset": 1669.2,
      "duration": 8.959
    },
    {
      "lang": "en",
      "text": "what authors are important, compare some",
      "offset": 1674.08,
      "duration": 7.839
    },
    {
      "lang": "en",
      "text": "of the top stories, and make a ranking",
      "offset": 1678.159,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "of what I should read. So, it didn't",
      "offset": 1681.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "immediately reach for a tool, but I can",
      "offset": 1683.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "further tell it to uh search the web to",
      "offset": 1685.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "confirm your findings. And now, it's",
      "offset": 1688.08,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "going off and and doing the work. So,",
      "offset": 1690.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "you can see that it got back the search",
      "offset": 1692.399,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "results for most important foundational",
      "offset": 1694,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "science fiction novels, essential",
      "offset": 1695.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "reading list. And then from that set of",
      "offset": 1696.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "results, it's now going off and getting",
      "offset": 1699.279,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the full page for each of the ones that",
      "offset": 1701.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "it thinks is important. Um, and you can",
      "offset": 1704.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "see that it's searching the web even",
      "offset": 1706.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "more. So, it did another search for",
      "offset": 1708.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "golden age science fiction, uh, Ozamov",
      "offset": 1710,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and Clark, science fiction, golden age,",
      "offset": 1712.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "big three. So, it came up with all these",
      "offset": 1714.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "different search terms to send off to",
      "offset": 1716.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "the, uh, search engine, and we can see",
      "offset": 1718.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "that happening in real time. So based on",
      "offset": 1720.799,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "my web search, I can confirm that my",
      "offset": 1722.559,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "original assessment aligns with",
      "offset": 1724.08,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "established lit literary opinions.",
      "offset": 1725.2,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "Fascinating. So this potentially is what",
      "offset": 1727.2,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "this built-in web search tool is doing.",
      "offset": 1730.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "But I like how transparent uh this tool",
      "offset": 1732.399,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "is because you can actually see the",
      "offset": 1735.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "various search terms that it used and",
      "offset": 1737.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "then also the specific pages that it",
      "offset": 1738.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "went off and and got to confirm its own",
      "offset": 1740.48,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "findings. Now, before you go off and",
      "offset": 1742.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "start developing your own MCP servers,",
      "offset": 1744.399,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "there is this list called awesome MCP",
      "offset": 1746.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "servers that has a ton of existing",
      "offset": 1748.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "servers that people have implemented",
      "offset": 1751.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "that you can try adding to your client",
      "offset": 1753.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "applications that you're using. Um, or",
      "offset": 1755.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "take a look at the source code to get",
      "offset": 1756.96,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "inspiration for your own MCP servers.",
      "offset": 1758.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "And that's actually what I did before I",
      "offset": 1760.399,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "started building out my own. I I kind of",
      "offset": 1761.919,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "looked to see how people were",
      "offset": 1763.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "implementing theirs. But this list has",
      "offset": 1765.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "all kinds of MCP servers that are worth",
      "offset": 1766.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "exploring. I'm going to show you a",
      "offset": 1768.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "couple that I've been using that I found",
      "offset": 1770.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "very useful. and let me know down in the",
      "offset": 1772.08,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "comments as well if there are some MCP",
      "offset": 1773.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "servers that you can't live without. So",
      "offset": 1775.279,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "this is the main idea with MCP.",
      "offset": 1777.039,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "Basically, you have a client",
      "offset": 1778.799,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "application. It can call these tools. To",
      "offset": 1779.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "write the tools is fairly simple,",
      "offset": 1782.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "especially if you're using these SDKs",
      "offset": 1783.679,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "and then they have some kind of",
      "offset": 1785.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "transport protocol. The easiest one is",
      "offset": 1786.559,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "that tool is running locally, just",
      "offset": 1788.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "spinning it out over standard IO. It's a",
      "offset": 1790.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "little bit more complex if you wanted to",
      "offset": 1792.32,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "communicate over the web with either",
      "offset": 1793.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "server events or HTTP. Now, I've been",
      "offset": 1795.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "using Cloud Desktop for all of the",
      "offset": 1797.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "examples I'm showing you so far. But you",
      "offset": 1799.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "can set up these tools inside of a lot",
      "offset": 1800.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "of other places. So, specifically, if",
      "offset": 1802.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "you're inside of the cursor IDE and you",
      "offset": 1804.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "press command shift P, you can look for",
      "offset": 1805.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "MCP settings. And this is where you can",
      "offset": 1807.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "set up all of your MCP servers. Now,",
      "offset": 1809.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "within cursor, if you want to add or",
      "offset": 1811.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "modify servers, you can click the edit",
      "offset": 1813.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "button on any one of these, and it will",
      "offset": 1815.039,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "open up a very similar JSON file that we",
      "offset": 1816.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "saw for cloud desktop and can add each",
      "offset": 1818.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "of these MCP servers that you want to",
      "offset": 1820.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "enable. Now, one of the publicly",
      "offset": 1822.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "available MCP servers I highly recommend",
      "offset": 1825.2,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "you add to cursor is called context 7.",
      "offset": 1827.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "And this is an MCP server that has a",
      "offset": 1830.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "tool which can retrieve documentation",
      "offset": 1832.48,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "for many many different libraries or",
      "offset": 1835.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "frameworks. You can see on the homepage",
      "offset": 1838.559,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "some of the most popular ones that are",
      "offset": 1840.24,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "available. And so essentially what",
      "offset": 1841.679,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "they've done is they've indexed the",
      "offset": 1843.279,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "documentation for all of these things.",
      "offset": 1845.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "And if you're ever asking cursor to do",
      "offset": 1846.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "something and it needs more context",
      "offset": 1849.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "about what you're working in or what",
      "offset": 1851.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "library you're using, it can use this",
      "offset": 1853.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "tool to retrieve the specific parts of",
      "offset": 1855.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "the documentation that might help with",
      "offset": 1857.84,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "that. Now, to see context 7 in action, I",
      "offset": 1859.279,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "actually used it to help me write the",
      "offset": 1861.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "code to talk to the pirate weather API.",
      "offset": 1862.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "And so, if we open up a new chat window",
      "offset": 1864.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "here, and I say, uh, call the pirate",
      "offset": 1866.559,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "weather API. The last time I did this,",
      "offset": 1869.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "it was like, I have no idea what the",
      "offset": 1871.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "pirate weather API is, so I can't help",
      "offset": 1873.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "you with that. But let's see. Let's see",
      "offset": 1875.84,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "what it outputs this time. Yeah, you can",
      "offset": 1876.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "see cursor is trying it's trying to find",
      "offset": 1878.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "the context. It's like, uh, what is",
      "offset": 1880.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that? What is that? Um, so yeah, there",
      "offset": 1882.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "are no references to the pirate API. Uh,",
      "offset": 1884.64,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "the typical endpoint is this URL. Uh, I",
      "offset": 1887.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "have a feeling it figured that out",
      "offset": 1890.24,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "because of the current context because I",
      "offset": 1891.84,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "like deleted the code that that already",
      "offset": 1893.279,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "talks to it. But check this out. Let's",
      "offset": 1894.72,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "start a brand new chat window and let's",
      "offset": 1896.559,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "say uh get the docs for the pirate",
      "offset": 1898.399,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "weather API. You'll see that it actually",
      "offset": 1901.279,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "makes a tool call to resolve library ID.",
      "offset": 1903.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "And so this is a tool that is available",
      "offset": 1906.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "via context 7. And so it's going to find",
      "offset": 1908.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the library ID for the pirate weather",
      "offset": 1910.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "API. And then it's going to get the",
      "offset": 1912.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "specific docs for pirate weather. And",
      "offset": 1913.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "then this just gives me the base",
      "offset": 1916.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "documentation. Um, now I haven't worked",
      "offset": 1918,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "with this a ton, so this is kind of how",
      "offset": 1920.48,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "I found it useful. Essentially, this",
      "offset": 1921.919,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "kind of primes the chat window here to",
      "offset": 1923.919,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "know that it has this documentation",
      "offset": 1926.399,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "available. And so now if I ask it to",
      "offset": 1928.399,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "call the API, it might even further",
      "offset": 1931.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "query their docs to find the specific",
      "offset": 1933.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "part that it needs. So let's ask it now.",
      "offset": 1935.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "So let's say uh call the pirate weather",
      "offset": 1938.24,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "API with the included options. And with",
      "offset": 1940.96,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "that, it was able to actually know the",
      "offset": 1944.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "exact endpoint it could call. And also",
      "offset": 1946.799,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "given the docs, it knows that it can",
      "offset": 1948.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "pass those units in via query params in",
      "offset": 1950.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "the URL. So this is just one example of",
      "offset": 1952.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "using context 7. If you're working with",
      "offset": 1954.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "any library or anything else, you can do",
      "offset": 1957.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "the exact same thing where in a chat",
      "offset": 1959.12,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "window you say, &quot;Hey, give me the docs.&quot;",
      "offset": 1960.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "It adds it to the context and then also",
      "offset": 1962.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "it didn't happen this time, but",
      "offset": 1964.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "potentially also it will make further",
      "offset": 1966.399,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "calls to get other parts of the",
      "offset": 1968.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "documentation because you can see in",
      "offset": 1970.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "context 7 some of these docs are",
      "offset": 1972.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "hundreds of thousands of tokens, but",
      "offset": 1974.64,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "their API essentially allows you to add",
      "offset": 1976.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "like a search term and then also set the",
      "offset": 1979.279,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "number of tokens that should be",
      "offset": 1981.519,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "returned. And so their tool is smart",
      "offset": 1982.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "enough to only give the right amount of",
      "offset": 1984.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "context to still keep the token window",
      "offset": 1986.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "open to still leave enough room in the",
      "offset": 1988.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "token window so that the LLM can",
      "offset": 1990.799,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "actually respond. Um so yeah, Context 7",
      "offset": 1993.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "is an awesome tool. I definitely",
      "offset": 1995.519,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "recommend you install it in cursor if",
      "offset": 1996.72,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "you haven't yet. Now speaking of other",
      "offset": 1998.32,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "clients, you can also add MCP servers",
      "offset": 1999.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "into VS Code. So, inside of VS Code, if",
      "offset": 2001.519,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "you press command shiftp and do mcplist",
      "offset": 2004.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "servers, one of the cool things about VS",
      "offset": 2006.64,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "Code is it will detect if you have cloud",
      "offset": 2008.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "desktop installed or cursor installed,",
      "offset": 2011.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and you can see that it's actually",
      "offset": 2013.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "allowing me to connect to any of these",
      "offset": 2015.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "MCP servers that are actually configured",
      "offset": 2017.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "inside of those other tools. Uh, so if I",
      "offset": 2019.519,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "want to get access to contact 7, I don't",
      "offset": 2022,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "even have to further configure it. I can",
      "offset": 2023.919,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "just say, hey, start that server. And",
      "offset": 2025.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "now inside of VS Code, I have access to",
      "offset": 2027.039,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "that tool and it's nice and configured.",
      "offset": 2030.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "So if we open up a chat window and say",
      "offset": 2032.32,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "uh get the docs for hono, you can see",
      "offset": 2034.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that it's making a tool call. It's going",
      "offset": 2037.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to reach out and find the ID for the",
      "offset": 2039.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "hono docs and then actually grab those",
      "offset": 2041.279,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "docs. So that's just like the main",
      "offset": 2043.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "documentation. And then let's say you're",
      "offset": 2045.039,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "trying to do something more niche. You",
      "offset": 2046.64,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "could say something like how do I add",
      "offset": 2047.919,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "the corors module in a hono app? Now it",
      "offset": 2049.919,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "was able to oneshot that. Let's come up",
      "offset": 2053.28,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "with something that maybe is not at the",
      "offset": 2055.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "top level of the docs. Let's just say uh",
      "offset": 2056.879,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "how can I set up open API with my Hono",
      "offset": 2059.359,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "app. It's oneshotting everything. But",
      "offset": 2063.119,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "honestly, this is kind of amazing",
      "offset": 2065.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "because all of my other experiences uh",
      "offset": 2066.639,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "trying to use like Hono isn't that new,",
      "offset": 2069.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "but it's not as popular. So, pretty",
      "offset": 2072,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "often LLM can't get it right. But this",
      "offset": 2074.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "is just getting it right. So, I have to",
      "offset": 2077.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "keep working with this. All I know is",
      "offset": 2079.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that this is making my life a whole lot",
      "offset": 2081.2,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "easier. and the LLM makes up stuff a",
      "offset": 2082.8,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "whole lot less because it's actually",
      "offset": 2084.56,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "grounded in the documentation. Now,",
      "offset": 2085.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "another spot you can set up MCP servers",
      "offset": 2087.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "is inside of the Gemini CLI. And so, if",
      "offset": 2089.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "you're not paying for Cloud Desktop or",
      "offset": 2091.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Cursor, Gemini CLI does have a free",
      "offset": 2093.359,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "tier. And also, VS Code with the Copilot",
      "offset": 2095.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "extension has a free tier. So, you can",
      "offset": 2098.32,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "get started testing out these tools and",
      "offset": 2100,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "using them with either of these things,",
      "offset": 2101.839,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "at least for now, while they still have",
      "offset": 2103.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "a free tier. But once you've installed",
      "offset": 2105.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the Gemini CLI, you can actually create",
      "offset": 2107.119,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "a Gemini folder inside of your repo and",
      "offset": 2109.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "inside of there you can set up a",
      "offset": 2113.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "settings.json file and it's exactly the",
      "offset": 2114.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "same as this settings file that we've",
      "offset": 2117.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "set up for cursor and VS Code and Cloud",
      "offset": 2118.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Desktop. Essentially, you have an MCP",
      "offset": 2121.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "server section. Specify the servers you",
      "offset": 2123.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "want and then you tell it how they",
      "offset": 2125.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "should run. And so this is another MCP",
      "offset": 2127.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "server I wrote called Denver events that",
      "offset": 2129.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "calls a few different APIs to figure out",
      "offset": 2131.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "what's happening in Denver today. and",
      "offset": 2133.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "let's see if I can get it to call those",
      "offset": 2135.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "tools using the Gemini CLI. So, it's up",
      "offset": 2137.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "and running. I'm gonna ask it, is there",
      "offset": 2139.68,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "a Rocky's game today? This is typically",
      "offset": 2142,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "something we want to know living in",
      "offset": 2145.359,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "Denver because either you want to go to",
      "offset": 2146.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the game or you want to know that",
      "offset": 2148.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "there's going to be some traffic because",
      "offset": 2150.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the game is happening. Um, and you can",
      "offset": 2152.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "see that it detected that I have",
      "offset": 2154.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "specifically a tool called list Rocky's",
      "offset": 2156.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "home games. And I'll say yes, allow that",
      "offset": 2158.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "tool to run. It spits back all the",
      "offset": 2161.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "upcoming home games for the Rockies and",
      "offset": 2163.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "then uh Gemini is able to respond to say",
      "offset": 2165.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "no, the Rockies are not playing today,",
      "offset": 2168.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "but they have a home game tomorrow, July",
      "offset": 2169.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "1st, against the Houston Astros at 6:40",
      "offset": 2171.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "p.m. And so the Gemini CLI is typically",
      "offset": 2173.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "for working with a code base. But as you",
      "offset": 2175.599,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "can see, it's can still call tools that",
      "offset": 2177.52,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "have nothing to do with code. And",
      "offset": 2179.04,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "really, this is just another example of",
      "offset": 2180.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "a different client being able to call",
      "offset": 2182.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "these custom tools that I created. Now,",
      "offset": 2184.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this Denver events MCP server, I think",
      "offset": 2186.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "is a good example of getting specific",
      "offset": 2188.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "data that technically you could get via",
      "offset": 2191.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "just a web search, but it's more",
      "offset": 2193.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "targeted, right? So, specifically get",
      "offset": 2194.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Rocky's home games or specifically get",
      "offset": 2196.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "all the events happening at the Mile",
      "offset": 2198.88,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "High Stadium, which is where the Broncos",
      "offset": 2200.32,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "play, or specifically get events",
      "offset": 2201.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "happening at Ball Arena. Now, you might",
      "offset": 2203.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "have used ChatGpt or Cloud Desktop, and",
      "offset": 2205.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "every now and then when you type",
      "offset": 2208.56,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "something in, it'll actually search the",
      "offset": 2209.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "web, and it could potentially answer",
      "offset": 2211.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "some of these questions, but this is",
      "offset": 2213.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "specific data about these things that's",
      "offset": 2215.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "going to allow it to have just slightly",
      "offset": 2217.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "more context when it's answering these",
      "offset": 2219.52,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "types of questions about the the Denver",
      "offset": 2220.88,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "area. And really, the main thing I want",
      "offset": 2222.48,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "to point out about these tools I created",
      "offset": 2223.76,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "is I kind of just found some",
      "offset": 2225.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "undocumented APIs and then did just a",
      "offset": 2226.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "little bit of scraping. So specifically,",
      "offset": 2229.119,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "if you look at the list Rocky's game, I",
      "offset": 2230.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "found this mlb.com endpoint just by",
      "offset": 2234.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "looking at the network traffic. And I'm",
      "offset": 2236.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "actually able to directly get back JSON",
      "offset": 2238.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "data that has the schedule. And you'll",
      "offset": 2241.359,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "notice that I'm I'm not spinning up a",
      "offset": 2244.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "web browser to navigate to this page and",
      "offset": 2246.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "get the contents and everything else. So",
      "offset": 2248.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "this is a whole lot faster to get back",
      "offset": 2250.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that relevant information than trying to",
      "offset": 2253.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "search the web or go directly to a",
      "offset": 2255.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "website. And I did the same thing with",
      "offset": 2257.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "ballerina. I was looking at the network",
      "offset": 2259.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "tab. I found that they had an",
      "offset": 2261.68,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "undocumented endpoint. I'm making the",
      "offset": 2262.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "request against there. And same thing",
      "offset": 2264.56,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "with my high stadium. They actually have",
      "offset": 2266,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "some endpoints that return some JSON",
      "offset": 2267.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "data. So this is really just an example",
      "offset": 2269.359,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "of you may not necessarily need to spin",
      "offset": 2271.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "up a browser or need to do any sort of",
      "offset": 2274.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "scraping. If you can find some",
      "offset": 2276.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "undocumented endpoints, you can turn",
      "offset": 2278.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "those into tools as well. Now we",
      "offset": 2279.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "mentioned that these MCP servers can",
      "offset": 2281.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "expose several different things. Tools,",
      "offset": 2283.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "prompts, and resources. Now, there are a",
      "offset": 2285.359,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "lot of different clients. We've talked",
      "offset": 2287.44,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "about a few so far, like cloud desktop",
      "offset": 2288.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and cursor and VS Code, but each of",
      "offset": 2290.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "these clients has varying levels of",
      "offset": 2293.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "support for all these features of MCP.",
      "offset": 2295.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "And so, there's actually a table on the",
      "offset": 2297.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "model context protocol website that",
      "offset": 2299.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "lists out all of the clients and says",
      "offset": 2301.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "what they actually support. Now, the",
      "offset": 2303.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "majority of clients support tool calls",
      "offset": 2305.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "like cloud desktop, cloud code, cursor,",
      "offset": 2308.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "VS code, all all of those that we're",
      "offset": 2310.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "mainly used to and a lot of these others",
      "offset": 2312.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "can make tool calls. But from there,",
      "offset": 2314.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it's kind of in up in the air of whether",
      "offset": 2317.28,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "or not they support it yet. And so",
      "offset": 2318.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "things like resources, prompts, uh",
      "offset": 2320.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "resource discovery, sampling, or roots",
      "offset": 2322,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "has limited support across all of these",
      "offset": 2324.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "clients. So your mileage may vary. Um",
      "offset": 2326.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "but I would check out this page to see",
      "offset": 2329.04,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "specifically what is supported. Now,",
      "offset": 2330.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "another MCP server I use is the Sentry",
      "offset": 2332.079,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "MCP. So every video you see here on the",
      "offset": 2334.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "syntax channel, every podcast episode,",
      "offset": 2337.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "everything we put out is brought to you",
      "offset": 2339.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "by Century and they allow you to",
      "offset": 2340.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "integrate all of the issues that are",
      "offset": 2343.359,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "reported in the cloud into your editor",
      "offset": 2346.56,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "directly using their MCP server. So you",
      "offset": 2348.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "can see here I'm logged into the Sentry",
      "offset": 2351.359,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "dashboard and we have all of these",
      "offset": 2352.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "ongoing issues. We can see when an issue",
      "offset": 2354.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "occurs. We can see what exactly the user",
      "offset": 2356.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "was doing when that issue happened. But",
      "offset": 2358.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "what's great about their MCP server is I",
      "offset": 2360.64,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "can have cursor open directly inside of",
      "offset": 2362.96,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "the site itself and then use the context",
      "offset": 2366.24,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "of those issues to help me solve and fix",
      "offset": 2368.8,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "some of them. So with the Sentry MCP",
      "offset": 2372.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "server installed and enabled, it's super",
      "offset": 2374.64,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "simple. You just point it at",
      "offset": 2376.64,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "mcp.entry.dev.",
      "offset": 2377.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Now whenever I'm in a chat session, I",
      "offset": 2379.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "can ask it for issues and also ask it",
      "offset": 2381.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "about specific issues. So for instance,",
      "offset": 2383.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "I can say list all the issues in the",
      "offset": 2385.44,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "century syntax project and it's going to",
      "offset": 2388.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "start calling those tools. And you can",
      "offset": 2391.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "see here it's calling the find projects",
      "offset": 2393.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "tool. And you can see that it figured",
      "offset": 2395.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "out via my prompt here that specifically",
      "offset": 2397.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "I need the organization called syntax-f.",
      "offset": 2400.32,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "So it's going to find all the projects.",
      "offset": 2403.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "It should find our website and then it's",
      "offset": 2405.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "going to list out all the issues. Now",
      "offset": 2407.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "this is great, but it's really no better",
      "offset": 2409.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "than just going to like century.io. One",
      "offset": 2410.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "of the cool things is we can start",
      "offset": 2413.359,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "working on a specific issue. So let's",
      "offset": 2414.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "say I grab the issue ID like this one.",
      "offset": 2416.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "So so this is returning an error when",
      "offset": 2418.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "someone attempts to make a post request",
      "offset": 2421.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "against this URL. And I think really",
      "offset": 2422.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "what we should be doing is just",
      "offset": 2424.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "returning a 404 because people shouldn't",
      "offset": 2426.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "be able to make post requests against",
      "offset": 2428.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "that endpoint. Uh so let's do this.",
      "offset": 2430.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Let's just say let's try and fix this.",
      "offset": 2432,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "We should just return a 404 instead. So",
      "offset": 2435.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "first of all, it's going to analyze this",
      "offset": 2439.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "issue using SEIR. So, Seir is actually",
      "offset": 2440.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "an AI debugger that Sentry makes",
      "offset": 2443.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "available and it can actually see all of",
      "offset": 2445.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the times that this issue has occurred.",
      "offset": 2448.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "It can see the source code and it has a",
      "offset": 2450.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "much better idea of how to fix it than",
      "offset": 2452.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "if cursor were to just try to go off and",
      "offset": 2454.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and try to fix this issue. So, Seir is",
      "offset": 2456.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "off running in the background and it",
      "offset": 2458.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "should potentially come back with some",
      "offset": 2460.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "fixes for us. So, we'll give it a second",
      "offset": 2462.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "and we'll see what it comes back with.",
      "offset": 2464.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "So you can see seer came back with an",
      "offset": 2465.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "analysis of what to do and now that's",
      "offset": 2468.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "being fed as context into cursor so that",
      "offset": 2470.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it can figure out what to update and in",
      "offset": 2473.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this case it's just adding a default 404",
      "offset": 2474.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "not found action to the specific route",
      "offset": 2477.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "but one thought I had is is this really",
      "offset": 2479.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the way to do this so we're going to add",
      "offset": 2481.119,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "further context and so I talked about",
      "offset": 2482.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "using context 7 earlier which basically",
      "offset": 2484.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "embeds docs as context so I said let's",
      "offset": 2487.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "check the docs for speltkit 5 and make",
      "offset": 2489.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "sure that the updated code is is correct",
      "offset": 2491.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "and doing the right thing. So, context 7",
      "offset": 2493.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "is now running and it's going to go off",
      "offset": 2495.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and get the docs for speltkit. And based",
      "offset": 2497.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "on getting the docs, it says this is the",
      "offset": 2500.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "right way to do it. But at this point,",
      "offset": 2502.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Sentry has done what it needs to do. So",
      "offset": 2504.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "from within the editor, I didn't even",
      "offset": 2506.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "have to go out to century.io. I was able",
      "offset": 2508.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "to list out the issues, target in on a",
      "offset": 2510.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "specific one, and then reach out to Seer",
      "offset": 2513.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "to automatically solve that issue,",
      "offset": 2515.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "integrate that context back into cursor,",
      "offset": 2517.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "and then instantly update the file. So",
      "offset": 2519.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "this is fantastic, right? Uh, basically",
      "offset": 2521.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "a user runs into some error on your",
      "offset": 2523.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "website and you can instantly get all",
      "offset": 2525.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the context you need to solve it right",
      "offset": 2527.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "from within your editor using the Sentry",
      "offset": 2529.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "MCP. If you want to try Centry out in",
      "offset": 2530.96,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "your own projects, head over to",
      "offset": 2532.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "centry.io/sax.",
      "offset": 2533.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Use code tasty treat. You'll get 2",
      "offset": 2535.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "months free. Thanks so much for",
      "offset": 2537.839,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "watching. If you have any resources for",
      "offset": 2539.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "MCP or servers that you like using, let",
      "offset": 2541.599,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "us know down in the comments because I'd",
      "offset": 2544.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "love to explore them as well. Also, if",
      "offset": 2546.319,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "there's more info that you think people",
      "offset": 2548.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "in the comments might need based on the",
      "offset": 2550.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "stuff that I talked about, let us know",
      "offset": 2552.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "as well. That's all I have for you in",
      "offset": 2553.76,
      "duration": 5.73
    },
    {
      "lang": "en",
      "text": "this one. I'll see you in the next one.",
      "offset": 2555.44,
      "duration": 13.88
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 2559.49,
      "duration": 9.83
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 2571.36,
      "duration": 3.069
    }
  ],
  "cleanText": "In this video, we're talking all about MCP, or Model Context Protocol. Talk about what it is, why it's needed, how to build your own servers, how to integrate with existing ones, how to debug them, and everything in between. That sounds good to you, let's dive in. My name is CJ. Welcome to Syntax.\n\n[Music]\n\nNow, before we talk about MCP, let's take a step back and just talk about how LLMs work. Now, if you're already familiar with all of this stuff, go ahead and skip ahead. You can see the timestamps in the description. But for all of this, including LLMs and MCP, we can think about things in terms of input, some process or blackbox, and some output. And the world of programming is like this as well. And a simple example of this is an add function. So add we can think of as our black box. Our inputs might be two numbers. So let's say we pass two and two into this add black box. And then the output of this would be four. Now add is predefined, right? We know how to add two numbers together. It's mathematical. We can basically take any two numbers and add them together. There's a very specific algorithm for doing that. We can also think of a black box that has a more interesting process. So for example, a text predictor. So let's say we have this black box called text predictor. It takes input which is text and spits out text as output. And one example might be if we pass in Mary had a little, we might expect that the text predictor responds with lamb. Uh because Mary had a little lamb is pretty common uh in the English language. Now, what actually happens inside of this text predictor, we don't know. Um we could come up with ways of creating a text predictor that isn't an LLM. We could come up with like a list of word pairings and say like 80% of the time when the words Mary and little appear in a sentence, lamb is likely the next word to occur. Like we could come up with our own algorithm for that. But LLMs are basically this with a much more complex process to come up with them. And it's not a specific algorithm. So the way we create an LLM is also through this input output process. So in this case the blackbox is training. The input is going to be some training data and the output is going to be the LLM itself. Now this training data in a lot of cases might be question answer pairs. So it might be a million different sets of questions and answers and we build out a neural network based on those questions and answers. And we built out this large language model that given some question will output a seemingly correct answer based on all of the data that it was trained on. But it's interesting to see that even the creation of an LLM is an input output process. Now once we have an LLM, it works exactly that way. So given some user input, it spits out some output and it actually is a text prediction model. So, as much as we might think that LLMs are smart or doing more than than what they actually are doing, for the most part, they're just predicting the next piece of text, the next token in any given sequence. And it actually turns out that if your training data is good enough and large enough and general enough, you actually can get an LLM that can work in most cases and seem like it's actually pretty smart to be able to uh answer questions or or give facts about certain things. Now, when you're interacting with an LLM in a tool like ChatGBT or Cloud Desktop or even like cursor ID or VS Code with GitHub Copilot, there's actually a lot more that goes into this user input that is eventually passed to that LLM. And it looks kind of like this. So, you typically have some kind of system prompt that you don't have access to, but the owners of this LLM service, whether it's OpenAI or Google or Anthropic, they've come up with some kind of system prompt that makes sure that the output it generates aligns with maybe their ideals. Maybe it adds some safety guards. Maybe it has a specific personality. And so this system prompt is going to to describe that. If you use a tool like chat GBT or cloud desktop, you know that sometimes it lets you save preferences like I want the LLM to always output the most succinct answer always or I don't want you to always agree with me. You should push back. So with tools like chat GBT and and cloud desktop, you add those in your user preferences and then those are sent along to the LLM in every single message that you send to it. The other aspect of this that gives us this answer response flow is your chat history is included in this when sending it to the LLM. And then finally, you have the actual user prompt. So that's the question you just asked or the follow-up question or whatever you just typed in, that's going to be the last thing included in what gets sent to the LLM. And so all of that gets wrapped up together, passed to the LLM, and then we get some output. In this case, it's going to be the response to the question or the follow-up that you just sent. Now the one thing to note about this whole process is this LLM is standalone. It doesn't have access to the internet or to the outside world. Basically it was trained once created and now all of your interactions with it are just with this black box. It has no way of of reaching out and getting new data. It's a snapshot in time based on all of the data that it was trained on. And when we interact with it, we're interacting with that snapshot. So there's no connection to the internet. Now, to get around this, we can actually insert another thing into this context that we're sending to the LLM along with the user's latest prompt. In this case, we'll send a list of available tools. And so, these are all things that the LLM could potentially invoke if it thinks it needs to perform an action or needs to go get more data. Essentially, every single call to the LLM, it knows what tools are available. An example of this might be let's say we have a tool available called get weather and we have another tool available called get coordinates and in this context window we say those two tools are available when you call them you specifically need to pass in latitude longitude to get the weather and then for the get coordinates tool you need to pass in a place name and so all of that information about those tools and how to call them is included here and let's say the user's prompt is what's the current weather in Denver Colorado part of the system prompt here is will say you can call these tools if you believe it has information that you might need. And so the LLM is going to think on this. It's going to see all of that context window. It's going to see the available tools. It's going to see the fact that it can call tools. It's going to see the user's input, which is what is the current weather in Denver, Colorado. And it might decide, hm, I know that I was trained on past data. The user wants very relevant, up-to-date information, and I have tools available that I can call. First, let's actually call the get coordinates tool because I want to be able to call the get weather tool, but I need some coordinates first. So it might actually output, hey, I would like to call the get coordinates tool for Denver, Colorado. And that's literally all it outputs. After that, it's done. But this output here says call this tool with the input Denver, Colorado. From there, the host application like chat GBT or cloud desktop or cursor. They will see that tool call and now they'll actually make the call. And so the tool itself can reach out to the internet. And the tool can be thought of as something that has inputs and outputs. And so in this case, the input is Denver, Colorado. The tool is get coordinates. It's going to call some web API that geoloccates things. So given the name of a place, it can come back with latitude longitude and its output are going to be the latitude longitude of Denver, Colorado. From there, we can now send all of that back into the LLM. So the tool output here will have the latitude longitude of Colorado. And in this case, the same user input of what is the current weather in Denver, Colorado. But now the LLM will potentially see, oh, uh, I have the coordinates and I want to know the weather. So maybe I'll make another tool call that will actually give me the weather based on some coordinates. So its output would actually be a tool call and then that will call the tool that will reach out to the API get the weather specifically for those coordinates and then all of that will again be included and finally the LLM will see okay I have the coordinates I have the weather forecast in my tool output and the user just asks what's the current weather in Denver Colorado. Okay, I think I can answer that question without calling any other tools. And then it will just answer the user to say what the weather is based on the the fact that it just got that weather forecast from that tool. And so when you're sitting at home talking to chat GPT or anything else, this process is just happening over and over and over. Every single time you send a new message in that chat window, this whole process is happening where if you have any tools available and you just ask the AI for something that it thinks it should invoke the tool for, it's going to invoke that tool. And then when the tool result comes back, that whole context of your conversation, the tool response, your latest question is all going to get passed back into the LLM. So it's this this loop where this context window here kind of just grows and grows as you chat with that LLM more and more. Now this is the current state of things.\nEssentially, if an LLM wants to have more up-to-date information, it needs to call these tools and all of the various tools like ChatGpt and Claude and VS Code and Cursor and all of these other things that can talk to LLMs have implemented a flow like this. Now, this is where MCP comes into play, which is the model context protocol because there's lots of different LLMs. There's lots of different clients that we can use to talk to LLMs and MCP was essentially an effort to standardize how these host applications and LLMs can talk to these various tools that are available. So, the model context protocol specification defines how an MCP client or host application can talk to an MCP server. talks about the kind of things an MCP server can expose like tools or prompts or resources and basically all of this is defined in a standardized way so that any application whether it's chat GPT or claude or cursor or VS code which in this case are going to be the MCP clients can all implement this way of talking to these servers and then regardless of who defined that server any one of these client applications can start to talk to it and this essentially opens up a whole world of connecting LLMs to the internet and data sources and all of the stuff that it doesn't have access to that is like the most up-to-date information or the most relevant information about a specific user or a specific company. Now these LLMs can get access to that information in a standardized way. Now I actually developed a tool for getting the weather based on a location and let's see it in action. So I'm just going to say what is the weather like right now? And because I set up Cloud Desktop with access to this MC MCP tool, you'll see that it first responds and says, &quot;I'd be happy to help you check the current weather to get accurate weather information for your area.&quot; I'll need to know your location. Could you tell me what city, state, or country you're in? So, because I made these tools available, Cloud Desktop sees, okay, I have a tool I can call, which is get weather, but that requires coordinates. Coordinates require location. So, the user asks me a very general question. I need to know where they are. So, I'm going to tell them, hey, I'm in Denver, Colorado. And we should see now that it has the context it needs, it's going to make a request out to the tool that I set up. So I have this tool available called get coordinates. And I'm just going to click allow once. And you can see that it called that tool with the place Denver, Colorado. And then from there, it got the coordinates. Now it can call get weather and pass those in. So you can see that these client applications can call multiple tools back to back and they can feed information from one tool called to another. So in this case, got the coordinates. It's going to pass that to get weather. And now we can say the current weather in Denver, Colorado is looking quite nice. It's 79° Fahrenheit, mostly clear skies, humidity of 43%, etc. So each of these actually reached out to my tool, my tool called various APIs to get that data. All of that was put into the context and now Claude has everything it needs to answer in a grounded way than not hallucinate about what the current weather is. And you can see for get coordinates, my tool literally just responds with some JSON data. So I'm using the nomenatim API which is from open street map. Basically given a place it'll give you back a list of place results that include latitude and longitude. So that's one tool call and it responded with that. And then get weather. I'm actually using the pirate weather API and it accepts latitude longitude. There's several different types you can pass in like do you want the current weather, the daily forecast, the hourly forecast, the minutely forecast and you can also pass in units. You can see this responded with Fahrenheit because I'm in the US and that's what we use. But it also accepts other units like SI and it would respond in Celsius. And then you can see the actual response is just this JSON object that has the current forecast for Denver. And this is the data we got back from the pirate weather API. So you can see how basically making these tools available to a client application allows it to be grounded in the current time and place and what the user is talking about and not just hallucinate things. Now reading this model context protocol spec can be a little bit dense at times. But I want to reassure you that creating tools and MCP servers is fairly easy especially if you just use their SDK. And so you can see here that there's SDKs for many different languages. I specifically work in the world of JavaScript and TypeScript. So I just use the TypeScript SDK. And even just looking at their readme, you can see how easy it is to set up these MCP servers. And so this defines a server. You register some tools. You define what that tool takes in as input. And then you have a function that will get called whenever that tool is invoked. And this function can do anything. It can talk to an API. It can talk to a database.\n\n\nAnd so it's this easy to create tools.\nAnd then what gets a little bit trickier is how you actually expose these MCP servers.\nAnd so in the default example here, it's just using the standard IO server.\nAnd that means that this tool whenever it's called is just running directly on your machine.\nThere is a way for you to define a remote server.\nSo that is an MCP server hosted in the cloud, and then anytime a host application wants to invoke those tools, it will actually make requests to your deployed server.\nThat gets a little bit trickier because you do need to know how to deploy that and potentially set things up with server sent events or with streaming HTTP.\nBut again, there are SDKs that make that much simpler.\nSo, aside from all of the spec and protocol descriptions and everything else that gets into the nitty-gritty, at the end of the day, as someone making MCP servers, really all you have to do is learn about the specific SDK for the language that you're familiar with and then also learn a little bit about the SDKs that have been defined to help you set up a remote server if that's the path you want to go down for your MCP server.\nNow, let's see my specific weather tool to see how I set all of this up.\nThe codes itself are fairly simple.\nI just have an entry point which actually creates the MCP server.\nAnd from here we register all of the available tools and then expose it over standard io.\nAnd then to register a tool you pass in a name.\nIn this case the name of the tool is get coordinates.\nYou can give it a title and then a description.\nNow I found with the description you can kind of give some hints as to when the host application should call this tool.\nSo here we have get the coordinates of a given place typically the user's location.\nIf you don't know the user's location, ask them for it before calling this tool.\nAnd so we saw that happen inside of Cloud Desktop.\nIt was like, \"Wait, I want to call that tool, but where are you?\"\nI said Denver, Colorado.\nAnd then it was able to call this tool and it passed in an input.\nAnd so for tool, you can define the input schema.\nAnd this is what data needs to be passed to this tool.\nNow, in this case, we're using zod to say that when you call this tool, you'll pass in place and place is a string.\nYou can see in the description, I also provided some examples of places so that way the LLM could potentially even reformat the user's input to look more like what we're expecting.\nAnd then that's what's going to be passed in here.\nSo all of this is the setup.\nIt's the tool name, the description.\nBasically, this is what is going to be exposed to the LLM in any prompt that a user types in to let them know that this tool is available.\nAnd then we can pass in a callback function.\nAnd this callback function is going to get access to that input.\nSo you can see here that it exactly corresponds to the input schema.\nAnd so when the LLM calls this tool, it's going to pass in a place and it figures out what that is, right?\nBased on the user's prompt or their text or their input, it's going to figure out what to pass into our function here.\nAnd from there, we can do the work.\nIn this case, I'm calling an API.\nSo like I mentioned earlier, we're just calling the Nanatim Open Street Map API.\nIt accepts a place name, responds with JSON, and in this case, I'm just sending the response exactly back.\nNow, depending on the tool that you're building, instead of just sending back JSON data, you could reformat this as like markdown.\nBut for these purposes, the LLM is actually really good at just parsing that JSON data that it gets back and it's able to use that in further tool calls.\nSo, we literally just stringify that data we got back from the place search API.\nAnd so then the LM can now use that coordinate data as further context for other prompts or in this case tool calls.\nBecause we saw earlier after it got the coordinates, then it called the get weather endpoint.\nAnd so similar idea, we give it a tool name.\nWe give it a title.\nAnd for the description, I also give it some hints that say if you don't have the latitude and longitude, you can use the get coordinates tool to get them.\nSo I'm basically letting it know, hey, call this other tool if you want to call this tool.\nAnd then this also accepts in the type.\nSo you can ask for multiple.\nSo you can ask for the current weather, hourly, daily, or minutely.\nAnd it can be any combination of these.\nAnd then you also pass in the units.\nNow in this case, when it called the tool, it probably inferred that my local was English.\nAnd so it just passed in the units as US.\nBut you can see here on input, we're going to get access to the latitude, longitude, what types of weather they're asking for, and then the units that we should respond with.\nAnd then again, we just call an API.\nSo if you look at my get weather function, I'm specifically talking to pirate weather.\nI have an API key set up.\nSo that gets passed in.\nWe pass in the latitude, longitude, and units.\nAnd then we get back the data.\nAnd then from there, whatever the LLM asks for.\nSo if it wanted current, hourly, daily or minute or any combination of those, we include that in the response and then again just respond with the JSON which gets stringified.\nSo these are fairly simple tools and when you're first getting started out with MCP, this is kind of the way you can think about things.\nThey're really just guided API connectors, right?\nUm they can get much more complex than this and of course you could have a function that itself calls multiple APIs and gathers data for multiple services but on the service level and when you're just getting started this is one way to think about how to build out these tools which is define how the LLM can structure data to call this API and then you write the code to actually call that API now the next thing is how is this thing actually running so here we're using the standard IO server transport you can see we're just importing that in from the SDK and then we're starting the server up Now when we configure this inside of cloud desktop we actually just tell it that it should start this by running this TypeScript file with Node.js.\nSo in cloud desktop if you press command comma and you head to your developer settings you can see that I have a couple of tools set up.\nAnd if you click on edit config that will actually show you where on your computer is that config file so that you can set all of these things up.\nAnd so if I open this JSON file with cursor, you can see first of all it has an MCP servers section.\nAnd then inside of there, we can set up each of our MCP servers.\nAnd for the git weather server, I tell it that the command it needs to use is node.\nNow, usually you can just specify node right here or python or however you typically would run your program, but in my case, I wanted it to use a specific version of node and I use NVM.\nSo I gave it the full path to that executable.\nSo essentially when cloud desktop wants to start up this server, it's going to use this node command and then it's going to pass in the argument of the file that it needs to run.\nAnd so whenever cloud desktop starts up, it literally runs Node.js with this file and that's just running as a background process that's going to be able to output data over standard IO.\nI also gave it the current working directory because this needs an API key, but ended up actually just having to specify my API key directly.\nSo for any MCP server that you're setting up in this way, you can also pass in environment variables.\nAnd in this case, I pass in my pirate weather API key.\nAnd when it's running this program, it'll have access to that environment variable.\nSo right now, this is somewhat manual and cumbersome.\nUh but I'm okay with this because I'm a developer.\nI know how to work inside of JSON files.\nUm and for the servers that I develop, I'm very likely just going to set them up this way, especially if I only need to access them on my computer.\nNow, another way you might set up or configure tools is to just use npx.\nSo if these are published to npm, you can actually just specify the name of an npm package and this will run it without having to manually point it to a directory or anything like that.\nSo this is another way of of getting MCP servers set up is you can just pull them directly from npm.\nSimilarly, if you find one on GitHub and you want to run it locally, you could clone it down into a folder and then set it up in a similar way to what I'm doing here.\nBut basically whenever cloud desktop starts up, it sees that these MCP servers need to be run and it will actually spin up these terminals in the background and then write to standard in and read from standard out in order to communicate with this process that's running.\nAnd so this is the the simplest form of MCP.\nThese are running directly on my machine.\nThat's the other thing to keep in mind here is when I prompt Claude that actually goes off to Anthropic and talks to their APIs and which interfaces with their LLM with which makes this response here.\nBut when it needs to call tools, if they're just set up as local tools, it's literally just talking to a process that's running on my machine.\nBut there are other types of tools that can actually be exposed over the web.\nAnd one example of this is the currency conversion Model Context Protocol server that Wesboss wrote.\nAnd his code is completely open source.\nIt's on GitHub.\nAnd in order to talk to it, he actually has a hosted server at currency-mcp.westboss.com.\nAnd so if anyone wants to add this, it's actually much easier.\nYou can actually just point it directly at his hosted server.\nSo, let me do this right now.\nI'm going to add it to my Cloud Desktop config.\nAnd typically, I've found I need to completely restart Cloud Desktop to make sure that it picks up all of those changes.\nNow, I tried just using these settings exactly for Cloud Desktop, but I ran into a bunch of issues, but I did find this gist which talks about how to use Cloud MCP with NVM, which is a node version manager.\nAnd so they have a few different things you can do with your shell configuration to make sure that this works.\nSo I got all of that working and I created a special command called PNPM for cloud.\nSo this specifically chooses the right version and then here we're using DLX and it can then run this MCP remote command with that server URL.\nSo with all of that now cloud desktop has the tool and I can say something like convert 25 USD to yen.\nOf course, you can see Cloud Desktop figured out, hey, I need to call that tool.\nSo, we're going to allow it.\nIt calls Wes's tool, which actually reaches out over the web to his deployed server, gives back a response.\nYou can see that he's just responding with some JSON data here, and then it's able to say, \"Hey, 25 USD is about 3600 Japanese yen.\"\nNow, I'll link all of the resources I found for setting up these remote servers inside of Cloud Desktop.\nBut one of the things to note here is this MCP remote tool.\nSo this is just a tool that lives on npm.\nAnd essentially you can take any remote server and turn it into a local server.\nAnd right now this is what's needed if you want to do this more developeresque setup of there's a server somewhere.\nMaybe you're working with a tool that doesn't support remote URLs.\nMCP remote basically turns it into a standard IO tool.\nBut let's take a look at the actual code that Wes had to write to make this a remotely deployed server.\nSo if you look in the entry point file here, he's actually using MCP agent which comes from the Cloudflare agents SDK.\nSo his server is actually deployed to Cloudflare that makes these tools available over the web.\nNow the code for initializing a server is very similar to our standard IO server.\nYou can see here that they register tools, they create an instance of the server, but then specifically in order to expose it over the web, this Cloudflare worker whenever it receives an incoming request can connect to that client, whether it was coming over server sentent events or just over the HTTP protocol and then respond accordingly.\nBut all of the nitty-gritty details of talking over that protocol are handled by the SDK.\nAnd so that's really another takeaway from developing these tools.\nWe're kind of at a point where you don't really have to worry about the specifics of the protocol as long as you're using an SDK.\nWriting the tools themselves is fairly simple.\nYou can see Wes is just calling out to some APIs given the input and just registering these tools here.\nBut then all of the protocol stuff is handled by the SDK itself.\nAnd this is one thing to think about if you are going to be creating a remote MCP server for people to use.\nYou're going to be paying for that server bandwidth, right?\nSo Wes absolutely is paying the monthly bill for this on Cloudflare to run these commands in the cloud.\nNow for some users it's easier to set up because they don't have to like download the whole repo and like host it locally.\nUm and this is probably the way you want to go especially if you maybe have some secret sauce that you don't want to just expose in the tool directly, right?\nBecause if people are just cloning down your repo, they have access to all of the tools source code.\nBut if you're hosting it in the cloud, anything that happens whenever a tool is called could do much more secret things, right?\nIt could talk to a database that maybe you don't want to expose the the password for or whatever else.\nBut in this case, Wes is just reaching out to a third party API.\nNothing crazy, but you could follow this format if you want to kind of hide what's happening in the tool call and not just have it run on the user's local machine.\nNow, when you're building out your MCP server locally, you're going to want to test it somehow, and it's pretty cumbersome to restart your client every single time you make changes to your server to see it in action.\nAnd this is where the model context protocol inspector can help you out.\nSo essentially you can run this command in the folder where you're developing your tool and it will give you a web dashboard where you can actually invoke your tools with various arguments.\nSo for instance I have this other tool which I've been working on which gets web search results from duck.go.\nBut if I want to run this and debug it, I can do npx model context protocol/insspector node and then the name of the file.\nNow, this will just spin up a local server.\nIf I head to that URL, I get a nice little dashboard and then I can connect to the server.\nAnd this is just essentially connecting to it\n\n\nvia standard IO.\n\nSo, it's spinning up that process in the background. And now all of the things that a client application like cursor or cloud desktop would do to interact with that tool, we can do from this web dashboard. So, for one, we can list the available tools. And you can see that I have two tools: I have list search results and get URL contents. So for instance, I can call list search results, pass in a search term, and this is going to search duck.go. So let's search for reverse string in JavaScript. This will run my tool. And you can see my tool responds with those search results that came back from duck.go. And so as you're building out these tools, this is going to be one of the easiest ways to make sure that your tools are outputting what's expected and test them with various types of input as well.\n\nNow, another tool I made available is called get URL contents. And so this essentially just takes in a URL, fetches that page, converts it to markdown, and then responds with the markdown and some metadata about the page. So you can see if I pass this Geeks forge Geeks URL into my tool, it actually pulls back the description of the page and then all of the content of the page as markdown. And then this could further be used as context whenever an LLM is trying to respond to a user's question.\n\nNow, if your tool isn't a standard IO tool, they do support testing out SSE servers or streaming HTTP. So, even if you're running them locally, you can connect here and do things like list tools and make tool calls. And so, like I said, this is great for testing things out before you actually add them into any host application.\n\nNow, after debugging that tool, I can use it, for instance, inside of Cloud. And personally, I've been liking using my integration instead of using the built-in web one because it's smart enough to basically choose which of the pages it wants to get the source for and and it's a whole lot faster. So, for instance, if I say search the web or how to reverse a string in JavaScript, it should call my web search tool. So, it's going to list those duck.go search results. I'm going to always allow it. How to reverse a string JavaScript methods. And then you can see that it got the list of results, but it's like, all right, I need more detailed information. And so now it's specifically going to make a request for one of those search results. And so typically this is actually the kind of question that LLMs are good at answering without tools. But this now grounds its answer in relevant results that it retrieved from the web.\n\nLike let's try another prompt like um what are the most foundational novels in science fiction? What authors are important, compare some of the top stories, and make a ranking of what I should read. So, it didn't immediately reach for a tool, but I can further tell it to uh search the web to confirm your findings. And now, it's going off and and doing the work. So, you can see that it got back the search results for most important foundational science fiction novels, essential reading list. And then from that set of results, it's now going off and getting the full page for each of the ones that it thinks is important. Um, and you can see that it's searching the web even more. So, it did another search for golden age science fiction, uh, Ozamov and Clark, science fiction, golden age, big three. So, it came up with all these different search terms to send off to the, uh, search engine, and we can see that happening in real time. So based on my web search, I can confirm that my original assessment aligns with established lit literary opinions. Fascinating.\n\nSo this potentially is what this built-in web search tool is doing. But I like how transparent uh this tool is because you can actually see the various search terms that it used and then also the specific pages that it went off and and got to confirm its own findings.\n\nNow, before you go off and start developing your own MCP servers, there is this list called awesome MCP servers that has a ton of existing servers that people have implemented that you can try adding to your client applications that you're using. Um, or take a look at the source code to get inspiration for your own MCP servers. And that's actually what I did before I started building out my own. I I kind of looked to see how people were implementing theirs. But this list has all kinds of MCP servers that are worth exploring.\n\nI'm going to show you a couple that I've been using that I found very useful. And let me know down in the comments as well if there are some MCP servers that you can't live without. So this is the main idea with MCP. Basically, you have a client application. It can call these tools. To write the tools is fairly simple, especially if you're using these SDKs and then they have some kind of transport protocol. The easiest one is that tool is running locally, just spinning it out over standard IO. It's a little bit more complex if you wanted to communicate over the web with either server events or HTTP.\n\nNow, I've been using Cloud Desktop for all of the examples I'm showing you so far. But you can set up these tools inside of a lot of other places. So, specifically, if you're inside of the cursor IDE and you press command shift P, you can look for MCP settings. And this is where you can set up all of your MCP servers. Now, within cursor, if you want to add or modify servers, you can click the edit button on any one of these, and it will open up a very similar JSON file that we saw for cloud desktop and can add each of these MCP servers that you want to enable.\n\nNow, one of the publicly available MCP servers I highly recommend you add to cursor is called context 7. And this is an MCP server that has a tool which can retrieve documentation for many many different libraries or frameworks. You can see on the homepage some of the most popular ones that are available. And so essentially what they've done is they've indexed the documentation for all of these things. And if you're ever asking cursor to do something and it needs more context about what you're working in or what library you're using, it can use this tool to retrieve the specific parts of the documentation that might help with that.\n\nNow, to see context 7 in action, I actually used it to help me write the code to talk to the pirate weather API. And so, if we open up a new chat window here, and I say, uh, call the pirate weather API. The last time I did this, it was like, I have no idea what the pirate weather API is, so I can't help you with that. But let's see. Let's see what it outputs this time. Yeah, you can see cursor is trying it's trying to find the context. It's like, uh, what is that? What is that? Um, so yeah, there are no references to the pirate API. Uh, the typical endpoint is this URL. Uh, I have a feeling it figured that out because of the current context because I like deleted the code that that already talks to it. But check this out. Let's start a brand new chat window and let's say uh get the docs for the pirate weather API. You'll see that it actually makes a tool call to resolve library ID. And so this is a tool that is available via context 7. And so it's going to find the library ID for the pirate weather API. And then it's going to get the specific docs for pirate weather. And then this just gives me the base documentation. Um, now I haven't worked with this a ton, so this is kind of how I found it useful. Essentially, this kind of primes the chat window here to know that it has this documentation available. And so now if I ask it to call the API, it might even further query their docs to find the specific part that it needs. So let's ask it now. So let's say uh call the pirate weather API with the included options. And with that, it was able to actually know the exact endpoint it could call. And also given the docs, it knows that it can pass those units in via query params in the URL. So this is just one example of using context 7. If you're working with any library or anything else, you can do the exact same thing where in a chat window you say, \"Hey, give me the docs.\" It adds it to the context and then also it didn't happen this time, but potentially also it will make further calls to get other parts of the documentation because you can see in context 7 some of these docs are hundreds of thousands of tokens, but their API essentially allows you to add like a search term and then also set the number of tokens that should be returned. And so their tool is smart enough to only give the right amount of context to still keep the token window open to still leave enough room in the token window so that the LLM can actually respond. Um so yeah, Context 7 is an awesome tool. I definitely recommend you install it in cursor if you haven't yet.\n\nNow speaking of other clients, you can also add MCP servers into VS Code. So, inside of VS Code, if you press command shiftp and do mcplist servers, one of the cool things about VS Code is it will detect if you have cloud desktop installed or cursor installed, and you can see that it's actually allowing me to connect to any of these MCP servers that are actually configured inside of those other tools. Uh, so if I want to get access to contact 7, I don't even have to further configure it. I can just say, hey, start that server. And now inside of VS Code, I have access to that tool and it's nice and configured. So if we open up a chat window and say uh get the docs for hono, you can see that it's making a tool call. It's going to reach out and find the ID for the hono docs and then actually grab those docs. So that's just like the main documentation. And then let's say you're trying to do something more niche. You could say something like how do I add the corors module in a hono app? Now it was able to oneshot that. Let's come up with something that maybe is not at the top level of the docs. Let's just say uh how can I set up open API with my Hono app. It's oneshotting everything. But honestly, this is kind of amazing because all of my other experiences uh trying to use like Hono isn't that new, but it's not as popular. So, pretty often LLM can't get it right. But this is just getting it right. So, I have to keep working with this. All I know is that this is making my life a whole lot easier. and the LLM makes up stuff a whole lot less because it's actually grounded in the documentation.\n\nNow, another spot you can set up MCP servers is inside of the Gemini CLI. And so, if you're not paying for Cloud Desktop or Cursor, Gemini CLI does have a free tier. And also, VS Code with the Copilot extension has a free tier. So, you can get started testing out these tools and using them with either of these things, at least for now, while they still have a free tier. But once you've installed the Gemini CLI, you can actually create a Gemini folder inside of your repo and inside of there you can set up a settings.json file and it's exactly the same as this settings file that we've set up for cursor and VS Code and Cloud Desktop. Essentially, you have an MCP server section. Specify the servers you want and then you tell it how they should run. And so this is another MCP server I wrote called Denver events that calls a few different APIs to figure out what's happening in Denver today. and let's see if I can get it to call those tools using the Gemini CLI. So, it's up and running. I'm gonna ask it, is there a Rocky's game today? This is typically something we want to know living in Denver because either you want to go to the game or you want to know that there's going to be some traffic because the game is happening. Um, and you can see that it detected that I have specifically a tool called list Rocky's home games. And I'll say yes, allow that tool to run. It spits back all the upcoming home games for the Rockies and then uh Gemini is able to respond to say no, the Rockies are not playing today, but they have a home game tomorrow, July 1st, against the Houston Astros at 6:40 p.m. And so the Gemini CLI is typically for working with a code base. But as you can see, it's can still call tools that have nothing to do with code. And really, this is just another example of a different client being able to call these custom tools that I created.\n\nNow, this Denver events MCP server, I think is a good example of getting specific data that technically you could get via just a web search, but it's more targeted, right? So, specifically get Rocky's home games or specifically get all the events happening at the Mile High Stadium, which is where the Broncos play, or specifically get events happening at Ball Arena. Now, you might have used ChatGpt or Cloud Desktop, and every now and then when you type something in, it'll actually search the web, and it could potentially answer some of these questions, but this is specific data about these things that's going to allow it to have just slightly more context when it's answering these types of questions about the the Denver area. And really, the main thing I want to point out about these tools I created is I kind of just found some undocumented APIs and then did just a little bit of scraping. So specifically, if you look at the list Rocky's game, I found this mlb.com endpoint just by looking at the network traffic. And I'm actually able to directly get back JSON data that has the schedule. And you'll notice that I'm I'm not spinning up a web browser to navigate to this page and get the contents and everything else. So this is a whole lot faster to get back that relevant information than trying to search the web or go directly to a website. And I did the same thing with ballerina. I was looking at the network tab. I found that they had an undocumented endpoint. I'm making the request against there. And same thing with my high stadium. They actually have some endpoints that return some JSON data. So this is really just an example of you may not necessarily need to spin up a browser or need to do any sort of scraping. If you can find some undocumented endpoints, you can turn those into tools as well.\n\nNow we mentioned that these MCP servers can expose several different things: tools, prompts, and resources. Now, there are a lot of different clients. We've talked about a few so far, like cloud desktop and cursor and VS Code, but each of these clients has varying levels of support for all these features of MCP. And so, there's actually a table on the model\n\n\nModel Context Protocol website that lists out all of the clients and says what they actually support.\nNow, the majority of clients support tool calls like cloud desktop, cloud code, cursor, VS Code, all of those that we're mainly used to, and a lot of these others can make tool calls.\nBut from there, it's kind of up in the air of whether or not they support it yet.\nAnd so things like resources, prompts, uh resource discovery, sampling, or roots has limited support across all of these clients.\nSo your mileage may vary.\nUm, but I would check out this page to see specifically what is supported.\nNow, another MCP server I use is the Sentry MCP.\nSo every video you see here on the syntax channel, every podcast episode, everything we put out is brought to you by Sentry, and they allow you to integrate all of the issues that are reported in the cloud into your editor directly using their MCP server.\nSo you can see here I'm logged into the Sentry dashboard, and we have all of these ongoing issues.\nWe can see when an issue occurs.\nWe can see what exactly the user was doing when that issue happened.\nBut what's great about their MCP server is I can have cursor open directly inside of the site itself and then use the context of those issues to help me solve and fix some of them.\nSo with the Sentry MCP server installed and enabled, it's super simple.\nYou just point it at mcp.entry.dev.\nNow whenever I'm in a chat session, I can ask it for issues and also ask it about specific issues.\nSo for instance, I can say list all the issues in the Sentry syntax project, and it's going to start calling those tools.\nAnd you can see here it's calling the find projects tool.\nAnd you can see that it figured out via my prompt here that specifically I need the organization called syntax-f.\nSo it's going to find all the projects.\nIt should find our website, and then it's going to list out all the issues.\nNow this is great, but it's really no better than just going to like Sentry.io.\nOne of the cool things is we can start working on a specific issue.\nSo let's say I grab the issue ID like this one.\nSo so this is returning an error when someone attempts to make a post request against this URL.\nAnd I think really what we should be doing is just returning a 404 because people shouldn't be able to make post requests against that endpoint.\nUh so let's do this.\nLet's just say let's try and fix this.\nWe should just return a 404 instead.\nSo first of all, it's going to analyze this issue using SEIR.\nSo, Seir is actually an AI debugger that Sentry makes available, and it can actually see all of the times that this issue has occurred.\nIt can see the source code, and it has a much better idea of how to fix it than if cursor were to just try to go off and and try to fix this issue.\nSo, Seir is off running in the background, and it should potentially come back with some fixes for us.\nSo, we'll give it a second and we'll see what it comes back with.\nSo you can see seer came back with an analysis of what to do, and now that's being fed as context into cursor so that it can figure out what to update, and in this case it's just adding a default 404 not found action to the specific route.\nBut one thought I had is is this really the way to do this?\nSo we're going to add further context, and so I talked about using context7 earlier, which basically embeds docs as context, so I said let's check the docs for speltkit 5 and make sure that the updated code is is correct and doing the right thing.\nSo, context7 is now running, and it's going to go off and get the docs for speltkit.\nAnd based on getting the docs, it says this is the right way to do it.\nBut at this point, Sentry has done what it needs to do.\nSo from within the editor, I didn't even have to go out to Sentry.io.\nI was able to list out the issues, target in on a specific one, and then reach out to Seer to automatically solve that issue, integrate that context back into cursor, and then instantly update the file.\nSo this is fantastic, right?\nUh, basically a user runs into some error on your website, and you can instantly get all the context you need to solve it right from within your editor using the Sentry MCP.\nIf you want to try Sentry out in your own projects, head over to sentry.io/sax.\nUse code tasty treat.\nYou'll get 2 months free.\nThanks so much for watching.\nIf you have any resources for MCP or servers that you like using, let us know down in the comments because I'd love to explore them as well.\nAlso, if there's more info that you think people in the comments might need based on the stuff that I talked about, let us know as well.\nThat's all I have for you in this one.\nI'll see you in the next one.\n[Music]\n[Music]\n",
  "dumpedAt": "2025-07-21T18:43:26.256Z"
}