{
  "episodeId": "-4jxZQix5Z0",
  "channelSlug": "@aidailybrief",
  "title": "What's the Bigger Deal for AI: 3 Pro or o3 80% Price Drop?",
  "publishedAt": "2025-06-11T22:08:41.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Welcome back to the AI daily brief. Boy,",
      "offset": 0.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you know that you are owning a news",
      "offset": 2.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "cycle when the title of the podcast is",
      "offset": 4.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "which of your two announcements was the",
      "offset": 6.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "bigger deal. Yesterday, I tweeted an 03",
      "offset": 8.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Pro that's more agentically capable, an",
      "offset": 11.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "80% cost reduction in existing 03, a",
      "offset": 13.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "massive acquisition light that could",
      "offset": 16,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "reshape competitive dynamics regarding",
      "offset": 17.359,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "data, multiple multi-billion dollar",
      "offset": 19.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "fundraises, a viral singularity",
      "offset": 21.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "prognostication, and a huge debate on",
      "offset": 22.88,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "reasoning. And it's barely Wednesday.",
      "offset": 24.72,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "Yes, of course. Based on the inscrutable",
      "offset": 27.439,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and immutable laws of the universe, when",
      "offset": 29.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "I am traveling, it has to be the biggest",
      "offset": 31.039,
      "duration": 4.001
    },
    {
      "lang": "en",
      "text": "week at AI we've had in some time.",
      "offset": 32.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Luckily for all of us, I've got all the",
      "offset": 35.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "equipment on the road, and we are going",
      "offset": 36.8,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "to dig into this. In a surprise",
      "offset": 38.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "announcement yesterday, Sam Alman",
      "offset": 40.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "tweeted, &quot;We dropped the price of 03 by",
      "offset": 41.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "80%. Excited to see what people will do",
      "offset": 43.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "with it now. Think you'll also be happy",
      "offset": 45.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "with 03 Pro pricing for the",
      "offset": 47.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "performance?&quot; A couple of hours later,",
      "offset": 49.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the official OpenAI account confirmed",
      "offset": 51.52,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "OpenAI 03 Pro today. And so these are of",
      "offset": 53.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "course the two big stories that we're",
      "offset": 56.719,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "going to focus on in this main episode.",
      "offset": 57.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "A highly performant new model that",
      "offset": 59.76,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "spoiler alert seems even more tuned for",
      "offset": 61.68,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the agentic era that we're moving into",
      "offset": 64.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "and a massive cost reduction that could",
      "offset": 66.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "have significant implications for what",
      "offset": 68.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "people build. So let's talk first about",
      "offset": 70.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "this price reduction. Chubby",
      "offset": 73.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "atkimenismus summed up many people's",
      "offset": 75.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "feelings when they tweeted this is the",
      "offset": 77.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "real revolution with a chart of the 87%",
      "offset": 79.04,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "price reduction between 03 Pro and 01",
      "offset": 82.32,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "Pro. Now keep in mind this is not even",
      "offset": 85.119,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the 80% reduction that we were talking",
      "offset": 87.439,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "about with 03. This is just the base",
      "offset": 89.439,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "cost of 03 Pro as it came out as",
      "offset": 91.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "compared to where 01 Pro was just a few",
      "offset": 93.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "months ago. But in terms of that big 03",
      "offset": 96.079,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "price drop, many people could hardly",
      "offset": 99.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "believe it. Now, the specifics here were",
      "offset": 101.439,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "that it went from $40 per million output",
      "offset": 103.36,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "tokens to just $8. And on top of that,",
      "offset": 105.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "they also announced that they were going",
      "offset": 108.399,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "to double the rate limits for 03 for",
      "offset": 109.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "plus users. Now, this led many to assume",
      "offset": 111.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "that this must be a distilled version of",
      "offset": 114.64,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "the model. Not so, said Adam, who does",
      "offset": 116.72,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "go to market at OpenAI. He tweeted in",
      "offset": 119.439,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "response, &quot;It's not distilled, same",
      "offset": 121.759,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "model.&quot; When someone said, &quot;Is it",
      "offset": 123.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "quantized though?&quot; Adam responded, &quot;It's",
      "offset": 125.84,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "the same model, full stop.&quot; And when",
      "offset": 128,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "someone asked then how was it done? Were",
      "offset": 130.239,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "there major improvements on the software",
      "offset": 132,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "side of things? Is this because of",
      "offset": 133.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "increased resources or did nothing",
      "offset": 134.959,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "change and you can just incur the cost",
      "offset": 136.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "now? Adam responded to that one as my",
      "offset": 138.239,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "teenage daughters would say the",
      "offset": 141.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "inference engineers ate basically then",
      "offset": 142.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "it seems like these are actual",
      "offset": 145.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "efficiency gains not just competitive",
      "offset": 147.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "pressure in a bigger balance sheet.",
      "offset": 149.84,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "You'll remember that OpenAI also has",
      "offset": 151.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "jumped from 5.5 billion in at the end of",
      "offset": 153.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "last year all the way to 10 billion now.",
      "offset": 155.599,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "Now, the claim here at least is that",
      "offset": 157.599,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "this is actual technical improvement.",
      "offset": 159.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "What's more, OpenAI researcher Nome",
      "offset": 161.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Brown reinforced that businesses need to",
      "offset": 163.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "be skating to where the puck is going in",
      "offset": 165.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "terms of cost, posting, &quot;Input is now $2",
      "offset": 167.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "per 1 million and output is now $8 per 1",
      "offset": 170,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "million. The cost versus intelligence",
      "offset": 172.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "curve will continue to improve rapidly.&quot;",
      "offset": 174.48,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Some people though, despite the",
      "offset": 177.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "protestations of OpenAI staffers, think",
      "offset": 178.959,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "that this is at least a little bit about",
      "offset": 181.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "competitive pressure. Lan Algaby, who",
      "offset": 183.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "featured prominently in our breakdown of",
      "offset": 185.28,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "the Apple intelligence report from",
      "offset": 186.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "yesterday, tweeted, &quot;Gemini 2.5 Pro and",
      "offset": 188.319,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "Sonnet might actually be forcing OpenAI",
      "offset": 191.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to lower their ridiculous 03 prices.&quot;",
      "offset": 193.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "However, others were just excited. Edwin",
      "offset": 195.84,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Arvis writes, &quot;Oh is 20% cheaper than",
      "offset": 198,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "GPT40, rethink everything.&quot; Bindu Ready",
      "offset": 200.319,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "celebrated the competition, saying, &quot;Oh",
      "offset": 203.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "price just dropped by 80%. This makes it",
      "offset": 206.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "less expensive than Sonnet 4. Finally,",
      "offset": 208.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "we have choice.&quot; Now, not to be petty",
      "offset": 210.799,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "here, but I do for just one moment want",
      "offset": 213.599,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "to bring things back to almost exactly a",
      "offset": 215.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "year ago. You might remember that as",
      "offset": 217.84,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "summer was taking hold in 2024, people",
      "offset": 219.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "were getting a little bit bored, and we",
      "offset": 221.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "had a whole slate of articles that",
      "offset": 223.84,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "wanted to discuss how AI was never going",
      "offset": 225.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "to pay back the big investment that was",
      "offset": 227.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "going on in it. Now, some part of that",
      "offset": 229.28,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "conversation was capex and Wall Street",
      "offset": 231.2,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "valuations, all things that I said were",
      "offset": 232.959,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "firmly in the realm of investors to",
      "offset": 234.879,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "decide how they should value things. But",
      "offset": 237.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you might remember that there was one",
      "offset": 239.439,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "part of a Goldman Sachs report that",
      "offset": 240.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "really ground my gears. The report was",
      "offset": 242.56,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "called Genai, too much spend, too little",
      "offset": 244.959,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "benefit. And while if you go back and",
      "offset": 246.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "listen to the show, I'm actually arguing",
      "offset": 248.959,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "that the report is not nearly as",
      "offset": 250.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "negative as the title suggests, one",
      "offset": 251.92,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "person who was very negative was Goldman",
      "offset": 254.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Sachs head of global equity research,",
      "offset": 256.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "Jim Cavllo. One thing that was",
      "offset": 258.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "particularly notable to me and I called",
      "offset": 260.32,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "out then was that when the interviewer",
      "offset": 261.84,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "asked, &quot;Even if AI technology is",
      "offset": 263.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "expensive today, isn't it often the case",
      "offset": 265.759,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "that technology costs decline",
      "offset": 267.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "dramatically as the technology evolves?&quot;",
      "offset": 269.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Jim first argued that that's revisionist",
      "offset": 271.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "history. But he also said even beyond",
      "offset": 273.84,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "that misconception, the tech world is",
      "offset": 276.08,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "too complacent in its assumption that AI",
      "offset": 277.759,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "costs will decline substantially over",
      "offset": 279.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "time. Moore's law and chips that enable",
      "offset": 281.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the smaller, faster, cheaper paradigm",
      "offset": 283.52,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "driving the history of technology",
      "offset": 284.96,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "innovation only proved true because",
      "offset": 286.08,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "competitors to Intel like AMD forced",
      "offset": 287.6,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "Intel and others to reduce costs and",
      "offset": 289.759,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "innovate over time to remain",
      "offset": 291.199,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "competitive. The starting point for",
      "offset": 292.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "costs, he continued, is also so high",
      "offset": 294.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that even if costs decline, they would",
      "offset": 296.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "have to do so dramatically to make",
      "offset": 298,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "automating tasks with AI affordable. And",
      "offset": 299.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "so obviously I think you know where I'm",
      "offset": 302.08,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "heading here. In three months, we have",
      "offset": 303.68,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "seen an 80% decline in arguably the most",
      "offset": 306.479,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "performant model, at least the most",
      "offset": 309.6,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "performant model when it comes to many",
      "offset": 311.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "agentic use cases. Not only is that a",
      "offset": 312.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "faster price decline than Jim predicted,",
      "offset": 315.039,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "it's faster than anything that anyone",
      "offset": 317.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "predicted. Simply put, whether you are",
      "offset": 319.28,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "skeptical of AI in general or not, cost",
      "offset": 322,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "will not be the constraining factor in",
      "offset": 324.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "how much impact it has. But what about",
      "offset": 326.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "this new model 03 Pro? If you are a",
      "offset": 329.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "regular listener, you'll know that I am",
      "offset": 331.68,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "a huge fan of 03. It is my default model",
      "offset": 333.199,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "for a huge amount of the sort of",
      "offset": 335.919,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "business strategy and ideiation type of",
      "offset": 337.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "use cases that are my day in and day",
      "offset": 339.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "out. And so I even more than most have a",
      "offset": 341.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "particular interest in digging in deep",
      "offset": 344.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "around 03 Pro. That said, I have only",
      "offset": 346.16,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "just barely scratched the surface. I'm",
      "offset": 349.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "planning on doing a top five use case",
      "offset": 352.08,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "type of show later in the week, and I'm",
      "offset": 353.84,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "still learning exactly what 03 Pro is",
      "offset": 355.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "really good for as compared to 03. But",
      "offset": 357.759,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "in the meantime, we do have some folks",
      "offset": 359.759,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "who have spent time with the models who",
      "offset": 361.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "shared some really interesting thoughts.",
      "offset": 363.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "The most notable of these comes from AI",
      "offset": 366.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "entrepreneur Ben Hilac, who wrote a",
      "offset": 367.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "guest post for Leight in Space. The",
      "offset": 369.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "piece, by the way, has the phenomenal",
      "offset": 371.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "title of God is hungry for context. But",
      "offset": 372.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "here's how Ben summed up his time with",
      "offset": 375.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "03 Pro. He said, &quot;The problem with",
      "offset": 377.6,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "evaluating 03 Pro. It's smarter, much",
      "offset": 379.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "smarter. But in order to see that, you",
      "offset": 382.639,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "need to give it a lot more context.&quot;",
      "offset": 384.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "There was no simple tester question I",
      "offset": 386.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "could ask that blew me away. But then I",
      "offset": 388.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "took a different approach. My",
      "offset": 391.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "co-founder, Alexis, and I took the time",
      "offset": 393.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "to assemble a history of all of our past",
      "offset": 395.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "planning meetings at Raindrop, all of",
      "offset": 396.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "our goals, even recorded voice memos,",
      "offset": 398.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and then asked 03 Pro to come up with a",
      "offset": 400.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "plan. We were blown away. It spit out",
      "offset": 402.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the exact kind of concrete plan and",
      "offset": 406.24,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "analysis I've always wanted an LLM to",
      "offset": 407.84,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "create, complete with target metrics,",
      "offset": 409.759,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "timelines, what to prioritize, and",
      "offset": 411.759,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "strict instructions on what to",
      "offset": 413.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "absolutely cut. But the plan 03 Pro gave",
      "offset": 414.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "us was specific and rooted enough that",
      "offset": 417.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "it actually changed how we are thinking",
      "offset": 419.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "about our future. This Ben points out is",
      "offset": 421.52,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "hard to capture in an eval. Now this is",
      "offset": 424.16,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "hugely resonant for me. I can in very",
      "offset": 427.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "simple language describe how different",
      "offset": 429.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "it is to talk about business strategy",
      "offset": 432.08,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "and ideas with 03 as compared to for",
      "offset": 434.08,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "example 40 or 45. But it's huge. It is",
      "offset": 436.479,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "incalculable. There is in most",
      "offset": 440.479,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "situations very little of value when",
      "offset": 442.479,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "sharing and trying to get feedback on an",
      "offset": 445.039,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "idea or processing a particular business",
      "offset": 446.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "problem when just chatting with 40 and",
      "offset": 448.479,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "45. 03 on the other hand is so",
      "offset": 450.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "frequently useful if not for its",
      "offset": 453.52,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "blistering insight than for different",
      "offset": 455.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "things like the way that it structures",
      "offset": 457.199,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "thinking through the answer to a",
      "offset": 458.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "particular problem that it's very rare",
      "offset": 460.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that when I'm brainstorming or",
      "offset": 462.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "ideulating or thinking about something I",
      "offset": 463.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "don't have a sort of ongoing dialogue",
      "offset": 466.08,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "with some combination of 03 raw and deep",
      "offset": 468.08,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "research with 03 and it sounds like from",
      "offset": 470.319,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "what Ben is arguing in this piece that",
      "offset": 472.479,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "the glow up and change between 03 and 03",
      "offset": 474.639,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Pro might even be more significant. It",
      "offset": 477.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "seemed to resonate with Sam Alman who",
      "offset": 480.639,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "tweeted that particular quote about how",
      "offset": 482.16,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "it changed how they're thinking about",
      "offset": 483.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "their future. Now, the other thing that",
      "offset": 484.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "I think is really important to note",
      "offset": 486.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "about Ben's review of 03 Pro and",
      "offset": 488.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "something which relates directly back to",
      "offset": 490.639,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the conversation we were having earlier",
      "offset": 492.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "this week about the Apple paper and",
      "offset": 494.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "whether and in what ways it mattered or",
      "offset": 496.479,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "not is that 03 Pro's power is a",
      "offset": 498.24,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "realworld contextual power. It's about",
      "offset": 501.44,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "application and interaction with the",
      "offset": 504.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "real world, not just raw power in the",
      "offset": 506.479,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "lab. Ben writes, &quot;Trying out 03 Pro made",
      "offset": 508.56,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "me realize that models today are so good",
      "offset": 511.28,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "in isolation, we're running out of",
      "offset": 513.039,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "simple tests. The real challenge is",
      "offset": 514.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "integrating them into society. It's",
      "offset": 516.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "almost like a really high IQ 12-year-old",
      "offset": 518.399,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "going to college. They might be smart,",
      "offset": 520.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "but they're not a useful employee if",
      "offset": 522,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "they can't integrate. Today, this",
      "offset": 523.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "integration primarily comes down to tool",
      "offset": 525.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "calls, how well the model collaborates",
      "offset": 527.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "with humans, external data, and other",
      "offset": 529.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "AIs. It's a great thinker, but it's got",
      "offset": 531.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "to grow into being a great doer. 03 Pro",
      "offset": 533.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "makes real jumps here. It's noticeably",
      "offset": 536,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "better at discerning what its",
      "offset": 538.32,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "environment is, accurately communicating",
      "offset": 539.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "what tools it has access to, when to ask",
      "offset": 541.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "questions about the outside world rather",
      "offset": 543.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "than pretending it has the information",
      "offset": 545.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "or access, and choosing the right tool",
      "offset": 546.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "for the job. In other words, this is a",
      "offset": 549.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "model that is meant to be in the real",
      "offset": 551.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "world with real context. He even says",
      "offset": 553.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "that on the flip side, its big",
      "offset": 555.76,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "shortcoming is that if you don't give it",
      "offset": 556.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "enough context, which could be anything",
      "offset": 558.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "from meeting notes to call transcripts",
      "offset": 560.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to PDFs to you name it, he says it tends",
      "offset": 562,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "to overthink. quote, &quot;It's insanely good",
      "offset": 564.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "at analyzing, amazing at using tools to",
      "offset": 567.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "do things, not so good at doing things",
      "offset": 569.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "directly itself. I think it would be a",
      "offset": 570.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "fantastic orchestrator.&quot; Now, as an",
      "offset": 573.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "example of that type of overthinking and",
      "offset": 575.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "why it's so important with new models to",
      "offset": 577.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "figure out what use cases they open up",
      "offset": 580.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and what use cases they're good for is",
      "offset": 582.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that investor Eric Wall demonstrated the",
      "offset": 584.399,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "other case. He pitted 03 against 03 Pro",
      "offset": 586.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "in selecting a group of animals to",
      "offset": 589.519,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "defend the user against the rest of the",
      "offset": 591.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "menagerie. There were selections like 50",
      "offset": 592.56,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "eagles, 10,000 rats, five gorillas, and",
      "offset": 595.2,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "a single human rifleman. To give you an",
      "offset": 597.279,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "idea of what we're dealing with here,",
      "offset": 598.959,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "after making their choice, the models",
      "offset": 600.8,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "then argue against each other to",
      "offset": 602.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "determine the winner. Wall writes, &quot;O3",
      "offset": 603.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Pro lost to 03 in this test despite",
      "offset": 606.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "thinking for 10 minutes. 03 thought for",
      "offset": 608.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "25 seconds.&quot; Interestingly, more telling",
      "offset": 611.12,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "was 03 Pro's explanation of why it lost.",
      "offset": 613.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "The model wrote, &quot;Thinking longer is",
      "offset": 616.079,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "only an advantage when the extra cycle",
      "offset": 618.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "surface new decisive information.&quot; Here",
      "offset": 620.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "they mostly amplified a hidden",
      "offset": 622.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "assumption and buried the robustness",
      "offset": 624.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "check. The lighter model's quick",
      "offset": 626.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "heristic minimize single point of",
      "offset": 627.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "failure maximize coverage was enough to",
      "offset": 629.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "nail the best answer faster. The point",
      "offset": 631.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "is once again that context is",
      "offset": 633.92,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "everything. If 03 Pro doesn't have",
      "offset": 635.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "enough context to chew on, it will",
      "offset": 637.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "actually use the extra inference to",
      "offset": 638.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "confuse itself by overthinking. Now for",
      "offset": 640.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "a somewhat more substantive evaluation,",
      "offset": 642.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "one of the few sets of eval aren't",
      "offset": 645.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "totally washed at this point is the ARC",
      "offset": 647.12,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "AGI tests. Now, in this test, the TLDDR",
      "offset": 649.12,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "basically of it is that 03 Pro is",
      "offset": 652.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "performing pretty much in line with 03",
      "offset": 655.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "on ARC AGI1, but for a much higher cost.",
      "offset": 656.88,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "However, what's worth noting is that ARC",
      "offset": 659.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "has intentionally started to limit the",
      "offset": 661.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "inference deployed against their tests",
      "offset": 663.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "as they're looking for sparks of AGI at",
      "offset": 665.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the consumer level. This means that 03",
      "offset": 667.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "Pro isn't performing at the level you",
      "offset": 669.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "would use it in in high-v value tasks",
      "offset": 671.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "during this testing. So, what does this",
      "offset": 673.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "all mean for 03 Pro? I'm not sure yet,",
      "offset": 675.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "but my strong guess is that if Ben's",
      "offset": 677.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "right, and that the real majesty of this",
      "offset": 679.6,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "model is in how it understands context",
      "offset": 681.279,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "and uses tools, it's going to take just",
      "offset": 683.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "a little while for us to really",
      "offset": 686.16,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "understand when you should be using 03",
      "offset": 687.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Pro and for what, as opposed to 03 or a",
      "offset": 689.519,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "different model. I am going to myself",
      "offset": 692.079,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "surely take some time, even though I'm",
      "offset": 694.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "traveling this week, to try to sus that",
      "offset": 696.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "out. And I will be back here to share",
      "offset": 698,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "what I've learned later in the week. For",
      "offset": 699.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "now, a very exciting day with big",
      "offset": 702.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "implications for the long term. As to",
      "offset": 704.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "this question of which of these is a",
      "offset": 706.64,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "bigger deal, the short answer is that",
      "offset": 708,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "they both are in totally different ways.",
      "offset": 709.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "They both show how things are trending",
      "offset": 711.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in totally different aspects. Model",
      "offset": 713.519,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "capabilities and practical utility even",
      "offset": 715.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "more continue to increase. Costs",
      "offset": 718.56,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "continue to decrease. The net of all of",
      "offset": 720.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that is a straight line to intelligence",
      "offset": 723.279,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "too cheap to meter and incredible new",
      "offset": 725.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "capabilities for all of us to deploy.",
      "offset": 727.68,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "For now though, that is going to do it",
      "offset": 729.92,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "for today's AI daily brief. Until next",
      "offset": 730.959,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "time, peace.",
      "offset": 732.959,
      "duration": 2.641
    }
  ],
  "cleanText": "Welcome back to The AI Daily Brief.\nBoy, you know that you are owning a news cycle when the title of the podcast is, \"Which of your two announcements was the bigger deal?\"\nYesterday, I tweeted an O3 Pro that's more agentically capable, an 80% cost reduction in existing O3, a massive acquisition light that could reshape competitive dynamics regarding data, multiple multi-billion dollar fundraises, a viral singularity prognostication, and a huge debate on reasoning.\nAnd it's barely Wednesday.\nYes, of course.\nBased on the inscrutable and immutable laws of the universe, when I am traveling, it has to be the biggest week at AI we've had in some time.\nLuckily for all of us, I've got all the equipment on the road, and we are going to dig into this.\nIn a surprise announcement yesterday, Sam Altman tweeted, \"We dropped the price of O3 by 80%. Excited to see what people will do with it now. Think you'll also be happy with O3 Pro pricing for the performance?\"\nA couple of hours later, the official OpenAI account confirmed OpenAI O3 Pro today.\nAnd so these are of course the two big stories that we're going to focus on in this main episode.\nA highly performant new model that, spoiler alert, seems even more tuned for the agentic era that we're moving into and a massive cost reduction that could have significant implications for what people build.\nSo let's talk first about this price reduction.\nChubby atkimenismus summed up many people's feelings when they tweeted, \"This is the real revolution,\" with a chart of the 87% price reduction between O3 Pro and O1 Pro.\nNow keep in mind this is not even the 80% reduction that we were talking about with O3.\nThis is just the base cost of O3 Pro as it came out as compared to where O1 Pro was just a few months ago.\nBut in terms of that big O3 price drop, many people could hardly believe it.\nNow, the specifics here were that it went from $40 per million output tokens to just $8.\nAnd on top of that, they also announced that they were going to double the rate limits for O3 for plus users.\nNow, this led many to assume that this must be a distilled version of the model.\nNot so, said Adam, who does go to market at OpenAI.\nHe tweeted in response, \"It's not distilled, same model.\"\nWhen someone said, \"Is it quantized though?\"\nAdam responded, \"It's the same model, full stop.\"\nAnd when someone asked then how was it done?\nWere there major improvements on the software side of things?\nIs this because of increased resources or did nothing change and you can just incur the cost now?\nAdam responded to that one as my teenage daughters would say, \"The inference engineers ate.\"\nBasically then it seems like these are actual efficiency gains, not just competitive pressure in a bigger balance sheet.\nYou'll remember that OpenAI also has jumped from 5.5 billion at the end of last year all the way to 10 billion now.\nNow, the claim here at least is that this is actual technical improvement.\nWhat's more, OpenAI researcher Nome Brown reinforced that businesses need to be skating to where the puck is going in terms of cost, posting, \"Input is now $2 per 1 million and output is now $8 per 1 million. The cost versus intelligence curve will continue to improve rapidly.\"\nSome people though, despite the protestations of OpenAI staffers, think that this is at least a little bit about competitive pressure.\nLan Algaby, who featured prominently in our breakdown of the Apple intelligence report from yesterday, tweeted, \"Gemini 2.5 Pro and Sonnet might actually be forcing OpenAI to lower their ridiculous O3 prices.\"\nHowever, others were just excited.\nEdwin Arvis writes, \"Oh is 20% cheaper than GPT40, rethink everything.\"\nBindu Ready celebrated the competition, saying, \"Oh price just dropped by 80%. This makes it less expensive than Sonnet 4. Finally, we have choice.\"\nNow, not to be petty here, but I do for just one moment want to bring things back to almost exactly a year ago.\nYou might remember that as summer was taking hold in 2024, people were getting a little bit bored, and we had a whole slate of articles that wanted to discuss how AI was never going to pay back the big investment that was going on in it.\nNow, some part of that conversation was capex and Wall Street valuations, all things that I said were firmly in the realm of investors to decide how they should value things.\nBut you might remember that there was one part of a Goldman Sachs report that really ground my gears.\nThe report was called \"GenAI, too much spend, too little benefit.\"\nAnd while if you go back and listen to the show, I'm actually arguing that the report is not nearly as negative as the title suggests, one person who was very negative was Goldman Sachs head of global equity research, Jim Cavllo.\nOne thing that was particularly notable to me and I called out then was that when the interviewer asked, \"Even if AI technology is expensive today, isn't it often the case that technology costs decline dramatically as the technology evolves?\"\nJim first argued that that's revisionist history.\nBut he also said even beyond that misconception, the tech world is too complacent in its assumption that AI costs will decline substantially over time.\nMoore's law and chips that enable the smaller, faster, cheaper paradigm driving the history of technology innovation only proved true because competitors to Intel like AMD forced Intel and others to reduce costs and innovate over time to remain competitive.\nThe starting point for costs, he continued, is also so high that even if costs decline, they would have to do so dramatically to make automating tasks with AI affordable.\nAnd so obviously I think you know where I'm heading here.\nIn three months, we have seen an 80% decline in arguably the most performant model, at least the most performant model when it comes to many agentic use cases.\nNot only is that a faster price decline than Jim predicted, it's faster than anything that anyone predicted.\nSimply put, whether you are skeptical of AI in general or not, cost will not be the constraining factor in how much impact it has.\nBut what about this new model O3 Pro?\nIf you are a regular listener, you'll know that I am a huge fan of O3.\nIt is my default model for a huge amount of the sort of business strategy and ideiation type of use cases that are my day in and day out.\nAnd so I even more than most have a particular interest in digging in deep around O3 Pro.\nThat said, I have only just barely scratched the surface.\nI'm planning on doing a top five use case type of show later in the week, and I'm still learning exactly what O3 Pro is really good for as compared to O3.\nBut in the meantime, we do have some folks who have spent time with the models who shared some really interesting thoughts.\nThe most notable of these comes from AI entrepreneur Ben Hilac, who wrote a guest post for Leight in Space.\nThe piece, by the way, has the phenomenal title of \"God is hungry for context.\"\nBut here's how Ben summed up his time with O3 Pro.\nHe said, \"The problem with evaluating O3 Pro. It's smarter, much smarter. But in order to see that, you need to give it a lot more context.\"\nThere was no simple tester question I could ask that blew me away.\nBut then I took a different approach.\nMy co-founder, Alexis, and I took the time to assemble a history of all of our past planning meetings at Raindrop, all of our goals, even recorded voice memos, and then asked O3 Pro to come up with a plan.\nWe were blown away.\nIt spit out the exact kind of concrete plan and analysis I've always wanted an LLM to create, complete with target metrics, timelines, what to prioritize, and strict instructions on what to absolutely cut.\nBut the plan O3 Pro gave us was specific and rooted enough that it actually changed how we are thinking about our future.\nThis Ben points out is hard to capture in an eval.\nNow this is hugely resonant for me.\nI can in very simple language describe how different it is to talk about business strategy and ideas with O3 as compared to, for example, 40 or 45.\nBut it's huge.\nIt is incalculable.\nThere is in most situations very little of value when sharing and trying to get feedback on an idea or processing a particular business problem when just chatting with 40 and 45.\nO3 on the other hand is so frequently useful, if not for its blistering insight, than for different things like the way that it structures thinking through the answer to a particular problem that it's very rare that when I'm brainstorming or ideulating or thinking about something I don't have a sort of ongoing dialogue with some combination of O3 raw and deep research with O3, and it sounds like from what Ben is arguing in this piece that the glow up and change between O3 and O3 Pro might even be more significant.\nIt seemed to resonate with Sam Altman who tweeted that particular quote about how it changed how they're thinking about their future.\nNow, the other thing that I think is really important to note about Ben's review of O3 Pro and something which relates directly back to the conversation we were having earlier this week about the Apple paper and whether and in what ways it mattered or not is that O3 Pro's power is a real-world contextual power.\nIt's about application and interaction with the real world, not just raw power in the lab.\nBen writes, \"Trying out O3 Pro made me realize that models today are so good in isolation, we're running out of simple tests. The real challenge is integrating them into society. It's almost like a really high IQ 12-year-old going to college. They might be smart, but they're not a useful employee if they can't integrate. Today, this integration primarily comes down to tool calls, how well the model collaborates with humans, external data, and other AIs. It's a great thinker, but it's got to grow into being a great doer. O3 Pro makes real jumps here. It's noticeably better at discerning what its environment is, accurately communicating what tools it has access to, when to ask questions about the outside world rather than pretending it has the information or access, and choosing the right tool for the job. In other words, this is a model that is meant to be in the real world with real context.\"\nHe even says that on the flip side, its big shortcoming is that if you don't give it enough context, which could be anything from meeting notes to call transcripts to PDFs to you name it, he says it tends to overthink.\nQuote, \"It's insanely good at analyzing, amazing at using tools to do things, not so good at doing things directly itself. I think it would be a fantastic orchestrator.\"\nNow, as an example of that type of overthinking and why it's so important with new models to figure out what use cases they open up and what use cases they're good for is that investor Eric Wall demonstrated the other case.\nHe pitted O3 against O3 Pro in selecting a group of animals to defend the user against the rest of the menagerie.\nThere were selections like 50 eagles, 10,000 rats, five gorillas, and a single human rifleman.\nTo give you an idea of what we're dealing with here, after making their choice, the models then argue against each other to determine the winner.\nWall writes, \"O3 Pro lost to O3 in this test despite thinking for 10 minutes. O3 thought for 25 seconds.\"\nInterestingly, more telling was O3 Pro's explanation of why it lost.\nThe model wrote, \"Thinking longer is only an advantage when the extra cycle surface new decisive information.\"\nHere they mostly amplified a hidden assumption and buried the robustness check.\nThe lighter model's quick heristic minimize single point of failure maximize coverage was enough to nail the best answer faster.\nThe point is once again that context is everything.\nIf O3 Pro doesn't have enough context to chew on, it will actually use the extra inference to confuse itself by overthinking.\nNow for a somewhat more substantive evaluation, one of the few sets of eval aren't totally washed at this point is the ARC AGI tests.\nNow, in this test, the TLDDR basically of it is that O3 Pro is performing pretty much in line with O3 on ARC AGI1, but for a much higher cost.\nHowever, what's worth noting is that ARC has intentionally started to limit the inference deployed against their tests as they're looking for sparks of AGI at the consumer level.\nThis means that O3 Pro isn't performing at the level you would use it in in high-v value tasks during this testing.\nSo, what does this all mean for O3 Pro?\nI'm not sure yet, but my strong guess is that if Ben's right, and that the real majesty of this model is in how it understands context and uses tools, it's going to take just a little while for us to really understand when you should be using O3 Pro and for what, as opposed to O3 or a different model.\nI am going to myself surely take some time, even though I'm traveling this week, to try to sus that out.\nAnd I will be back here to share what I've learned later in the week.\nFor now, a very exciting day with big implications for the long term.\nAs to this question of which of these is a bigger deal, the short answer is that they both are in totally different ways.\nThey both show how things are trending in totally different aspects.\nModel capabilities and practical utility even more continue to increase.\nCosts continue to decrease.\nThe net of all of that is a straight line to intelligence too cheap to meter and incredible new capabilities for all of us to deploy.\nFor now though, that is going to do it for today's AI Daily Brief.\nUntil next time, peace.\n",
  "dumpedAt": "2025-07-21T18:43:25.652Z"
}