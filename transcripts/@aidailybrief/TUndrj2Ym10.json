{
  "episodeId": "TUndrj2Ym10",
  "channelSlug": "@aidailybrief",
  "title": "The Illusion of [Good] Thinking: Why You Can Safely Ignore Apple's New AI Paper",
  "publishedAt": "2025-06-11T11:55:36.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Today on the AI Daily Brief, the",
      "offset": 0.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "hullaloo around this new paper from",
      "offset": 2.399,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "Apple and why I actually think it",
      "offset": 5.279,
      "duration": 6.001
    },
    {
      "lang": "en",
      "text": "doesn't all that much matter. Welcome",
      "offset": 8.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "back to the AI Daily Brief. Heads up, I",
      "offset": 11.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "am traveling all this week, so if",
      "offset": 13.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "anything sounds echoey at any point or",
      "offset": 15.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "there's any weird quality differences,",
      "offset": 17.359,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "it's cuz I'm doing these in hotel rooms.",
      "offset": 18.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "And today, of course, we are talking",
      "offset": 20.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "about Apple. First, we're going to talk",
      "offset": 22.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "about their non-existent AI at WWDC, but",
      "offset": 24.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "then we're going to spend more time on",
      "offset": 27.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this paper that everyone is talking",
      "offset": 30.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "about, the illusion of thinking. You can",
      "offset": 32.16,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "probably tell from my title how I feel",
      "offset": 34.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "about it, but that is for just a minute",
      "offset": 36.719,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "from now. First of all, however, let's",
      "offset": 39.04,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "talk about WWDC yesterday. Now you may",
      "offset": 41.52,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "remember that last year Apple finally",
      "offset": 45.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "came out of the gate and shared an AI",
      "offset": 48.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "strategy for the first time since the",
      "offset": 50,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "launch of Chad GBT. It was of course",
      "offset": 51.76,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "Apple intelligence because Apple had to",
      "offset": 54.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "brand its own thing. And the idea of it",
      "offset": 56.879,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "was in short to provide regular everyday",
      "offset": 59.12,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "users with the use cases that actually",
      "offset": 61.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "would matter to them. AI that wasn't big",
      "offset": 64.239,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and techy and burdensome but was just",
      "offset": 67.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "useful. The principle of it was good. It",
      "offset": 68.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "felt just like Apple. The problem has",
      "offset": 71.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "been in execution. None of the solutions",
      "offset": 73.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "they were talking about were really",
      "offset": 75.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "ready. Siri was an absolute disgrace.",
      "offset": 76.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "And basically, Apple has pushed nothing",
      "offset": 79.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "of note on Apple Intelligence, which",
      "offset": 81.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "just falls farther and farther behind.",
      "offset": 82.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Now, expectations were already on the",
      "offset": 85.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "floor heading into this event when it",
      "offset": 87.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "came to AI specifically because it",
      "offset": 89.2,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "basically seemed like they were going to",
      "offset": 91.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "forego the topic entirely. And indeed,",
      "offset": 92.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that's exactly what we got. There were",
      "offset": 95.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "no big announcements like we've seen in",
      "offset": 97.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "previous years. AI Siri was completely",
      "offset": 98.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "absent from the conference. There were",
      "offset": 101.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "some minor feature updates and a new",
      "offset": 102.96,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "image model, but nothing really",
      "offset": 104.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "compelling was unveiled. We did, I",
      "offset": 105.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "guess, get a new numbering system for",
      "offset": 107.92,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "iOS models. And we got a graphical",
      "offset": 109.92,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "redesign of iOS that has just been",
      "offset": 112.479,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "universally maligned for being confusing",
      "offset": 114.399,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and weird and not really clearly having",
      "offset": 116.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "any particular purpose. Reports were",
      "offset": 118.799,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "pretty grim out on the conference floor.",
      "offset": 121.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Lannis Einsteam tweeted, &quot;Apple has",
      "offset": 123.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "clearly missed the mark for far too many",
      "offset": 125.6,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "times now. I felt today was yet another",
      "offset": 127.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "one of these occurrences. Sadly, Apple",
      "offset": 129.119,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "is trying hard to do too much. There's",
      "offset": 131.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "too much fat. They need to trim it and",
      "offset": 133.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "back to basics. Apple desperately needs",
      "offset": 135.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "to reinvent itself or become the new",
      "offset": 137.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Nokia. During the first 40 minutes,",
      "offset": 139.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "there was nothing that made me feel wow.",
      "offset": 141.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Actually, there was one thing after",
      "offset": 143.44,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "another, leaving me with way more",
      "offset": 144.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "questions than answers. Genoji,",
      "offset": 145.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "backgrounds in group messages, visual",
      "offset": 148.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "intelligence, Apple games, and what is",
      "offset": 149.84,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "up with the new unified design language?",
      "offset": 151.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "The glass UI is a UX nightmare. Visual",
      "offset": 153.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "after visual in the presentation is",
      "offset": 156.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "worse than the previous. Apple needs to",
      "offset": 157.599,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "go back to its roots. Make a really good",
      "offset": 159.599,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "operating system. Make really good",
      "offset": 161.36,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "scaffolding for others to make the apps",
      "offset": 162.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and stuff that lives on the device. I'm",
      "offset": 164.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "completely underwhelmed. Apple needs a",
      "offset": 166.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "step change to their entire existence if",
      "offset": 168.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "things are going to turn around. Sure,",
      "offset": 170.319,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "I'm typing this on an Apple device",
      "offset": 172.08,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "because there are not a lot of options",
      "offset": 173.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "out there, but clearly this WWDC might",
      "offset": 174.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "go down as the most boring one ever.",
      "offset": 177.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Now, Apple Watcher Bloomberg's Mark",
      "offset": 179.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "German was a little more charitable. He",
      "offset": 181.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "said, &quot;Excellent WWDC, cohesive story,",
      "offset": 183.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "deep integration and continuity across",
      "offset": 186.4,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "the devices. Zero false promises,",
      "offset": 188.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "impressive new UI, and significant new",
      "offset": 190.239,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "productivity features on the Mac and",
      "offset": 192.159,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "iPad. But the lack of any real new AI",
      "offset": 193.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "features, despite that being my",
      "offset": 196.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "expectation, is startling.&quot; Azimar said,",
      "offset": 197.84,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "&quot;Can it really be excellent without an",
      "offset": 200.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "AI feature?&quot; And also, as I mentioned,",
      "offset": 202.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "clearly Gur is in the minority when it",
      "offset": 204.56,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "comes to his thoughts, for example, on",
      "offset": 206.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "the new UI. Even investors who aren't as",
      "offset": 208.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "plugged into the tech scene, are",
      "offset": 210.799,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "starting to see Apple's AI strategy as",
      "offset": 212,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "what it is, a crisis. Andrew Choy, a",
      "offset": 214,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "portfolio manager at Parnacus",
      "offset": 216.48,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "Investments, commented, &quot;It's hard to",
      "offset": 217.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "argue that Apple's lack of standing with",
      "offset": 219.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "AI isn't an existential risk. If it can",
      "offset": 221.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "paint a future where it's integrating",
      "offset": 223.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "and commoditizing AI, that would be",
      "offset": 225.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "compelling because otherwise, what is",
      "offset": 226.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "going to get people to buy their next",
      "offset": 228.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "phone for a lot more money?&quot; Still,",
      "offset": 229.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "rather than a breathtaking conference",
      "offset": 232.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "roll out, Apple is trending on AI",
      "offset": 234.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "Twitter for a very different reason.",
      "offset": 236.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "They've just released a controversial",
      "offset": 239.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "new paper entitled The Illusion of",
      "offset": 240.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Thinking: Understanding the Strengths",
      "offset": 242.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "and Limitations of Reasoning Models Via",
      "offset": 244.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the Lens of Problem Complexity. AI",
      "offset": 246.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "threader Ruben Hassid writes, &quot;Apple",
      "offset": 248.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "just proved AI reasoning models like",
      "offset": 250.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Claude, Deepsecar1, and 03 Mini don't",
      "offset": 252.4,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "actually reason at all. They just",
      "offset": 254.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "memorize patterns really well.&quot; Now,",
      "offset": 256.639,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Reuben actually went on to provide a",
      "offset": 258.959,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "lengthy explanation of the paper, but",
      "offset": 260.239,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "judging the way the likes fell off after",
      "offset": 261.919,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "these 13.4 million views, very few",
      "offset": 263.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "people made it past the first post.",
      "offset": 266.4,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "Now, for many who follow AI development,",
      "offset": 268.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the notion that Apple would release an",
      "offset": 271.199,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "authoritative paper on the topic was",
      "offset": 272.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "perhaps somewhat ironic. Henry",
      "offset": 274.479,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Arithmquin wrote, &quot;Be Apple, richest",
      "offset": 276.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "company in the world, every advantage",
      "offset": 279.199,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "imaginable. Go all in on AI. Make",
      "offset": 280.639,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "countless promises. Get immediately",
      "offset": 282.479,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "lapped by anyone 2 years into the race.",
      "offset": 284.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Nothing to show for it. Give up. Write a",
      "offset": 286.08,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "paper about how it's all fake and",
      "offset": 288,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "doesn't matter anyway.&quot; Ply the",
      "offset": 289.28,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "Liberator wrote, &quot;I'm not reading a",
      "offset": 291.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "single AI research paper coming out of",
      "offset": 293.199,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "that giant stale donut in Certino until",
      "offset": 294.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Siri can do a little bit more than",
      "offset": 297.04,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "create calendar events on the fourth",
      "offset": 298.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "try. If I were CEO of Apple and someone",
      "offset": 299.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "from my team put out a paper focused",
      "offset": 302.16,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "solely on documenting the limitations of",
      "offset": 303.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "current models, I'd fire everyone",
      "offset": 305.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "involved on the spot.&quot; Andrew White of",
      "offset": 307.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Future House SF noted that this isn't",
      "offset": 309.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "even the first paper from Apple on the",
      "offset": 311.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "limitations to AI. He writes, &quot;Apple's",
      "offset": 313.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "AI researchers have embraced a kind of",
      "offset": 315.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "anti-LM cynic ethos, publishing multiple",
      "offset": 317.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "papers trying to argue that reasoning",
      "offset": 320.56,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "LLMs are somehow limited and cannot",
      "offset": 322.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "generalize. Apple also has the worst AI",
      "offset": 323.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "products. No idea what their quote",
      "offset": 326.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "unquote strategy is here.&quot; Now, on the",
      "offset": 328.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "flip side, the paper was absolutely",
      "offset": 331.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "jumped on by AI skeptics who believe the",
      "offset": 333.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "technology won't get better than it",
      "offset": 336.4,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "currently is. Gary Marcus, who when it",
      "offset": 337.759,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "comes to AI is basically a real life",
      "offset": 340.479,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "version of the well actually meme,",
      "offset": 342.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "published his own lengthy screed on the",
      "offset": 344.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "paper, calling it a knockout blow for",
      "offset": 346.08,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "LLMs. He wrote, &quot;Anyone who thinks LLMs",
      "offset": 348.16,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "are a direct route to the sort of AGI",
      "offset": 351.28,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "that could fundamentally transform",
      "offset": 353.039,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "society for the good is kidding",
      "offset": 354.32,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "themselves. This does not mean that the",
      "offset": 355.68,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "field of neural networks is dead or that",
      "offset": 357.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "deep learning is dead. LM are just one",
      "offset": 359.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "form of deep learning, and maybe others,",
      "offset": 361.28,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "especially those that play nicer with",
      "offset": 362.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "symbols, will eventually thrive. Time",
      "offset": 364.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "will tell, but this particular approach",
      "offset": 366.56,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "has limits that are clearer by the day.",
      "offset": 368,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Now, Marcus has been declaring that AI",
      "offset": 370.319,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "development has hit a wall every few",
      "offset": 372.16,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "months since at least March of 2022,",
      "offset": 373.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "back when it was still referred to as",
      "offset": 375.759,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "deep learning. So, that is important",
      "offset": 377.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "context that you can do what you will",
      "offset": 379.919,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "with. Remarking on the state of the",
      "offset": 381.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "discourse, AI safety discusser",
      "offset": 383.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "extraordinaire Cat Woods wrote, &quot;I hate",
      "offset": 385.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "it when people just read the titles of",
      "offset": 387.84,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "papers and think they understand the",
      "offset": 389.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "results. The illusion of thinking paper",
      "offset": 390.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "does not say LLMs don't reason. It says",
      "offset": 392.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "currently large reasoning models do",
      "offset": 395.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "reason just not with 100% accuracy and",
      "offset": 397.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "not on very hard problems. This would be",
      "offset": 399.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "like saying human reasoning falls apart",
      "offset": 401.68,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "when placed in tribal situations.",
      "offset": 403.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Therefore, humans don't reason. It even",
      "offset": 405.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "says so in the abstract. People are just",
      "offset": 407.44,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "getting distracted by the clever title.",
      "offset": 409.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "So with that in mind, let's talk about",
      "offset": 411.759,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "what the research actually set out to",
      "offset": 413.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "demonstrate. The study was designed to",
      "offset": 415.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "test the limits of a reasoning model by",
      "offset": 417.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "asking it to solve a number of puzzles,",
      "offset": 418.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "specifically a Tower of Hanoi puzzle.",
      "offset": 420.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "This puzzle features a number of",
      "offset": 423.52,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "differently sized discs stacked on a",
      "offset": 424.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "game board consisting of three poles.",
      "offset": 426.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "The goal is to transfer all of the discs",
      "offset": 428.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "without stacking a larger disc on a",
      "offset": 430.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "smaller disc. The game has an",
      "offset": 432.56,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "algorithmic solution for any number of",
      "offset": 434.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "discs, but the number of steps increases",
      "offset": 435.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "exponentially as you add discs to the",
      "offset": 437.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "puzzle. The paper measured the point at",
      "offset": 439.759,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "which the reasoning models fail to",
      "offset": 441.52,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "reason through the steps and observed",
      "offset": 442.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "how the models fail. The core finding",
      "offset": 444.319,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "was that Claude 3.7 with thinking",
      "offset": 446.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "enabled could easily complete a six disc",
      "offset": 448.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "game, struggled a little more with a",
      "offset": 450.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "seven- dis game, and had little ability",
      "offset": 452.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "to reason through the solution to a game",
      "offset": 454.72,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "with eight or more discs. Similar",
      "offset": 456.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "results were found for 03 mini high, and",
      "offset": 458.479,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the results were consistent across other",
      "offset": 460.8,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "logic puzzles where complexity can be",
      "offset": 462.479,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "modulated. The abstract for the paper",
      "offset": 464.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "stated, &quot;We found that reasoning models",
      "offset": 466.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "have limitations in exact computation.",
      "offset": 468.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "They fail to use explicit algorithms and",
      "offset": 470.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "reason inconsistently across puzzles.&quot;",
      "offset": 472.08,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Essentially, the big takeaway was that",
      "offset": 474,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "reasoning doesn't scale beyond a certain",
      "offset": 475.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "point, even if there are resources left,",
      "offset": 477.199,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "with the notion being that simply",
      "offset": 479.12,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "getting the models to think longer won't",
      "offset": 480.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "yield better performance. There were a",
      "offset": 482,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "lot of issues with the methodology that",
      "offset": 485.039,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "the internet quickly went to task",
      "offset": 486.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "unpacking. Lisan Algab scaling01",
      "offset": 488.16,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "repeated the exact prompts used in the",
      "offset": 491.28,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "paper and found that the models were",
      "offset": 493.039,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "running up against token limits. The",
      "offset": 494.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "structured output required 10 tokens for",
      "offset": 496.319,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "each move and the number of moves is",
      "offset": 498.16,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "known for this puzzle. Therefore, the",
      "offset": 499.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "models were running into their limits at",
      "offset": 501.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "predictable levels of complexity. They",
      "offset": 502.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "weren't hitting the limits of reasoning.",
      "offset": 504.56,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "They couldn't physically print out all",
      "offset": 506.56,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "of the moves while staying inside the",
      "offset": 507.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "output limits. Now, the most interesting",
      "offset": 509.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "part of this failure was that the models",
      "offset": 511.52,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "actually recognized that they couldn't",
      "offset": 513.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "reason through the solution with their",
      "offset": 514.959,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "current limits. Instead of starting off",
      "offset": 516.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the reasoning process and failing when",
      "offset": 518.399,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "the number of discs was too large, they",
      "offset": 520,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "recognized this fact and provided",
      "offset": 522,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "instructions for how to use the solution",
      "offset": 523.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "algorithm instead. For Claw, this",
      "offset": 525.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "behavior started at eight discs, hence",
      "offset": 527.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the sharp drop off in performance. Lison",
      "offset": 529.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "commented, &quot;All of this is just",
      "offset": 532.08,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "nonsense, but no, they didn't even",
      "offset": 533.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "bother looking at the outputs. The",
      "offset": 535.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "models literally recite the algorithm in",
      "offset": 537.519,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "their chains of thought in plain text",
      "offset": 539.279,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "and in code.&quot; Basically, the takeaway",
      "offset": 540.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "from this analysis was that the Apple",
      "offset": 542.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "researchers weren't measuring the limits",
      "offset": 545.2,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "of reasoning models. They were kind of",
      "offset": 546.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "just using a ton of extra steps to",
      "offset": 548.56,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "measure the engineering limits that AI",
      "offset": 550,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "labs have imposed on the models. That's",
      "offset": 551.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "a fairly big problem when the AI",
      "offset": 553.519,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "research is being used to suggest that",
      "offset": 555.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "reasoning has hit a fundamental wall",
      "offset": 556.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "rather than a technical limitation. Now,",
      "offset": 558.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "one of the big criticisms from Gary",
      "offset": 560.56,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "Marcus was that the models didn't choose",
      "offset": 562,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "to access readily available solutions",
      "offset": 563.519,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "algorithms on the internet and write",
      "offset": 565.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "Python code to solve the problem.",
      "offset": 567.04,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "Careful reading of the paper, however,",
      "offset": 569.279,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "uncovers that the researchers had",
      "offset": 570.959,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "actually prevented the models from",
      "offset": 572.48,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "coding, which is fine if we're strictly",
      "offset": 574.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "talking about the limitations of scaling",
      "offset": 576.399,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "up reasoning. But if we're talking about",
      "offset": 577.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "model capabilities in general and",
      "offset": 579.92,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "specifically model capabilities in",
      "offset": 581.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "practice, then access to coding tools,",
      "offset": 583.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "which is something they have access to,",
      "offset": 585.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "should be a part of the discussion.",
      "offset": 587.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Matthew Burman commented that access to",
      "offset": 589.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "tools really changes the math, writing,",
      "offset": 591.44,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "&quot;The biggest weakness of Apple's paper",
      "offset": 593.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "showing large reasoning models might not",
      "offset": 594.959,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "actually be reasoning all that well is",
      "offset": 596.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that they do not include the ability for",
      "offset": 598.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "models to write code to solve problems.",
      "offset": 599.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "State-of-the-art models failed the Tower",
      "offset": 601.92,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "of Hanoi puzzle at a complexity",
      "offset": 603.36,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "threshold of greater than eight discs",
      "offset": 604.72,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "when using natural language alone to",
      "offset": 606.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "solve it. However, ask it to write code",
      "offset": 607.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "to solve it and it flawlessly does up to",
      "offset": 609.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "seemingly unlimited complexity. Kevin",
      "offset": 611.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Brian, a professor of strategic",
      "offset": 614.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "management at the University of Toronto,",
      "offset": 615.68,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "remarked that this paper is really",
      "offset": 617.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "measuring self-imposed limits to",
      "offset": 618.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "reasoning rather than reasoning itself.",
      "offset": 620.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "He wrote, &quot;We can of course program an",
      "offset": 622.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "LLM to spit out millions of tokens in",
      "offset": 624.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "response to good evening and use",
      "offset": 626.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "reinforcement learning to iterate",
      "offset": 628.16,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "creatively on all sorts of possible",
      "offset": 629.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "interpretations, then collate, then",
      "offset": 630.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "brainstorm more, etc.&quot; When the models",
      "offset": 633.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "don't do that, it's not because they",
      "offset": 635.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "can't. It's because we use post-training",
      "offset": 636.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "to stop them from doing something so",
      "offset": 638.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "crazy. This does mean that in some cases",
      "offset": 640.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "it should think longer. We know from",
      "offset": 642.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "things like code with claude and",
      "offset": 644.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "internal benchmarks that performance",
      "offset": 646.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "strictly increases as we increase in",
      "offset": 648,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "tokens used for inference. On circa",
      "offset": 649.68,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "every problem domain tried, but LLM",
      "offset": 652,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "companies can do this. You can't because",
      "offset": 654.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the model you have access to tries not",
      "offset": 656.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "to overthink. Now, as one case in point,",
      "offset": 658.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "you might remember when OpenAI tested 03",
      "offset": 662.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "with essentially limitless compute and",
      "offset": 664.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "found a model that effectively beats the",
      "offset": 665.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "ARGI test. However, these runs cost",
      "offset": 667.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "millions of dollars. So, the model that",
      "offset": 670.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "was finally released was constrained to",
      "offset": 672,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "a more reasonable amount of reasoning.",
      "offset": 673.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "TLDDR on all of this is that paper is",
      "offset": 675.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "measuring engineering and cost",
      "offset": 677.92,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "constraints rather than detecting a",
      "offset": 679.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "scaling wall. Models predictably fail",
      "offset": 680.64,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "when they know they can't turn out",
      "offset": 682.72,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "enough tokens to present a full",
      "offset": 683.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "solution. This is actually the desired",
      "offset": 685.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "behavior. You don't want a reasoning",
      "offset": 688.079,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "model to spend hundreds of dollars",
      "offset": 690.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "failing to reach a full solution. The",
      "offset": 691.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "failure case is also very telling.",
      "offset": 693.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Rather than spinning their wheels on",
      "offset": 695.279,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "pointless reasoning that won't reach a",
      "offset": 696.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "conclusion, the models instead describe",
      "offset": 697.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "an algorithmic solution that is",
      "offset": 699.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "categorically different to just giving",
      "offset": 701.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "up on a more complex problem as some of",
      "offset": 703.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the commentary suggested was happening.",
      "offset": 704.8,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "TLDDR the paper ultimately says",
      "offset": 706.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "absolutely nothing about the fundamental",
      "offset": 708.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "limits of reasoning models. It just runs",
      "offset": 710,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "up against resource constraints in",
      "offset": 712.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "currently deployed AI systems. And yet,",
      "offset": 713.68,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "this is not even my biggest beef. My",
      "offset": 716.959,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "biggest beef is who cares? If you tell",
      "offset": 719.68,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "me right now that 03 isn't actually",
      "offset": 723.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "reasoning, I'm going to look over at the",
      "offset": 725.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "copious amount of work that I have done",
      "offset": 728,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "with this tool over the last month,",
      "offset": 729.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "shrug my shoulders, and then I'm going",
      "offset": 731.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to keep on prompting 03 to go do",
      "offset": 733.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "business in ways that wasn't possible",
      "offset": 735.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "before. This gets to a bigger divide",
      "offset": 737.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "right now where some people are looking",
      "offset": 740.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "at AI in the context of research and the",
      "offset": 742.079,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "long-term pursuit of AGI and others are",
      "offset": 745.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "just focused on capabilities in the here",
      "offset": 747.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and now. Broadly speaking, it's the",
      "offset": 749.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "research community on the one hand and",
      "offset": 751.6,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "the business community on the other.",
      "offset": 753.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Now, of course, these things do relate",
      "offset": 754.959,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "to one another. The research community",
      "offset": 757.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "needs its place because it's going to",
      "offset": 759.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "drive the advancements that ultimately",
      "offset": 760.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "manifest as better performance. But in",
      "offset": 762,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the same way that I've said before that",
      "offset": 764.72,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "AGI is the least relevant term in all of",
      "offset": 766.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "AI for business people, this is sort of",
      "offset": 768.399,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "the same idea. I don't care if my agent",
      "offset": 770.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "is an automated workflow as long as it",
      "offset": 773.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "significantly increases my human",
      "offset": 775.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "leverage and upscales my valuable AI",
      "offset": 776.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "output. I don't care if my reasoning",
      "offset": 778.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "model is actually reasoning in air",
      "offset": 780.959,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "quotes as long as it can do things my",
      "offset": 782.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "non-reasoning models can't. Josh Gans,",
      "offset": 784.88,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "who's a professor of management at the",
      "offset": 787.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "University of Toronto, published a long",
      "offset": 788.959,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "piece basically articulating a version",
      "offset": 791.44,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "of what I'm saying. After explaining",
      "offset": 793.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that reasoning models are actually doing",
      "offset": 794.959,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "a ton of incredible work in enterprise",
      "offset": 796.8,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "and academia, he commented, &quot;They work",
      "offset": 798.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "exactly as people explain they would",
      "offset": 800.399,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "work and did not work in some miraculous",
      "offset": 802,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "way that the hyperconern around them",
      "offset": 803.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "generated. And if you worked with them,",
      "offset": 805.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you would know all this.&quot; Now, to the",
      "offset": 807.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "extent that you are looking for a",
      "offset": 809.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "steelman argument for why these issues",
      "offset": 811.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "actually do matter and that we in the",
      "offset": 813.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "business side of this and the applied",
      "offset": 815.279,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "side of this should care about some of",
      "offset": 816.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "these questions, machine learning",
      "offset": 818.48,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "scientist Francois Chalet commented, &quot;By",
      "offset": 820.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the perhaps superficial semantic",
      "offset": 822.639,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "distinction between reasoning and",
      "offset": 824.32,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "pattern matching, there is a fundamental",
      "offset": 825.68,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "gap in the practical capabilities and",
      "offset": 827.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "behavior of these systems. You don't",
      "offset": 829.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "create an invention machine by iterating",
      "offset": 831.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "on an automation machine. The reason we",
      "offset": 832.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "care about reasoning is because of what",
      "offset": 835.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it enables. It's not about definitions.",
      "offset": 837.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "It's about capabilities. You can use",
      "offset": 839.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "pattern matching to emulate specific",
      "offset": 841.199,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "well-known skills, but you cannot use",
      "offset": 842.8,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "pattern matching to produce autonomous",
      "offset": 844.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "skill acquisition in new domains.",
      "offset": 845.76,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "All of that is well taken. I just don't",
      "offset": 848.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "care, man. And for the vast majority of",
      "offset": 850.639,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "you who are listening now, also doesn't",
      "offset": 852.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "matter to you. At least not in the here",
      "offset": 854.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and now. Maybe it does in terms of what",
      "offset": 856.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "we get to in the future. As Gan summed",
      "offset": 858.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "it up, I don't care whether my tool is",
      "offset": 860.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "thinking or reasoning. I care how much",
      "offset": 861.92,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "it's helping, which is a very different",
      "offset": 863.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "thing. Sure, there is an intellectual",
      "offset": 864.8,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "question regarding cognition, but that's",
      "offset": 866.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "far removed from the transformational",
      "offset": 868.399,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "impact AI can have right now. Nathan",
      "offset": 869.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Snell wrote, &quot;I'm surprised Apple's",
      "offset": 872.639,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "research paper on LRM is getting so much",
      "offset": 874.56,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "attention. LRM has limited reasoning",
      "offset": 876.32,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "capacity. Shocker. It's clear if you use",
      "offset": 878.959,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "it doesn't make it less valuable.&quot; He",
      "offset": 881.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "also said what we're all thinking when",
      "offset": 884.399,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "he added, &quot;Also, is anyone else",
      "offset": 885.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "inherently skeptical about research put",
      "offset": 887.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "out by Apple related to AI? They don't",
      "offset": 889.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "exactly have a great track record",
      "offset": 891.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "there.&quot; And this is one of the I think",
      "offset": 892.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "sort of sad things for these",
      "offset": 895.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "researchers. This all feels to me like",
      "offset": 896.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "it might have been a case of very bad",
      "offset": 898.88,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "timing. WWDC was gearing up to announce",
      "offset": 900.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "literally squat zero about AI and Apple",
      "offset": 904.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "researchers dropped this paper that",
      "offset": 906.8,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "seemed to sort of self- servingly say",
      "offset": 908.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "that AI matters less than we all think",
      "offset": 909.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "it does. Essentially, the paper was a",
      "offset": 911.44,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "roar shack test on AI. For some reason,",
      "offset": 913.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "there is an entire sector of AI",
      "offset": 916.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "discourse in the economy that seems to",
      "offset": 919.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "be dedicated to turning Paul Krugman's",
      "offset": 921.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "internet is no more significant than a",
      "offset": 923.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "fact quote from 1998 into an entire",
      "offset": 924.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "career positioning. Author Euan Morrison",
      "offset": 927.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "posted, &quot;AI has hit a wall. AI companies",
      "offset": 930,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "will try to hide this. Hundreds of",
      "offset": 932.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "billions have been spent on the wrong",
      "offset": 934.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "path.&quot; Kevin Roose really sums it up",
      "offset": 936,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "when he writes, &quot;There is a strain of AI",
      "offset": 938.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "skepticism that's rooted in pretending",
      "offset": 940.959,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "like it's still 2021 and nobody can",
      "offset": 942.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "actually use this stuff for themselves.",
      "offset": 945.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "It's survived for longer than I would",
      "offset": 947.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "have guessed.&quot; Look, when it comes down",
      "offset": 949.199,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to it, I think it's important that",
      "offset": 951.199,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "researchers have great debates about all",
      "offset": 953.759,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "of these things. And I think it's great",
      "offset": 956.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "from the standpoint of what I want as a",
      "offset": 958.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "person in business who uses these tools",
      "offset": 961.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "for business, which is constantly",
      "offset": 963.199,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "improving models. The academic",
      "offset": 965.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "discussion and discourse that is so",
      "offset": 967.759,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "important is way upstream from business",
      "offset": 969.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "value. Yes, but it is still part of the",
      "offset": 971.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "same stream. And academic research",
      "offset": 973.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "should be a place where different ideas",
      "offset": 976.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "can compete and people can disagree",
      "offset": 977.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "strenuously. I just think that when it",
      "offset": 979.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "comes to the practical day-to-day for",
      "offset": 982.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "most people using these tools, it",
      "offset": 983.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "doesn't matter a fig. And for those who",
      "offset": 985.92,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "are trying to turn this into some sort",
      "offset": 988.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "of gotcha, I just don't know what",
      "offset": 989.759,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "they're trying to accomplish. Signal",
      "offset": 991.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "hilariously tweets, Apple proves that",
      "offset": 994.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "this feathered aquatic robot that looks,",
      "offset": 996.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "walks, flies, and quacks like a duck may",
      "offset": 998.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "not actually be a duck. We're no closer",
      "offset": 1000.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "to having robot ducks after all. What",
      "offset": 1002.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "are we even doing here anymore? The",
      "offset": 1005.12,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "answer, at least for people who are",
      "offset": 1008.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "listening to this probably, is building",
      "offset": 1010.079,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "really cool stuff, doing really cool",
      "offset": 1012.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "things, being really excited about what",
      "offset": 1014.639,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "capabilities AI has, and ultimately not",
      "offset": 1017.12,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "caring all that much over whether you",
      "offset": 1020.079,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "call it a duck or a feathered aquatic",
      "offset": 1022.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "robot. That's going to do it for today's",
      "offset": 1024.4,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "AI daily brief. Until next time, peace.",
      "offset": 1026.48,
      "duration": 4.719
    }
  ],
  "cleanText": "Today on *The AI Daily Brief*, the hullabaloo around this new paper from Apple and why I actually think it doesn't all that much matter.\n\nWelcome back to *The AI Daily Brief*. Heads up, I am traveling all this week, so if anything sounds echoey at any point or there's any weird quality differences, it's cuz I'm doing these in hotel rooms. And today, of course, we are talking about Apple. First, we're going to talk about their non-existent AI at WWDC, but then we're going to spend more time on this paper that everyone is talking about, *The Illusion of Thinking*. You can probably tell from my title how I feel about it, but that is for just a minute from now.\n\nFirst of all, however, let's talk about WWDC yesterday. Now you may remember that last year Apple finally came out of the gate and shared an AI strategy for the first time since the launch of Chad GBT. It was of course Apple intelligence because Apple had to brand its own thing. And the idea of it was in short to provide regular everyday users with the use cases that actually would matter to them. AI that wasn't big and techy and burdensome but was just useful. The principle of it was good. It felt just like Apple. The problem has been in execution. None of the solutions they were talking about were really ready. Siri was an absolute disgrace. And basically, Apple has pushed nothing of note on Apple Intelligence, which just falls farther and farther behind.\n\nNow, expectations were already on the floor heading into this event when it came to AI specifically because it basically seemed like they were going to forego the topic entirely. And indeed, that's exactly what we got. There were no big announcements like we've seen in previous years. AI Siri was completely absent from the conference. There were some minor feature updates and a new image model, but nothing really compelling was unveiled. We did, I guess, get a new numbering system for iOS models. And we got a graphical redesign of iOS that has just been universally maligned for being confusing and weird and not really clearly having any particular purpose.\n\nReports were pretty grim out on the conference floor. Lannis Einsteam tweeted, \"Apple has clearly missed the mark for far too many times now. I felt today was yet another one of these occurrences. Sadly, Apple is trying hard to do too much. There's too much fat. They need to trim it and back to basics. Apple desperately needs to reinvent itself or become the new Nokia. During the first 40 minutes, there was nothing that made me feel wow. Actually, there was one thing after another, leaving me with way more questions than answers. Genoji, backgrounds in group messages, visual intelligence, Apple games, and what is up with the new unified design language? The glass UI is a UX nightmare. Visual after visual in the presentation is worse than the previous. Apple needs to go back to its roots. Make a really good operating system. Make really good scaffolding for others to make the apps and stuff that lives on the device. I'm completely underwhelmed. Apple needs a step change to their entire existence if things are going to turn around. Sure, I'm typing this on an Apple device because there are not a lot of options out there, but clearly this WWDC might go down as the most boring one ever.\"\n\nNow, Apple Watcher Bloomberg's Mark German was a little more charitable. He said, \"Excellent WWDC, cohesive story, deep integration and continuity across the devices. Zero false promises, impressive new UI, and significant new productivity features on the Mac and iPad. But the lack of any real new AI features, despite that being my expectation, is startling.\" Azimar said, \"Can it really be excellent without an AI feature?\" And also, as I mentioned, clearly Gur is in the minority when it comes to his thoughts, for example, on the new UI.\n\nEven investors who aren't as plugged into the tech scene, are starting to see Apple's AI strategy as what it is, a crisis. Andrew Choy, a portfolio manager at Parnacus Investments, commented, \"It's hard to argue that Apple's lack of standing with AI isn't an existential risk. If it can paint a future where it's integrating and commoditizing AI, that would be compelling because otherwise, what is going to get people to buy their next phone for a lot more money?\"\n\nStill, rather than a breathtaking conference roll out, Apple is trending on AI Twitter for a very different reason. They've just released a controversial new paper entitled *The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models Via the Lens of Problem Complexity*. AI threader Ruben Hassid writes, \"Apple just proved AI reasoning models like Claude, Deepsecar1, and 03 Mini don't actually reason at all. They just memorize patterns really well.\" Now, Reuben actually went on to provide a lengthy explanation of the paper, but judging the way the likes fell off after these 13.4 million views, very few people made it past the first post.\n\nNow, for many who follow AI development, the notion that Apple would release an authoritative paper on the topic was perhaps somewhat ironic. Henry Arithmquin wrote, \"Be Apple, richest company in the world, every advantage imaginable. Go all in on AI. Make countless promises. Get immediately lapped by anyone 2 years into the race. Nothing to show for it. Give up. Write a paper about how it's all fake and doesn't matter anyway.\" Ply the Liberator wrote, \"I'm not reading a single AI research paper coming out of that giant stale donut in Certino until Siri can do a little bit more than create calendar events on the fourth try. If I were CEO of Apple and someone from my team put out a paper focused solely on documenting the limitations of current models, I'd fire everyone involved on the spot.\" Andrew White of Future House SF noted that this isn't even the first paper from Apple on the limitations to AI. He writes, \"Apple's AI researchers have embraced a kind of anti-LM cynic ethos, publishing multiple papers trying to argue that reasoning LLMs are somehow limited and cannot generalize. Apple also has the worst AI products. No idea what their quote unquote strategy is here.\"\n\nNow, on the flip side, the paper was absolutely jumped on by AI skeptics who believe the technology won't get better than it currently is. Gary Marcus, who when it comes to AI is basically a real life version of the well actually meme, published his own lengthy screed on the paper, calling it a knockout blow for LLMs. He wrote, \"Anyone who thinks LLMs are a direct route to the sort of AGI that could fundamentally transform society for the good is kidding themselves. This does not mean that the field of neural networks is dead or that deep learning is dead. LM are just one form of deep learning, and maybe others, especially those that play nicer with symbols, will eventually thrive. Time will tell, but this particular approach has limits that are clearer by the day. Now, Marcus has been declaring that AI development has hit a wall every few months since at least March of 2022, back when it was still referred to as deep learning. So, that is important context that you can do what you will with.\n\nRemarking on the state of the discourse, AI safety discusser extraordinaire Cat Woods wrote, \"I hate it when people just read the titles of papers and think they understand the results. The illusion of thinking paper does not say LLMs don't reason. It says currently large reasoning models do reason just not with 100% accuracy and not on very hard problems. This would be like saying human reasoning falls apart when placed in tribal situations. Therefore, humans don't reason. It even says so in the abstract. People are just getting distracted by the clever title.\"\n\nSo with that in mind, let's talk about what the research actually set out to demonstrate. The study was designed to test the limits of a reasoning model by asking it to solve a number of puzzles, specifically a *Tower of Hanoi* puzzle. This puzzle features a number of differently sized discs stacked on a game board consisting of three poles. The goal is to transfer all of the discs without stacking a larger disc on a smaller disc. The game has an algorithmic solution for any number of discs, but the number of steps increases exponentially as you add discs to the puzzle. The paper measured the point at which the reasoning models fail to reason through the steps and observed how the models fail. The core finding was that Claude 3.7 with thinking enabled could easily complete a six disc game, struggled a little more with a seven- dis game, and had little ability to reason through the solution to a game with eight or more discs. Similar results were found for 03 mini high, and the results were consistent across other logic puzzles where complexity can be modulated. The abstract for the paper stated, \"We found that reasoning models have limitations in exact computation. They fail to use explicit algorithms and reason inconsistently across puzzles.\"\n\nEssentially, the big takeaway was that reasoning doesn't scale beyond a certain point, even if there are resources left, with the notion being that simply getting the models to think longer won't yield better performance. There were a lot of issues with the methodology that the internet quickly went to task unpacking. Lisan Algab scaling01 repeated the exact prompts used in the paper and found that the models were running up against token limits. The structured output required 10 tokens for each move and the number of moves is known for this puzzle. Therefore, the models were running into their limits at predictable levels of complexity. They weren't hitting the limits of reasoning. They couldn't physically print out all of the moves while staying inside the output limits.\n\nNow, the most interesting part of this failure was that the models actually recognized that they couldn't reason through the solution with their current limits. Instead of starting off the reasoning process and failing when the number of discs was too large, they recognized this fact and provided instructions for how to use the solution algorithm instead. For Claw, this behavior started at eight discs, hence the sharp drop off in performance. Lison commented, \"All of this is just nonsense, but no, they didn't even bother looking at the outputs. The models literally recite the algorithm in their chains of thought in plain text and in code.\"\n\nBasically, the takeaway from this analysis was that the Apple researchers weren't measuring the limits of reasoning models. They were kind of just using a ton of extra steps to measure the engineering limits that AI labs have imposed on the models. That's a fairly big problem when the AI research is being used to suggest that reasoning has hit a fundamental wall rather than a technical limitation.\n\nNow, one of the big criticisms from Gary Marcus was that the models didn't choose to access readily available solutions algorithms on the internet and write Python code to solve the problem. Careful reading of the paper, however, uncovers that the researchers had actually prevented the models from coding, which is fine if we're strictly talking about the limitations of scaling up reasoning. But if we're talking about model capabilities in general and specifically model capabilities in practice, then access to coding tools, which is something they have access to, should be a part of the discussion.\n\nMatthew Burman commented that access to tools really changes the math, writing, \"The biggest weakness of Apple's paper showing large reasoning models might not actually be reasoning all that well is that they do not include the ability for models to write code to solve problems. State-of-the-art models failed the *Tower of Hanoi* puzzle at a complexity threshold of greater than eight discs when using natural language alone to solve it. However, ask it to write code to solve it and it flawlessly does up to seemingly unlimited complexity. Kevin Brian, a professor of strategic management at the University of Toronto, remarked that this paper is really measuring self-imposed limits to reasoning rather than reasoning itself. He wrote, \"We can of course program an LLM to spit out millions of tokens in response to good evening and use reinforcement learning to iterate creatively on all sorts of possible interpretations, then collate, then brainstorm more, etc.\" When the models don't do that, it's not because they can't. It's because we use post-training to stop them from doing something so crazy. This does mean that in some cases it should think longer. We know from things like code with claude and internal benchmarks that performance strictly increases as we increase in tokens used for inference. On circa every problem domain tried, but LLM companies can do this. You can't because the model you have access to tries not to overthink.\n\nNow, as one case in point, you might remember when OpenAI tested 03 with essentially limitless compute and found a model that effectively beats the ARGI test. However, these runs cost millions of dollars. So, the model that was finally released was constrained to a more reasonable amount of reasoning.\n\nTLDDR on all of this is that paper is measuring engineering and cost constraints rather than detecting a scaling wall. Models predictably fail when they know they can't turn out enough tokens to present a full solution. This is actually the desired behavior. You don't want a reasoning model to spend hundreds of dollars failing to reach a full solution. The failure case is also very telling. Rather than spinning their wheels on pointless reasoning that won't reach a conclusion, the models instead describe an algorithmic solution that is categorically different to just giving up on a more complex problem as some of the commentary suggested was happening.\n\nTLDDR the paper ultimately says absolutely nothing about the fundamental limits of reasoning models. It just runs up against resource constraints in currently deployed AI systems. And yet, this is not even my biggest beef. My biggest beef is who cares? If you tell me right now that 03 isn't actually reasoning, I'm going to look over at the copious amount of work that I have done with this tool over the last month, shrug my shoulders, and then I'm going to keep on prompting 03 to go do business in ways that wasn't possible before. This gets to a bigger divide right now where some people are looking at AI in the context of research and the long-term pursuit of AGI and others are just focused on capabilities in the here and now. Broadly speaking, it's the research community on the one hand and the business community on the other.\n\nNow, of course, these things do relate to one another. The research community needs its place because it's going to drive the advancements that ultimately manifest as better performance. But in the same way that I've said before that AGI is the least relevant term in all of AI for business people, this is sort of the same idea. I don't care if my agent is an automated workflow as long as it significantly increases my human leverage and upscales my valuable AI output. I don't care if my reasoning\n\n\nA model is actually reasoning in air quotes as long as it can do things my non-reasoning models can't.\n\nJosh Gans, who's a professor of management at the University of Toronto, published a long piece basically articulating a version of what I'm saying. After explaining that reasoning models are actually doing a ton of incredible work in enterprise and academia, he commented, \"They work exactly as people explain they would work and did not work in some miraculous way that the hyperconern around them generated. And if you worked with them, you would know all this.\"\n\nNow, to the extent that you are looking for a steelman argument for why these issues actually do matter and that we in the business side of this and the applied side of this should care about some of these questions, machine learning scientist Francois Chalet commented, \"By the perhaps superficial semantic distinction between reasoning and pattern matching, there is a fundamental gap in the practical capabilities and behavior of these systems. You don't create an invention machine by iterating on an automation machine. The reason we care about reasoning is because of what it enables. It's not about definitions. It's about capabilities. You can use pattern matching to emulate specific well-known skills, but you cannot use pattern matching to produce autonomous skill acquisition in new domains.\n\nAll of that is well taken. I just don't care, man. And for the vast majority of you who are listening now, also doesn't matter to you. At least not in the here and now. Maybe it does in terms of what we get to in the future. As Gan summed it up, I don't care whether my tool is thinking or reasoning. I care how much it's helping, which is a very different thing. Sure, there is an intellectual question regarding cognition, but that's far removed from the transformational impact AI can have right now.\n\nNathan Snell wrote, \"I'm surprised Apple's research paper on LRM is getting so much attention. LRM has limited reasoning capacity. Shocker. It's clear if you use it doesn't make it less valuable.\" He also said what we're all thinking when he added, \"Also, is anyone else inherently skeptical about research put out by Apple related to AI? They don't exactly have a great track record there.\"\n\nAnd this is one of the I think sort of sad things for these researchers. This all feels to me like it might have been a case of very bad timing. WWDC was gearing up to announce literally squat zero about AI and Apple researchers dropped this paper that seemed to sort of self- servingly say that AI matters less than we all think it does. Essentially, the paper was a roar shack test on AI.\n\nFor some reason, there is an entire sector of AI discourse in the economy that seems to be dedicated to turning Paul Krugman's internet is no more significant than a fact quote from 1998 into an entire career positioning.\n\nAuthor Euan Morrison posted, \"AI has hit a wall. AI companies will try to hide this. Hundreds of billions have been spent on the wrong path.\"\n\nKevin Roose really sums it up when he writes, \"There is a strain of AI skepticism that's rooted in pretending like it's still 2021 and nobody can actually use this stuff for themselves. It's survived for longer than I would have guessed.\"\n\nLook, when it comes down to it, I think it's important that researchers have great debates about all of these things. And I think it's great from the standpoint of what I want as a person in business who uses these tools for business, which is constantly improving models. The academic discussion and discourse that is so important is way upstream from business value. Yes, but it is still part of the same stream. And academic research should be a place where different ideas can compete and people can disagree strenuously. I just think that when it comes to the practical day-to-day for most people using these tools, it doesn't matter a fig. And for those who are trying to turn this into some sort of gotcha, I just don't know what they're trying to accomplish.\n\nSignal hilariously tweets, Apple proves that this feathered aquatic robot that looks, walks, flies, and quacks like a duck may not actually be a duck. We're no closer to having robot ducks after all. What are we even doing here anymore?\n\nThe answer, at least for people who are listening to this probably, is building really cool stuff, doing really cool things, being really excited about what capabilities AI has, and ultimately not caring all that much over whether you call it a duck or a feathered aquatic robot.\n\nThat's going to do it for today's AI Daily Brief. Until next time, peace.\n",
  "dumpedAt": "2025-07-21T18:43:25.740Z"
}