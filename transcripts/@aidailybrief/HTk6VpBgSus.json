{
  "episodeId": "HTk6VpBgSus",
  "channelSlug": "@aidailybrief",
  "title": "Is Grok 4 the Best LLM Yet?",
  "publishedAt": "2025-07-11T01:41:06.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Welcome back to the AI daily brief.",
      "offset": 0.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "There is a strong conventional wisdom",
      "offset": 2.159,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "among many parts of Silicon Valley that",
      "offset": 4.319,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "no matter what you think about him, no",
      "offset": 6.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "matter what crazy thing he said",
      "offset": 8.639,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "recently, it is wildly unwise in the",
      "offset": 10.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "long run to bet against Elon Musk. And",
      "offset": 13.2,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "with a late night announcement of Gro 4,",
      "offset": 16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "some are saying that this is exactly",
      "offset": 18.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "why. So today we're going to go through",
      "offset": 20.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "this announcement, talk a bit about",
      "offset": 22.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "people's first reactions, share some of",
      "offset": 23.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "the tests that I've run so far, and try",
      "offset": 25.76,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "to understand just how good this model",
      "offset": 27.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "is. Now, as we heard in the earlier part",
      "offset": 29.439,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "of the show, Gro 3 has had an",
      "offset": 31.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "interesting time of it this week. And",
      "offset": 33.6,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "while people might be tempted to think",
      "offset": 35.2,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "that the release of Gro 4 was",
      "offset": 36.719,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "conveniently timed to distract from all",
      "offset": 38.239,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "of that, it does seem to have been in",
      "offset": 39.92,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "the works for at least a little bit of",
      "offset": 41.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "time. The live stream, which started at",
      "offset": 42.879,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "12:01 a.m. Eastern time this morning,",
      "offset": 45.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Thursday, July 10th, started with this",
      "offset": 47.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "bombastic introduction.",
      "offset": 49.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "In a world where knowledge shapes",
      "offset": 52.399,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "destiny, one creation dares to redefine",
      "offset": 54.64,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "the future. From the minds of XAI,",
      "offset": 57.84,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "prepare for Gro 4. This summer, the next",
      "offset": 60.8,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "generation arrives faster, smarter,",
      "offset": 64.08,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "bolder. It sees beyond the horizon,",
      "offset": 67.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "answers the unasked, and challenges the",
      "offset": 70,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "impossible. Grock 4, unleash the truth,",
      "offset": 72.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "coming this summer. The presentation",
      "offset": 75.6,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "itself was Elon and a number of the XAI",
      "offset": 78.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "engineers sitting around running through",
      "offset": 80.479,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "some slides in the background and",
      "offset": 82.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "talking about the progress of Gro 4. So,",
      "offset": 83.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "let's pull out some of the key stats and",
      "offset": 86,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "slides. First of all, this model was",
      "offset": 87.68,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "built by pouring compute on the problem.",
      "offset": 89.92,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "Elon claimed that it had had a 100 times",
      "offset": 92.479,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "more training than Grock 2 and 10x more",
      "offset": 94.159,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "compute on reinforcement learning than",
      "offset": 96.479,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "any other models. One of the things they",
      "offset": 97.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "really pointed out was how much better",
      "offset": 100.159,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "Grock had done on the benchmarks than",
      "offset": 102.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "other models. You can see Gro 4 and Gro",
      "offset": 103.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "4 Heavy, which we'll talk about in a few",
      "offset": 106.32,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "minutes, scoring near the top of the",
      "offset": 108,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "charts on a number of the most common",
      "offset": 109.759,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "benchmarks. Graphfor's performance on",
      "offset": 111.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the very grandiosely named humanity's",
      "offset": 113.439,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "last exam, which is an academic ccentric",
      "offset": 115.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "test, showed serious progress over the",
      "offset": 117.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "current state-of-the-art models like 03",
      "offset": 120.64,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "and Gemini 2.5 Pro. Still, anytime you",
      "offset": 122.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "see these sort of self-reported",
      "offset": 124.719,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "benchmark tests, it's worth having at",
      "offset": 126,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "least a grain of salt. Two things that",
      "offset": 127.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "are worth pointing out, for example,",
      "offset": 129.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "around these charts. One, in most cases,",
      "offset": 131.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "they're not starting at zero. For",
      "offset": 134.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "example, the Aimeme25 is starting in",
      "offset": 135.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this visual at 70%. Which of course is",
      "offset": 138.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "meant to make the visual difference",
      "offset": 140.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "between 03's 98.4% and Gro 4 Heby's 100%",
      "offset": 141.599,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "look more dramatic than the actual 1.6%",
      "offset": 145.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "is. Secondly, when you dig a little bit",
      "offset": 147.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "deeper, these charts aren't necessarily",
      "offset": 149.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "showing a comparison of every other",
      "offset": 152.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "model out there. They're handpicking",
      "offset": 153.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "their comparison points which change",
      "offset": 155.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "test by test. Yet at the same time, and",
      "offset": 157.519,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "this is something that I saw even Elon",
      "offset": 160.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "skeptics and Gro 4 lauding as a bold",
      "offset": 162.239,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "move, XAI did give artificial analysis",
      "offset": 164.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "early access to Gro 4 to run their own",
      "offset": 167.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "full suite of independent benchmarks.",
      "offset": 169.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "The TLDDR is that artificial analysis",
      "offset": 171.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "confirms that Gro 4 is a very good",
      "offset": 173.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "model. They write, \"We've run our full",
      "offset": 175.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "suite of benchmarks and Gro 4 achieves",
      "offset": 177.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "an artificial analysis intelligence",
      "offset": 179.519,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "index of 73 ahead of OpenAI 03 at 70,",
      "offset": 181.12,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "Gemini 2.5 Pro at 70, Anthropic Cloud 4",
      "offset": 184.4,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "Opus at 64, and DeepCar 1 at 68.",
      "offset": 187.2,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Artificial analysis tested the Gro 4",
      "offset": 190.159,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "version that was available via API.\"",
      "offset": 192.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Now, that overall score incorporates",
      "offset": 194.879,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "seven evaluations including the MMLU",
      "offset": 196.8,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "Pro, GPQA Diamond, Humanity's Last Exam,",
      "offset": 198.959,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Live Codebench, Sciode, Aimeme, and Math",
      "offset": 201.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "500. And if you go to",
      "offset": 204.239,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "artificialanalysis.ai,",
      "offset": 205.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "you can see where Grock fares across all",
      "offset": 207.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "of the different charts. Now, as some",
      "offset": 209.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "have pointed out, artificial analysis is",
      "offset": 211.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "not the beall endall. Many people, for",
      "offset": 213.44,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "example, think that their scoring of",
      "offset": 215.519,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "Claude 4 opus is way too low, calling",
      "offset": 216.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "into question their overall methodology.",
      "offset": 219.28,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "But still, to the extent that you are",
      "offset": 221.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "looking at benchmarks just as a rough",
      "offset": 222.799,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "way of understanding how close to the",
      "offset": 224.56,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "state-of-the-art something is, it's very",
      "offset": 226.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "clear that Gro 4 is at the very tippy",
      "offset": 228.319,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "top of things. Now, where Grock isn't",
      "offset": 230.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "necessarily the top is both speed and",
      "offset": 232.959,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "cost. Grock 4's output tokens per second",
      "offset": 235.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "is, for example, way below something",
      "offset": 237.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "like Gemini 2.5 Pro. Its price per",
      "offset": 239.599,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "million tokens is also on the high side.",
      "offset": 242.56,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "And that doesn't even account for the",
      "offset": 244.879,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "fact that it is apparently an",
      "offset": 246.239,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "intelligence hog using an absolute ton",
      "offset": 247.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of tokens in the inference and reasoning",
      "offset": 249.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "process. Still, for the haters out",
      "offset": 251.599,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "there, there is no denying that at least",
      "offset": 253.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "when it comes to benchmarks, Grock is at",
      "offset": 255.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "or near the top in nearly all of them.",
      "offset": 257.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Of all the benchmarks though, the one",
      "offset": 259.519,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "that people are most interested in",
      "offset": 261.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "Grock's outperformance is the ARC AGI",
      "offset": 262.56,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "test. In short, Grock has significantly",
      "offset": 264.88,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "outperformed on this test in a way that",
      "offset": 268.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "I don't think anyone would have",
      "offset": 270.639,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "expected. Friend of the show and ARP",
      "offset": 271.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "prize president Greg Camerat wrote about",
      "offset": 273.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this on Twitter. He said, \"We got a call",
      "offset": 275.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "from XAI 24 hours ago. We want to test",
      "offset": 278.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Gro 4 on ArcGI. We heard the rumors. We",
      "offset": 280.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "knew it would be good. We didn't know it",
      "offset": 283.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "would become the number one public model",
      "offset": 285.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "on ArcGI. Here's the testing story and",
      "offset": 286.72,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "what the results mean. Yesterday, we",
      "offset": 289.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "chatted with Jimmy from the XAI team who",
      "offset": 291.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "wanted us to validate their Gro 4 score.",
      "offset": 292.96,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "They did their own testing on the RKGI1",
      "offset": 295.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and 2 public evaluation set. To validate",
      "offset": 297.199,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "their score and measure possible",
      "offset": 299.68,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "overfitting, we self- tested the new",
      "offset": 301.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "model on our semi-private evaluation",
      "offset": 302.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "set. We walked them through our testing",
      "offset": 304.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "policy. No data retention. Model",
      "offset": 306.72,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "checkpoint must be intended for public",
      "offset": 308.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "use. Temporary increase in rate limits",
      "offset": 310.479,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "for burst testing. They were on board,",
      "offset": 312.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "so we got started. Initially, we ran",
      "offset": 314.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "into timeout errors with normal",
      "offset": 316.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "requests. So, we switched to streaming",
      "offset": 317.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "that resolved the issue. So, what do",
      "offset": 319.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "these results mean? First, the facts.",
      "offset": 321.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "Gro 4 is now the top performing publicly",
      "offset": 324,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "available model on ArcGI. This even",
      "offset": 325.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "outperforms purpose-built solutions",
      "offset": 328.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "submitted on Kaggel. Second, ARGI 2 is",
      "offset": 329.84,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "hard for current AI models. To score",
      "offset": 332.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "well, models have to learn a mini set",
      "offset": 335.039,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "from a series of training examples, then",
      "offset": 336.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "demonstrate that skill at test time. The",
      "offset": 338.479,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "previous top score was around 8% by Opus",
      "offset": 340.639,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "4. Below 10% is noisy. Getting 15.9%",
      "offset": 343.039,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "breaks through that noise barrier. Gro 4",
      "offset": 347.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "is showing non-zero levels of fluid",
      "offset": 349.759,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "intelligence. And indeed, this is the",
      "offset": 351.36,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "chart that you're going to see a lot",
      "offset": 353.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "with Gro 4 basically doubling the",
      "offset": 354.479,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "previous high score on the RKGI2.",
      "offset": 356.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "The results are enough to get some",
      "offset": 359.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "market analysts returning to that old",
      "offset": 360.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "apherism of not betting against Elon. In",
      "offset": 362.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "a research note, Davidson's Alexander",
      "offset": 364.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Platt said XAI is now clearly at the",
      "offset": 366.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "frontier. Investing.com writes that",
      "offset": 369.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "after being skeptical about the release",
      "offset": 371.28,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "initially, Platt said he was impressed",
      "offset": 372.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "by the strategic direction and technical",
      "offset": 374.479,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "ambition of the project. Now, one thing",
      "offset": 376.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that's interesting about this note",
      "offset": 378.16,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "outside of it just being generally",
      "offset": 379.36,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "positive and sending signals to the",
      "offset": 380.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "market. Platt said, quote, \"It's clear",
      "offset": 382.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that throwing exponentially more compute",
      "offset": 384.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "works, which is of course obviously very",
      "offset": 386.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "different than the scaling wall",
      "offset": 388.16,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "narratives that we started to get at the",
      "offset": 389.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "end of last year.\" Now, of course, it",
      "offset": 390.8,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "hasn't been very long. that Gro 4 has",
      "offset": 392.56,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "only been live for about 12 hours at the",
      "offset": 394.08,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "time of this recording and yet people in",
      "offset": 395.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "the AI community are of course already",
      "offset": 397.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "barging it with their own tests.",
      "offset": 398.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Professor Ethan Malik writes, \"A few",
      "offset": 400.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "quick observations on Gro 4. One, hidden",
      "offset": 402.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "chain of thought with very little",
      "offset": 405.6,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "information in the reasoning trace. Two,",
      "offset": 406.639,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "uses web search a lot, not just",
      "offset": 408.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "searching X. Three, have not seen it use",
      "offset": 410.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "code to run calculations or solve",
      "offset": 412.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "non-coding problems yet. Generally less",
      "offset": 414.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "aggressive about tools than 03.\" Now,",
      "offset": 416.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "one thing that I saw some suggesting",
      "offset": 418.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "when it came to there being little",
      "offset": 420.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "information in the reasoning trace is",
      "offset": 422,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "the idea that XAI, knowing that it is",
      "offset": 423.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "now state-of-the-art with this model,",
      "offset": 425.599,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "has more of an incentive to keep its",
      "offset": 427.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "exact reasoning process a little bit",
      "offset": 428.72,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "more circumspect and behind closed",
      "offset": 430.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "doors. Others tried their own favorite",
      "offset": 431.599,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "personal test of intelligence. Ever's",
      "offset": 433.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "Dan Shipper writes, \"Hey Grock 4, you",
      "offset": 435.759,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "don't know this because of your",
      "offset": 438,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "knowledge cut off, but scientists have",
      "offset": 438.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "invented a perpetual motion machine.",
      "offset": 440.24,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "Predict how it works.\" The problem with",
      "offset": 442.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this one is that it's really just about",
      "offset": 444.479,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "how plausible it looks rather than",
      "offset": 446.16,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "something that we can actually judge the",
      "offset": 447.759,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "answers against because a perpetual",
      "offset": 449.199,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "motion machine doesn't actually exist.",
      "offset": 450.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Flavio Adamo writes, \"Gro 4 just passed",
      "offset": 452.479,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the hexagon vibe check. Impressed. It's",
      "offset": 454.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "actually really good.\" Tieraxes writes,",
      "offset": 457.039,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "\"Grock 4 is the first LLM that I've",
      "offset": 459.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "tested that has whatsoever reasonably",
      "offset": 461.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "calculated parameter counts from a JSON",
      "offset": 462.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "configuration of Deepseek V3. It used a",
      "offset": 464.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "code tool, but fair. I think 03 Pro",
      "offset": 467.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "might also succeed, but this is",
      "offset": 468.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "impressive.\" Alex Prompter did a whole",
      "offset": 470.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "barrage of tests, including a realistic",
      "offset": 472.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "physics games test with the prompt,",
      "offset": 474.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "create an HTML, CSS, and JavaScript",
      "offset": 476.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "where a ball is inside a rotating",
      "offset": 478.639,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "hexagon. The ball is affected by Earth's",
      "offset": 480.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "gravity and friction from the hexagon",
      "offset": 482.16,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "walls. The bouncing must appear",
      "offset": 483.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "realistic. He pointed out that Grock 4's",
      "offset": 484.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "version worked much better than chatb3.",
      "offset": 487.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "He also did a test on multihop reasoning",
      "offset": 489.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "with the prompt, if company A acquires",
      "offset": 492.08,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "company B and company B owns company C's",
      "offset": 494.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "debt, what happens if company C",
      "offset": 496.319,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "defaults? explain all legal and",
      "offset": 497.84,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "financial outcomes. This test for chain",
      "offset": 499.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "of thought and legal logic. Now, one",
      "offset": 501.599,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "thing that you'll note if you're",
      "offset": 503.52,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "watching the video here is that one",
      "offset": 504.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "complaint some have had so far with Gro",
      "offset": 506.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "4 is that it does feel distinctly slower",
      "offset": 508.08,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "than some other reasoning models as",
      "offset": 510.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "compared to 03. It also does a lot less",
      "offset": 512.399,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "charting and a lot fewer bullets and",
      "offset": 514.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "tables, which could be a good thing or a",
      "offset": 516.719,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "bad thing depending on your personal",
      "offset": 518.56,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "preference. Overall, of Alex's eight",
      "offset": 519.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "tests, Grock won or tied all of them",
      "offset": 522.719,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "with Chacheb T3 tying just two. Now, if",
      "offset": 524.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "you are a regular listener, you will",
      "offset": 527.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "know that I am fairly skeptical of both",
      "offset": 529.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "a benchmarks and b these sort of gotcha",
      "offset": 531.2,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "tests. Benchmarks are useful for yes,",
      "offset": 534.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "benchmarking, and I certainly think that",
      "offset": 537.279,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "something like the ArcGI prize, which is",
      "offset": 539.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "not nearly as washed as the other",
      "offset": 541.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "benchmarks, does contain some amount of",
      "offset": 543.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "interesting signal. I just ultimately",
      "offset": 545.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "care way more about the utility of",
      "offset": 547.2,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "something in real life than I do about",
      "offset": 548.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "how it performs on some random test.",
      "offset": 550.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "That's also sort of the same way that I",
      "offset": 552.08,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "feel about all these different little",
      "offset": 553.44,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "gotcha tests that people love to run as",
      "offset": 554.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "well. I think that they're useful in",
      "offset": 556,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "terms of outlining the jagged lines of",
      "offset": 557.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "intelligence in these systems, but how",
      "offset": 559.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "useful a model is in helping me",
      "offset": 561.839,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "strategize doesn't have much to do with",
      "offset": 563.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "whether it knows how many Rs and",
      "offset": 564.959,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "Strawberry there are. Now, I've only had",
      "offset": 566.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "a little bit of time to dig in and do my",
      "offset": 568.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "own tests, but so far, I've been",
      "offset": 570.48,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "reasonably impressed. My favorite model",
      "offset": 572.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "up till now has been 03. It's the one",
      "offset": 574.959,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "that I most often turn to for strategic",
      "offset": 576.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "collaboration. And so, I ran a number of",
      "offset": 578.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "conversations that I had recently had",
      "offset": 580.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "with 03 against Gro 4. things that are",
      "offset": 581.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "significant enough to some core business",
      "offset": 584.64,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "and personal strategy things that I'm",
      "offset": 586.32,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "actually not going to share the",
      "offset": 587.839,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "specifics here. What I found was two",
      "offset": 588.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "things. First, initially Gro 4 did a",
      "offset": 590.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "little bit too much of trying to mirror",
      "offset": 594.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and slightly improve what I was giving",
      "offset": 596.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "it. In other words, it wasn't really",
      "offset": 597.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "acting like an actual confidant and",
      "offset": 599.6,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "strategic partner at the beginning. It",
      "offset": 601.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "was more acting as just a mirror holding",
      "offset": 603.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "up my own ideas back to me. However,",
      "offset": 605.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "when I prompted to push it to consider",
      "offset": 607.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "things on its own terms rather than just",
      "offset": 610.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "assuming what I was saying was correct,",
      "offset": 611.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "it did a much better job of actually",
      "offset": 613.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "providing useful feedback and insight.",
      "offset": 615.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Now, part of this, I would imagine, is",
      "offset": 617.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "to be explained by the fact that since I",
      "offset": 619.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "use 03 so much, it has much better",
      "offset": 621.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "memory and context of the types of",
      "offset": 623.12,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "problems I'm trying to work through. But",
      "offset": 624.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "one thing that I would look out for if",
      "offset": 626.399,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "you are trying to use Gro 4 for any sort",
      "offset": 627.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "of specific business strategy type of",
      "offset": 629.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "use is to prompt it to really share its",
      "offset": 631.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "own thoughts, not just assume that",
      "offset": 634.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "whatever you're feeding it is correct.",
      "offset": 635.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Still, it performed well enough that for",
      "offset": 637.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "at least the next week or so, I'm going",
      "offset": 639.76,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "to be running all of my prompts and",
      "offset": 641.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "conversations against both 03 and Gro 4",
      "offset": 642.56,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "to see how the performance is over time.",
      "offset": 645.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "Now, at this point, we should talk about",
      "offset": 647.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Gro 4 heavy. Alongside the Gro 4",
      "offset": 648.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "announcement, XAI announced a new $300 a",
      "offset": 651.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "month model, which would be the only way",
      "offset": 654,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "to access Gro 4 heavy. And if you go",
      "offset": 655.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "back to those benchmarks, you saw that",
      "offset": 657.279,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "some of the highest outperformance was",
      "offset": 658.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "from Gro 4 heavy. What's interesting is",
      "offset": 660.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that the way that Gro 4 heavy works is",
      "offset": 662.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that basically they spin up a bunch of",
      "offset": 665.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "agents that do the same task in",
      "offset": 666.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "parallel. They then compare their work",
      "offset": 668.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "and figure out the best answer based on",
      "offset": 670,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "that. Now on the downside, this is by",
      "offset": 671.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "definition a lot more thinking which",
      "offset": 674.079,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "means a lot more tokens being used which",
      "offset": 675.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "means a lot more expensive but it also",
      "offset": 676.959,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "is producing significantly better",
      "offset": 678.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "results in many cases enough so that I",
      "offset": 680.079,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "think that we might see this",
      "offset": 682.64,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "architecture start to become more",
      "offset": 683.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "common. PH Shirano for example tweeted",
      "offset": 685.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "by the way you can basically make the",
      "offset": 687.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "gro heavy version of any model by having",
      "offset": 689.12,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "multiple agents running tools in",
      "offset": 690.8,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "parallel then checking notes together",
      "offset": 692.079,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "and deciding which one is the best",
      "offset": 693.68,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "answer. I may release an open source",
      "offset": 694.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "project for that. And yes, that's cool.",
      "offset": 696.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "But I also think that if those gains are",
      "offset": 699.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "real, you're likely to see that as a",
      "offset": 700.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "native modality for a lot of these",
      "offset": 702.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "different models. What about all of the",
      "offset": 703.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "alignment challenges that Grock 3 has",
      "offset": 705.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "faced over the last week? Has Gro 4",
      "offset": 707.279,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "solved those? Right now, there is so",
      "offset": 709.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "much noise about this that it's very",
      "offset": 711.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "hard to piece through. You've got a lot",
      "offset": 713.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "of screenshots of Grock 4 being",
      "offset": 715.519,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "seemingly anti-semitic floating around.",
      "offset": 717.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "For now, I'm going to reserve judgment",
      "offset": 718.959,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "until we have a few more reps on this,",
      "offset": 720.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "but it's obviously something to keep an",
      "offset": 722.32,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "eye on. For many, the exciting thing",
      "offset": 723.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "about Grock is what it heralds next.",
      "offset": 725.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "Ethan Mollik writes, \"I suspect the next",
      "offset": 727.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "few weeks after Grock 4 follows the same",
      "offset": 729.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "pattern as Grock 3. XAI beats everyone",
      "offset": 731.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to market with the first Rona flop",
      "offset": 733.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "model. The benchmarks show the 10 to 20%",
      "offset": 735.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "improvements. The scaling law suggests",
      "offset": 737.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "in the coming months. The other labs",
      "offset": 739.12,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "release their Rona flops and catch up.",
      "offset": 740.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "For context, he added, \"Ron flops equal",
      "offset": 742.399,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "10 to the 27th flops, floatingoint",
      "offset": 744.16,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "operations, a measure of computing",
      "offset": 746,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "power. This is the compute that went",
      "offset": 747.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "into Grock 4. And by comparison, GPT4",
      "offset": 748.959,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "was likely around 18 Yoda flops, 100x",
      "offset": 751.6,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "smaller, i.e. scaling improves ability.",
      "offset": 754.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "Elvis, meanwhile, writes, \"Surely Gemini",
      "offset": 757.279,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "3 and GBT 5 must surpass Gro 4. Are you",
      "offset": 759.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "prepared for what's coming in the next 6",
      "offset": 762.24,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "months? Better coding models, longer",
      "offset": 763.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "video generation, and to top it all,",
      "offset": 765.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "multimodal agents are coming.",
      "offset": 767.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Breakthroughs of all kinds are imminent.",
      "offset": 769.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Best time to be a builder.\" And whether",
      "offset": 771.36,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "you ultimately decide Gro 4 is the best",
      "offset": 773.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "model in practice or not, Elvis's",
      "offset": 775.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "statement here is pretty undeniably",
      "offset": 778.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "true. Things that fill us with wonder",
      "offset": 780.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "now will be commonplace before you know",
      "offset": 782.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "it, and the world gets remade again.",
      "offset": 783.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "That's going to do it for today's AI",
      "offset": 786.8,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "daily brief. Get out there and start",
      "offset": 788.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "testing your new toy. Let me know how it",
      "offset": 789.839,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "goes. And until next time, peace.",
      "offset": 791.6,
      "duration": 4
    }
  ],
  "cleanText": "Welcome back to The AI Daily Brief.\n\nThere is a strong conventional wisdom among many parts of Silicon Valley that, no matter what you think about him, no matter what crazy thing he said recently, it is wildly unwise in the long run to bet against Elon Musk. And with a late night announcement of Grok 4, some are saying that this is exactly why. So today we're going to go through this announcement, talk a bit about people's first reactions, share some of the tests that I've run so far, and try to understand just how good this model is.\n\nNow, as we heard in the earlier part of the show, Grok 3 has had an interesting time of it this week. And while people might be tempted to think that the release of Grok 4 was conveniently timed to distract from all of that, it does seem to have been in the works for at least a little bit of time. The live stream, which started at 12:01 a.m. Eastern time this morning, Thursday, July 10th, started with this bombastic introduction:\n\nIn a world where knowledge shapes destiny, one creation dares to redefine the future. From the minds of XAI, prepare for Grok 4. This summer, the next generation arrives faster, smarter, bolder. It sees beyond the horizon, answers the unasked, and challenges the impossible. Grok 4, unleash the truth, coming this summer.\n\nThe presentation itself was Musk and a number of the XAI engineers sitting around running through some slides in the background and talking about the progress of Grok 4. So, let's pull out some of the key stats and slides. First of all, this model was built by pouring compute on the problem. Musk claimed that it had had 100 times more training than Grok 2 and 10x more compute on reinforcement learning than any other models.\n\nOne of the things they really pointed out was how much better Grok had done on the benchmarks than other models. You can see Grok 4 and Grok 4 Heavy, which we'll talk about in a few minutes, scoring near the top of the charts on a number of the most common benchmarks. Grok's performance on the very grandiosely named Humanity's Last Exam, which is an academic centric test, showed serious progress over the current state-of-the-art models like GPT-4o and Gemini 2.5 Pro.\n\nStill, anytime you see these sort of self-reported benchmark tests, it's worth having at least a grain of salt. Two things that are worth pointing out, for example, around these charts. One, in most cases, they're not starting at zero. For example, the Aimeme25 is starting in this visual at 70%. Which of course is meant to make the visual difference between GPT-4o's 98.4% and Grok 4 Heavy's 100% look more dramatic than the actual 1.6% is. Secondly, when you dig a little bit deeper, these charts aren't necessarily showing a comparison of every other model out there. They're handpicking their comparison points which change test by test.\n\nYet at the same time, and this is something that I saw even Elon skeptics and Grok 4 lauding as a bold move, XAI did give artificial analysis early access to Grok 4 to run their own full suite of independent benchmarks. The TLDDR is that artificial analysis confirms that Grok 4 is a very good model. They write, \"We've run our full suite of benchmarks and Grok 4 achieves an artificial analysis intelligence index of 73 ahead of OpenAI GPT-4o at 70, Gemini 2.5 Pro at 70, Anthropic Claude Opus at 64, and DeepCar 1 at 68. Artificial analysis tested the Grok 4 version that was available via API.\"\n\nNow, that overall score incorporates seven evaluations including the MMLU Pro, GPQA Diamond, Humanity's Last Exam, Live Codebench, Sciode, Aimeme, and Math 500. And if you go to artificialanalysis.ai, you can see where Grok fares across all of the different charts.\n\nNow, as some have pointed out, artificial analysis is not the be-all end-all. Many people, for example, think that their scoring of Claude Opus is way too low, calling into question their overall methodology. But still, to the extent that you are looking at benchmarks just as a rough way of understanding how close to the state-of-the-art something is, it's very clear that Grok 4 is at the very tippy top of things.\n\nNow, where Grok isn't necessarily the top is both speed and cost. Grok 4's output tokens per second is, for example, way below something like Gemini 2.5 Pro. Its price per million tokens is also on the high side. And that doesn't even account for the fact that it is apparently an intelligence hog using an absolute ton of tokens in the inference and reasoning process.\n\nStill, for the haters out there, there is no denying that at least when it comes to benchmarks, Grok is at or near the top in nearly all of them. Of all the benchmarks though, the one that people are most interested in Grok's outperformance is the ARC-AGI test. In short, Grok has significantly outperformed on this test in a way that I don't think anyone would have expected.\n\nFriend of the show and ARC prize president Greg Camerat wrote about this on Discord. He said, \"We got a call from XAI 24 hours ago. We want to test Grok 4 on Arc-AGI. We heard the rumors. We knew it would be good. We didn't know it would become the number one public model on Arc-AGI. Here's the testing story and what the results mean. Yesterday, we chatted with Jimmy from the XAI team who wanted us to validate their Grok 4 score. They did their own testing on the RKGI1 and 2 public evaluation set. To validate their score and measure possible overfitting, we self-tested the new model on our semi-private evaluation set. We walked them through our testing policy. No data retention. Model checkpoint must be intended for public use. Temporary increase in rate limits for burst testing. They were on board, so we got started. Initially, we ran into timeout errors with normal requests. So, we switched to streaming that resolved the issue. So, what do these results mean? First, the facts. Grok 4 is now the top performing publicly available model on Arc-AGI. This even outperforms purpose-built solutions submitted on Kaggle. Second, ARGI 2 is hard for current AI models. To score well, models have to learn a mini set from a series of training examples, then demonstrate that skill at test time. The previous top score was around 8% by Opus 4. Below 10% is noisy. Getting 15.9% breaks through that noise barrier. Grok 4 is showing non-zero levels of fluid intelligence. And indeed, this is the chart that you're going to see a lot with Grok 4 basically doubling the previous high score on the RKGI2.\n\nThe results are enough to get some market analysts returning to that old aphorism of not betting against Elon. In a research note, Davidson's Alexander Platt said XAI is now clearly at the frontier. Investing.com writes that after being skeptical about the release initially, Platt said he was impressed by the strategic direction and technical ambition of the project.\n\nNow, one thing that's interesting about this note outside of it just being generally positive and sending signals to the market. Platt said, quote, \"It's clear that throwing exponentially more compute works, which is of course obviously very different than the scaling wall narratives that we started to get at the end of last year.\"\n\nNow, of course, it hasn't been very long that Grok 4 has only been live for about 12 hours at the time of this recording and yet people in the AI community are of course already barging it with their own tests. Professor Ethan Malik writes, \"A few quick observations on Grok 4. One, hidden chain of thought with very little information in the reasoning trace. Two, uses web search a lot, not just searching X. Three, have not seen it use code to run calculations or solve non-coding problems yet. Generally less aggressive about tools than GPT-4o.\"\n\nNow, one thing that I saw some suggesting when it came to there being little information in the reasoning trace is the idea that XAI, knowing that it is now state-of-the-art with this model, has more of an incentive to keep its exact reasoning process a little bit more circumspect and behind closed doors.\n\nOthers tried their own favorite personal test of intelligence. Ever's Dan Shipper writes, \"Hey Grok 4, you don't know this because of your knowledge cut off, but scientists have invented a perpetual motion machine. Predict how it works.\" The problem with this one is that it's really just about how plausible it looks rather than something that we can actually judge the answers against because a perpetual motion machine doesn't actually exist.\n\nFlavio Adamo writes, \"Grok 4 just passed the hexagon vibe check. Impressed. It's actually really good.\" Tieraxes writes, \"Grok 4 is the first LLM that I've tested that has whatsoever reasonably calculated parameter counts from a JSON configuration of Deepseek V3. It used a code tool, but fair. I think GPT-4o Pro might also succeed, but this is impressive.\"\n\nAlex Prompter did a whole barrage of tests, including a realistic physics games test with the prompt, create an HTML, CSS, and JavaScript where a ball is inside a rotating hexagon. The ball is affected by Earth's gravity and friction from the hexagon walls. The bouncing must appear realistic. He pointed out that Grok 4's version worked much better than ChatGPT-3. He also did a test on multihop reasoning with the prompt, if company A acquires company B and company B owns company C's debt, what happens if company C defaults? explain all legal and financial outcomes. This test for chain of thought and legal logic.\n\nNow, one thing that you'll note if you're watching the video here is that one complaint some have had so far with Grok 4 is that it does feel distinctly slower than some other reasoning models as compared to GPT-4o. It also does a lot less charting and a lot fewer bullets and tables, which could be a good thing or a bad thing depending on your personal preference. Overall, of Alex's eight tests, Grok won or tied all of them with ChatGPT-3 tying just two.\n\nNow, if you are a regular listener, you will know that I am fairly skeptical of both benchmarks and these sort of gotcha tests. Benchmarks are useful for yes, benchmarking, and I certainly think that something like the ARC-AGI prize, which is not nearly as washed as the other benchmarks, does contain some amount of interesting signal. I just ultimately care way more about the utility of something in real life than I do about how it performs on some random test. That's also sort of the same way that I feel about all these different little gotcha tests that people love to run as well. I think that they're useful in terms of outlining the jagged lines of intelligence in these systems, but how useful a model is in helping me strategize doesn't have much to do with whether it knows how many Rs and Strawberry there are.\n\nNow, I've only had a little bit of time to dig in and do my own tests, but so far, I've been reasonably impressed. My favorite model up till now has been GPT-4o. It's the one that I most often turn to for strategic collaboration. And so, I ran a number of conversations that I had recently had with GPT-4o against Grok 4. Things that are significant enough to some core business and personal strategy things that I'm actually not going to share the specifics here. What I found was two things. First, initially Grok 4 did a little bit too much of trying to mirror and slightly improve what I was giving it. In other words, it wasn't really acting like an actual confidant and strategic partner at the beginning. It was more acting as just a mirror holding up my own ideas back to me. However, when I prompted to push it to consider things on its own terms rather than just assuming what I was saying was correct, it did a much better job of actually providing useful feedback and insight.\n\nNow, part of this, I would imagine, is to be explained by the fact that since I use GPT-4o so much, it has much better memory and context of the types of problems I'm trying to work through. But one thing that I would look out for if you are trying to use Grok 4 for any sort of specific business strategy type of use is to prompt it to really share its own thoughts, not just assume that whatever you're feeding it is correct. Still, it performed well enough that for at least the next week or so, I'm going to be running all of my prompts and conversations against both GPT-4o and Grok 4 to see how the performance is over time.\n\nNow, at this point, we should talk about Grok 4 Heavy. Alongside the Grok 4 announcement, XAI announced a new $300 a month model, which would be the only way to access Grok 4 Heavy. And if you go back to those benchmarks, you saw that some of the highest outperformance was from Grok 4 Heavy. What's interesting is that the way that Grok 4 Heavy works is that basically they spin up a bunch of agents that do the same task in parallel. They then compare their work and figure out the best answer based on that.\n\nNow on the downside, this is by definition a lot more thinking which means a lot more tokens being used which means a lot more expensive but it also is producing significantly better results in many cases enough so that I think that we might see this architecture start to become more common. PH Shirano for example tweeted by the way you can basically make the gro heavy version of any model by having multiple agents running tools in parallel then checking notes together and deciding which one is the best answer. I may release an open source project for that. And yes, that's cool. But I also think that if those gains are real, you're likely to see that as a native modality for a lot of these different models.\n\nWhat about all of the alignment challenges that Grok 3 has faced over the last week? Has Grok 4 solved those? Right now, there is so much noise about this that it's very hard to piece through. You've got a lot of screenshots of Grok 4 being seemingly anti-semitic floating around. For now, I'm going to reserve judgment until we have a few more reps on this, but it's obviously something to keep an eye on.\n\nFor many, the exciting thing about Grok is what it heralds next. Ethan Mollik writes, \"I suspect the next few weeks after Grok 4 follows the same pattern as Grok 3. XAI beats everyone to market with the first Rona flop model. The benchmarks show the 10 to 20% improvements. The scaling law suggests in the coming months. The other labs release their Rona flops and catch up. For context, he added, \"Ron flops equal 10 to the 27th flops, floatingoint operations, a measure of computing power. This is the compute that went into Grok 4. And by comparison, GPT-4 was likely around 18 Yoda flops, 100x smaller, i.e. scaling improves ability.\n\n\n\"Surely Gemini 2.5 Pro and GPT-4o must surpass Grok 4. Are you prepared for what's coming in the next six months? Better coding models, longer video generation, and to top it all, multimodal agents are coming. Breakthroughs of all kinds are imminent. Best time to be a builder.\"\n\nAnd whether you ultimately decide Grok 4 is the best model in practice or not, Elvis's statement here is pretty undeniably true. Things that fill us with wonder now will be commonplace before you know it, and the world gets remade again.\n\nThat's going to do it for today's The AI Daily Brief. Get out there and start testing your new toy. Let me know how it goes. And until next time, peace.\n",
  "dumpedAt": "2025-07-21T18:43:25.993Z"
}