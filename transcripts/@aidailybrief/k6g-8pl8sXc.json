{
  "episodeId": "k6g-8pl8sXc",
  "channelSlug": "@aidailybrief",
  "title": "How Big a Deal is Llama 4's 10M Token Context Window?",
  "publishedAt": "2025-04-08T23:12:56.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Meta has released their latest models,",
      "offset": 0.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the Llama 4 family, and coming with it",
      "offset": 1.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "is a 10 million token context window.",
      "offset": 3.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "So, just how big a deal is this? Welcome",
      "offset": 6.4,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "back to the AI daily brief. Some",
      "offset": 8.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "exciting new model announcements to",
      "offset": 10.719,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "close out the end of last week. On",
      "offset": 12.639,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Friday, Meta revealed their new Llama 4",
      "offset": 14.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "family of models. As is the case every",
      "offset": 17.119,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "time Meta announces a new set of models,",
      "offset": 19.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "there is a lot to dig into here. These",
      "offset": 21.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "models feature all new architecture,",
      "offset": 23.279,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "including multimodal functionality for",
      "offset": 24.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the first time. The models are the first",
      "offset": 26.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to utilize the mixture of experts",
      "offset": 28.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "architecture that most recently has been",
      "offset": 30.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "seen in DeepSeek. It's an architecture",
      "offset": 31.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that allows the models to access a",
      "offset": 33.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "subset of parameters within a larger",
      "offset": 35.36,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "model, making inference more efficient.",
      "offset": 36.96,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "The Llama 4 family includes three",
      "offset": 38.719,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "different models. Llama for Scout is a",
      "offset": 40.719,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "17 billion parameter model with 16",
      "offset": 43.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "experts, which Meta claims is the quote",
      "offset": 44.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "best multimodal model in the world in",
      "offset": 47.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "its class and is more powerful than all",
      "offset": 48.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "previous generation Llama models while",
      "offset": 51.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "fitting in a single Nvidia H100 GPU.",
      "offset": 52.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Llama for Maverick has the same 17",
      "offset": 55.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "billion active parameters, but includes",
      "offset": 58,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "128 experts. Basically meaning it's a",
      "offset": 60.16,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "total of 400 billion parameters. Meta",
      "offset": 62.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "states that the model is the quote best",
      "offset": 64.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "multimodal model in its class, beating",
      "offset": 66.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "GPT40 and Gemini 20 Flash across a broad",
      "offset": 68.159,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "range of widely reported benchmarks",
      "offset": 70.799,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "while achieving comparable results to",
      "offset": 72.479,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "the new Deepseek V3 on reasoning and",
      "offset": 74.08,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "coding at less than half the active",
      "offset": 76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "parameters. Llama for Behemoth is still",
      "offset": 78.119,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "in training. It's set to feature 288",
      "offset": 80.4,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "billion active parameters with 16",
      "offset": 82.799,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "experts for a total of two trillion",
      "offset": 84.479,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "parameters. So Meta here is taking the",
      "offset": 86.08,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "same strategy that they did with Llama",
      "offset": 88.159,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "3, which is release a couple of the",
      "offset": 89.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "smaller models early to get people",
      "offset": 91.439,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "excited and then release the biggest",
      "offset": 93.04,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "version of the model a couple months",
      "offset": 94.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "later. Now when it comes to Llama 4",
      "offset": 95.92,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "behemoth, this will be the first time a",
      "offset": 98,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "model has reached into the trillions of",
      "offset": 99.439,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "parameters that we know for sure and the",
      "offset": 100.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "first mixture of experts model of this",
      "offset": 102.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "size. So we don't really know how model",
      "offset": 104.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "performance will be affected. Looking at",
      "offset": 106,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "costs, Llama Force seems to be pretty",
      "offset": 108.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "competitive. Inference service provider",
      "offset": 110.32,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "Grock has the hosted model available",
      "offset": 112.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "already. Scout costs 11 cents per",
      "offset": 114.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "million input tokens and 34 cents per",
      "offset": 116.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "million output tokens, while Maverick's",
      "offset": 118.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "prices are 50 cents and 77 cents per",
      "offset": 120,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "million for input and output,",
      "offset": 122,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "respectively, in that both models",
      "offset": 123.2,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "undercut DeepSeek Gemini 2.0 Flash and",
      "offset": 125.28,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "Quen's",
      "offset": 128.239,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "QWQ32B. When it comes to benchmarks, the",
      "offset": 129.8,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "new models look comparable to their",
      "offset": 132.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "peers. Scout outperforms models like",
      "offset": 134.239,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Mistl 3.1, Gemini 2.0 Flashlight, and",
      "offset": 136.16,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "Gemma 3 on some benchmarks, while",
      "offset": 138.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "Maverick beats out GPT40 and Gemini 20",
      "offset": 140.959,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "Flash on most multimmodal reasoning",
      "offset": 143.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "benchmarks. Notably, neither of those",
      "offset": 145.16,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "models are a true reasoning model",
      "offset": 147.2,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "utilizing chain of thought or test time",
      "offset": 148.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "compute. Now, one thing that's really",
      "offset": 150.239,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "important to note is the context into",
      "offset": 152.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "which Llama 4 is entering. A couple",
      "offset": 154.08,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "months ago, we got this leak from inside",
      "offset": 156.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "the company which claimed that the",
      "offset": 158.319,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "Metagenai organization was in panic",
      "offset": 159.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "mode. The leaker wrote, &quot;It started with",
      "offset": 161.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Deepseek V3, which rendered the Llama 4",
      "offset": 164,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "already behind in benchmarks. Adding",
      "offset": 166,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "insult to injury was the unknown Chinese",
      "offset": 167.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "company with 5.5 million training",
      "offset": 169.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "budget. Engineers are moving frantically",
      "offset": 171.28,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "to dissect DeepSeek and copying anything",
      "offset": 173.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and everything we can from it. I'm not",
      "offset": 174.959,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "even exaggerating. Management is worried",
      "offset": 176.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "about justifying the massive cost of the",
      "offset": 178.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Genai or how would they face the",
      "offset": 180.16,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "leadership when every single leader of",
      "offset": 181.92,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "Genai or is making more than what it",
      "offset": 183.28,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "costs to train Deepseek V3 entirely, and",
      "offset": 184.879,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "we have dozens of such leaders? Deepseek",
      "offset": 186.879,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "R1 made things even scarier. I can't",
      "offset": 189.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "reveal confidential info, but it'll soon",
      "offset": 191.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "be public anyways. It should have been",
      "offset": 192.959,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "an engineering focused small",
      "offset": 194.72,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "organization, but since a bunch of",
      "offset": 195.92,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "people wanted to join the impact, grab",
      "offset": 197.28,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "an artificially inflate hiring in the",
      "offset": 198.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "org, everyone loses. So, this was the",
      "offset": 200.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "type of report that we were getting",
      "offset": 202.959,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "behind the scenes. And in the wake of",
      "offset": 204.159,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "these announcements, there is a lot of",
      "offset": 206,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "discussion about the feeling that maybe",
      "offset": 207.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this release was rushed and that there",
      "offset": 209.68,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "might even be something more nefarious",
      "offset": 211.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "than that going on. Mencho writes,",
      "offset": 213.36,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "&quot;Yikes, llama benchmarks looked insane,",
      "offset": 215.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "but something feels off. Reddit leak",
      "offset": 217.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "claims Meta cooked it. In the 24 hours",
      "offset": 219.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "following the announcement, as people",
      "offset": 222.4,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "started to dig in, they seem to be",
      "offset": 224,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "finding a fairly big difference in",
      "offset": 225.68,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "output between what Meta was claiming",
      "offset": 227.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "and what seemed to be the reality.",
      "offset": 228.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "TechCrunch writes, &quot;Researchers on X",
      "offset": 230.799,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "have observed stark differences in the",
      "offset": 232.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "behavior of the publicly downloadable",
      "offset": 234.319,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "Maverick compared to the model hosted on",
      "offset": 235.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "LM Marina. The Ella Marina version seems",
      "offset": 237.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "to use a lot of emojis and give",
      "offset": 239.599,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "incredibly long-winded answers.&quot; Even",
      "offset": 240.959,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "more concerning was a Reddit post from",
      "offset": 243.36,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "someone who claimed that they were a",
      "offset": 244.959,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "Meta engineer. The post they shared said",
      "offset": 246.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this. Despite repeated training efforts,",
      "offset": 248.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the internal model's performance still",
      "offset": 250.56,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "falls short of open source",
      "offset": 252,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "state-of-the-art benchmarks, lagging",
      "offset": 253.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "significantly behind. Company leadership",
      "offset": 254.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "suggested blending test sets from",
      "offset": 257.28,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "various benchmarks during the",
      "offset": 258.72,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "post-training process, aiming to meet",
      "offset": 259.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the targets across various metrics and",
      "offset": 261.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "produce a presentable result,",
      "offset": 263.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "presentable in air quotes. Failure to",
      "offset": 264.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "achieve this goal by the end of April",
      "offset": 267.04,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "deadline would lead to dire",
      "offset": 268.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "consequences. Following yesterday's",
      "offset": 269.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "release of Llama 4, many users on X and",
      "offset": 271.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Reddit have already reported extremely",
      "offset": 273.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "poor real world test results. As someone",
      "offset": 275.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "currently in academia, I find this",
      "offset": 277.6,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "approach utterly unacceptable.",
      "offset": 279.04,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "Consequently, I have submitted my",
      "offset": 280.639,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "resignation and explicitly requested",
      "offset": 281.919,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "that my name be excluded from the",
      "offset": 283.6,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "technical report of Lava 4. Notably, the",
      "offset": 284.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "VP of AI at Meta also resigned for",
      "offset": 287.199,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "similar reasons. There have been a lot",
      "offset": 289.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "of people referencing this post without",
      "offset": 291.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "a ton of verification yet. Bernie Techch",
      "offset": 293.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "wrote, &quot;Llama 4 gained benchmarks so",
      "offset": 296.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "hard, LMAO, completely out of touch with",
      "offset": 298.32,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "reality and practice.&quot; Andrew Allen",
      "offset": 300.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "summed it up this way. He wrote, &quot;Meta",
      "offset": 302.479,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "just dropped Llama 4 and scored number",
      "offset": 304.72,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "two on LM Marina, beating GPT40 and",
      "offset": 306.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Grock, but users are calling it garbage",
      "offset": 308.479,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "in Vaporware. Let's unpack the biggest",
      "offset": 310.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "benchmark controversy of 2025 so far.",
      "offset": 312.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "The numbers look incredible on paper. 10",
      "offset": 314.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "million token context window, 1417 ELO",
      "offset": 316.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "score on LM Marina, the second highest,",
      "offset": 319.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "beating many top closed models. But",
      "offset": 321.199,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "something doesn't add up when users",
      "offset": 323.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "actually try it. He pointed to a tweet",
      "offset": 324.72,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "from Harsh Varton that writes, &quot;Tried",
      "offset": 326.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "out Meta Llama 4 for coding related",
      "offset": 328.479,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "tasks. Found it super basic and almost",
      "offset": 330.32,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "useless.&quot; DD Doss from Menllo Ventures",
      "offset": 332.4,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "writes, &quot;Llama 4 seems to be actually a",
      "offset": 334.479,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "poor model for coding. Elo maxing on",
      "offset": 336.479,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "Ella Marina doesn't create the best",
      "offset": 338.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "models.&quot; Back to Andrew. He continues,",
      "offset": 340.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "&quot;The disconnect is stark. On paper,",
      "offset": 342.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "second highest on Ella Marina",
      "offset": 344.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "leaderboard. In practice, super basic",
      "offset": 346.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and almost useless for coding. Marketed",
      "offset": 348,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "revolutionary capabilities. reality",
      "offset": 350.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "struggling with basic construction",
      "offset": 352.479,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "following. The most serious allegation,",
      "offset": 353.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "Meta may have submitted a different",
      "offset": 355.84,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "model for benchmarks than what's",
      "offset": 357.199,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "publicly available. This raises major",
      "offset": 358.479,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "questions about benchmark integrity.",
      "offset": 360.479,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "User reports highlight specific",
      "offset": 362.56,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "failures, freezing when run locally on",
      "offset": 364,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Macs, poor coding capabilities compared",
      "offset": 365.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "to clawed and GPT, inability to follow",
      "offset": 367.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "instructions consistently, declining",
      "offset": 369.44,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "quality with longer contexts. Many users",
      "offset": 371.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "are calling the 10 million token context",
      "offset": 373.759,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "window marketing fluff that doesn't",
      "offset": 375.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "translate to better performance. And",
      "offset": 376.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "we'll be coming back to that 10 million",
      "offset": 378.8,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "token context window in just a minute.",
      "offset": 380.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "But Andrew also points out there are",
      "offset": 382.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "bright spots. It's fast 512 tokens per",
      "offset": 383.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "second on Grock, cost effective,",
      "offset": 386.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "improved vision capabilities over Llama",
      "offset": 388.8,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "3, and open source enabling community",
      "offset": 390.72,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "innovation. Ultimately, he writes, &quot;What",
      "offset": 393.16,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "this reveals about AI development",
      "offset": 395.199,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "benchmark scores do not equal real world",
      "offset": 396.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "utility. The gap between lab performance",
      "offset": 399.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and practical use is widening and users",
      "offset": 400.8,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "increasingly value reliability over raw",
      "offset": 403.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "specs. Obviously, we'll get a lot more",
      "offset": 405.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "information in the days to come. And",
      "offset": 407.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "even if there hasn't been nefarious",
      "offset": 409.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "behavior here, there's still some pretty",
      "offset": 410.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "big gaps between the marketing promise",
      "offset": 412.88,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "and what people are actually finding in",
      "offset": 414.56,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "practice. Outside of all that",
      "offset": 416.6,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "dubiousness, the big point of discussion",
      "offset": 418.68,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "and the thing that has everyone's mind",
      "offset": 420.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "racing is that Llama Force Scout",
      "offset": 422.16,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "theoretically features a 10 million",
      "offset": 424.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "token context window. Until now,",
      "offset": 425.759,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "Google's development of a functional",
      "offset": 428.16,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "million token context window for their",
      "offset": 429.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Gemini models was state-of-the-art. It",
      "offset": 431.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "was five times as large as the same",
      "offset": 433.36,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "class of models from OpenAI and",
      "offset": 435.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Anthropic. Now, ultra long context",
      "offset": 436.52,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "windows are a really big deal for a",
      "offset": 438.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "variety of use cases. For example, for",
      "offset": 440.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "coding assistants, the longer the",
      "offset": 442.639,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "context window, the more a coding",
      "offset": 444.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "assistant is able to ingest an entire",
      "offset": 446.479,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "codebase to be understood all at once.",
      "offset": 448.16,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "For agents, long context allows for much",
      "offset": 450.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "longer tasks to be completed before",
      "offset": 453.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "losing coherence. Meta demonstrated the",
      "offset": 454.639,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "performance with a retrieval needle in a",
      "offset": 456.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "haststack test across 10 million lines",
      "offset": 458.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "of code. Scout didn't have a single",
      "offset": 460.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "failure across their testing. Now,",
      "offset": 462.96,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "independent benchmarks weren't anywhere",
      "offset": 465.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "near as impressive, and yet still in",
      "offset": 467.199,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "this case, most of the conversation",
      "offset": 469.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "wasn't so much about meta and llama 4",
      "offset": 471.039,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "specifically, but about what the",
      "offset": 473.52,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "implications are as the tech improves.",
      "offset": 475.199,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "Representing around a million variants",
      "offset": 477.759,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "on this take, Marvin Aziz, the community",
      "offset": 479.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "manager at Lindy, wrote, &quot;Rag is dead.",
      "offset": 481.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Why bother with a knowledge base when",
      "offset": 483.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you can shove 10 million tokens into a",
      "offset": 484.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "context window and call it a day?&quot; Rag",
      "offset": 486.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "of course refers to retrieval augmented",
      "offset": 488.56,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "generation which is the process of",
      "offset": 490.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "hooking up an LLM to a database or",
      "offset": 491.919,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "knowledge source to search up any",
      "offset": 493.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "information it might need. Then again",
      "offset": 494.8,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the opposite take was just as prolific",
      "offset": 496.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "with AI evaluations designer HL Hussein",
      "offset": 498.879,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "writing rag is dead posts are annoying",
      "offset": 501.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "AF. R is retrieval and AG is the LLM.",
      "offset": 503.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "This means you think retrieval is dead.",
      "offset": 506.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Seriously you think retrieval is dead?",
      "offset": 508.08,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "Keyword search metadata filtering like",
      "offset": 509.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "dates and users GP and other filtering",
      "offset": 511.759,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "are retrieval. Good luck without",
      "offset": 513.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "retrieval. Charles Fry writes, &quot;Rag is",
      "offset": 514.959,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "dead is also the sort of thing only said",
      "offset": 517.36,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "by someone who has never run LLM",
      "offset": 518.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "inference themselves, let alone been on",
      "offset": 520.159,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "the hook for cost and latency.&quot;",
      "offset": 522,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "Enigmatically, Swix writes, &quot;Unpopular",
      "offset": 523.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "opinion right now, but Llama force's 10",
      "offset": 525.839,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "million token window will finally",
      "offset": 527.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "actually end the long context versus rag",
      "offset": 528.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "debate, but not the way the other guy is",
      "offset": 530.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "thinking for those trying to tow a more",
      "offset": 532.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "middle of the line.&quot; They basically",
      "offset": 534.72,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "point out that we just don't know enough",
      "offset": 536,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "yet to declare the end of rag or really",
      "offset": 537.2,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "understand how well long context windows",
      "offset": 538.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "are going to work. Near cyan wrote, &quot;I",
      "offset": 540.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "haven't played with the Llama 4 series,",
      "offset": 542.88,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "but needle in a haystack is woefully",
      "offset": 544.16,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "insufficient to know the strength of a",
      "offset": 545.839,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "context window. If you want needle in a",
      "offset": 547.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "haststack, we have GP for that.&quot; Grep is",
      "offset": 549.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "a Linux command for searching databases.",
      "offset": 551.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "OpenAI co-founder Andre Carpathy falls",
      "offset": 553.839,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "into the category of wanting to believe,",
      "offset": 555.839,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "adding, &quot;My reaction too when reading",
      "offset": 557.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "all the rag is dead tweets earlier",
      "offset": 559.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "today. Huge amount of optimism that the",
      "offset": 560.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "context window is also usable in",
      "offset": 562.56,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "practice for real problem solving and",
      "offset": 564,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "not just in theory. Could very well be",
      "offset": 565.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "true. I just don't super know.&quot; Now, the",
      "offset": 567.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "community with the most enthusiasm about",
      "offset": 569.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "an ultra long context window was the",
      "offset": 570.959,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "vibe coders. Plain game creator Peter",
      "offset": 572.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Levelvels wrote, &quot;This is insane and",
      "offset": 574.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "makes it finally possible to vibe code",
      "offset": 576.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "up to giant code sizes. The limit just",
      "offset": 578,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "weeks ago was context window. AI would",
      "offset": 580.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "get lost once your vibe coded game or",
      "offset": 581.92,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "app became too big. Imagine an AI with",
      "offset": 583.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "memory loss that starts breaking stuff.",
      "offset": 585.279,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "With 10 million tokens, there's",
      "offset": 587.279,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "practically no limit. Really quite big",
      "offset": 588.56,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "for vibe coding and another big hit for",
      "offset": 590.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the perpetual naysayers.&quot; AI consultant",
      "offset": 591.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "Sasha Lei added, &quot;At this point, you can",
      "offset": 594,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "throw the entire documentation of",
      "offset": 596.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "multiple libraries with examples in your",
      "offset": 597.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "project into the context window and it",
      "offset": 599.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "will handle tasks in one shot.&quot; In my",
      "offset": 600.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "opinion, the bottleneck now lies more on",
      "offset": 603.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the agentic side. These systems need to",
      "offset": 604.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "operate without me babysitting them.",
      "offset": 606.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Still, there were many trying to harsh",
      "offset": 608.72,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "the vibes with practical issues of using",
      "offset": 609.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "a 10 million token context window. They",
      "offset": 611.519,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "assumed that loading that many tokens",
      "offset": 613.6,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "would be painfully slow and questioned",
      "offset": 614.959,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "whether a Gemini 2.0 flashlight class",
      "offset": 616.959,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "model would be up to the task of",
      "offset": 618.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "generating functional code. Developer",
      "offset": 620.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "Nick Dobos rebutted, &quot;Lazy take. Use it",
      "offset": 622.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to ask questions and plan. Use the high",
      "offset": 624.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "tier models to write the actual code.",
      "offset": 626.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Not hard.&quot; His point being that even if",
      "offset": 628.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "the model isn't really up to writing",
      "offset": 630.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "code or even developing a plan, simply",
      "offset": 632.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "creating an outline of a large codebase",
      "offset": 634.16,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "for use in another LLM is a new feature",
      "offset": 635.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that hasn't previously been accessible.",
      "offset": 637.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "LinkedIn co-founder Reed Hoffman had the",
      "offset": 639.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "less combative take, posting, &quot;Spending",
      "offset": 641.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the day playing with Llama 4. One of the",
      "offset": 643.36,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "many interesting things, the massive",
      "offset": 645.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "context window is a gamecher. I don't",
      "offset": 646.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "think it's the end of Rag, but for a",
      "offset": 648.88,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "surprising number of workflows, the long",
      "offset": 650.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "context alone is enough. And I think",
      "offset": 651.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "this is an important point. Ultraong",
      "offset": 653.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "context doesn't have to be perfect or",
      "offset": 655.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "completely replace RAG to be a really",
      "offset": 657.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "big deal. To the extent that it holds up",
      "offset": 658.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "at all, this feature could unlock a huge",
      "offset": 660.8,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "range of functionality that wasn't",
      "offset": 662.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "possible before. Orchestration platform",
      "offset": 664.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "OLEX commented that this is just one",
      "offset": 666.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "tool in future workflow design, writing,",
      "offset": 667.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "&quot;Long context doesn't replace rag, but",
      "offset": 669.92,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "it absolutely shifts the trade-offs for",
      "offset": 672.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "structured contained workflows like",
      "offset": 674.399,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "contracts, single docs, or chat history.",
      "offset": 675.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Context alone is simpler, faster, and",
      "offset": 677.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "good enough. Rag still shines when you",
      "offset": 679.92,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "need external dynamic or filtered",
      "offset": 681.839,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "retrieval. The future probably blends",
      "offset": 683.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "both. Long context for memory, rag for",
      "offset": 685.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "knowledge access, orchestrators for",
      "offset": 687.519,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "choosing the best tool in real time.",
      "offset": 689.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Matthew Burman zoomed out even more.",
      "offset": 691.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "While noting a ton of Llama for",
      "offset": 692.8,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "shortcomings, he added, &quot;Here's the",
      "offset": 694.24,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "strategic insight that everyone's",
      "offset": 695.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "missing. Meta's 10 million token context",
      "offset": 697.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "window isn't about today's performance.",
      "offset": 699.519,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "It's about signaling tomorrow's",
      "offset": 701.04,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "direction. They're showing us a future",
      "offset": 702.32,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "where AI doesn't just retrieve",
      "offset": 703.839,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "knowledge, but transforms your entire",
      "offset": 705.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "knowledge base into manipulable working",
      "offset": 706.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "memory. Zuckerberg understands the truth",
      "offset": 708.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "Google accidentally leaked. Closed",
      "offset": 710.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "source AI has no moat. Foundation models",
      "offset": 712.399,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "are becoming commodities faster than",
      "offset": 714.56,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "anyone predicted. And Meta is",
      "offset": 716,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "accelerating this transformation. Meta",
      "offset": 717.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "strategy becomes clear when you connect",
      "offset": 719.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "the dots. Commoditize foundation models",
      "offset": 721.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "through open source. Make context the",
      "offset": 723.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "new competitive battleground. force",
      "offset": 725.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "innovation up the application layer,",
      "offset": 726.88,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "leverage their massive social graph",
      "offset": 728.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "advantage, and ultimately create an open",
      "offset": 729.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "ecosystem where social and application",
      "offset": 731.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "data become the true moes. Still, at the",
      "offset": 733.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "end of the day, as much as they are",
      "offset": 735.839,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "helping shape the conversation, it's",
      "offset": 736.959,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "hard not to view this release so far as",
      "offset": 738.639,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "a disappointment. Professor Ethan Malik",
      "offset": 740.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "even commented that their flagship model",
      "offset": 743.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "doesn't stack up, writing, looks like",
      "offset": 744.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "even Llama Behemoth doesn't come that",
      "offset": 746.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "close to Gemini 2.5, so no open model",
      "offset": 748.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "parody with the state-of-the-art",
      "offset": 750.88,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "enclosed models. We will see what",
      "offset": 751.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "happens when people slap a reasoner on",
      "offset": 753.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "Llama, though. doesn't seem like they're",
      "offset": 755.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "launching with one. And indeed, this was",
      "offset": 756.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "another common take. Andre Burkoff",
      "offset": 759.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "writes, &quot;If today's disappointing",
      "offset": 761.12,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "release of Llama 4 tells us something,",
      "offset": 762.48,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "it's that even 30 trillion training",
      "offset": 763.92,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "tokens and two trillion parameters",
      "offset": 765.519,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "doesn't make your non-reasoning model",
      "offset": 767.279,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "better than small reasoning models.",
      "offset": 768.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Model and data size scaling are over.&quot;",
      "offset": 770.639,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "And so, as we wrap up here, I'm not yet",
      "offset": 773.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "exactly sure what to make of this. On",
      "offset": 775.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the one hand, it feels a little rushed.",
      "offset": 777.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "It does seem like the Deep Seek pressure",
      "offset": 779.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "is getting to Meta. At the same time,",
      "offset": 780.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "given that they are taking an open",
      "offset": 783.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "strategy, the consequences of releasing",
      "offset": 784.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "early are a little bit less severe for",
      "offset": 786.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "them than perhaps for other companies.",
      "offset": 788.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "If it's cost-effective, better than some",
      "offset": 790.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "of the things that people had access to",
      "offset": 792.56,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "before, there's still going to be a lot",
      "offset": 793.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "of developers building on it. Indeed,",
      "offset": 795.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "holding aside wanting every single model",
      "offset": 797.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to break the mold every single time,",
      "offset": 799.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "ultimately for developers, this just",
      "offset": 801.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "represents another set of choices, which",
      "offset": 802.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "in a very fastmoving environment is",
      "offset": 804.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "nothing but a good thing. For now",
      "offset": 806.56,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "though, that is going to do it for",
      "offset": 808.48,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "today's AI daily brief. Appreciate you",
      "offset": 809.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "listening or watching as always and",
      "offset": 811.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "until next time, peace.",
      "offset": 812.8,
      "duration": 3.279
    }
  ],
  "cleanText": null,
  "dumpedAt": "2025-07-21T18:43:26.035Z"
}