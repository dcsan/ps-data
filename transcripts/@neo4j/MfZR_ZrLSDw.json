{
  "episodeId": "MfZR_ZrLSDw",
  "channelSlug": "@neo4j",
  "title": "NODES 2024 - A Graph Entity Resolution Playbook",
  "publishedAt": "2024-11-19T18:30:52.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "my name is Nathan Smith I'm a senior",
      "offset": 8.719,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "data scientist in the Neo forj",
      "offset": 10.28,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "Professional Services Division I joined",
      "offset": 12.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Neo forj in 2021 so I've been here for a",
      "offset": 14.519,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "little bit over three years before",
      "offset": 16.68,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "coming to Neo forj I had done previous",
      "offset": 18.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "graph work as a data scientist at love",
      "offset": 20.56,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "ever and P Health Sciences and my home",
      "offset": 22.32,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "is in Kansas City",
      "offset": 25.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Missouri I'd like to kind of motivate",
      "offset": 26.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "this session with a quot from Nick",
      "offset": 28.96,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "harway who said who wrote garbage in",
      "offset": 31.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "garbage out or rather more felicitously",
      "offset": 34.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the tree of nonsense is watered with",
      "offset": 36.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "error and from its branches swing the",
      "offset": 38.2,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "pumpkins of disaster on almost every",
      "offset": 40.12,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "data science project that I work with",
      "offset": 43.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "with Neo forj one of the first steps is",
      "offset": 45.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "always doing some kind of entity",
      "offset": 48.48,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "resolution and that's um really",
      "offset": 50.6,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "important to make sure that whether the",
      "offset": 53.32,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "data is all coming from one system or",
      "offset": 54.879,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "whether it's coming from multiple",
      "offset": 56.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "systems that we've resolved those",
      "offset": 58.16,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "entities to match um items in the real",
      "offset": 60.32,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "world and when I failed to do that",
      "offset": 63.32,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "upfront then often the pumpkin of",
      "offset": 65.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "disaster has come back to smack me in",
      "offset": 67.119,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "the end there are several sessions today",
      "offset": 68.92,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "about entity resolution it's a great",
      "offset": 71.6,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "topic there in fact there's one going on",
      "offset": 73.2,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "right now with Paco Nathan from sensing",
      "offset": 74.68,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "there's another I saw earlier today from",
      "offset": 77.32,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "linkurious and so I would encourage you",
      "offset": 79.479,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "to check those out on the videos you",
      "offset": 81.52,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "know sometimes you need a more of a rich",
      "offset": 83.4,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "application type of approach to any",
      "offset": 85.72,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "resolution the approach that I'm going",
      "offset": 87.6,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "to take is more of a lightweight",
      "offset": 88.72,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "approach that you might take um before",
      "offset": 91.119,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "you maybe advance and move on to",
      "offset": 94.159,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "something that's more um application",
      "offset": 96.52,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "focus and more U",
      "offset": 99.119,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "complex in talking about this title of",
      "offset": 101.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "this session is an entity resolution",
      "offset": 104.88,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "Playbook I want to distinguish between",
      "offset": 106.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "uh a recipe versus a Playbook when I",
      "offset": 109.56,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "think of a recipe I think of like the",
      "offset": 112,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "technical Challenge on the British",
      "offset": 113.719,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "baking show where you got an explicit",
      "offset": 115.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "list of step-by-step things to do you've",
      "offset": 117.719,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "got the exact ingredients that you need",
      "offset": 119.68,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "and you want everything to come out very",
      "offset": 121.799,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "consistently exactly the same way every",
      "offset": 123.24,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "time and contrast that with a Playbook",
      "offset": 125.399,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "you know being from Kansas City it's",
      "offset": 128.16,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "almost obligatory that I'm a fan of the",
      "offset": 129.64,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "Kansas City Chiefs and their head coach",
      "offset": 131.48,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Andy Reid comes into the game not with a",
      "offset": 133.44,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "recipe of what he's going to do um step",
      "offset": 135.879,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "by step all through the whole game but",
      "offset": 138.2,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "he does have a Playbook he's got some",
      "offset": 139.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "things that he has worked out in advance",
      "offset": 142.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "that he knows have worked many times in",
      "offset": 144.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "other contexts that then he can apply as",
      "offset": 146.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "needed against the various opponent or",
      "offset": 149.319,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "based on injuries or the weather or",
      "offset": 151.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "whatever changes he can adapt but he's",
      "offset": 153,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "got a bag of tricks that he can pull",
      "offset": 155.28,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "from and that's really what I want you",
      "offset": 157.2,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "to come away from this session is not",
      "offset": 158.28,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "necessarily an explicit recipe but a bag",
      "offset": 160.28,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "of tricks that you can pull from as",
      "offset": 162.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "you're working on your own",
      "offset": 164.08,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "projects so at a high level this graph",
      "offset": 166.72,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "entity resolution process that I'm going",
      "offset": 169,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to outline for you Begins by designing a",
      "offset": 170.68,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "graph data model that shows shared",
      "offset": 173.48,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "identifiers once we have that data model",
      "offset": 176.2,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "we're going to populate it with",
      "offset": 178.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "standardized data and we're also going",
      "offset": 180.239,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to flag what I call placeholders and",
      "offset": 182.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "we'll talk about what that means later",
      "offset": 184.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "then we want to identify candidate",
      "offset": 186.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "entity pairs that might be entities in",
      "offset": 188.4,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "the real world that are the same then",
      "offset": 190.64,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "we'll calculate a similarity score and",
      "offset": 193.4,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "for items that um are above a threshold",
      "offset": 195.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "on that similarity score we're going to",
      "offset": 198.64,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "record the results of the enti",
      "offset": 200.12,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "resolution process in our",
      "offset": 201.68,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "graph so to begin we need to find a good",
      "offset": 203.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "graph data model and sometimes when I",
      "offset": 206.44,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "come into a project I see a data model",
      "offset": 209.28,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "that looks like the one on the left and",
      "offset": 211.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "in some ways this makes sense because I",
      "offset": 213,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "want to find out if these two people are",
      "offset": 214.48,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "the same so I've got the two person",
      "offset": 216.2,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "nodes and then here I've got a whole",
      "offset": 217.56,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "bunch of properties that tell me",
      "offset": 219.28,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "everything I know about that person the",
      "offset": 220.64,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "challenge with this data model for",
      "offset": 223.319,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "entity resolution though is that from a",
      "offset": 224.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "graph perspective there's really nothing",
      "offset": 226.599,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "that connects these two people I have to",
      "offset": 229.64,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "look at the individual properties the",
      "offset": 232.28,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "looking at the individual properties",
      "offset": 234.799,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "like that is almost like I might as well",
      "offset": 236.239,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "just do the NTI resolution and python",
      "offset": 237.959,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "with record linkage or some other",
      "offset": 239.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "technology that's not really a",
      "offset": 241.76,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "graph however if I come over here at",
      "offset": 243.68,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "this data model that's on the right if I",
      "offset": 245.72,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "refactor the data so that um the shared",
      "offset": 247.56,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "identifiers are actually shared nodes",
      "offset": 252,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "that both of these um people nodes are",
      "offset": 255.079,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "connected to they both have the same",
      "offset": 257.359,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "phone number they both have the same",
      "offset": 258.88,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "social security number now as just as a",
      "offset": 260.359,
      "duration": 4.001
    },
    {
      "lang": "en",
      "text": "visual when I look at this from a graph",
      "offset": 262.84,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "standpoint I can suddenly see where the",
      "offset": 264.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "connections are and I don't have to",
      "offset": 266.72,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "compare property by properties I would",
      "offset": 268.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "with the model on the left so",
      "offset": 270.52,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "identifying these shared identifiers and",
      "offset": 272.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "breaking them out as separate nodes is a",
      "offset": 274.56,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "good first",
      "offset": 276.36,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "step now there's also a potential",
      "offset": 277.88,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "Pitfall here because I think it's",
      "offset": 280,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "important we identif or make a",
      "offset": 281.919,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "difference between what I call",
      "offset": 284,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "identifiers versus descriptors",
      "offset": 285.24,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "identifiers are things that are pretty",
      "offset": 287.12,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "unique that wouldn't be shared by more",
      "offset": 288.8,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "than a few people in the real world like",
      "offset": 290.44,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "a phone number maybe two or three people",
      "offset": 292.28,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "share the same phone number but not 100",
      "offset": 293.759,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "people um or a social security number or",
      "offset": 295.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "something like that a descriptor on the",
      "offset": 297.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "other hand is something that might be",
      "offset": 300,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "shared by a whole lot of people so if",
      "offset": 301.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "you look at this picture on the right",
      "offset": 303.12,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "we've broken out gender as its own node",
      "offset": 304.919,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "and then everybody who has the same",
      "offset": 307.16,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "value for gender is now suddenly",
      "offset": 309.28,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "pointing to the same node it creates a",
      "offset": 310.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "super node which is not ideal for us and",
      "offset": 313.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the fact that two people are connected",
      "offset": 315.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "to the same gender node doesn't really",
      "offset": 317.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "tell me that much that they are actually",
      "offset": 319.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the same person they just happen to have",
      "offset": 321.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "the same gender so this would be a poor",
      "offset": 322.8,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "example of splitting out every single",
      "offset": 324.919,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "property into its own um node and and",
      "offset": 327.4,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "linking them together if it's really a",
      "offset": 330.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "descriptor and not an",
      "offset": 332.08,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "identifier another piece of the data",
      "offset": 335.639,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "model that I often find useful is to um",
      "offset": 337.52,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "treat the addresses in a special way",
      "offset": 341.36,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "often um location data can be an",
      "offset": 343.88,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "important part of telling if two things",
      "offset": 346.479,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "are the same and here I'm looking at um",
      "offset": 348,
      "duration": 7.319
    },
    {
      "lang": "en",
      "text": "an address node and what we can do is",
      "offset": 352.479,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "apply a geocoding service maybe from",
      "offset": 355.319,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "ezri or from Google Map apps or all of",
      "offset": 358.08,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "the cloud providers um have these",
      "offset": 360.319,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "geocoding Services where you can put in",
      "offset": 362.84,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "an address and then it's going to give",
      "offset": 365.8,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "you back a latitude and a longitude and",
      "offset": 367.28,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "um and so I'll make a separate node for",
      "offset": 371.639,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that location that has the latitude and",
      "offset": 374.08,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "longitude with the point type uh within",
      "offset": 376.199,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "Neo for J and that way if I have two",
      "offset": 378.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "different addresses where maybe there's",
      "offset": 380.8,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "just a slight variation like this one",
      "offset": 382.44,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "was spelled St or this one was spelled",
      "offset": 383.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "Street all spelled out but otherwise",
      "offset": 386.639,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "it's basically the same address",
      "offset": 388.24,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "um I can tell that they're at least",
      "offset": 390.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "pointing to the same location in the",
      "offset": 392.44,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "real",
      "offset": 394.44,
      "duration": 2.28
    },
    {
      "lang": "en",
      "text": "world now once we have that data model",
      "offset": 397.24,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "um in mind we want to start to fill it",
      "offset": 400.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in with the actual data that we're",
      "offset": 403.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "trying to um clean up and as we do that",
      "offset": 404.919,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "it's important that we standardize the",
      "offset": 408.16,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "data and identify",
      "offset": 409.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "placeholders so um as we're looking at",
      "offset": 411.36,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "our raw data we want to apply whatever",
      "offset": 414.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "formatting is necessary to bring it into",
      "offset": 417.28,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "a standard format so if there's maybe",
      "offset": 419.12,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "leading or trailing white spaces we want",
      "offset": 421.199,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "to strip strip those off um for the",
      "offset": 422.879,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "phone numbers if there's like",
      "offset": 425.879,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "parentheses around the area code or or",
      "offset": 427.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the country codes or different things",
      "offset": 429.599,
      "duration": 2.761
    },
    {
      "lang": "en",
      "text": "like that we just want to make sure that",
      "offset": 431.16,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "every record is consistent that way if I",
      "offset": 432.36,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "see the same string value I know that",
      "offset": 434.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "that actually is the same thing um from",
      "offset": 436.479,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "The Source data same thing for emails",
      "offset": 439.4,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "make sure they're all lowercase Social",
      "offset": 441.36,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "Security numbers do they have the dashes",
      "offset": 443.039,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "to separate the segments or do they not",
      "offset": 445.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "all things like this that can",
      "offset": 447.479,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "standardize the property before we load",
      "offset": 449,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "it into the",
      "offset": 450.879,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "graph then there's also things that we",
      "offset": 452.36,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "can do to validate properties because",
      "offset": 454.36,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "there are certain rules that apply to",
      "offset": 456.319,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "different types of data that say whether",
      "offset": 458.599,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "or not it's a valid value or not for",
      "offset": 460.28,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "example if you're dealing with phone",
      "offset": 463.199,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "numbers if in the United States there",
      "offset": 464.8,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "are no us area codes that begin with the",
      "offset": 467.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "range 100 to 199 so if you see that",
      "offset": 469.72,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "value come in you know oh this one's",
      "offset": 472.44,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "actually invalid there's a typo going on",
      "offset": 474.72,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "here or maybe there's some kind of fraud",
      "offset": 476.96,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "uh same thing for Social Security",
      "offset": 479.319,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "numbers there are certain ranges that",
      "offset": 480.84,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "are invalid ranges I've recently been",
      "offset": 482.56,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "working on a project with NPI numbers",
      "offset": 484.96,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "that identify pharmacies or medical",
      "offset": 486.919,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "professionals and the last number of the",
      "offset": 490.52,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "MPI number is actually a check digit",
      "offset": 493.599,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "that has to have a certain value based",
      "offset": 495.759,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "on the other numbers that are part of",
      "offset": 497.479,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that string and so I can tell maybe",
      "offset": 499.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "there was a typo along the way somewhere",
      "offset": 501.639,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "or maybe this NPI number was just made",
      "offset": 503.639,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "up by somebody um so I usually go ahead",
      "offset": 505.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and load this invalid data into the",
      "offset": 508.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "graph because it could be a s a signal",
      "offset": 510,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "for fraud detection or something but I",
      "offset": 512.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "put a special label on it and so I can",
      "offset": 514.279,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "exclude it from the candidate matching",
      "offset": 516.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "because just because two people have the",
      "offset": 518.24,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "same invalid identifier um in common",
      "offset": 520.399,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that means that doesn't necessarily mean",
      "offset": 523.64,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "that they're probably the same person in",
      "offset": 525.279,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "the real world it just means they both",
      "offset": 526.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "made a typo is what I would normally",
      "offset": 527.839,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "assume from",
      "offset": 529.839,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "that now there also what I call",
      "offset": 532.64,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "placeholders and these are things that",
      "offset": 535.08,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "happen when somebody has required field",
      "offset": 537.519,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "build on a form but they don't know what",
      "offset": 539.44,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "to put in there and so they just put my",
      "offset": 541.32,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "phone number is",
      "offset": 543,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "9999999999 or something like that or",
      "offset": 544.519,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "none at.com is my email address again",
      "offset": 546.76,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "this is not something that is going to",
      "offset": 549.64,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "help me identify a person in the real",
      "offset": 551.279,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "world because there is no such phone",
      "offset": 553.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "number as that in the real world and so",
      "offset": 555.68,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "we want to try to identify these",
      "offset": 558.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "placeholder values and um hold them out",
      "offset": 559.88,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "from our",
      "offset": 562.959,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "analysis and one way that we can do that",
      "offset": 564.519,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "is using the graph data science degree",
      "offset": 567.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "algorithm to figure out are that some of",
      "offset": 569.959,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "these identifiers have a very high",
      "offset": 572.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "degree because remember an identifier is",
      "offset": 574.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "something that you wouldn't expect to be",
      "offset": 576.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "shared by more than you know a handful",
      "offset": 577.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "of of people or objects in the real",
      "offset": 579.88,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "world so I might make a graph projection",
      "offset": 583.04,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "that has the phone numbers and then the",
      "offset": 585.519,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "people associated with those phone",
      "offset": 587.519,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "numbers and if there's a phone number",
      "offset": 589,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that has a very high degree then it's",
      "offset": 590.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "probably a placeholder and I can run",
      "offset": 592.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that um degree algorithm in stats mode",
      "offset": 594.839,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "to just get a sense of the overall",
      "offset": 597.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "distribution like where's the 99th",
      "offset": 598.8,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "percentile for the the most um common",
      "offset": 600.6,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "phone numbers and then I can also run it",
      "offset": 604.519,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "in stream um mode to get back the actual",
      "offset": 606.56,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "values and then again I can label these",
      "offset": 610.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "values that are above whatever threshold",
      "offset": 612.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "I want to say hold these out and don't",
      "offset": 614.839,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "include them in the um next steps of the",
      "offset": 617.48,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "process so now that we have our data",
      "offset": 622.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "model loaded into the graph the next",
      "offset": 624.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "step is to identify entity pairs that",
      "offset": 626.92,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "might be duplicates now when you think",
      "offset": 629.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "about this process of comparing nodes",
      "offset": 631.44,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "with each other if I compare every",
      "offset": 633.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "single node with every single other node",
      "offset": 635.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "in the graph that's a quadratic um",
      "offset": 637.839,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "operation there that's going to take a",
      "offset": 640.839,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "lot of resources a lot of memory and a",
      "offset": 642.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "lot of time to compare every single",
      "offset": 644.279,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "thing with every single other thing and",
      "offset": 646.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "so um if I can narrow down the universe",
      "offset": 648.48,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "of things that need to be compared my",
      "offset": 651.44,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "entity resolution operation can happen",
      "offset": 653.959,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "much faster so this is the workflow that",
      "offset": 656.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "I that I follow usually I'll load the",
      "offset": 659.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "graph data model and then the first",
      "offset": 661.56,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "thing I'll do is use an algorithm called",
      "offset": 663.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "weekly connected components to um start",
      "offset": 664.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "to narrow down the list of candidate",
      "offset": 667.92,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "matches and if that gives me a small",
      "offset": 670.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "enough number of candidates that I can",
      "offset": 672.76,
      "duration": 3.079
    },
    {
      "lang": "en",
      "text": "afford to evaluate them all then I'll go",
      "offset": 674.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "on to my next steps in the process of",
      "offset": 675.839,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "calculating string similarity",
      "offset": 677.8,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "calculating descriptor penalties and",
      "offset": 679.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "getting the final score but if we cck",
      "offset": 680.8,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "connected components gives me still",
      "offset": 683.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "leaves me with too many um possible",
      "offset": 685.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "pairs it hasn't narrowed things down far",
      "offset": 687.639,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "enough then I might move on to another",
      "offset": 689.6,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "algorithm called node similarity which",
      "offset": 692.32,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "is going to allow me to um narrow the",
      "offset": 694.839,
      "duration": 6.361
    },
    {
      "lang": "en",
      "text": "the field even further and if that is",
      "offset": 698.56,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "still too much data to process or if the",
      "offset": 701.2,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "the number of candidates is too high to",
      "offset": 705.44,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "run node similarity because node",
      "offset": 707.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "similarity is also a rather expensive",
      "offset": 709.079,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "operation another approach is to use",
      "offset": 711.12,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "fast RP with KNN and we're going to talk",
      "offset": 713.92,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "about each of these three options on the",
      "offset": 716.12,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "next few slides",
      "offset": 717.72,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "so the weekly connected components um",
      "offset": 719.68,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "algorithm is one that just asks the",
      "offset": 722.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "question is there any possible path that",
      "offset": 724.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "can get me from one node to another node",
      "offset": 726.88,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "in the graph it doesn't care about the",
      "offset": 729.8,
      "duration": 2.839
    },
    {
      "lang": "en",
      "text": "direction of the relationships it just",
      "offset": 731.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "says can I get from here to there so as",
      "offset": 732.639,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "I look at this P oops as I look at this",
      "offset": 735,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "picture um you know these three blue",
      "offset": 736.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "person nodes they all do have some kind",
      "offset": 739.399,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "of a path that links them together so I",
      "offset": 741.48,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "would want to evaluate and say okay How",
      "offset": 743.76,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "likely is it that any of them are",
      "offset": 745.6,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "actually duplicates whereas this person",
      "offset": 747.24,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "Noe over here on the right there is no",
      "offset": 749.72,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "path that connects me from this person",
      "offset": 752.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "to this person that means they're going",
      "offset": 754.16,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "to be in different weekly connected",
      "offset": 755.76,
      "duration": 3.079
    },
    {
      "lang": "en",
      "text": "components and there's really no reason",
      "offset": 757.279,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "that I need to spend time checking other",
      "offset": 758.839,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "Downstream tasks to see if they're the",
      "offset": 761.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "same person because they have no",
      "offset": 763.76,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "identifiers in common and so that allows",
      "offset": 765.04,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "me to segment the graph and break up my",
      "offset": 767.199,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "work in an efficient",
      "offset": 769.56,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "way now the next possible way of",
      "offset": 772.6,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "filtering things down even further is to",
      "offset": 775.44,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "use an algorithm called node similarity",
      "offset": 777.279,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "node similarity is asking uh how similar",
      "offset": 779.32,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "are two nodes sets of neighbors so if I",
      "offset": 782.12,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "look at this picture I've got two blue",
      "offset": 785.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "people nodes and they both share a phone",
      "offset": 786.639,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "and they share a location and then this",
      "offset": 789.88,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "one has also a social security number",
      "offset": 792.16,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "node that's not shared so two out of the",
      "offset": 794.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "three neighbors are shared and so this",
      "offset": 797.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "would have a jard score of",
      "offset": 799.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "23 and the jard is one of the metrics",
      "offset": 801.959,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "that you can use when you're running",
      "offset": 805.12,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "node similarity and it's often a good",
      "offset": 806.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Baseline you have an option of two other",
      "offset": 808.12,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "metrics one of them is called overlap",
      "offset": 810.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and with the overlap score instead of",
      "offset": 812.56,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "taking the size of the intersection of",
      "offset": 814.48,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "their neighborhood divided by the size",
      "offset": 817.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "of the Union of the neighborhood you the",
      "offset": 820.279,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "numerator of the fraction for overlap is",
      "offset": 823.24,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "the same it's the size of the",
      "offset": 825.399,
      "duration": 2.761
    },
    {
      "lang": "en",
      "text": "intersection of the neighborhood but",
      "offset": 826.639,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "then for the denominator we take the",
      "offset": 828.16,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "size of the smaller neighborhood so in",
      "offset": 830.279,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this case there are two nodes in common",
      "offset": 832.279,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "and then the node with the smaller",
      "offset": 834.759,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "neighborhood has two nodes in its",
      "offset": 836.079,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "neighborhood and so we have two over two",
      "offset": 838.279,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "so the um overlap score would be 1.0",
      "offset": 841.24,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "versus 2/3 for the jard score overlap",
      "offset": 844.04,
      "duration": 7.239
    },
    {
      "lang": "en",
      "text": "can be useful when you have missing data",
      "offset": 847.44,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "but it's not um it's not necessarily",
      "offset": 851.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "different data so in this case you know",
      "offset": 854.32,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "this person probably has a social",
      "offset": 856,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "security number I just don't know what",
      "offset": 857.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "it is so I don't want to penalize their",
      "offset": 859.199,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "um their relationship as far as possibly",
      "offset": 862.839,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "being the same thing just because I",
      "offset": 865.519,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "don't happen to have ass number",
      "offset": 866.959,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "associated with this",
      "offset": 869.56,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "account the final U metric that you can",
      "offset": 871.399,
      "duration": 8.521
    },
    {
      "lang": "en",
      "text": "um consider is the um cosine similarity",
      "offset": 875.519,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "cosine similarity um is good when you",
      "offset": 879.92,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "have weighted relationships uh between",
      "offset": 882.56,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "these nodes and and that brings up the",
      "offset": 885.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "point that all these relationships can",
      "offset": 887.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "potentially be weighted if some of the",
      "offset": 890.16,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "relationships are more significant than",
      "offset": 892.36,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "others and I also want to mention that",
      "offset": 895.24,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "if you're wanting to use weighted",
      "offset": 898,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "relationships with node similarity I",
      "offset": 899.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "would encourage you to make sure that",
      "offset": 901.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "your GDs version is upgraded to version",
      "offset": 904,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "2.10.1 there was an important bug fix in",
      "offset": 907.079,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "that release that um solves some issues",
      "offset": 910.32,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "with weighted jard and so 2.10.1 or",
      "offset": 913.519,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "later is recommended if you're using",
      "offset": 917.6,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "node similarity in a weighted",
      "offset": 919.639,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "context now the um node similarity is a",
      "offset": 923.639,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "great algorithm but it's also a little",
      "offset": 926.959,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "bit expensive and for a really big graph",
      "offset": 929.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "it can be slow to run and so another",
      "offset": 931.399,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "alternative um is to use an algorithm",
      "offset": 934.04,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "called Fast RP which creates embeddings",
      "offset": 937.36,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "for our for our nodes in the graph so",
      "offset": 940.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "basically if you start with a graph that",
      "offset": 943.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "looks like this you apply fast RP and",
      "offset": 945.199,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "you turn each of those nodes into a",
      "offset": 947.639,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "point in a vector space and then I can",
      "offset": 949.8,
      "duration": 7.88
    },
    {
      "lang": "en",
      "text": "look for each node um node Vector what",
      "offset": 952.48,
      "duration": 7.64
    },
    {
      "lang": "en",
      "text": "are the other node vectors that are most",
      "offset": 957.68,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "nearby that's what the k nearest",
      "offset": 960.12,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "neighbors stand for and so if I was",
      "offset": 961.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "asking for the two nearest neighbors for",
      "offset": 963.6,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "this note it would point me to this one",
      "offset": 965.48,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "and this one as blue nodes that are",
      "offset": 967.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "neighbors of this one in space and those",
      "offset": 969.399,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "would then become the candidates that I",
      "offset": 971.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "would check to see if they might be",
      "offset": 973.319,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "duplicates the fast RP um is very very",
      "offset": 975.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "fast to run that's that's how it got its",
      "offset": 979,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "name it just does some um magical matrix",
      "offset": 980.839,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "multiplication uh to run and so that's",
      "offset": 984.319,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the advantage of this approach the dis",
      "offset": 987.44,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "Advantage is it's an approximate",
      "offset": 988.959,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "approach it's not exact like you would",
      "offset": 990.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "get with um with the node similarity",
      "offset": 992.399,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "approach so there's a little bit of a",
      "offset": 996.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "trade-off with performance and",
      "offset": 998.319,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "approximation if you go this route uh a",
      "offset": 1000.399,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "couple of of pointers that I would offer",
      "offset": 1004.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you one of the most important parameters",
      "offset": 1006.24,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "that you can tune with fast RP is the",
      "offset": 1008.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "iteration weights and that tells you as",
      "offset": 1011.639,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "you're running fast RP how far out",
      "offset": 1014.44,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "across the graph do I need to listen for",
      "offset": 1017.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "signals to create the embedding for each",
      "offset": 1020.079,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "node and in our case if it's like a",
      "offset": 1022.44,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "bipartite graph like we've been looking",
      "offset": 1024.4,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "at I really don't need to go out more",
      "offset": 1026.079,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "than two or three hops I don't need to",
      "offset": 1028.12,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "have an iteration weight that has five",
      "offset": 1029.959,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "or six or seven um positions in that",
      "offset": 1031.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "iteration weight Vector because that's",
      "offset": 1035.199,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "lising way too far out when I'm really",
      "offset": 1037.039,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "just looking for who are my nodes that",
      "offset": 1039,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "are just a couple of hops out and so set",
      "offset": 1041,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "a low iteration weight of probably two",
      "offset": 1043.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "or three at the most uh when you're",
      "offset": 1045.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "using fasp for this purpose and then",
      "offset": 1047.76,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "when you're running K nearest neighbors",
      "offset": 1050.76,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "what it's doing is it's starting with a",
      "offset": 1052.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "node and then it is getting a suggested",
      "offset": 1053.799,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "set of other neighbors that might be the",
      "offset": 1057.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "closest K nodes and then it just tries",
      "offset": 1059.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "to swap out other um nodes into that",
      "offset": 1061.32,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "neighbor set to see if it can improve",
      "offset": 1063.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the the distances Associated from the",
      "offset": 1066.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "node that you started from well that",
      "offset": 1068.76,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "initial um potential neighbor set that",
      "offset": 1071.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it starts from can be generated in a",
      "offset": 1074.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "couple ways one is with just a uniform",
      "offset": 1076.4,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "random sample where it could pick any",
      "offset": 1078.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "node from anywhere in the in the vector",
      "offset": 1079.72,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "space anywhere on the graph the other",
      "offset": 1081.84,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "alternative is to use a random walk and",
      "offset": 1083.919,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "this is usually the better approach if",
      "offset": 1086.039,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you're trying to just find the nearest",
      "offset": 1087.799,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "neighbors because it's just going to",
      "offset": 1089.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "search out um starting from your Source",
      "offset": 1090.36,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "node and find neighbors within a random",
      "offset": 1094.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "walk around it and those are the ones",
      "offset": 1097.32,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "that we're most interested in checking",
      "offset": 1099,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to see if they are duplicates anyway so",
      "offset": 1100.4,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "the random walk initializer is a good um",
      "offset": 1103.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "Step if you're using fast RP with kest",
      "offset": 1105.919,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "neighbors",
      "offset": 1108.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "all right so now that we've identified",
      "offset": 1109.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "our candidates we're going to move on to",
      "offset": 1111.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "calculating the similarity score and",
      "offset": 1114.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "there are probably some properties like",
      "offset": 1117.64,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "a product name or a person name that are",
      "offset": 1119.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "just text properties that we would like",
      "offset": 1121.52,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "to compare and Neo forj within our APO",
      "offset": 1123.24,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "text uh Library offers a whole bunch you",
      "offset": 1127.12,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "see a long list here on this slide of",
      "offset": 1130.36,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "different ways of comparing texts I'll",
      "offset": 1132.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "just point out a couple that I think are",
      "offset": 1135.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "the most useful for our purposes the",
      "offset": 1136.84,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "11in distance is a very common text uh",
      "offset": 1138.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "comparison algorithm it just is really",
      "offset": 1141.6,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "about edit distance how many",
      "offset": 1143.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "transpositions or substitutions or",
      "offset": 1144.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "deletions are required to turn one",
      "offset": 1147.28,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "string into another string so that's a a",
      "offset": 1149.12,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "good Baseline one to start from Le",
      "offset": 1151.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "similarity is basically the same",
      "offset": 1154.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "algorithm but it's just been inverted so",
      "offset": 1156.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "that a high score coming from Leen",
      "offset": 1158.64,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "similarity means that the two nodes are",
      "offset": 1160.799,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "almost or the two strings are almost the",
      "offset": 1163.24,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "same whereas a high score with line",
      "offset": 1165.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "distance means that they are very",
      "offset": 1167.919,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "different because you had to do a lot of",
      "offset": 1169.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "edits to turn one into the other so just",
      "offset": 1171,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "keep in mind that very similar strings",
      "offset": 1173.159,
      "duration": 6.041
    },
    {
      "lang": "en",
      "text": "will have a low L distance and a high 11",
      "offset": 1175.6,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "similarity another algorithm to be aware",
      "offset": 1179.2,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "of is the gero Winkler distance and this",
      "offset": 1181.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "algorithm prioritizes matching the",
      "offset": 1184.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "beginning of the strings and it's",
      "offset": 1186.24,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "usually a good one for personal names",
      "offset": 1187.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "because if I was typing in my name",
      "offset": 1189.799,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "surely I'm going to get my first initial",
      "offset": 1191.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "right uh and maybe down you know later",
      "offset": 1192.919,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "on in the string I might slip up and",
      "offset": 1195.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "make a typo but this can be a good one",
      "offset": 1196.64,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "for um for",
      "offset": 1199.4,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "names this is also the point in our um",
      "offset": 1202.6,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "entity resolution process where we're",
      "offset": 1206,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "going to look at conflicting descriptors",
      "offset": 1207.559,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "and create some kind of a penalty",
      "offset": 1210.08,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "associated with that if I look at this",
      "offset": 1211.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "picture here's two PE person nodes they",
      "offset": 1213,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "both share the same phone they both",
      "offset": 1215.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "share the same address oh so that looks",
      "offset": 1216.6,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "promising that might be the same if I",
      "offset": 1218.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "look at their names the strings are only",
      "offset": 1219.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "one character apart so that seems also",
      "offset": 1222,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "very promising Robert Johnson Roberta",
      "offset": 1224.08,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "Johnson you might be thinking they're",
      "offset": 1225.96,
      "duration": 2.839
    },
    {
      "lang": "en",
      "text": "the same but then when you look at",
      "offset": 1227.64,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "gender this one is male this one is",
      "offset": 1228.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "female and you realize oh that actually",
      "offset": 1230.72,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "makes it now that I have that extra",
      "offset": 1233.12,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "piece of information it actually makes",
      "offset": 1234.6,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "it a lot less likely the same person",
      "offset": 1236,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "that they duplicates and so um so that's",
      "offset": 1238.559,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "an important um piece of information we",
      "offset": 1241.6,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "want include in our final",
      "offset": 1244.08,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "formula so to find this final formula",
      "offset": 1246.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "basically we're just going to combine",
      "offset": 1249.08,
      "duration": 2.44
    },
    {
      "lang": "en",
      "text": "all the ingredients that we've been",
      "offset": 1250.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "working with so far I'm going to take",
      "offset": 1251.52,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "the node similarity score that's maybe",
      "offset": 1253.32,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "going to come from K nearest neighbors",
      "offset": 1255.4,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "or coming from node similarity and",
      "offset": 1256.88,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "that's the way that I'm going to account",
      "offset": 1258.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "for the the common neighbors I've also",
      "offset": 1260.12,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "got maybe a string similarity score",
      "offset": 1262.76,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "that's based on how similar the text",
      "offset": 1264.799,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "properties are and then I've also got a",
      "offset": 1266.4,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "penalty for unmatched um descriptors and",
      "offset": 1268.6,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "I will apply some kind of a weight and",
      "offset": 1271.64,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "sometimes I'll just kind of look at the",
      "offset": 1273.559,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "data and kind of play with those",
      "offset": 1274.72,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "different ways to see what seems to work",
      "offset": 1276.279,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "best or if we have a d duplicated data",
      "offset": 1278.039,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "set that you're already confident in I",
      "offset": 1281.279,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "could train a machine learning model to",
      "offset": 1282.72,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "find the right way to combine these",
      "offset": 1284.36,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "ingredients maybe with a logistic",
      "offset": 1285.96,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "regression to get the right weights for",
      "offset": 1287.4,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "our",
      "offset": 1289.679,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "inputs so here's an example of a Cypher",
      "offset": 1290.799,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "query how we could do this um I'm going",
      "offset": 1293.24,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "to start by streaming out I created in",
      "offset": 1296.2,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "mutate mode when I ran um node",
      "offset": 1298.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "similarity a new relationship in my",
      "offset": 1301.799,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "projection called has similar",
      "offset": 1303.88,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "identifiers and it's going to have a",
      "offset": 1305.279,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "similarity score that I'm going to get",
      "offset": 1306.72,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "back from utap mode and then um when it",
      "offset": 1308.32,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "comes back from the graph projection The",
      "offset": 1312.919,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "Source node ID is just a number the",
      "offset": 1315.679,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "target node ID is just a number so I'm",
      "offset": 1317.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "going to call gdsu till. as node to turn",
      "offset": 1319.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "those into actual",
      "offset": 1322.08,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "nodes and now I've got those nodes I can",
      "offset": 1323.64,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "retrieve their text properties their",
      "offset": 1326.039,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "name properties here and then I can call",
      "offset": 1327.679,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "the Lin similarity function to get the",
      "offset": 1329.36,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "text",
      "offset": 1331.88,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "similarity I can also check to see if",
      "offset": 1333.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "their gender properties are different",
      "offset": 1335.36,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "and if they are I can include a penalty",
      "offset": 1337.039,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "for having different",
      "offset": 1339.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "genders and finally I'm just going to",
      "offset": 1340.84,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "combine it so I'm going to wait the",
      "offset": 1342.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "identifier similarity is 65% of the",
      "offset": 1344.64,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "score the text similarity is 35% of the",
      "offset": 1346.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "score and then add on the descriptor",
      "offset": 1349.96,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "penalties and that's going to give me my",
      "offset": 1351.159,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "final similarity score and then anything",
      "offset": 1352.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "that's above a threshold I'm going to",
      "offset": 1355.44,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "say these are duplicate nodes anything",
      "offset": 1357.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "below the threshold I'm going to say is",
      "offset": 1359.799,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "probably not",
      "offset": 1361.24,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "duplicates so now I figured out what is",
      "offset": 1362.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "probably a duplicate I'm going to store",
      "offset": 1365.76,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "the results in My Graph one way to do",
      "offset": 1367.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "this is to actually create a new node",
      "offset": 1370.12,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "like in this case a person group node",
      "offset": 1372.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "and all of the nodes that have a a",
      "offset": 1375.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "similarity score above the the threshold",
      "offset": 1377.52,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "get related to that same uh person group",
      "offset": 1380.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "node and the nice thing about this is I",
      "offset": 1383.36,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "can still see all of the inputs oops all",
      "offset": 1385.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of the inputs that went into that person",
      "offset": 1387.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "group node so if I come back later and",
      "offset": 1389.44,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "wonder why these things are related I",
      "offset": 1391.799,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "can see you know well this is what they",
      "offset": 1393.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "had in common or this is what the",
      "offset": 1395.6,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "similarity score was so this is often a",
      "offset": 1396.76,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "good way to to handle um the the results",
      "offset": 1399.32,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "of your similarity um",
      "offset": 1404.039,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "calculations another option is we have",
      "offset": 1406.52,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "this ao. reactor. merge nodes procedure",
      "offset": 1408.799,
      "duration": 6.521
    },
    {
      "lang": "en",
      "text": "that you can call now this is going to",
      "offset": 1412.559,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "actually take those separate nodes and",
      "offset": 1415.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "collapse them down into one and this can",
      "offset": 1417.159,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "be nice because your end users sometimes",
      "offset": 1419.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "don't want to have to go look out to",
      "offset": 1421.88,
      "duration": 2.919
    },
    {
      "lang": "en",
      "text": "that group node they just want to see",
      "offset": 1423.08,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "you know the result um collapsed like",
      "offset": 1424.799,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "that the disadvantage to collapsing them",
      "offset": 1427.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "is that you kind of destroy the the",
      "offset": 1429.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "input ingredients a little bit harder to",
      "offset": 1432.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "retrace and see why you collaps these",
      "offset": 1434.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "nodes that were separate in the source",
      "offset": 1436.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "system to be together so that's that's",
      "offset": 1438.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the major downside but if you choose to",
      "offset": 1440.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "use this you have some options uh if the",
      "offset": 1442.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "The Source nodes have slightly different",
      "offset": 1445.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "properties you can choose to take the",
      "offset": 1447.72,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "property value from the first node or",
      "offset": 1449.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "take the value from the last node in the",
      "offset": 1451.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "list that you're collapsing or you can",
      "offset": 1453.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "actually preserve all the unique values",
      "offset": 1455.279,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "as a list valued property um when you",
      "offset": 1457.36,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "combine them so that's something that",
      "offset": 1459.4,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "you can configure you can also configure",
      "offset": 1460.559,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "if these two nodes that you're combining",
      "offset": 1462.799,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "are both related to the same neighbor",
      "offset": 1464.36,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "node then you can um choose to collapse",
      "offset": 1466.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "that relationship that way after you've",
      "offset": 1469.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "done the merging you don't end up with",
      "offset": 1471,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "two parallel relationships pointing to",
      "offset": 1472.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "the same NE you just have one",
      "offset": 1474,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "relationship so those are some things to",
      "offset": 1475.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "configure with",
      "offset": 1477.44,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "that another option is um not to change",
      "offset": 1479.44,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "your graph at all but to send your",
      "offset": 1483.52,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "results back to the source system and",
      "offset": 1485.32,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "then you can merge them there or D",
      "offset": 1487.559,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "duplicate them perhaps with a human in",
      "offset": 1489.279,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "the loop to help you figure out you know",
      "offset": 1491.279,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "was was this really a data entry error",
      "offset": 1493.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "of some kind that you can clean up and",
      "offset": 1495.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "then when you reing that data to neop",
      "offset": 1497.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "forj the duplicates that you have",
      "offset": 1499.08,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "identified will be cleaned",
      "offset": 1500.679,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "up so that gives us our whole graph",
      "offset": 1504.399,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "entity resolution process from beginning",
      "offset": 1507.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "to end we designed the graph data model",
      "offset": 1509.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that showed the shared",
      "offset": 1511.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "identifiers then we made sure that we",
      "offset": 1512.84,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "standardized the data uh before we",
      "offset": 1515.08,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "loaded into the graph and then we could",
      "offset": 1517.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "also use GDs to flag the placeholders",
      "offset": 1518.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "where we had the same value showing up",
      "offset": 1521.279,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "more often than we would expect it to",
      "offset": 1522.96,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "with different",
      "offset": 1524.52,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "profiles um then we identifi the",
      "offset": 1525.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "candidate entity pairs that we wanted to",
      "offset": 1528.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "compare and we had three different ways",
      "offset": 1530.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "to do that depending really on the",
      "offset": 1532.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "volume of the data and then um we",
      "offset": 1534.039,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "calculated the similarity score things",
      "offset": 1537.52,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "that were above a certain threshold with",
      "offset": 1539.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that similarity score we assume are the",
      "offset": 1541.279,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "same and then we could record those",
      "offset": 1543.08,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "results of the entity resolution process",
      "offset": 1545.08,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "in the graph so thank you very much for",
      "offset": 1548.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "your attention are there any questions",
      "offset": 1551.64,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "let me jump over to the Q&amp;A",
      "offset": 1553.52,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "how is fast RP different from",
      "offset": 1563.32,
      "duration": 8.599
    },
    {
      "lang": "en",
      "text": "vectorizing the property of each",
      "offset": 1568.52,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "node um oh let's see there's more to",
      "offset": 1571.919,
      "duration": 8.76
    },
    {
      "lang": "en",
      "text": "this like the new Neo forj Vector index",
      "offset": 1575.2,
      "duration": 10.44
    },
    {
      "lang": "en",
      "text": "so um that's a good question Nick um",
      "offset": 1580.679,
      "duration": 8.081
    },
    {
      "lang": "en",
      "text": "fast RP is really about vectorizing",
      "offset": 1585.64,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "the topology of the graph you can",
      "offset": 1588.76,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "potentially include node properties when",
      "offset": 1590.799,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "you run fast RP but for the the",
      "offset": 1592.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "situation that we're doing here I would",
      "offset": 1595.24,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "recommend that you simply you've already",
      "offset": 1597.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "moved those properties for the shared",
      "offset": 1600.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "identifiers off to be their own nodes",
      "offset": 1602.08,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "and then it's really the the topology or",
      "offset": 1604.48,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "the",
      "offset": 1606.52,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "relationships um within the graph that",
      "offset": 1607.279,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "we're trying to encode with",
      "offset": 1609.559,
      "duration": 8.84
    },
    {
      "lang": "en",
      "text": "um with the fast RP and so that's that's",
      "offset": 1613.279,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "what you're going to get out versus um",
      "offset": 1618.399,
      "duration": 7.88
    },
    {
      "lang": "en",
      "text": "the vector index is more um if I have a",
      "offset": 1620.72,
      "duration": 8.839
    },
    {
      "lang": "en",
      "text": "new query Vector that I want to check on",
      "offset": 1626.279,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "um I can query that and it's kind of",
      "offset": 1629.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "like the K nearest neighbors but it's",
      "offset": 1632.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "done in real time for one specific",
      "offset": 1633.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Vector that you're trying to trying to",
      "offset": 1636.2,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "match so hopefully that answers that",
      "offset": 1638.6,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "question adequately and Kenneth asks if",
      "offset": 1641.159,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "I have a blog post for this methodology",
      "offset": 1644.08,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "and I don't but it would be a good idea",
      "offset": 1646.32,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "to write one um so thank you for that",
      "offset": 1648.52,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "suggestion and this video will also be",
      "offset": 1651.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "um available on our YouTube channel so",
      "offset": 1655,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "you can come back and refer to that as",
      "offset": 1657.48,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "well and Mark asks",
      "offset": 1659.159,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "um the recommended strategies are to be",
      "offset": 1664.24,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "done after we have data in the graph",
      "offset": 1666.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "what are some data collection NLP andg",
      "offset": 1668.279,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "resolution processes you can do",
      "offset": 1671.12,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "beforehand and that's very true that um",
      "offset": 1673.44,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "you know C ly you don't have to do",
      "offset": 1677.159,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "everything after it's in the graph that",
      "offset": 1680.159,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "um and I think some of the",
      "offset": 1683.6,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "standardization topics that we talked",
      "offset": 1685.559,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "about about um you know um just trimming",
      "offset": 1687.519,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "the white spaces around or making sure",
      "offset": 1691.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that everything's in the same format",
      "offset": 1692.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that's a really good way before you even",
      "offset": 1694.6,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "load the data into the graph to begin to",
      "offset": 1696.6,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "um to handle this entity resolution but",
      "offset": 1700,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "as much of the processes you've done in",
      "offset": 1703.279,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "advance in in other ways with with other",
      "offset": 1705.399,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "tools tools and then you bring that into",
      "offset": 1707.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the graph you can still reflect the",
      "offset": 1709.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "results of that in the same way that we",
      "offset": 1711.6,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "were showing with the graph-based",
      "offset": 1713.6,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "approach where maybe you make a group",
      "offset": 1714.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "node that you relate everything to um or",
      "offset": 1716.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "or you possibly even merge the nodes",
      "offset": 1719.76,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "after you bring them in that can still",
      "offset": 1721.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "be relevant even if you've done some of",
      "offset": 1724.76,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "the other work",
      "offset": 1726.36,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "Upstream so let's see I think we're just",
      "offset": 1728.64,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "about out of time but do we have any",
      "offset": 1731.12,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "more um questions",
      "offset": 1733,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "here um I think we might have addressed",
      "offset": 1735.88,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "them",
      "offset": 1739.08,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "all great well enjoy the rest of nodes",
      "offset": 1740.519,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "and if you have any questions uh beyond",
      "offset": 1743.6,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "what I answer today feel free to reach",
      "offset": 1745.76,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "out and we'd be happy to continue the",
      "offset": 1747.32,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "conversation",
      "offset": 1749,
      "duration": 3
    }
  ],
  "cleanText": "My name is Nathan Smith.\nI'm a senior data scientist in the Neo4j Professional Services Division.\nI joined Neo4j in 2021, so I've been here for a little bit over three years.\nBefore coming to Neo4j, I had done previous graph work as a data scientist at Love Every and P Health Sciences, and my home is in Kansas City, Missouri.\nI'd like to kind of motivate this session with a quote from Nick Harway, who said, \"Who wrote garbage in, garbage out,\" or rather more felicitously, \"The tree of nonsense is watered with error, and from its branches swing the pumpkins of disaster.\"\nOn almost every data science project that I work with with Neo4j, one of the first steps is always doing some kind of entity resolution, and that's um, really important to make sure that whether the data is all coming from one system or whether it's coming from multiple systems, that we've resolved those entities to match um, items in the real world.\nAnd when I failed to do that upfront, then often the pumpkin of disaster has come back to smack me in the end.\nThere are several sessions today about entity resolution.\nIt's a great topic.\nThere in fact, there's one going on right now with Paco Nathan from Sensing.\nThere's another I saw earlier today from Linkurious, and so I would encourage you to check those out on the videos.\nYou know, sometimes you need a more of a rich application type of approach to entity resolution.\nThe approach that I'm going to take is more of a lightweight approach that you might take um, before you maybe advance and move on to something that's more um, application focused and more complex.\nIn talking about this, the title of this session is a Graph Entity Resolution Playbook.\nI want to distinguish between uh, a recipe versus a Playbook.\nWhen I think of a recipe, I think of like the technical challenge on the British Baking Show, where you got an explicit list of step-by-step things to do, you've got the exact ingredients that you need, and you want everything to come out very consistently, exactly the same way every time.\nAnd contrast that with a Playbook, you know, being from Kansas City, it's almost obligatory that I'm a fan of the Kansas City Chiefs, and their head coach Andy Reid comes into the game not with a recipe of what he's going to do um, step by step all through the whole game, but he does have a Playbook.\nHe's got some things that he has worked out in advance that he knows have worked many times in other contexts that then he can apply as needed against the various opponent or based on injuries or the weather or whatever changes.\nHe can adapt, but he's got a bag of tricks that he can pull from, and that's really what I want you to come away from this session is not necessarily an explicit recipe, but a bag of tricks that you can pull from as you're working on your own projects.\nSo at a high level, this graph entity resolution process that I'm going to outline for you begins by designing a graph data model that shows shared identifiers.\nOnce we have that data model, we're going to populate it with standardized data, and we're also going to flag what I call placeholders, and we'll talk about what that means later.\nThen we want to identify candidate entity pairs that might be entities in the real world that are the same.\nThen we'll calculate a similarity score, and for items that um, are above a threshold on that similarity score, we're going to record the results of the entity resolution process in our graph.\nSo to begin, we need to find a good graph data model, and sometimes when I come into a project, I see a data model that looks like the one on the left, and in some ways this makes sense because I want to find out if these two people are the same.\nSo I've got the two person nodes, and then here I've got a whole bunch of properties that tell me everything I know about that person.\nThe challenge with this data model for entity resolution, though, is that from a graph perspective, there's really nothing that connects these two people.\nI have to look at the individual properties.\nThe looking at the individual properties like that is almost like I might as well just do the entity resolution in Python with record linkage or some other technology that's not really a graph.\nHowever, if I come over here at this data model that's on the right, if I refactor the data so that um, the shared identifiers are actually shared nodes that both of these um, people nodes are connected to, they both have the same phone number, they both have the same social security number, now as just as a visual, when I look at this from a graph standpoint, I can suddenly see where the connections are, and I don't have to compare property by properties I would with the model on the left.\nSo identifying these shared identifiers and breaking them out as separate nodes is a good first step.\nNow there's also a potential pitfall here because I think it's important we identify or make a difference between what I call identifiers versus descriptors.\nIdentifiers are things that are pretty unique that wouldn't be shared by more than a few people in the real world, like a phone number, maybe two or three people share the same phone number, but not 100 people, um, or a social security number or something like that.\nA descriptor on the other hand is something that might be shared by a whole lot of people.\nSo if you look at this picture on the right, we've broken out gender as its own node, and then everybody who has the same value for gender is now suddenly pointing to the same node.\nIt creates a super node, which is not ideal for us, and the fact that two people are connected to the same gender node doesn't really tell me that much that they are actually the same person, they just happen to have the same gender.\nSo this would be a poor example of splitting out every single property into its own um, node and and linking them together if it's really a descriptor and not an identifier.\nAnother piece of the data model that I often find useful is to um, treat the addresses in a special way.\nOften um, location data can be an important part of telling if two things are the same, and here I'm looking at um, an address node, and what we can do is apply a geocoding service, maybe from Esri or from Google Map apps, or all of the cloud providers um, have these geocoding services where you can put in an address and then it's going to give you back a latitude and a longitude, and um, and so I'll make a separate node for that location that has the latitude and longitude with the point type uh, within Neo4j, and that way if I have two different addresses where maybe there's just a slight variation, like this one was spelled St or this one was spelled Street, all spelled out, but otherwise it's basically the same address, um, I can tell that they're at least pointing to the same location in the real world.\nNow once we have that data model um, in mind, we want to start to fill it in with the actual data that we're trying to um, clean up, and as we do that, it's important that we standardize the data and identify placeholders.\nSo um, as we're looking at our raw data, we want to apply whatever formatting is necessary to bring it into a standard format.\nSo if there's maybe leading or trailing white spaces, we want to strip strip those off.\nUm, for the phone numbers, if there's like parentheses around the area code or or the country codes or different things like that, we just want to make sure that every record is consistent that way if I see the same string value, I know that that actually is the same thing um, from the source data.\nSame thing for emails, make sure they're all lowercase.\nSocial Security numbers, do they have the dashes to separate the segments or do they not?\nAll things like this that can standardize the property before we load it into the graph.\nThen there's also things that we can do to validate properties because there are certain rules that apply to different types of data that say whether or not it's a valid value or not.\nFor example, if you're dealing with phone numbers, if in the United States, there are no US area codes that begin with the range 100 to 199, so if you see that value come in, you know, oh, this one's actually invalid, there's a typo going on here, or maybe there's some kind of fraud.\nUh, same thing for Social Security numbers, there are certain ranges that are invalid ranges.\nI've recently been working on a project with NPI numbers that identify pharmacies or medical professionals, and the last number of the NPI number is actually a check digit that has to have a certain value based on the other numbers that are part of that string, and so I can tell maybe there was a typo along the way somewhere, or maybe this NPI number was just made up by somebody.\nUm, so I usually go ahead and load this invalid data into the graph because it could be a signal for fraud detection or something, but I put a special label on it, and so I can exclude it from the candidate matching because just because two people have the same invalid identifier um, in common, that means that doesn't necessarily mean that they're probably the same person in the real world, it just means they both made a typo is what I would normally assume from that.\nNow there also what I call placeholders, and these are things that happen when somebody has a required field build on a form, but they don't know what to put in there, and so they just put my phone number is 9999999999 or something like that, or none at.com is my email address.\nAgain, this is not something that is going to help me identify a person in the real world because there is no such phone number as that in the real world, and so we want to try to identify these placeholder values and um, hold them out from our analysis.\nAnd one way that we can do that is using the graph data science degree algorithm to figure out are that some of these identifiers have a very high degree because remember an identifier is something that you wouldn't expect to be shared by more than you know, a handful of people or objects in the real world.\nSo I might make a graph projection that has the phone numbers and then the people associated with those phone numbers, and if there's a phone number that has a very high degree, then it's probably a placeholder, and I can run that um, degree algorithm in stats mode to just get a sense of the overall distribution, like where's the 99th percentile for the the most um, common phone numbers, and then I can also run it in stream um, mode to get back the actual values, and then again, I can label these values that are above whatever threshold I want to say, hold these out and don't include them in the um, next steps of the process.\nSo now that we have our data model loaded into the graph, the next step is to identify entity pairs that might be duplicates.\nNow when you think about this process of comparing nodes with each other, if I compare every single node with every single other node in the graph, that's a quadratic um, operation there that's going to take a lot of resources, a lot of memory, and a lot of time to compare every single thing with every single other thing, and so um, if I can narrow down the universe of things that need to be compared, my entity resolution operation can happen much faster.\nSo this is the workflow that I that I follow usually.\nI'll load the graph data model, and then the first thing I'll do is use an algorithm called weakly connected components to um, start to narrow down the list of candidate matches, and if that gives me a small enough number of candidates that I can afford to evaluate them all, then I'll go on to my next steps in the process of calculating string similarity, calculating descriptor penalties, and getting the final score.\nBut if we connected components gives me still leaves me with too many um, possible pairs, it hasn't narrowed things down far enough, then I might move on to another algorithm called node similarity, which is going to allow me to um, narrow the the field even further, and if that is still too much data to process or if the the number of candidates is too high to run node similarity because node similarity is also a rather expensive operation, another approach is to use fast RP with KNN, and we're going to talk about each of these three options on the next few slides.\nSo the weakly connected components um, algorithm is one that just asks the question, is there any possible path that can get me from one node to another node in the graph?\nIt doesn't care about the direction of the relationships, it just says, can I get from here to there?\nSo as I look at this P, oops, as I look at this picture, um, you know, these three blue person nodes, they all do have some kind of a path that links them together, so I would want to evaluate and say, okay, how likely is it that any of them are actually duplicates, whereas this person node over here on the right, there is no path that connects me from this person to this person.\nThat means they're going to be in different weakly connected components, and there's really no reason that I need to spend time checking other downstream tasks to see if they're the same person because they have no identifiers in common, and so that allows me to segment the graph and break up my work in an efficient way.\nNow the next possible way of filtering things down even further is to use an algorithm called node similarity.\nNode similarity is asking uh, how similar are two nodes sets of neighbors.\nSo if I look at this picture, I've got two blue people nodes, and they both share a phone, and they share a location, and then this one has also a social security number node that's not shared.\nSo two out of the three neighbors are shared, and so this would have a Jaccard score of 2/3, and the Jaccard is one of the metrics that you can use when you're running node similarity, and it's often a good baseline.\nYou have an option of two other metrics, one of them is called overlap, and with the overlap score, instead of taking the size of the intersection of their neighborhood divided by the size of the union of the neighborhood, you the numerator of the fraction for overlap is the same, it's the size of the intersection of the neighborhood, but then for the denominator, we take the size of the smaller neighborhood.\nSo in this case, there are two nodes in common, and then the node with the smaller neighborhood has two nodes in its neighborhood, and so we have two over two, so the um, overlap score would be 1.0 versus 2/3 for the Jaccard score.\nOverlap can be useful when you have missing data, but it's not um, it's not necessarily different data.\nSo in this case, you know, this person probably has a social security number, I just don't know what it is, so I don't want to penalize their um, their relationship as far as possibly being the same thing just because I don't happen to have a SS number associated with this account.\nThe final metric that you can um, consider is the um, cosine similarity.\nCosine similarity um, is good when you have weighted relationships uh, between these nodes, and and that brings up the point that all these relationships can potentially be weighted if some of the relationships are more significant than others, and I also want to mention that if you're wanting to use weighted relationships with node similarity, I would encourage you to make sure that your GDS version is upgraded to version 2.10.1.\nThere was an important bug fix in that release that um, solves some issues with weighted Jaccard, and so 2.10.1 or later is recommended if you're using node similarity in a weighted context.\nNow the um, node similarity is a great algorithm, but it's also a little bit expensive, and for a really big graph, it can be slow to run, and so another alternative um, is to use an algorithm called Fast RP, which creates embeddings for our for our nodes in the graph.\nSo basically, if you start with a graph that looks like this, you apply fast RP, and you turn each of those nodes into a point in a vector space, and then I can look for each node um, node vector, what are the other node vectors that are most\n\n\nNearby, that's what the K nearest neighbors stand for. So, if I was asking for the two nearest neighbors for this node, it would point me to this one and this one as blue nodes that are neighbors of this one in space, and those would then become the candidates that I would check to see if they might be duplicates.\n\nThe fast RP, um, is very, very fast to run. That's how it got its name. It just does some, um, magical matrix multiplication, uh, to run, and so that's the advantage of this approach. The disadvantage is it's an approximate approach. It's not exact like you would get with, um, with the node similarity approach. So there's a little bit of a trade-off with performance and approximation if you go this route.\n\nUh, a couple of pointers that I would offer you: one of the most important parameters that you can tune with fast RP is the iteration weights, and that tells you as you're running fast RP, how far out across the graph do I need to listen for signals to create the embedding for each node. And in our case, if it's like a bipartite graph like we've been looking at, I really don't need to go out more than two or three hops. I don't need to have an iteration weight that has five or six or seven, um, positions in that iteration weight vector because that's listening way too far out when I'm really just looking for who are my nodes that are just a couple of hops out. So set a low iteration weight of probably two or three at the most, uh, when you're using fast RP for this purpose.\n\nAnd then when you're running K nearest neighbors, what it's doing is it's starting with a node, and then it is getting a suggested set of other neighbors that might be the closest K nodes, and then it just tries to swap out other, um, nodes into that neighbor set to see if it can improve the distances associated from the node that you started from. Well, that initial, um, potential neighbor set that it starts from can be generated in a couple ways. One is with just a uniform random sample where it could pick any node from anywhere in the vector space, anywhere on the graph. The other alternative is to use a random walk, and this is usually the better approach if you're trying to just find the nearest neighbors because it's just going to search out, um, starting from your source node and find neighbors within a random walk around it, and those are the ones that we're most interested in checking to see if they are duplicates anyway. So the random walk initializer is a good, um, step if you're using fast RP with K nearest neighbors.\n\nAll right, so now that we've identified our candidates, we're going to move on to calculating the similarity score. And there are probably some properties like a product name or a person name that are just text properties that we would like to compare. And Neo4j, within our APOC text, uh, library, offers a whole bunch. You see a long list here on this slide of different ways of comparing texts. I'll just point out a couple that I think are the most useful for our purposes. The Levenshtein distance is a very common text, uh, comparison algorithm. It just is really about edit distance: how many transpositions or substitutions or deletions are required to turn one string into another string. So that's a good baseline one to start from. Levenshtein similarity is basically the same algorithm, but it's just been inverted so that a high score coming from Levenshtein similarity means that the two nodes are almost, or the two strings are almost the same, whereas a high score with Levenshtein distance means that they are very different because you had to do a lot of edits to turn one into the other. So just keep in mind that very similar strings will have a low Levenshtein distance and a high Levenshtein similarity. Another algorithm to be aware of is the Jaro-Winkler distance, and this algorithm prioritizes matching the beginning of the strings, and it's usually a good one for personal names because if I was typing in my name, surely I'm going to get my first initial right, uh, and maybe down, you know, later on in the string, I might slip up and make a typo, but this can be a good one for, um, for names.\n\nThis is also the point in our, um, entity resolution process where we're going to look at conflicting descriptors and create some kind of a penalty associated with that. If I look at this picture, here's two person nodes. They both share the same phone, they both share the same address. Oh, so that looks promising, that might be the same. If I look at their names, the strings are only one character apart, so that seems also very promising: Robert Johnson, Roberta Johnson. You might be thinking they're the same, but then when you look at gender, this one is male, this one is female, and you realize, oh, that actually makes it, now that I have that extra piece of information, it actually makes it a lot less likely they're the same person, that they're duplicates. And so, um, so that's an important, um, piece of information we want to include in our final formula.\n\nSo to find this final formula, basically, we're just going to combine all the ingredients that we've been working with so far. I'm going to take the node similarity score that's maybe going to come from K nearest neighbors or coming from node similarity, and that's the way that I'm going to account for the common neighbors. I've also got maybe a string similarity score that's based on how similar the text properties are, and then I've also got a penalty for unmatched, um, descriptors, and I will apply some kind of a weight, and sometimes I'll just kind of look at the data and kind of play with those different ways to see what seems to work best, or if we have a deduplicated data set that you're already confident in, I could train a machine learning model to find the right way to combine these ingredients, maybe with a logistic regression to get the right weights for our inputs.\n\nSo here's an example of a Cypher query, how we could do this. Um, I'm going to start by streaming out. I created in mutate mode when I ran, um, node similarity, a new relationship in my projection called HAS_SIMILAR_IDENTIFIERS, and it's going to have a similarity score that I'm going to get back from UMAP mode. And then, um, when it comes back from the graph projection, the source node ID is just a number, the target node ID is just a number, so I'm going to call `gds.util.asNode` to turn those into actual nodes. And now I've got those nodes, I can retrieve their text properties, their name properties here, and then I can call the Levenshtein similarity function to get the text similarity. I can also check to see if their gender properties are different, and if they are, I can include a penalty for having different genders. And finally, I'm just going to combine it. So I'm going to weight the identifier similarity is 65% of the score, the text similarity is 35% of the score, and then add on the descriptor penalties, and that's going to give me my final similarity score. And then anything that's above a threshold, I'm going to say these are duplicate nodes. Anything below the threshold, I'm going to say is probably not duplicates.\n\nSo now I figured out what is probably a duplicate. I'm going to store the results in my graph. One way to do this is to actually create a new node, like in this case, a person group node, and all of the nodes that have a similarity score above the threshold get related to that same, uh, person group node. And the nice thing about this is I can still see all of the inputs, oops, all of the inputs that went into that person group node. So if I come back later and wonder why these things are related, I can see, you know, well, this is what they had in common, or this is what the similarity score was. So this is often a good way to to handle, um, the results of your similarity, um, calculations.\n\nAnother option is we have this `apoc.refactor.mergeNodes` procedure that you can call. Now, this is going to actually take those separate nodes and collapse them down into one, and this can be nice because your end users sometimes don't want to have to go look out to that group node, they just want to see, you know, the result, um, collapsed like that. The disadvantage to collapsing them is that you kind of destroy the input ingredients a little bit, harder to retrace and see why you collapsed these nodes that were separate in the source system to be together. So that's the major downside, but if you choose to use this, you have some options. Uh, if the source nodes have slightly different properties, you can choose to take the property value from the first node or take the value from the last node in the list that you're collapsing, or you can actually preserve all the unique values as a list-valued property, um, when you combine them. So that's something that you can configure. You can also configure if these two nodes that you're combining are both related to the same neighbor node, then you can, um, choose to collapse that relationship that way. After you've done the merging, you don't end up with two parallel relationships pointing to the same node, you just have one relationship. So those are some things to configure with that.\n\nAnother option is, um, not to change your graph at all, but to send your results back to the source system, and then you can merge them there or deduplicate them, perhaps with a human in the loop to help you figure out, you know, was this really a data entry error of some kind that you can clean up, and then when you re-ingest that data to Neo4j, the duplicates that you have identified will be cleaned up.\n\nSo that gives us our whole graph entity resolution process from beginning to end. We designed the graph data model that showed the shared identifiers, then we made sure that we standardized the data, uh, before we loaded into the graph, and then we could also use GDS to flag the placeholders where we had the same value showing up more often than we would expect it to with different profiles. Um, then we identified the candidate entity pairs that we wanted to compare, and we had three different ways to do that, depending really on the volume of the data. And then, um, we calculated the similarity score. Things that were above a certain threshold with that similarity score, we assume are the same, and then we could record those results of the entity resolution process in the graph. So thank you very much for your attention. Are there any questions? Let me jump over to the Q&A.\n\nHow is fast RP different from vectorizing the property of each node? Um, oh, let's see, there's more to this, like the new Neo4j vector index. So, um, that's a good question, Nick. Um, fast RP is really about vectorizing the topology of the graph. You can potentially include node properties when you run fast RP, but for the situation that we're doing here, I would recommend that you simply, you've already moved those properties for the shared identifiers off to be their own nodes, and then it's really the topology or the relationships, um, within the graph that we're trying to encode with, um, with the fast RP. And so that's, that's what you're going to get out versus, um, the vector index is more, um, if I have a new query vector that I want to check on, um, I can query that and it's kind of like the K nearest neighbors, but it's done in real time for one specific vector that you're trying to, trying to match. So hopefully that answers that question adequately.\n\nAnd Kenneth asks if I have a blog post for this methodology, and I don't, but it would be a good idea to write one. Um, so thank you for that suggestion, and this video will also be, um, available on our YouTube channel, so you can come back and refer to that as well.\n\nAnd Mark asks, um, the recommended strategies are to be done after we have data in the graph. What are some data collection, NLP, and entity resolution processes you can do beforehand? And that's very true, that, um, you know, certainly you don't have to do everything after it's in the graph, that, um, and I think some of the standardization topics that we talked about, about, um, you know, um, just trimming the white spaces around or making sure that everything's in the same format, that's a really good way before you even load the data into the graph to begin to, um, to handle this entity resolution. But as much of the processes you've done in advance in, in other ways with, with other tools, and then you bring that into the graph, you can still reflect the results of that in the same way that we were showing with the graph-based approach, where maybe you make a group node that you relate everything to, um, or, or you possibly even merge the nodes after you bring them in. That can still be relevant even if you've done some of the other work upstream.\n\nSo let's see, I think we're just about out of time, but do we have any more, um, questions here? Um, I think we might have addressed them all. Great. Well, enjoy the rest of NODES 2024, and if you have any questions, uh, beyond what I answer today, feel free to reach out, and we'd be happy to continue the conversation.\n",
  "dumpedAt": "2025-07-21T18:43:26.012Z"
}