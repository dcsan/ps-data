{
  "episodeId": "Ej4pBDaHspk",
  "channelSlug": "@growproduct",
  "title": "If you only have 2 hrs, this is how to become an AI PM",
  "publishedAt": "2025-06-15T22:39:45.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Companies are laying off entire teams,",
      "offset": 0.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "entire orgs, and PMs are sort of grouped",
      "offset": 2.399,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "up into that. I almost never see it",
      "offset": 4.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "where an AIPM team is going to be laid",
      "offset": 6.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "off to some degree. Can anyone become an",
      "offset": 9.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "AIPM? I think we're all kind of feeling",
      "offset": 11.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "it, right? Like as product managers, the",
      "offset": 13.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "expectations on us. We kind of know our",
      "offset": 15.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "role is changing. What is the right way",
      "offset": 18.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to teach this material? What is the",
      "offset": 20,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "right sectioning of this material? And",
      "offset": 21.68,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "we've come up with five steps for you",
      "offset": 23.279,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "guys. So, we're going to go through AI",
      "offset": 25.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "prototyping, which is kind of the heart",
      "offset": 26.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "and soul of it all. We'll go into",
      "offset": 28.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "observability on top of our prototype,",
      "offset": 29.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "eval on our prototype, the difference",
      "offset": 32,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "between rag fine-tuning and prompt",
      "offset": 34.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "engineering. And then we'll end with",
      "offset": 36.399,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "working with AI engineers, working with",
      "offset": 38.079,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "researchers. So let's hop into AI",
      "offset": 40.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "prototyping.",
      "offset": 43.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "So for AIPMs, you'd really recommend",
      "offset": 44.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "they learn cursor over the other tools.",
      "offset": 47.12,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "I would recommend getting familiar with",
      "offset": 49.28,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "it. Definitely. Yeah. When it comes to",
      "offset": 50.879,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "people creating AIPM content, Aman Con",
      "offset": 52.879,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "is amongst the most insightful and",
      "offset": 55.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "informed. And that's because he's been",
      "offset": 57.92,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "an AIPM since 2019. He worked at Cruz on",
      "offset": 59.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "self-driving cars. He's worked with",
      "offset": 63.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "Spotify on their AI systems. And now he",
      "offset": 64.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "works at Arise, one of the leading",
      "offset": 67.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "observability and eval companies. So if",
      "offset": 68.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "we go back then and we compare those",
      "offset": 71.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "three terms that fine-tuning, prompt",
      "offset": 72.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "engineering, rag, how do those all",
      "offset": 74.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "compare? I think it's helpful to have",
      "offset": 76.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "just like a really quick diagram here of",
      "offset": 78.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like what is each thing. It kind of",
      "offset": 80.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "depends on what your goal is. So if your",
      "offset": 82.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "goal is to adjust the tone or the",
      "offset": 84.32,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "instructions, I think prompt engineering",
      "offset": 86.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "is really helpful for that. With rag,",
      "offset": 89.119,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "you can provide context over a lot of",
      "offset": 91.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "data. Fine-tuning is think of this as",
      "offset": 93.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "adjusting the model layer a little bit.",
      "offset": 95.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "So it's actually taking the LOI and",
      "offset": 97.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "making it more specialized. Working with",
      "offset": 99.759,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "AI engineers and researchers, working on",
      "offset": 101.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "these longer development timelines, how",
      "offset": 103.92,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "can AIPMs master that? Yeah. So, I think",
      "offset": 106,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "this is where",
      "offset": 108.799,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "really quickly I think a crazy stat is",
      "offset": 112.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "that more than 50% of you listening are",
      "offset": 115.119,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "not subscribed. If you can subscribe on",
      "offset": 117.2,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "YouTube, follow on Apple or Spotify",
      "offset": 119.6,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "podcasts, my commitment to you is that",
      "offset": 121.759,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "we'll continue to make this content",
      "offset": 124.719,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "better and better. And now on to today's",
      "offset": 126.479,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "episode.",
      "offset": 128.959,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "Welcome to the podcast, Aman. Thanks so",
      "offset": 131.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "much for having me, Akash. It's great to",
      "offset": 133.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "be here. I'm I've been waiting for this",
      "offset": 135.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "one for a long time. I'm so excited to",
      "offset": 136.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "speak to you. So, yeah, I think that",
      "offset": 138.48,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "there's no better person to really give",
      "offset": 140.8,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "us a crash course in all of the key AIPM",
      "offset": 142.879,
      "duration": 8.561
    },
    {
      "lang": "en",
      "text": "skills as they stand here in June 2025.",
      "offset": 147.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "But before we even get there, I need to",
      "offset": 151.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "know, can anyone become an AIPM? Yeah, I",
      "offset": 153.12,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "mean, I think the the whole narrative",
      "offset": 156.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "here of like, you know, I think we're",
      "offset": 159.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "all kind of feeling it, right? Like as",
      "offset": 161.599,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "product managers,",
      "offset": 163.599,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "the expectations on us, we we kind of",
      "offset": 165.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "know our role is changing. Our",
      "offset": 167.84,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "stakeholders are expecting more from us.",
      "offset": 170.08,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Our customers are expecting more from",
      "offset": 171.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "us. And I think we're already feeling",
      "offset": 173.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that role of AI in our day-to-day life",
      "offset": 176.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "more and more. I mean, that's the reason",
      "offset": 178.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "why that that narrative is really",
      "offset": 180,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "sticking. It's that, you know, can any",
      "offset": 181.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "PM become an AIPM? And I really think to",
      "offset": 183.84,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "just define what an AIPM is, it's really",
      "offset": 187.12,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "some flavor of either adopting AI in",
      "offset": 189.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "your day-to-day workflow. Think of this",
      "offset": 192.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "as like an AI powered PM or building AI",
      "offset": 194.08,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "into your product, which is you can",
      "offset": 197.92,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "think of that as like an AI product PM.",
      "offset": 199.84,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "And I really don't think that, you know,",
      "offset": 202.879,
      "duration": 7.841
    },
    {
      "lang": "en",
      "text": "being an AI PM is not an eitheror. I",
      "offset": 206.56,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "really view it more as an X. Meaning",
      "offset": 210.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "like you can think of yourself as a",
      "offset": 212.879,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "fintech X AIPM or a healthcare X AIPM.",
      "offset": 215.28,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "And the reason I say that is because AI",
      "offset": 219.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "is really powering your workflows as a",
      "offset": 222.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "product manager rather than taking the",
      "offset": 224.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "job you have away. you really want to be",
      "offset": 226.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "able to take that core insight and",
      "offset": 229.04,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "knowledge and specific industry uh sort",
      "offset": 231.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "of knowledge that you have and apply",
      "offset": 234.64,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "that towards the field using AI you know",
      "offset": 237.04,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "sort of to power those workflows. So",
      "offset": 240.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that's really how I view it. I think I",
      "offset": 242.239,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "think every PM will become some flavor",
      "offset": 243.92,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "of AIPM either using those tools or",
      "offset": 246.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "building around them if you aren't",
      "offset": 249.519,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "already. And I wouldn't view it as",
      "offset": 250.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "mutually exclusive with the type of",
      "offset": 252.319,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "product management you you might already",
      "offset": 254,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "be doing. So that's kind of how I view",
      "offset": 255.519,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "it. Think of it as like more of an",
      "offset": 256.799,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "accelerator on top of the workflows you",
      "offset": 258.239,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "already have. Agreed. And I think that",
      "offset": 260.639,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "people often come up with the edge cases",
      "offset": 263.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "like, &quot;Hey, I'm an internal tools PM or",
      "offset": 264.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "I work in this really regulated",
      "offset": 267.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "industry.&quot; But in the last few weeks and",
      "offset": 268.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "months, I've been talking to exactly",
      "offset": 270.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "those types of PMs implementing AI. I",
      "offset": 272.24,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "talked to an experimentation PM who is",
      "offset": 274.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "dealing with the problem that everybody",
      "offset": 276.479,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "else has a slight variation on their PRD",
      "offset": 277.84,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "template by getting an LLM to convert",
      "offset": 280,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "that into a clear output of what the",
      "offset": 282.479,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "hypothesis is, what the Northstar metric",
      "offset": 284.479,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "is, what the Gorald Royal metrics is. So",
      "offset": 286.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "genius use case to standardize input",
      "offset": 288.72,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "into his experimentation system. I've",
      "offset": 291.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "been talking to people over in the",
      "offset": 293.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "financial industries. They're working on",
      "offset": 294.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "new credit models based on AI. So it",
      "offset": 296.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "seems like whatever exception you draw",
      "offset": 299.44,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "up, there's going to be a counterpoint",
      "offset": 301.199,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "to that exception. And just about every",
      "offset": 302.639,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "PM needs to learn how to build AI",
      "offset": 304.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "features. I think that's that's totally",
      "offset": 306.08,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "true. Like and I I think there's",
      "offset": 308.32,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "definitely a feeling where",
      "offset": 312.479,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "there's maybe some some amount of like",
      "offset": 316.24,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "hesitation or, you know, unsure of like",
      "offset": 318.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "wanting to brand or label yourself as",
      "offset": 320.639,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "like, oh, I'm an AIP. I'm like kind of",
      "offset": 322.56,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "worried you might be jumping on some",
      "offset": 324.08,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "sort of like hype train. that I really",
      "offset": 325.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "urge folks to think about what the",
      "offset": 327.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "market for product management looks like",
      "offset": 329.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "and what the roles and skill sets will",
      "offset": 332.08,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "require in the future. And that's really",
      "offset": 334.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "why I think that, you know, the sooner",
      "offset": 337.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "that you kind of think of yourself as an",
      "offset": 339.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "AI PM building in fintech, building in",
      "offset": 341.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "healthcare, the faster you'll kind of",
      "offset": 344.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "adopt those tools, the faster you'll",
      "offset": 346.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "become a leader in in your own space in",
      "offset": 347.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that using using AI as well.",
      "offset": 349.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "So, enough talking. Let's get into the",
      "offset": 352.32,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "five skills. You and I have been going",
      "offset": 354.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "back and forth on what is the right way",
      "offset": 355.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to teach this material, what is the",
      "offset": 357.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "right sectioning of this material, and",
      "offset": 359.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "we've come up with five steps for you",
      "offset": 361.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "guys. So, we're going to go through AI",
      "offset": 362.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "prototyping, which is kind of the heart",
      "offset": 364.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "and soul of it all. We'll go into",
      "offset": 366.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "observability on top of our prototype,",
      "offset": 368.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Eval on our prototype, the difference",
      "offset": 370.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "between rag, fine-tuning, and prompt",
      "offset": 373.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "engineering. And then we'll end with",
      "offset": 376.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "working with AI engineers, working with",
      "offset": 378.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "researchers. All right, so now we're",
      "offset": 380.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "going to get into these skills starting",
      "offset": 382.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "with AI prototyping. So maybe even",
      "offset": 384.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "consider opening up your browser",
      "offset": 386.479,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "alongside Aman as we walk you through",
      "offset": 388.16,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "these key skills. Okay, so let's hop",
      "offset": 390.08,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "into AI prototyping. Um, so what we've",
      "offset": 393.199,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "got here, if you haven't seen this tool",
      "offset": 396.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "before, this is cursor. Cursor is",
      "offset": 399.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "basically fork of VS code which is a",
      "offset": 401.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "really common tool used by developers",
      "offset": 404.08,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "for actually you know has been used for",
      "offset": 406.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "many years to kind of write and iterate",
      "offset": 408.639,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "on code in an IDE which is an",
      "offset": 410.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "interactive developer environment. We're",
      "offset": 412.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "going to hop into using cursor as our",
      "offset": 415.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "prototyping tool just because the amount",
      "offset": 417.919,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "of improvements that have been made to",
      "offset": 420.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "it in sort of the recent weeks and",
      "offset": 422.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "months have made it really my go-to tool",
      "offset": 424.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "for prototyping even relative to some of",
      "offset": 427.199,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the others. right now. Um, you know,",
      "offset": 429.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "there's there and just to maybe linger",
      "offset": 432.319,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "on that point for a moment, there's a",
      "offset": 434,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "lot of tools out there like lovable,",
      "offset": 435.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "bolt, replet, versel, vzero, and I think",
      "offset": 437.68,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "they all have their place when it comes",
      "offset": 441.039,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "to prototyping. For instance, you know,",
      "offset": 443.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Verscell is really strong at front end.",
      "offset": 445.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Lovable and bolt is really easy to",
      "offset": 447.28,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "deploy and get started with. Uh, Replet",
      "offset": 449.199,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "is really powerful for Python-based",
      "offset": 451.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "applications and having an agent built",
      "offset": 453.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "in. But the reason I really like cursor",
      "offset": 455.759,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "is just because of the amount of control",
      "offset": 458.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and flexibility it gives me to be able",
      "offset": 460.479,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "to iterate on specific components. Um, I",
      "offset": 462.96,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "completely admit like it there's a",
      "offset": 466.639,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "little bit of a learning curve to get",
      "offset": 468.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "started with using cursor, but I promise",
      "offset": 470,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "you if you, you know, spend a little bit",
      "offset": 472.319,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of time on being able to just be able to",
      "offset": 474.319,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "kind of feel comfortable with the",
      "offset": 477.039,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "interface, you're going to get a lot",
      "offset": 478.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "more out of the tool just because of the",
      "offset": 480.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "the sort of the features and components",
      "offset": 482.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "it has built into it from a usability",
      "offset": 485.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "perspective. Um, maybe just so for",
      "offset": 487.919,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "AIPMs, you'd really recommend they learn",
      "offset": 490.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "cursor over the other tools. I would",
      "offset": 492.16,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "recommend getting familiar with it.",
      "offset": 494.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Definitely. Yeah. I I think that the",
      "offset": 495.919,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "other tools are going to keep improving",
      "offset": 498.16,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "and they're really helpful for building",
      "offset": 499.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "a really quick and dirty mock uh you",
      "offset": 501.759,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "know you know to build like just a quick",
      "offset": 504.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "UI. But if you really want to get a",
      "offset": 505.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "little bit deeper than that and",
      "offset": 508.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "understand how do I implement let's say",
      "offset": 510.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "an agent next or uh can I have more",
      "offset": 512.479,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "control over the system, you're going to",
      "offset": 515.839,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "need a tool like cursor. Um definitely.",
      "offset": 518.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Okay, cool. Yeah, maybe we can prototype",
      "offset": 521.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "like a agentic system since that's",
      "offset": 524,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "what's hot. Yeah, absolutely. I think",
      "offset": 526.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that's a great idea. So, let me go ahead",
      "offset": 528.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and actually start uh here from scratch.",
      "offset": 530.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "So, when you first load up cursor,",
      "offset": 532.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you're going to get um you know the",
      "offset": 534.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "screen where you can either set up a",
      "offset": 536.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "repo or set up a directory. It doesn't",
      "offset": 537.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "really matter what you get started with",
      "offset": 540.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "here. I have a starting point of a of a",
      "offset": 541.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "workspace, but the two this the two",
      "offset": 543.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "commands that you want to kind of hit",
      "offset": 547.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "right off the bat on your laptop are",
      "offset": 548.64,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "command T, which pulls up your terminal.",
      "offset": 550.959,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "And don't worry, you can actually just",
      "offset": 553.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "type in natural language instructions",
      "offset": 555.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "here to get started with uh terminal",
      "offset": 557.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "commands as well. So that's actually",
      "offset": 559.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "running the code on your computer. and",
      "offset": 561.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "then command K, which is uh really how",
      "offset": 563.68,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "you spin up the the the agent um which",
      "offset": 566.48,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "which you're going to be using for uh",
      "offset": 570,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "oh, looks like that commands. Oh, sorry,",
      "offset": 572.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "not command K. Uh what you're going to",
      "offset": 575.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "want to do is actually hit command L to",
      "offset": 577.12,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "pull up the agent. And the agent is this",
      "offset": 579.76,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "new kind of some somewhat new feature in",
      "offset": 583.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "cursor that allows you to uh go ahead",
      "offset": 585.68,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "and and actually it will write the code",
      "offset": 588.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "for you and actually run the code for",
      "offset": 591.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "you too. What I've been using recently",
      "offset": 593.6,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "is Claude 4 sonnet. Cloud 4 is just I",
      "offset": 596.64,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "think a massive improvement on top of",
      "offset": 600.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "previous models here when it comes to",
      "offset": 603.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "understanding commands and writing code.",
      "offset": 605.12,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "So really, I just go ahead and start",
      "offset": 607.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "typing in what I want this agent to do",
      "offset": 610.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and it's able to kind of get started",
      "offset": 613.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "from there. Um, let's take an example.",
      "offset": 614.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "So when we were talking about",
      "offset": 617.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "agent-based systems, I kind of pulled",
      "offset": 619.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this up. This is in our uh repo in",
      "offset": 620.8,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "Arise. It's a fully open source repo.",
      "offset": 623.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "It's a workflow for actually using Crew",
      "offset": 626.399,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "AI, which is a very kind of popular",
      "offset": 629.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "framework these days for setting up",
      "offset": 631.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "agent-based systems. Um, you can either",
      "offset": 634.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "use Crew AI. There's a ton of others out",
      "offset": 636.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "there. Uh, it doesn't really matter, but",
      "offset": 638.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "all I'm all I wanted to do is pull up",
      "offset": 641.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "some example context that I can use and",
      "offset": 643.519,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "plug in so that I kind of know what the",
      "offset": 646.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "output looks like. So, this is a",
      "offset": 648.399,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "notebook that just creates a Crew AI",
      "offset": 649.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "agent. Really just starts spinning up a",
      "offset": 652.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "workflow for research and deciding, you",
      "offset": 654.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "know, being able to do some market",
      "offset": 658.16,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "research. It doesn't matter, but it's mo",
      "offset": 659.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "more so just for grounding the the agent",
      "offset": 661.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in the first place. And what I'm going",
      "offset": 663.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "to do is actually rebuild and",
      "offset": 665.36,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "rearchitect this system entirely on the",
      "offset": 667.519,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "fly just using this code example. So the",
      "offset": 670.399,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "instructions I'm going to give are build",
      "offset": 672.8,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "me a trip planner agents using",
      "offset": 674.72,
      "duration": 8.679
    },
    {
      "lang": "en",
      "text": "instead of crew AI",
      "offset": 679.6,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "use lane graph",
      "offset": 683.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "which is just another framework really",
      "offset": 686.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "just to show like it doesn't matter",
      "offset": 688.32,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "which agent framework you use you can be",
      "offset": 689.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "really flexible here. The trip planner",
      "offset": 691.519,
      "duration": 8.401
    },
    {
      "lang": "en",
      "text": "should have a front end I can use as an",
      "offset": 695.36,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "application. So what I'm doing here is",
      "offset": 699.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "is basically defining I want this agent",
      "offset": 702.32,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "to have a UI that I can actually click",
      "offset": 705.68,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and interact with further. So we've got",
      "offset": 708.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "kind of two components in here uh which",
      "offset": 710.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "is build me a trip planner agent. here's",
      "offset": 712.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the framework to use and then if you",
      "offset": 714.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "need to, you know, you what you used to",
      "offset": 716.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "be able to do uh in the sort of before",
      "offset": 718.88,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "was actually use at web and um and at",
      "offset": 721.279,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "web allows the agent to go and sort of",
      "offset": 725.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "search the internet as well and take",
      "offset": 728.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "action actually search look at documents",
      "offset": 730,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and take that information and apply it",
      "offset": 732.639,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "in the code. So let's go ahead and and",
      "offset": 734.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "hit enter here and see the agent sort of",
      "offset": 736.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "go off on its own and and see what it",
      "offset": 739.2,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "generates. And it's not a very complex",
      "offset": 741.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "prompt really. No. And that that's sort",
      "offset": 743.519,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of the beauty of it. Like I I know that",
      "offset": 745.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "there's a ton of upfront work you can do",
      "offset": 748.399,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "to make that initial shot uh sort of",
      "offset": 751.04,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "what we kind of call in and prompting is",
      "offset": 754.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "like the first shot or zero shot better.",
      "offset": 756.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "But just know that the workflow I really",
      "offset": 758.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "promote in terms of people getting",
      "offset": 761.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "comfortable with these tools is just",
      "offset": 763.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "being able to iterate. And so knowing",
      "offset": 765.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "how to ask the right questions from the",
      "offset": 767.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "agent to give it what you want. So let's",
      "offset": 769.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "take a look here. So it says, I'll help",
      "offset": 772.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you build a trip planner agent using",
      "offset": 774.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "langraph instead of crew AI with a",
      "offset": 775.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "front-end application. And so it'll",
      "offset": 777.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "actually go in and read the tutorial and",
      "offset": 780.16,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "understand what the components are.",
      "offset": 782,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "Great. and says, &quot;Okay, I'm going to go",
      "offset": 790.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "ahead and take a look at this",
      "offset": 792.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "implementation and create the Langraph",
      "offset": 794.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "trip planner.&quot; So, it's going to go",
      "offset": 796.24,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "ahead and create a new directory for me.",
      "offset": 797.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "So, see, it didn't even matter what my",
      "offset": 799.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "starting point was because the agent can",
      "offset": 800.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "actually create folders on your machine.",
      "offset": 802.48,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "It can create directories. It can pull",
      "offset": 805.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "in the right data and even import",
      "offset": 806.959,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "packages. So, it's actually going off",
      "offset": 808.959,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "and doing this live. It's creating the",
      "offset": 810.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "requirements for the agent in the first",
      "offset": 812.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "place. Today's episode is brought to you",
      "offset": 814.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "by Miro. Let me ask you something. How",
      "offset": 816.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "many tools are you juggling just to get",
      "offset": 818.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "a single project across the finish line?",
      "offset": 820.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "One for brainstorming, another for",
      "offset": 822.079,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "planning, something else for tracking",
      "offset": 823.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "tickets. That's where Miro comes in. It",
      "offset": 825.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "becomes an all-in-one collaboration",
      "offset": 828,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "workspace. Whether you're consolidating",
      "offset": 830.24,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "user research from several interviews,",
      "offset": 832.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "developing and synthesizing product",
      "offset": 834.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "briefs or a wireframe or project",
      "offset": 836.399,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "managing development, Miro brings",
      "offset": 838.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "everyone into the same space. It's fast,",
      "offset": 841.279,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "intuitive, and fully loaded with",
      "offset": 844.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "features like project templates, two-way",
      "offset": 845.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "Jiraync, and integration with software",
      "offset": 848.24,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "like draw.io and plant UML. Miro's AI",
      "offset": 850.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "features can be used to synthesize",
      "offset": 854.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "elements in a board to develop a",
      "offset": 855.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "readyto-review product requirements",
      "offset": 857.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "document in seconds. If you're tired of",
      "offset": 859.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "tab overload and scattered workflows,",
      "offset": 861.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "try Murro. Head to miro.com and see why",
      "offset": 864.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "over 90 million users choose Murro to",
      "offset": 866.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "guide from idea to outcome. Today's",
      "offset": 868.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "episode is brought to you by Jira",
      "offset": 870.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "product discovery. If you're like most",
      "offset": 872.24,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "product managers, you're probably in",
      "offset": 874,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Jira tracking tickets and managing the",
      "offset": 875.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "backlog. But what about everything that",
      "offset": 877.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "happens before delivery? Jira product",
      "offset": 879.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "discovery helps you move your discovery,",
      "offset": 882.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "prioritization, and even road mapping",
      "offset": 884.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "work out of spreadsheets and into a",
      "offset": 886.32,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "purpose-built tool designed for product",
      "offset": 889.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "teams. Capture insights, prioritize what",
      "offset": 891.92,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "matters, and create road maps you can",
      "offset": 894.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "easily tailor for any audience. And",
      "offset": 896.959,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "because it's built to work with Jira,",
      "offset": 899.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "everything stays connected from idea to",
      "offset": 901.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "delivery. Used by product teams at",
      "offset": 903.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "Canva, Deliveroo, and even The",
      "offset": 905.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Economist. Check out why and try it for",
      "offset": 907.839,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "free today at aten.com/roduct-discovery.",
      "offset": 910.48,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "That's atlasia.com/roduct-discovery.",
      "offset": 915.519,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "Jurroduct discovery. Build the right",
      "offset": 922.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "thing.",
      "offset": 924.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "That chain of thought reasoning is",
      "offset": 927.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "really useful, too. It seems like that's",
      "offset": 928.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "one of the important steps for people is",
      "offset": 930.16,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "to actually understand a little bit of",
      "offset": 931.839,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "what's going on and not just ignore",
      "offset": 933.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that, but start learning. And as you do",
      "offset": 934.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that 10, 20 times, then you really get",
      "offset": 936.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "used to it. Absolutely. And being able",
      "offset": 938.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to, you know, what's what's really cool",
      "offset": 941.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "about this is you can actually go in and",
      "offset": 943.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "see what are the files that it",
      "offset": 945.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "referenced. Um, be able to see, okay,",
      "offset": 946.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "here's what it's referencing. So if you",
      "offset": 948.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "need to, you can always pause it, pause",
      "offset": 950.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "the agent and say, &quot;Hey, I actually want",
      "offset": 952.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "you to go take a look at this part of",
      "offset": 954.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the code or this resource.&quot; And what's",
      "offset": 956.079,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "really cool and we can kind of we'll",
      "offset": 958.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "kind of show this is you can even paste",
      "offset": 960.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "in images and using those images, the",
      "offset": 962,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "agent can actually, you know, kind of",
      "offset": 964.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "infer, oh, this is what I want the UI to",
      "offset": 966.079,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "look like or not. So it's a really",
      "offset": 968.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "really powerful multimodalbased",
      "offset": 969.519,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "uh agent that can write code. Um, so now",
      "offset": 972.399,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "it's actually writing the code of the",
      "offset": 975.68,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "file itself.",
      "offset": 977.759,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "And here",
      "offset": 983.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "what is going on behind the scenes? It's",
      "offset": 985.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "using those websites and the Phoenix uh",
      "offset": 987.519,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "thing that we started off with or it's",
      "offset": 991.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "writing a lot of scratch code. What's",
      "offset": 992.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "going on? Yeah. So, so actually, you",
      "offset": 994.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "know, the repo I kind of gave was just a",
      "offset": 996.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "starting point and it can really just be",
      "offset": 998.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "any directory.",
      "offset": 1000.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "What's going on underneath the hood is",
      "offset": 1002.24,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "the agent has kicked off a search. it",
      "offset": 1004.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "well first it took the prompt and the",
      "offset": 1007.199,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "context I gave the agent and it said let",
      "offset": 1008.959,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "me build a plan and that's actually the",
      "offset": 1012,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "first step in all of this is actually to",
      "offset": 1014.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "generate a plan uh which you it doesn't",
      "offset": 1016.639,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "show here but there is a a basically a",
      "offset": 1019.44,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "chain of thought for the plan here so if",
      "offset": 1022.639,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "you hit this uh thought for 4 seconds",
      "offset": 1025.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "you'll see what the agent is thinking it",
      "offset": 1027.52,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "should do and it says I should first",
      "offset": 1030,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "look at the crew AI tutorial design a",
      "offset": 1032.559,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "lang graphbased trip planner then build",
      "offset": 1034.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "a front-end application and then",
      "offset": 1037.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "integrate it all together. And so that's",
      "offset": 1038.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "just like you would give this to an",
      "offset": 1041.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "engineer if you were hopefully you're",
      "offset": 1042.799,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "giving better requirements to an",
      "offset": 1044.48,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "engineer, but you don't have to give",
      "offset": 1045.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "really good requirements to your agent",
      "offset": 1046.959,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "because the agent will just like make",
      "offset": 1048.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "sense of whatever you've given it and",
      "offset": 1050.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "try its best to figure it out. So it's",
      "offset": 1052.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "very robust to that.",
      "offset": 1054.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "So once you've got that plan, then the",
      "offset": 1057.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "agent executes code on your machine to",
      "offset": 1059.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "actually implement that plan. The first",
      "offset": 1062.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "thing it did was create a directory that",
      "offset": 1065.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "it's writing code into. So, it's",
      "offset": 1067.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "actually created a new folder uh in my",
      "offset": 1069.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "my workspace where it's actually writing",
      "offset": 1072.48,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "code uh you know on my machine. And the",
      "offset": 1074.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "code is really just text files. In this",
      "offset": 1077.919,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "case, it's Python. Um you can define",
      "offset": 1080.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "different frameworks if you want to. I",
      "offset": 1082.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "could have said use Python or use React,",
      "offset": 1084.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "but in this case, I've just let the",
      "offset": 1086.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "agent go off and do its thing. I wasn't",
      "offset": 1088.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "super prescriptive. Um so, great. So it",
      "offset": 1090.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "actually built the back end here which",
      "offset": 1092.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "you can see",
      "offset": 1094.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "and now it's going to build the React",
      "offset": 1096.799,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "front end. So it's going and actually",
      "offset": 1098.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "building uh you know building the UI",
      "offset": 1100.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "components. And just to zoom out for a",
      "offset": 1102.4,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "moment, to be able to do this even a",
      "offset": 1104.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "year ago would have been really really",
      "offset": 1107.84,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "challenging because you're just not",
      "offset": 1109.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "going to get robust UI components and uh",
      "offset": 1111.2,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "sort of an agent that understands what",
      "offset": 1114.96,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "goes into building a React application",
      "offset": 1118.799,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "with a degree of like confidence and",
      "offset": 1121.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "understanding when there's errors, how",
      "offset": 1124.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to fix those errors. So let me show you",
      "offset": 1125.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "an example here. The agent actually",
      "offset": 1127.84,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "built a file and what it found was that",
      "offset": 1130.16,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "there was an error in the file and on",
      "offset": 1133.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the fly it went back and it's rewriting",
      "offset": 1135.919,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "parts of the file because the agent can",
      "offset": 1138.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "actually see and read errors as they as",
      "offset": 1140.559,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "they come up and can is able to go back",
      "offset": 1142.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and iterate on those same files uh all",
      "offset": 1145.36,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "within the chat window as well.",
      "offset": 1148,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "Okay, in this case, there's times when",
      "offset": 1151.84,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "you as a human might need to intervene,",
      "offset": 1154.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "particularly when there's files being",
      "offset": 1157.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "deleted. So, it might prompt you to",
      "offset": 1159.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "either accept to do something or not.",
      "offset": 1161.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Um, I generally just let, you know, I'll",
      "offset": 1164,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "I'll take a look at what the agent is",
      "offset": 1165.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "asking me to review and then I'll either",
      "offset": 1167.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "accept or reject based on that. And it",
      "offset": 1169.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "can actually tweak its path based on",
      "offset": 1170.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "whether or not you accept or reject the",
      "offset": 1172.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "suggestion.",
      "offset": 1175.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Okay, great. So now it's going ahead and",
      "offset": 1177.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "creating a directory and installing all",
      "offset": 1179.919,
      "duration": 7.481
    },
    {
      "lang": "en",
      "text": "of the components for the UI right now.",
      "offset": 1182.48,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "So it seems like from 0 to one it might",
      "offset": 1187.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "be a teeny bit slower than a lovable",
      "offset": 1189.679,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "bolt or v 0ero but after 0 to one the",
      "offset": 1192.32,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "power to edit more implement more cursor",
      "offset": 1195.919,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "is allowing more potential. Absolutely.",
      "offset": 1198.64,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "I think that one way to think of it is",
      "offset": 1201.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "like the application that we've given it",
      "offset": 1203.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "is and I'm using a pretty capable model",
      "offset": 1206.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "as well. I'm using cloud 4 which is a",
      "offset": 1208.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "reasoning model. So it's a little bit",
      "offset": 1211.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "slower than some of the faster models",
      "offset": 1213.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "out there. But the reason that you you",
      "offset": 1214.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "know one reason to actually start here",
      "offset": 1217.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "is you just have complete control over",
      "offset": 1218.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the files. You can go in and if you",
      "offset": 1220.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "wanted to, one thing I do is actually",
      "offset": 1223.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "I'll take a look at the file and I'll",
      "offset": 1225.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "ask the agent. You can reference a",
      "offset": 1227.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "specific file here in the context window",
      "offset": 1229.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "and you can actually say what is going",
      "offset": 1232,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "on in this file and you can just have a",
      "offset": 1234.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "conversation with the code uh you know",
      "offset": 1236.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "with the agent on top of your code. So",
      "offset": 1239.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "even if you you know want to know do I",
      "offset": 1241.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "really need this file? Um can you make",
      "offset": 1244,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "this better? I noticed this one thing my",
      "offset": 1246.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "engineer pointed something out. you're",
      "offset": 1249.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "just going to have a lot more control",
      "offset": 1251.039,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "over that system using cursor. So, it's",
      "offset": 1252.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "it's worthwhile to invest a little bit",
      "offset": 1254.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "more time to get this thing set up on",
      "offset": 1256.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "your machine. Okay. And is it possible",
      "offset": 1258.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "to do those types of things in parallel",
      "offset": 1260.96,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "or while it's working? While it's",
      "offset": 1262.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "generating, you can't chat until this",
      "offset": 1263.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "generation is done. Yeah, I I think you",
      "offset": 1265.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "know we could try actually. So, I've",
      "offset": 1267.44,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "started a new chat. Let's see.",
      "offset": 1269.12,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "Okay.",
      "offset": 1281.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Yeah. So, so with cursor, you actually",
      "offset": 1283.28,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "Yeah, you can't have multiple",
      "offset": 1285.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "I don't believe you can have multiple",
      "offset": 1288.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "chat windows going at the same time. I",
      "offset": 1290.32,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "think you can only do one chat, but",
      "offset": 1292.64,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "maybe someone can prove me wrong there.",
      "offset": 1295.52,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "So now that it's done, you could chat",
      "offset": 1299.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "with it though. Yeah. Let's see. So this",
      "offset": 1300.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "one I think it I think we may have",
      "offset": 1302.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "broken it actually",
      "offset": 1305.76,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "continue building",
      "offset": 1308.08,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "which is you know part of part of",
      "offset": 1311.679,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "exploration. Did it actually finish or",
      "offset": 1313.039,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "not? Uh let's see.",
      "offset": 1314.64,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "Okay. So so what's funny is like the",
      "offset": 1319.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "system is super robust, right? Oh gosh.",
      "offset": 1321.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Like we we just broke it because I went",
      "offset": 1322.72,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "to another tab and I came back and I'm",
      "offset": 1324.4,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "like, &quot;Hey, you know what? I'm sorry for",
      "offset": 1326.159,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "interrupting your work. Just keep doing",
      "offset": 1327.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "what you were doing.&quot; And it's just",
      "offset": 1329.36,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "like, &quot;Oh, okay. Here's what I was doing",
      "offset": 1330.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "before. Let me just recap it for myself.",
      "offset": 1332.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "I'm just going to keep going on my way.&quot;",
      "offset": 1334.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "Right? It's sort of like tapping an",
      "offset": 1335.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "engineer on the shoulder. Like I'm not",
      "offset": 1337.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "worried about breaking my code anymore",
      "offset": 1339.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "or like changing one line because I know",
      "offset": 1341.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and I have so much confidence that the",
      "offset": 1344.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "system is going to be able to recover",
      "offset": 1346.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "from some of those mistakes when it",
      "offset": 1348.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "comes from starting from scratch. for",
      "offset": 1350.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "sure. Um, I would say if you try to go",
      "offset": 1352,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "to your like production codebase and",
      "offset": 1355.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you're like, &quot;Hey, can we start using",
      "offset": 1357.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "cursor all over the place like this?&quot;",
      "offset": 1358.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "You're going to get a lot of push back",
      "offset": 1360.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "because I will say like with these types",
      "offset": 1362,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of agents, they're really good for going",
      "offset": 1364.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "from zero to one and maybe even building",
      "offset": 1366.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "something that gets you to production.",
      "offset": 1368.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "But when you already have a system",
      "offset": 1371.039,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "that's using multiple dependencies,",
      "offset": 1373.12,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "it gets a little bit harder to know are",
      "offset": 1376.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "that like you really do want to make",
      "offset": 1379.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "sure the changes that you're making are",
      "offset": 1380.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "correct in the first place. So I do",
      "offset": 1382.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "recommend that you know at least when",
      "offset": 1384.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "you're just getting started. Use this on",
      "offset": 1386,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like zero to one projects that you own",
      "offset": 1388,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "entirely and not so much necessarily",
      "offset": 1390,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "your production code base that you might",
      "offset": 1392,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "be building on top of.",
      "offset": 1393.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Yeah, I was worried that it was going to",
      "offset": 1396.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "break when we were clicking around, but",
      "offset": 1398.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "it just started right back up. Yeah, I",
      "offset": 1400.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "think that's part of where Look, I mean,",
      "offset": 1402.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "I think I'll just say like from the",
      "offset": 1404.559,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "perspective of a product manager today,",
      "offset": 1406.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "being comfortable with the fact that",
      "offset": 1409.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "this thing is writing code. It's just",
      "offset": 1411.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "going to go off and start doing things.",
      "offset": 1413.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "You should really just feel comfortable",
      "offset": 1415.36,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "knowing how to interact with it. And",
      "offset": 1416.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that's I think part of that is just it's",
      "offset": 1418.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "it's just a comfort level that comes",
      "offset": 1420.72,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "with working with these tools.",
      "offset": 1422.24,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "for sure. Looks like can I edit some",
      "offset": 1426.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "files? But it'll just go out and",
      "offset": 1428.559,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "continue on its own. And this read me,",
      "offset": 1430.24,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "can we read that me read me and see",
      "offset": 1431.679,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "what's going on behind the Yeah,",
      "offset": 1433.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "absolutely. So, it's actually when it's",
      "offset": 1434.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "writing the file. So, you used to be",
      "offset": 1436.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "able to just see it like writing uh code",
      "offset": 1438.559,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "in real time. I think with the agent um",
      "offset": 1441.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the agent mode you have to wait until",
      "offset": 1443.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the file is written but let's give it a",
      "offset": 1445.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "sec to write that file and we can read",
      "offset": 1449.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "what the read me is because I think it's",
      "offset": 1450.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "often like a prd style doc exactly and",
      "offset": 1452.559,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and and you you could you know I think",
      "offset": 1455.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "that there's some really great examples",
      "offset": 1457.279,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "if we were being more sophisticated I",
      "offset": 1459.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "could have given it a better prompt as",
      "offset": 1461.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "well but you're right it's it's",
      "offset": 1463.84,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "basically here's what's going on",
      "offset": 1465.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "underneath the system nice and it says",
      "offset": 1466.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "this is what I did here are the fees",
      "offset": 1469.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that it has",
      "offset": 1471.44,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "architecture backend, front end, and",
      "offset": 1474.24,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "then written with full emojis.",
      "offset": 1476.799,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "Yeah, I don't know why uh LLMs really",
      "offset": 1480.08,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "like to use emojis these days. Um",
      "offset": 1482.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "um that's how you know somebody's",
      "offset": 1486.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "LinkedIn post had some chat GPT editing.",
      "offset": 1487.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Oh my gosh. I mean, that's I mean, for",
      "offset": 1489.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "sure. Yeah. Chat GPT Claude were",
      "offset": 1491.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "definitely trained on LinkedIn as well.",
      "offset": 1494.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "So So it kind of goes both ways, right?",
      "offset": 1496.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "It's like self-reinforcing with these",
      "offset": 1498.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "models. Yeah.",
      "offset": 1499.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Okay. So, it's actually so tried to run",
      "offset": 1502.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the code. It hit an example. It hit a",
      "offset": 1504.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "problem here and now it's actually",
      "offset": 1506,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "creating the Docker file. We don't",
      "offset": 1508.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "necessarily need Docker, but it's",
      "offset": 1510.08,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "helpful if you wanted to actually deploy",
      "offset": 1511.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "this thing. Docker is a way for you to",
      "offset": 1513.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "just wrap everything up and think of it",
      "offset": 1515.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "as like a folder that you can deploy and",
      "offset": 1517.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "put on the internet. Um. Yep. Okay. So,",
      "offset": 1519.279,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "it's writing all this. Uh, and what what",
      "offset": 1522.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "we can actually do is it's given me",
      "offset": 1525.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "enough information here where I can",
      "offset": 1526.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "actually try to run this live. So, uh, I",
      "offset": 1528.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "don't need to have it finish the Docker",
      "offset": 1531.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "file. Um, and it's sort of just running",
      "offset": 1533.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "tests. So, it actually knows to actually",
      "offset": 1535.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "test the agent itself, make sure that",
      "offset": 1537.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "the backend is working. And as long as",
      "offset": 1539.919,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "it's working, then it'll actually move",
      "offset": 1542,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "on to the next step.",
      "offset": 1543.279,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "Um, let's go ahead and So, it's got",
      "offset": 1545.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "local host. We've got it here. I have a",
      "offset": 1549.12,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "feeling that this might break. Uh but we",
      "offset": 1551.52,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "will try it because it didn't ask me for",
      "offset": 1555.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "an open AI key. So let's see what",
      "offset": 1558.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "happens.",
      "offset": 1559.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Okay,",
      "offset": 1561.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "let's first actually go to here.",
      "offset": 1563.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "Go to the back end. And so all I've done",
      "offset": 1566.559,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "now is I'm looking at the readme and it",
      "offset": 1568.64,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "actually lays out the quick start steps",
      "offset": 1571.279,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "for how to spin up the system. So all",
      "offset": 1573.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you have to do is copy paste these lines",
      "offset": 1575.919,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "of code. So I can go to lane graph. Um,",
      "offset": 1578.159,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and the a little bit of like the",
      "offset": 1581.919,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "terminal commands is helpful to know",
      "offset": 1583.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "like cd dot dot to navigate your",
      "offset": 1584.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "directory structure. Um, but we're going",
      "offset": 1587.12,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "to go ahead and and dot dot like moves",
      "offset": 1589.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you up a level, right? Exactly. Dot dot",
      "offset": 1593.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "moves you up a level and then ls lists",
      "offset": 1594.96,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "the files in there. Yeah.",
      "offset": 1597.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Um,",
      "offset": 1600.799,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "so we're going to try to go to cd agent",
      "offset": 1602.48,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "and cd is just change directory.",
      "offset": 1606.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "directory. Exactly.",
      "offset": 1608.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "PIP uh is your Python. So, um let's make",
      "offset": 1610.64,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "sure",
      "offset": 1614.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "we're in we're going to create a new",
      "offset": 1616.64,
      "duration": 7.919
    },
    {
      "lang": "en",
      "text": "Python um environment. So, let's call",
      "offset": 1620.4,
      "duration": 7.159
    },
    {
      "lang": "en",
      "text": "this.",
      "offset": 1624.559,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "So, we created a workspace. We set up a",
      "offset": 1635.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "project. Do we have an environment?",
      "offset": 1637.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "No. So, so one thing you definitely want",
      "offset": 1640.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "to be careful of when you're running",
      "offset": 1643.36,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "Python on your machine, every developer",
      "offset": 1644.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "will have faced this at some point. It's",
      "offset": 1647.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "sort of a right of passage, is you don't",
      "offset": 1648.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "want to be writing uh, you know,",
      "offset": 1651.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "updating packages and installing",
      "offset": 1653.2,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "packages to your Python locally. You",
      "offset": 1656,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "want to be using virtual environments uh",
      "offset": 1658.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "because your system Python is sort of",
      "offset": 1660.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "you want to kind of keep that protected",
      "offset": 1662.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "um because that can really break things.",
      "offset": 1664.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "So what we've done is just created a",
      "offset": 1666.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "virtual environment using a tool called",
      "offset": 1668.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "cond. And if you have if you get stuck",
      "offset": 1671.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "on that or you're like what is going on",
      "offset": 1673.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "here? Uh don't worry the agent will",
      "offset": 1675.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "actually you can you can also specify",
      "offset": 1677.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "use a virtual environment or you know",
      "offset": 1680,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "how should I do this on my machine and",
      "offset": 1682.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "it will help you out. It'll guide you",
      "offset": 1684,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "through those steps as well. Okay. Yeah.",
      "offset": 1685.36,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "Okay. So now we've kind of done that.",
      "offset": 1690.559,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "Now we're going to install our",
      "offset": 1692.159,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "requirements. So, we just we're in the",
      "offset": 1693.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "right directory and now we're just going",
      "offset": 1695.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "to hit pip install requirements. And if",
      "offset": 1696.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "this works, it will actually install",
      "offset": 1698.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "those requirements into my Python",
      "offset": 1700.48,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "virtual environment. Okay,",
      "offset": 1703.039,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "great. Um, set up environment variables.",
      "offset": 1708.559,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "Okay, so let me go here uh and open up",
      "offset": 1711.36,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "that file. So, we actually want to uh",
      "offset": 1715.039,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "name this env. So, actually, let's see",
      "offset": 1718.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "what environment variables it needs. I'm",
      "offset": 1720.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "not even sure. So, we're just going to",
      "offset": 1722.64,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "run the Python main and see what pops",
      "offset": 1724.32,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "up.",
      "offset": 1726.399,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "So, we'll go back and do the ENV",
      "offset": 1730,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "variables after exactly. Yeah, because",
      "offset": 1731.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "I'm kind of curious. I, you know, I",
      "offset": 1734.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "could go in and read it. Okay, module",
      "offset": 1736.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "not found. So, it looks like it hit a",
      "offset": 1738.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "problem here. This is great. Um, because",
      "offset": 1740.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "what that means is like I can go in and",
      "offset": 1742.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "just copy that error and say, &quot;Hey, you",
      "offset": 1744.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "hit this error. Let's see what Let's see",
      "offset": 1747.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "how it fixes that.&quot;",
      "offset": 1749.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Hit skip. Stop. And all I mostly do as",
      "offset": 1751.52,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "my workflow is copy the terminal, paste",
      "offset": 1755.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "it in and say, you know, just literally",
      "offset": 1758.32,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "just give it back to it and say, &quot;Hey,",
      "offset": 1760.08,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "there's this bug here.&quot; And it will read",
      "offset": 1761.52,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "the terminal lines and understand what's",
      "offset": 1764.399,
      "duration": 9.561
    },
    {
      "lang": "en",
      "text": "going on and try and infer that. Nice.",
      "offset": 1767.6,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "So, this is what I mean where I'm like",
      "offset": 1774.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "where I say don't be scared about things",
      "offset": 1776.159,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "breaking. They're going to break. What",
      "offset": 1778.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "matters is how you can work with the",
      "offset": 1781.279,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "agent to fix your problems. Yep. Today's",
      "offset": 1783.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "episode is brought to you by Maven. If",
      "offset": 1786.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you're enjoying this episode with Ammon,",
      "offset": 1788.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you'll love his course on Maven, today's",
      "offset": 1790.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "podcast sponsor. The problem with most",
      "offset": 1793.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "courses online like Udemy is there's no",
      "offset": 1795.36,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "live component and the instructors",
      "offset": 1797.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "aren't experts in their fields. They're",
      "offset": 1799.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "professors. At Maven, you get direct",
      "offset": 1800.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "live access to experts and operators",
      "offset": 1803.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "from the world's best tech companies.",
      "offset": 1805.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "You can't get that access anywhere else.",
      "offset": 1807.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "in any university and you usually can't",
      "offset": 1809.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "find them on YouTube either. I've",
      "offset": 1811.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "featured so many of Maven's experts in",
      "offset": 1812.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the newsletter and podcast for that",
      "offset": 1814.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "reason. To help you out, I've put",
      "offset": 1816.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "together a collection of courses I",
      "offset": 1818.88,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "recommend at maven.com/x/ashos.",
      "offset": 1820.24,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "This includes courses like AI",
      "offset": 1824.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "prototyping for PMs, product sense for",
      "offset": 1825.679,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "PMs, and getting an AIPM certification.",
      "offset": 1828.24,
      "duration": 7.4
    },
    {
      "lang": "en",
      "text": "Visit it now at mavve.comx",
      "offset": 1831.44,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "aka.",
      "offset": 1837.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "Today's episode is brought to you by",
      "offset": 1840.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "Amplitude. Replays of mobile user",
      "offset": 1841.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "engagement are critical to building",
      "offset": 1844.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "better products and experiences, but",
      "offset": 1846.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "many session replay tools don't capture",
      "offset": 1848.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "the full picture. Some tools take",
      "offset": 1850.48,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "screenshots every second, leading to",
      "offset": 1852.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "choppy replays and high storage costs",
      "offset": 1853.84,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "from enormous capture sizes. Others use",
      "offset": 1856.559,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "wireframes. But key moments go missing,",
      "offset": 1859.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "creating gaps in your understanding.",
      "offset": 1861.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "Neither approach gives you a truly",
      "offset": 1863.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "mobile experience. Amplitude does things",
      "offset": 1865.039,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "differently. Their mobile replays",
      "offset": 1867.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "capture the full experience. Every tap,",
      "offset": 1868.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "every scroll, and every gesture with no",
      "offset": 1871.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "lag, and no performance hit. It's the",
      "offset": 1873.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "most accurate way to understand mobile",
      "offset": 1875.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "behavior. See the full story with",
      "offset": 1877.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "amplitude and also setting aside enough",
      "offset": 1879.279,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "time to just persevere. Definitely.",
      "offset": 1881.44,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 1884.159,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Okay, now it's going to actually try to",
      "offset": 1891.679,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "run these commands. Let's see if that",
      "offset": 1893.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "works. Okay, so I have to",
      "offset": 1894.64,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "enter in OpenAI key. That's what I was",
      "offset": 1897.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "kind of expecting. So it actually built",
      "offset": 1899.919,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "this file. And great. Let me go ahead",
      "offset": 1901.6,
      "duration": 7.919
    },
    {
      "lang": "en",
      "text": "and insert an open AI key. Hopefully",
      "offset": 1905.12,
      "duration": 8.159
    },
    {
      "lang": "en",
      "text": "this works. Um I'm going to go ahead and",
      "offset": 1909.519,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "move this to",
      "offset": 1913.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "different window.",
      "offset": 1915.279,
      "duration": 6.841
    },
    {
      "lang": "en",
      "text": "so I don't blast this on the internet.",
      "offset": 1917.279,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "Okay. Yeah. Don't share your open AI",
      "offset": 1927.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "keys or your keys, you know, widely. Uh",
      "offset": 1929.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that's definitely something to keep in",
      "offset": 1932.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "mind. Um that'll be expensive fast.",
      "offset": 1934.24,
      "duration": 7.799
    },
    {
      "lang": "en",
      "text": "Yeah. Okay. Press enter.",
      "offset": 1936.88,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "Okay. Port is already in use. Go ahead.",
      "offset": 1943.039,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "Today's episode is brought to you by",
      "offset": 1947.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "Amplitude. Replays of mobile user",
      "offset": 1949.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "engagement are critical to being I had",
      "offset": 1951.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "something working in the background.",
      "offset": 1954.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Many session replay tools don't capture",
      "offset": 1956.48,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "the full picture. Some tools take",
      "offset": 1958.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "screenshots every second leading to",
      "offset": 1959.919,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "choppy replays, high storage costs from",
      "offset": 1961.679,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "enormous capture. Others use wireframes,",
      "offset": 1964.799,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "but key moments go missing, creating",
      "offset": 1967.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "gaps in your understanding. Neither",
      "offset": 1969.679,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "approach gives you a truly mobile",
      "offset": 1971.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "experience",
      "offset": 1973.039,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "does things different. Their mobile",
      "offset": 1974.559,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "replays capture the full experience",
      "offset": 1976.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "every tap",
      "offset": 1978.159,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "every gesture with no lag and no",
      "offset": 1980.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "performance. It's the most accurate way",
      "offset": 1981.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to understand mobile behavior. See the",
      "offset": 1984.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "full story with and also setting aside",
      "offset": 1986.159,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "enough time to just persevere.",
      "offset": 1988.96,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "Definitely.",
      "offset": 1991.279,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Okay. Now it's going to actually try to",
      "offset": 1999.44,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "run these commands. Let's see if that",
      "offset": 2000.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "works. Okay, so I have to",
      "offset": 2002.399,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "enter in OpenAI key. That's what I was",
      "offset": 2005.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "kind of expecting. So it actually built",
      "offset": 2007.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "this ENV file. And great. Let me go",
      "offset": 2009.36,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "ahead and insert an open AI key.",
      "offset": 2012.48,
      "duration": 8.24
    },
    {
      "lang": "en",
      "text": "Hopefully this works. Um I'm going to go",
      "offset": 2015.919,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "ahead and move this to",
      "offset": 2020.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "different window",
      "offset": 2023.039,
      "duration": 6.841
    },
    {
      "lang": "en",
      "text": "so I don't blast this on the internet.",
      "offset": 2025.039,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "Okay. Yeah. Don't share your OpenAI keys",
      "offset": 2035.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "or your keys, you know, widely. Uh",
      "offset": 2037.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that's definitely something to keep in",
      "offset": 2040.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "mind. Um that'll be expensive fast.",
      "offset": 2042,
      "duration": 7.88
    },
    {
      "lang": "en",
      "text": "Yeah. Okay. Press enter.",
      "offset": 2044.64,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "Okay. Port is already in use. Go ahead.",
      "offset": 2050.8,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "Not a big deal. I I had something",
      "offset": 2061.28,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "working in the background and it's going",
      "offset": 2062.879,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "to um kill that process. Okay, I added",
      "offset": 2064.399,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "my OpenAI key. Great. And now it says",
      "offset": 2068.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "it's built.",
      "offset": 2071.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Let's go ahead and navigate to that and",
      "offset": 2073.44,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "see where it's running.",
      "offset": 2075.28,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "I I feel like I didn't see the UI. Uh it",
      "offset": 2080.639,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "it looks like it ran the back end. Okay.",
      "offset": 2083.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "And now it says in a new terminal do",
      "offset": 2086.48,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "this. So let's go ahead and do that.",
      "offset": 2088.24,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "So we're going to go ahead and run this.",
      "offset": 2092.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "We're going to try this again. See if it",
      "offset": 2094.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "actually fixed the problems before.",
      "offset": 2096.399,
      "duration": 6.521
    },
    {
      "lang": "en",
      "text": "Still hitting this problem.",
      "offset": 2099.2,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "Existing virtual environment with an old",
      "offset": 2118.72,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "incompatible version. Okay,",
      "offset": 2121.119,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "that's okay. I mean, we'll just try that",
      "offset": 2125.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "again. We're going to uninstall those",
      "offset": 2127.119,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "old versions.",
      "offset": 2129.599,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "So, some of the steps that has you do",
      "offset": 2132.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "Oh, you could have hit run actually.",
      "offset": 2134.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Yeah, I can hit run in uh the terminal",
      "offset": 2135.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "environment on the right or the one on",
      "offset": 2138.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the left. Um for me, I just wanted to to",
      "offset": 2140.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "kind of take a look at it here. Um so,",
      "offset": 2142.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "I'm going to run it over here. Okay.",
      "offset": 2144,
      "duration": 7.8
    },
    {
      "lang": "en",
      "text": "Okay. Let's try this again.",
      "offset": 2147.68,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "So, we're going to install a fresh",
      "offset": 2152,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "virtual environment.",
      "offset": 2153.28,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Okay.",
      "offset": 2156.32,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "And when we see those errors there, what",
      "offset": 2161.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "are those like ignored the following",
      "offset": 2163.359,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "yanked version? Yeah, I think um so some",
      "offset": 2165.28,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "of these are uh if some of those",
      "offset": 2168.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "versions or those uh packages existed",
      "offset": 2171.599,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "already um then you know it kind of",
      "offset": 2174.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "looks a little bit scary because it's",
      "offset": 2176.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "like all in red or versions are",
      "offset": 2178.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "mismatching. Again, I would just say",
      "offset": 2180.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "like if you hit a bug or a problem, you",
      "offset": 2182.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "can always pass those back off to the",
      "offset": 2184.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "agent to go and fix. Okay. So, in this",
      "offset": 2185.839,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "case, it looks like it's trying to uh in",
      "offset": 2188.8,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "use a version that doesn't exist. So,",
      "offset": 2191.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "that might be part of the problem here",
      "offset": 2193.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "is it's uh actually trying to use a",
      "offset": 2194.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "version for a package that doesn't",
      "offset": 2196.96,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "exist.",
      "offset": 2198.24,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Okay.",
      "offset": 2201.599,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Yeah, I think there we go. It noticed",
      "offset": 2206.4,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "the same thing. So, it's going to work",
      "offset": 2207.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "with the current package.",
      "offset": 2209.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "So here it's saying okay you know what",
      "offset": 2212.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "let me just try to create a more simple",
      "offset": 2214,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "version of this uh this uh this agent",
      "offset": 2215.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and see if that works. So let's see if",
      "offset": 2218.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "this works in the first place just to",
      "offset": 2220.72,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "get something off the ground. So even",
      "offset": 2222.16,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "the the agent is sort of realizing you",
      "offset": 2223.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "know what I may have overbuilt this",
      "offset": 2225.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "first version. Let me go ahead and build",
      "offset": 2226.4,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "a simple version.",
      "offset": 2228,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "Probably PMs can relate with their PRDS.",
      "offset": 2233.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Maybe you overbuilt the first Yeah.",
      "offset": 2236.96,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "build a simpler MVP, right?",
      "offset": 2238.96,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "Happened to me certainly.",
      "offset": 2243.76,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "So, I'm just trying to read the code",
      "offset": 2250,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "here. Okay, it's generating. Yeah. So,",
      "offset": 2251.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "we can we can go ahead and read through",
      "offset": 2253.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "what's going on here actually a little",
      "offset": 2254.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "bit as well. Feels like co being able to",
      "offset": 2256.64,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "read this code is just a key skill. You",
      "offset": 2259.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "know, the best part is the reason I like",
      "offset": 2262.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "to work in Python is it is it is very",
      "offset": 2264.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "readable and the agent does a pretty",
      "offset": 2266.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "good job of commenting as well what it's",
      "offset": 2268.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "trying to do uh in the code. So you can",
      "offset": 2271.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "see okay so it's importing a bunch of",
      "offset": 2273.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "packages loading environment variables.",
      "offset": 2274.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Uh all that means is it's like loading",
      "offset": 2277.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "up the state that it needs to get",
      "offset": 2279.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "started and then it starts defining",
      "offset": 2281.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "classes and functions to actually",
      "offset": 2283.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "execute on the code. So let's go ahead",
      "offset": 2285.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and see what it's done here. So okay, so",
      "offset": 2287.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "we've created a simplified version Let's",
      "offset": 2289.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "try this and see if it works. And if it",
      "offset": 2292.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "doesn't, then",
      "offset": 2294.48,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "we're back to square one.",
      "offset": 2297.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "Okay. So, okay. So, it might just need",
      "offset": 2301.28,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "this package.",
      "offset": 2303.04,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "So, I'm just going to go ahead and paste",
      "offset": 2309.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "in those those errors again. I remember",
      "offset": 2311.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "doing all this without an agent. It was",
      "offset": 2314.079,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "like a lot of looking up Stack Overflow",
      "offset": 2315.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "and stuff. At least you have somebody to",
      "offset": 2317.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "talk to now. Yeah. Let's exactly let's",
      "offset": 2319.119,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "try on this uh let's try on this this",
      "offset": 2322.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "window and see if this is working. So",
      "offset": 2324.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "okay so there's a version conflict. So",
      "offset": 2327.76,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "it's because I think it actually created",
      "offset": 2329.599,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "like um two versions of the requirements",
      "offset": 2331.359,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "file and they were sort of sitting on",
      "offset": 2335.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "top of each other. That's okay. Let's",
      "offset": 2336.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "try this minimal version. Yeah and we",
      "offset": 2339.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "see like requirements minimal",
      "offset": 2341.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "requirements simple requirements.",
      "offset": 2343.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Yeah exactly. Right? This is really bad",
      "offset": 2346.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "practice that it implemented and you can",
      "offset": 2348,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "always go back and be like hey some you",
      "offset": 2349.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "know fix up the problems that you have",
      "offset": 2351.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "uh in your codebase and it will also be",
      "offset": 2353.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "able to go and simplify and remove",
      "offset": 2355.76,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "extraneous files. So I think that's like",
      "offset": 2358.24,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "a pretty common um occurrence like if",
      "offset": 2361.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you're testing with Python it's very",
      "offset": 2363.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "likely you're going to have package and",
      "offset": 2366.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "version dependency",
      "offset": 2368.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "uh problems. Yeah. Yeah. And so just I",
      "offset": 2370.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "think just accepting that that's like",
      "offset": 2372.8,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "part of working with Python through",
      "offset": 2374.16,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "again you're getting you're getting one",
      "offset": 2375.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "level deeper than like bolt and lovable",
      "offset": 2377.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "right so you you a little bit of that",
      "offset": 2378.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "comfort of there's a little bit more",
      "offset": 2381.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "code here but knowing that you can just",
      "offset": 2383.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "kind of again mostly what I'm doing is",
      "offset": 2386.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "copy pasting the errors and letting the",
      "offset": 2388.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "agent figure things out. I could go in",
      "offset": 2390,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "and read the code and try to understand",
      "offset": 2391.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "things better and that's worthwhile to",
      "offset": 2393.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "do when you're building something um to",
      "offset": 2395.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "production. But to just get something",
      "offset": 2397.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "off of the ground, I kind of let the",
      "offset": 2398.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "agent define, you know, here's the right",
      "offset": 2400.72,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "environment for me to work in. Yep.",
      "offset": 2402.64,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "Let's test if the simplified version",
      "offset": 2408.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "works.",
      "offset": 2410.72,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "Okay. Server",
      "offset": 2412.72,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "because it's actually testing if the",
      "offset": 2420.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "server has started and seeing what's the",
      "offset": 2422.64,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "problem with the server.",
      "offset": 2424.96,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "Okay, well we have a server up now. All",
      "offset": 2430.56,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "right, look at that. So, it actually",
      "offset": 2433.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "figured out, okay, you know what? I",
      "offset": 2435.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "might be on the wrong port. Let me see",
      "offset": 2436.64,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "if I should try to run this thing",
      "offset": 2438.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "differently. And here we go. So you can",
      "offset": 2439.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "actually see this is a Python server",
      "offset": 2442.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that it started and this is a backend",
      "offset": 2444.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "server that actually just routes the",
      "offset": 2446.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "calls that we're going to be using for",
      "offset": 2448.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "our trip planner agent. So this is a",
      "offset": 2449.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this is a backend that's up. Now what do",
      "offset": 2451.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you want to change about the backend?",
      "offset": 2454,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "The backend is basically a way to route",
      "offset": 2455.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "calls to open to open AI or to other",
      "offset": 2457.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "services. Um so it's actually uh you",
      "offset": 2459.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "know kind of doing this um in real time",
      "offset": 2461.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "like it it just built this back end for",
      "offset": 2464.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "us.",
      "offset": 2465.599,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "Nice. And what is it working on now?",
      "offset": 2467.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "It's a good question. It looks like it",
      "offset": 2470.96,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "has Okay, let's try to hit skip here.",
      "offset": 2472.8,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "You know what? Let's see. Okay, so it",
      "offset": 2476.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "wanted to test the back end and in the",
      "offset": 2479.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "in the Okay, so this is interesting.",
      "offset": 2481.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "That's actually really good example you",
      "offset": 2482.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "just pointed out, Akash. Sometimes when",
      "offset": 2485.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the agent is trying to run code in the",
      "offset": 2488,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "terminal, if it's a longstanding",
      "offset": 2490.16,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "process, it can get stuck. Uh and so you",
      "offset": 2492.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "might need to hit you know move to",
      "offset": 2495.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "background or skip just to have it move",
      "offset": 2496.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "on to the next step.",
      "offset": 2499.2,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "Okay. So let's try to actually run this",
      "offset": 2501.839,
      "duration": 9.921
    },
    {
      "lang": "en",
      "text": "now. Run the end to end application",
      "offset": 2506.8,
      "duration": 8.12
    },
    {
      "lang": "en",
      "text": "for me.",
      "offset": 2511.76,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "And remind me what's the difference",
      "offset": 2517.52,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "between this right side and the m the",
      "offset": 2518.72,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "bottom middle",
      "offset": 2520.48,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "the terminal you mean or the uh yeah",
      "offset": 2524.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "okay so so on the right side this is",
      "offset": 2527.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "think of this as like the agent",
      "offset": 2530.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "environment it can interact with your",
      "offset": 2531.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "terminal or you can have multiple",
      "offset": 2534.079,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "terminals up so you you'll see it",
      "offset": 2535.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "actually the terminal is these are the",
      "offset": 2537.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "idees consist of different windows that",
      "offset": 2540.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you can reconfigure in different ways",
      "offset": 2542.319,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that you want to so like I have a",
      "offset": 2544.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "terminal running in here. It actually",
      "offset": 2545.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "pulled up the terminal in this area. You",
      "offset": 2547.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "can have a terminal down here, but it's",
      "offset": 2550.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "really just wherever you're executing",
      "offset": 2551.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "code on the machine. Okay. So, the right",
      "offset": 2553.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "is the chat and it can go in and do",
      "offset": 2556.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "terminal commands. And sometimes you're",
      "offset": 2558.96,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "doing manual terminal commands in the",
      "offset": 2560.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "bottom middle. That's right. Exactly.",
      "offset": 2561.839,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Exactly. That's that's that's definitely",
      "offset": 2563.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "correct.",
      "offset": 2565.599,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "Okay. Now, it's starting the front end.",
      "offset": 2567.2,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "Let's see what it looks like.",
      "offset": 2568.56,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "Oh, it noticed there's a package",
      "offset": 2573.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "dependency. Now it's going to go back,",
      "offset": 2575.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "read that file, and let's look at it in",
      "offset": 2576.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "real time. It's removing the problematic",
      "offset": 2578.8,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "dependency.",
      "offset": 2580.64,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "But what's great is that the back end is",
      "offset": 2586.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "up. The backend server is working here.",
      "offset": 2587.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Okay,",
      "offset": 2590.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "let's work on dependencies.",
      "offset": 2592,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Yeah, if anyone's ever tried to teach",
      "offset": 2595.2,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "themselves Python before, they probably",
      "offset": 2596.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "face this as well.",
      "offset": 2598.16,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "This is like a lot of versioning type",
      "offset": 2600.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "issues. There's there's definitely this",
      "offset": 2603.359,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "like upfront work when you go from a",
      "offset": 2605.44,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "rapid prototyping tool like Bolt and",
      "offset": 2609.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Lovable to Cursor, but the amount of",
      "offset": 2611.359,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "control it's going to give you and",
      "offset": 2614.079,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "flexibility and and that, you know, it's",
      "offset": 2615.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "it's it's it's a worthwhile investment,",
      "offset": 2617.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "I think, to be able to read the code uh",
      "offset": 2618.96,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "and understand what's going on.",
      "offset": 2621.52,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "So, what are these like unsupported",
      "offset": 2627.44,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "engine warnings that we're seeing here?",
      "offset": 2628.88,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "So, let's see what's going on.",
      "offset": 2633.44,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "Looks like it might be hitting a problem",
      "offset": 2637.52,
      "duration": 7.079
    },
    {
      "lang": "en",
      "text": "with the packages it decided to use.",
      "offset": 2639.359,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "See if it can figure it out. I might hit",
      "offset": 2644.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "skip here just to have it keep moving.",
      "offset": 2647.04,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "See what happens.",
      "offset": 2649.2,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "Wow. I feel like we hit like every",
      "offset": 2653.839,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "possible thing that can go wrong with",
      "offset": 2655.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the versions of no in this one. So, it's",
      "offset": 2657.04,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "a really extensive demo, but what it",
      "offset": 2660.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "realiz is like it's using a version of",
      "offset": 2662.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Node that actually has problems with",
      "offset": 2664.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "some of the other packages. So, it's",
      "offset": 2667.68,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "going to go and and uh reinstall uh the",
      "offset": 2669.599,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "the front end environment.",
      "offset": 2673.119,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "Cool. Again, you know, it's going to",
      "offset": 2676.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "happen. is just accepting that there's",
      "offset": 2679.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "going to be this, you know, sort of a",
      "offset": 2681.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "little bit of friction of like is the",
      "offset": 2683.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "agent doing the right thing and it's",
      "offset": 2685.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "just kind of making it move along and",
      "offset": 2687.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "figure it out. I feel like we got the",
      "offset": 2689.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "agent today on an off day. Uh like it",
      "offset": 2691.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "has didn't have its morning coffee or",
      "offset": 2693.359,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "something, you know? It's like making a",
      "offset": 2694.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "a bunch more mistakes, but um that's",
      "offset": 2696.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "okay. And node for people who don't",
      "offset": 2698.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "know, that's like a runtime environment.",
      "offset": 2701.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "What does that do for us? So this gives",
      "offset": 2702.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you your uh your front end. So this is",
      "offset": 2705.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "actually able to uh accept and take",
      "offset": 2707.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "requests make requests to the to the",
      "offset": 2710.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "backend server which was your Python",
      "offset": 2712.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "code and serve you a UI or front end. So",
      "offset": 2714.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "it's sort of think of this is like when",
      "offset": 2718.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you go to any website like what the the",
      "offset": 2720,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "UI that you see is. Okay. Okay. So it",
      "offset": 2722.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "says both services are running. Let me",
      "offset": 2726.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "check the status. So it's going to go",
      "offset": 2728.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "ahead and check. It looks like things",
      "offset": 2729.44,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "are have wow agent is stoked today.",
      "offset": 2731.92,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "Um, so all right. So we've got a front",
      "offset": 2737.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "end. Let's go ahead and take a look at",
      "offset": 2739.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "what that front end front end looks",
      "offset": 2741.359,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "like. So it even says here's how to use",
      "offset": 2743.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "your trip planner agent. Okay, now we're",
      "offset": 2744.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "going to go back. All right, that was a",
      "offset": 2747.2,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "deep dive. Boom. Oh, wow. So that is the",
      "offset": 2749.839,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "application you just built. Um, we just",
      "offset": 2754.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "built it and all it took was giving a",
      "offset": 2756.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "couple of examples, persevering through",
      "offset": 2760,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the Python dependencies that we hit. And",
      "offset": 2762.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "we have a real prototype here. You have",
      "offset": 2765.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "a UI that can point to the back end and",
      "offset": 2766.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "actually uh you know actually service",
      "offset": 2769.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "serve up requests that we want to make.",
      "offset": 2772,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "So that's that's a real prototype. Let's",
      "offset": 2774.319,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "go ahead and test it now. What do you",
      "offset": 2775.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "think Akash? Yeah, let's see it. And",
      "offset": 2777.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "let's also just explain like we were",
      "offset": 2779.599,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "trying to create an agentic system. So",
      "offset": 2781.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "where are the agents involved here?",
      "offset": 2782.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Yeah, so great question. So, we went",
      "offset": 2785.359,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "ahead and um it's funny, it actually it",
      "offset": 2787.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "does list them out here in the UI, but",
      "offset": 2790.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "you can specify whatever agents you",
      "offset": 2792.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "want. Some of these were actually",
      "offset": 2795.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "determined in the example that I gave,",
      "offset": 2797.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "but let's go ahead and and kind of break",
      "offset": 2799.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "down like what are the agents here. So,",
      "offset": 2801.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the agents that we've built in, and",
      "offset": 2803.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "again, this is fully customizable. So,",
      "offset": 2805.52,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "you can give different agents for more",
      "offset": 2807.839,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "specific tasks. The agents here are a",
      "offset": 2810.319,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "research specialist. So that's an agent",
      "offset": 2813.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that's like an expert on doing research",
      "offset": 2815.92,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "on a specific geography like climate,",
      "offset": 2818.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "you know, the attractions, etc. You have",
      "offset": 2821.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "a planner agent that can plan day by",
      "offset": 2824.16,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "day. So for a specific day, what what",
      "offset": 2826.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "should we do for uh you know, for this",
      "offset": 2829.599,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "trip? You have a budget advisor and a",
      "offset": 2831.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "local curator. So budget adviser just",
      "offset": 2834.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "takes a budget and actually, you know,",
      "offset": 2836.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "does analysis on that to to based on the",
      "offset": 2838.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "user's input here, which you're going to",
      "offset": 2840.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "you're going to put in your budget. and",
      "offset": 2842.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "then a local curator to kind of find um",
      "offset": 2844.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you know maybe off the beaten path",
      "offset": 2846.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "things. But these are these agents. You",
      "offset": 2848.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "can kind of think of them as",
      "offset": 2850.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "LLMs and prompts and contexts that",
      "offset": 2854,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "you've packaged and wrapped together to",
      "offset": 2856.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "perform a specific task. It's a lot like",
      "offset": 2859.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "saying I'm an expert on a specific area",
      "offset": 2861.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and I'm just going to go ahead and focus",
      "offset": 2864.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "on giving the best possible output for",
      "offset": 2866.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "that specific thing. Like the budget",
      "offset": 2868.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "agent is going to be really good at",
      "offset": 2870.319,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "budgeting. the planner agent is going to",
      "offset": 2871.839,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "be really good at making plans. So,",
      "offset": 2873.44,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "that's kind of how I would view these",
      "offset": 2875.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "different systems a little bit. Cool.",
      "offset": 2876.319,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "So, let's go ahead and give this a shot.",
      "offset": 2879.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "So, we're gonna say we're gonna go to",
      "offset": 2880.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Spain. Um, you know, let's say we're",
      "offset": 2882.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "going to do like a quick Euro trip. I",
      "offset": 2884.96,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "know you you recently did like a summer",
      "offset": 2886.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "trip to Europe. Uh, let's go ahead and",
      "offset": 2887.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "click Spain. We can say, um, let's type",
      "offset": 2889.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "in we're going for one week. We're going",
      "offset": 2891.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "to give a budget of let's just say like",
      "offset": 2894.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "$1,000. And maybe some interest we can",
      "offset": 2896.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "give our food. And then we can even",
      "offset": 2899.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "click the travel style. So let's say we",
      "offset": 2902,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "want to go a little bit more adventure.",
      "offset": 2903.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "And these are this form is fully",
      "offset": 2906.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "programmatic, right? So if I wanted to,",
      "offset": 2908.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "I could go back here and say um you know",
      "offset": 2910.48,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "change the form color, change the form",
      "offset": 2913.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "fields. This is too long. Change how it",
      "offset": 2915.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "looks and feels. But you've given",
      "offset": 2917.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "something that kind of uh is is a good",
      "offset": 2918.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "starting point um for for you know a",
      "offset": 2921.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "prototype you might want to build for",
      "offset": 2923.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "yourself. Okay. I'm going to click plan",
      "offset": 2925.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "my trip.",
      "offset": 2927.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "And what's going on in the background",
      "offset": 2930.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and you know this this loading state's",
      "offset": 2932.16,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "not great and that's probably something",
      "offset": 2933.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "I could ask the you know the agent to go",
      "offset": 2935.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and improve on the loading state. But",
      "offset": 2937.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "what it's actually going to do is build",
      "offset": 2939.2,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "an itinerary for me here. And uh and",
      "offset": 2942,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "it's going to take the inputs I have.",
      "offset": 2945.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Great. And it says here's a 7-day",
      "offset": 2947.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "itinerary for Spain food and adventure.",
      "offset": 2949.599,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "And it's actually given me a daytoday",
      "offset": 2952.4,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "sort of hour to hour level analysis of",
      "offset": 2956.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "what I could be doing in different",
      "offset": 2959.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "cities.",
      "offset": 2961.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Nice. As well as days. Yeah. So, but it",
      "offset": 2962.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "was pretty detailed. It's faster than a",
      "offset": 2966.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "real human pip planner would have been",
      "offset": 2968.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "for sure. You reading up 10 Google",
      "offset": 2969.68,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "search results. Right. Right. Or even if",
      "offset": 2972.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you pasted like think of this interface",
      "offset": 2974.559,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "here, right? Like what you've basically",
      "offset": 2976.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "done is you've wrapped those prompts of",
      "offset": 2978.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "plan me a trip to Spain for one week",
      "offset": 2980.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "with a budget of $1,000, interest or",
      "offset": 2982.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "food, and in this range, and you've",
      "offset": 2984.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "created something that's a lot more",
      "offset": 2987.359,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "programmatic on top of that. You've",
      "offset": 2988.8,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "created a prototype that you could",
      "offset": 2990.559,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "actually go and deploy. And you can",
      "offset": 2991.839,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "build so much more on top of this,",
      "offset": 2993.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "right? You can have it reference like",
      "offset": 2994.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "maybe you want to use a specific API to",
      "offset": 2997.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "help you book the flight or suggest",
      "offset": 2999.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "flights. You can hook it up to that. You",
      "offset": 3001.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "can give it access to search. And so",
      "offset": 3002.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "it's a fully programmatic system that",
      "offset": 3004.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you can really go in and and tweak on",
      "offset": 3007.119,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "the fly in your cursor environment as",
      "offset": 3009.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "well.",
      "offset": 3012.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "Okay. So we've gotten we've gotten uh an",
      "offset": 3014.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "output here. Now this is really helpful",
      "offset": 3017.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "to just get started, but I think we want",
      "offset": 3019.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "to go one level deeper, right? Like as a",
      "offset": 3021.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "product manager, just being able to look",
      "offset": 3023.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "at this like I'm not I'm not really sure",
      "offset": 3025.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "what's going underneath the hood unless",
      "offset": 3028.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "I go and read the code. And that's kind",
      "offset": 3029.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of takes us to what observability is.",
      "offset": 3032.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "And observability is sort of a a key",
      "offset": 3034.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "part of being able to understand your AI",
      "offset": 3037.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "application. So let's go ahead and and",
      "offset": 3040,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "hop to that. So yes, so what we did when",
      "offset": 3042.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "we actually built the system is we've",
      "offset": 3046,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "we've added what's called tracing. And",
      "offset": 3047.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "tracing is a really standard way of",
      "offset": 3050.24,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "looking at the calls that your server is",
      "offset": 3053.04,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "making. um that's actually uh related to",
      "offset": 3055.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "the tool that I I'm kind of working on",
      "offset": 3058.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "which which helps with observability and",
      "offset": 3060.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "with with uh with sort of tracing",
      "offset": 3063.2,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "applications. Um and so let's go ahead",
      "offset": 3065.52,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "and look at some specific examples here.",
      "offset": 3068.319,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "So um so these are some requests that",
      "offset": 3071.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I've made which are basically to this",
      "offset": 3073.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "agent-based system and um this is one we",
      "offset": 3075.599,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "just made which was uh Spain one week.",
      "offset": 3078.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "In this case I clicked sailing um and",
      "offset": 3080.96,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "adventure. This diagram is really cool.",
      "offset": 3083.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "What are we seeing here on the bottom",
      "offset": 3086.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "left? Yeah. So, this is uh actually the",
      "offset": 3087.839,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "same agent that you just built in code",
      "offset": 3090.96,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "represented graphically. So, uh so what",
      "offset": 3094.16,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "you actually have is a a way for you to",
      "offset": 3097.2,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "visually see what is your agentbased",
      "offset": 3100.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "system doing. And remember we we were",
      "offset": 3104.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you asked a great question which was",
      "offset": 3106.24,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "like what agents can we build? We have a",
      "offset": 3107.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "research agent, we have a local",
      "offset": 3110.319,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "experiences agent, we have a budget",
      "offset": 3111.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "agent and all of that goes into an",
      "offset": 3113.599,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "itinerary and that's what the output is.",
      "offset": 3115.92,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "And so what's what's really helpful",
      "offset": 3118.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "looking at this is when you are thinking",
      "offset": 3121.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "about going one step further from your",
      "offset": 3123.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "AI prototype to building a prototyped",
      "offset": 3126.079,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "agent or an agent application being able",
      "offset": 3129.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "to visually see what are the paths that",
      "offset": 3132.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "the agent is taking to accomplish a",
      "offset": 3134.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "goal. You can see what happens here is",
      "offset": 3136.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "when I give the input, it kicks off",
      "offset": 3138.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "three different agents in parallel to",
      "offset": 3140.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "generate an output and all of those go",
      "offset": 3142.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "into the itinerary. Remember, I didn't",
      "offset": 3145.28,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "even really define this. I gave this to",
      "offset": 3147.52,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "cursor to go write and I said cursor go",
      "offset": 3150.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "ahead and build an agent-based system",
      "offset": 3153.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and this is the architecture it",
      "offset": 3155.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "developed and came back to me and uh and",
      "offset": 3157.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "that's what what gives you the output",
      "offset": 3160,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "that you get on the other end. And so",
      "offset": 3161.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "what I'd gotten is one level deeper on",
      "offset": 3163.359,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "cursor. And that's actually a really key",
      "offset": 3166.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "point which is it's it's kind of tough",
      "offset": 3169.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to do this with like Bolton level.",
      "offset": 3171.839,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "You're not going to get this",
      "offset": 3173.359,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "representation the same way. And so if",
      "offset": 3174.4,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "you want to see what's going on",
      "offset": 3176.4,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "underneath the hood, you kind of need to",
      "offset": 3177.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "use you have to be a little bit more in",
      "offset": 3179.599,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the code to be able to define how to get",
      "offset": 3181.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "those outputs. And you could probably",
      "offset": 3184.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "use wind surf too, right? That's right.",
      "offset": 3186.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Yeah. So as long as you as long really",
      "offset": 3188.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "what matters is that you can edit the",
      "offset": 3190.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "code. Um so whether that's winer for",
      "offset": 3192.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "cursor um you know being able to add to",
      "offset": 3194.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "the code uh tracing is really what",
      "offset": 3197.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "matters and you know I work on this tool",
      "offset": 3199.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "but there's a lot of other tools out",
      "offset": 3201.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "there for tracing as well. I think what",
      "offset": 3203.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "matters is like what's your workflow so",
      "offset": 3205.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "I'm you know don't don't take my word",
      "offset": 3207.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "for it. go out and try a tool and",
      "offset": 3209.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "implement tracing or ask your work with",
      "offset": 3212.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "your engineer to implement tracing and",
      "offset": 3214.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "you'll be able to kind of get a",
      "offset": 3216.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "visualization like this um at the end of",
      "offset": 3218.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "the day. And what was the steps involved",
      "offset": 3220.48,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "with implementing tracing? Yeah. So um",
      "offset": 3221.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "to that I think it's probably easier to",
      "offset": 3225.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "just kind of show what that looks like",
      "offset": 3227.68,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "here which is this is our docs for arise",
      "offset": 3230,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "and um so we actually have a whole",
      "offset": 3233.839,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "section on tracing. Tracing is think of",
      "offset": 3236.96,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "this as like the units of work that your",
      "offset": 3240.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "code is making. And it's it's actually",
      "offset": 3243.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "because this is, you know, we're taking",
      "offset": 3246.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "software best practices and applying",
      "offset": 3248.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "them to this like AI agent world. It's",
      "offset": 3250.8,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "actually fairly straightforward these",
      "offset": 3253.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "days. All you really have to do is",
      "offset": 3255.359,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "install a tracing package and wrap your",
      "offset": 3257.599,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "code in a sort of a decorator that is a",
      "offset": 3260.559,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "fancy word for saying take this process",
      "offset": 3264.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "or this function and call that a span or",
      "offset": 3266.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "a trace so that when you're actually",
      "offset": 3268.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "running that code it picks up that unit",
      "offset": 3270.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "and it puts it into what you see here",
      "offset": 3273.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "which is the UI for each of the steps",
      "offset": 3276.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "that the agent is taking. So it's it's",
      "offset": 3278.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "really the short answer Akash is like",
      "offset": 3280.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it's a line of code that you uh that you",
      "offset": 3282.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "implement on top of um on on top of your",
      "offset": 3285.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "functions. So you could probably just",
      "offset": 3288.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "point the agent to this doc and it would",
      "offset": 3290.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "figure it out. Totally. That's actually",
      "offset": 3292.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "how I did it as well. Yeah. So like and",
      "offset": 3294.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "and so so that's where the example that",
      "offset": 3296,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "I kind of gave it had tracing in it",
      "offset": 3298.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "already as a starting point. But what",
      "offset": 3300.319,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you can do is is just literally copy",
      "offset": 3302.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "paste this type it in here and I could",
      "offset": 3305.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "say you know implement tracing. I I",
      "offset": 3307.92,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "won't need to do that now because it",
      "offset": 3309.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "already has it, but it will be able to",
      "offset": 3310.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "go and infer. Okay, here are the steps I",
      "offset": 3313.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "need to go and implement the traces.",
      "offset": 3315.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Nice. And then you get that awesome",
      "offset": 3318.079,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "thing that we were looking at. Can you",
      "offset": 3320,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "break down the top left what we're",
      "offset": 3321.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "reading as well? It looks like there's",
      "offset": 3323.04,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "like multiple levels there. So, it's",
      "offset": 3324.24,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "like budget. Then what are we seeing",
      "offset": 3325.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "after that? Yeah, exactly. So, these are",
      "offset": 3327.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "the agents that we've defined now,",
      "offset": 3330.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "right? This is a multi- aent system",
      "offset": 3332.319,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "using langraph and I've got a budget",
      "offset": 3334.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "here which is you can look at the the",
      "offset": 3337.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "input. Let's take a look at the input",
      "offset": 3340,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "really quick. So this isn't a ch chat",
      "offset": 3341.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "based agent right like uh I think",
      "offset": 3344.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "everyone a lot of people it makes sense",
      "offset": 3346.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "right you want to build something with",
      "offset": 3348.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "chat but what if you just take a form",
      "offset": 3350.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "and take these inputs and actually put",
      "offset": 3352.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "them into here. That's what this looks",
      "offset": 3355.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "like. Spain, one week, the budget, let's",
      "offset": 3357.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "in this case it's sailing and then the",
      "offset": 3360.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "advent the travel style and those are",
      "offset": 3362.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "inputs to the system and then those get",
      "offset": 3365.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "kicked out to each of these agents.",
      "offset": 3367.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "Let's go ahead and take a look at what's",
      "offset": 3370.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "going on. And this is really the budget",
      "offset": 3372.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "agent, the local experiences agent,",
      "offset": 3374.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "research agent. That agent has its own",
      "offset": 3376.16,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "sort of tool that it has access to here.",
      "offset": 3379.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "And let's go ahead and and go one level",
      "offset": 3383.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "deeper at the prompt. So this is the",
      "offset": 3384.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "system prompt of the agent. The system",
      "offset": 3387.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "prompt says analyze budget requirements",
      "offset": 3390,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "for a oneweek trip to Spain. And here's",
      "offset": 3392.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "the budget. So it actually plumbed in",
      "offset": 3394.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the the budget from the form. And it",
      "offset": 3396.64,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "says this is what you should do. Include",
      "offset": 3399.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "a breakdown of all of these things.",
      "offset": 3401.839,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "These are all things that you would",
      "offset": 3403.92,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "think about when you're developing a",
      "offset": 3405.599,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "budget. Like what would I spend money on",
      "offset": 3406.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "when I'm traveling? And so the agent has",
      "offset": 3408.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "actually defined for itself in the",
      "offset": 3410.799,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "system prompt. How should I take this",
      "offset": 3412.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "thousand dollars and best allocate it",
      "offset": 3414.16,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "for accommodations? And what's",
      "offset": 3416.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "interesting is it it's, you know, it's",
      "offset": 3419.359,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "actually kind of gone and done a pretty",
      "offset": 3420.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "wide search for different tiers of",
      "offset": 3422.559,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "options because it's not really making a",
      "offset": 3425.599,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "decision on what uh, you know, what is",
      "offset": 3428.079,
      "duration": 7.841
    },
    {
      "lang": "en",
      "text": "the um the range of the type of trip I",
      "offset": 3431.599,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "want to take. It's offloading that to",
      "offset": 3435.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "another agent to make that decision. All",
      "offset": 3437.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "it's doing is saying, &quot;I have $1,000.",
      "offset": 3440,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "what can I do with $1,000? How should I",
      "offset": 3441.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "think about spending that money and let",
      "offset": 3444,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the other agents decide how to best uh",
      "offset": 3446.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "pull that together? So then that goes",
      "offset": 3449.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "into what's called this like analyzing",
      "offset": 3451.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this budget uh tool which takes that",
      "offset": 3453.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "destination the week and the budget and",
      "offset": 3456.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that's that's basically think of this as",
      "offset": 3459.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "like pulling out the a structured JSON",
      "offset": 3461.28,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "that goes into the into the system",
      "offset": 3465.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "prompt. So these tools are basically",
      "offset": 3467.28,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "ways for you to get data from an",
      "offset": 3469.76,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "unstructured way or from some one format",
      "offset": 3473.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "and put it into another format. And it's",
      "offset": 3475.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "really important to think about tools or",
      "offset": 3478.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "functions as ways for you to get uh you",
      "offset": 3480.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "know sort of think of them as like API",
      "offset": 3483.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "calls or ways to get data from a system",
      "offset": 3485.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "for your agent to use. And that's what",
      "offset": 3487.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "this little icon kind of represents here",
      "offset": 3489.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "um is a is a tool. And then this is uh",
      "offset": 3492.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the actual LLM call. And this is the top",
      "offset": 3495.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "level agent which wraps all of that",
      "offset": 3498.16,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "together. And and you'll notice like",
      "offset": 3499.839,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "this this kind of looks complex if this",
      "offset": 3502.799,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "is the first time you are seeing a",
      "offset": 3505.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "system like this, right? Like what are",
      "offset": 3507.839,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "all of these lines? There's all these",
      "offset": 3509.359,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "boxes and colors, but I would really",
      "offset": 3510.96,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "stress like this type of system is is",
      "offset": 3514.16,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "truly an MVP in today's world of agents.",
      "offset": 3517.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "So if your team or you're an AIPM and",
      "offset": 3520.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "you're thinking about building an",
      "offset": 3523.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "agent-based system, your first starting",
      "offset": 3524.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "point would probably look something like",
      "offset": 3527.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "this. It's not really going to look a",
      "offset": 3529.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "ton simpler to be honest for a for",
      "offset": 3531.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "multiple agents. It's more likely that",
      "offset": 3533.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "there will be multiple calls being made",
      "offset": 3536.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to different services and taking data",
      "offset": 3538.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "out of that and putting them back in to",
      "offset": 3540.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "then use for LLM calls. So just wanted",
      "offset": 3542.799,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "to set that kind of context which is",
      "offset": 3545.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "like your starting point is to see",
      "offset": 3547.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "what's going on underneath the hood and",
      "offset": 3550.24,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "try to understand LLMs, LLM calls, tool",
      "offset": 3552.72,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "calls, agents and how they all sort of",
      "offset": 3556.4,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "ladder up into this overall system and",
      "offset": 3558.559,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "we even get the time. So we were saying",
      "offset": 3561.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "like oh this might be a little bit slow",
      "offset": 3563.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "but this is break down if you wanted to",
      "offset": 3565.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "observe it which is what we're talking",
      "offset": 3566.96,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "about here. This is how you can break",
      "offset": 3568.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "down. Okay, maybe we chip off some time",
      "offset": 3569.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "with the budgeting one and then you",
      "offset": 3572.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "could go in and you could work on that.",
      "offset": 3573.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Absolutely. I mean, and think about it",
      "offset": 3575.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "this way, like, you know, if I'm using a",
      "offset": 3576.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "model, how do I know if I want to change",
      "offset": 3578.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "to a different model? Um, you know, so",
      "offset": 3581.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "like let's say OpenAI launches a new",
      "offset": 3583.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "model tomorrow, is that a good thing for",
      "offset": 3586.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "me to implement into my system? Well,",
      "offset": 3588.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "you should probably be able to see an AB",
      "offset": 3590.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "test just like you would AB test an",
      "offset": 3593.119,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "enduser experience. You can now AB test",
      "offset": 3595.599,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "different models. you can AB test",
      "offset": 3598.559,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "different prompts and the fact is that",
      "offset": 3600.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "you probably want to you know in your",
      "offset": 3603.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "tool that you're actually using for",
      "offset": 3605.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "observability you should think about",
      "offset": 3607.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "ways to be able to do that. So let's",
      "offset": 3609.04,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "actually take one of those examples",
      "offset": 3611.04,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "here. This is this is a good one where",
      "offset": 3612.559,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "it took a really long time to generate",
      "offset": 3614.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "this itinerary.",
      "offset": 3615.839,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "Um and what we can do is actually go and",
      "offset": 3617.68,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "you know from here",
      "offset": 3622.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "we can actually go into a prompt",
      "offset": 3624.72,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "playground.",
      "offset": 3627.599,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "So this is what it looks like when you",
      "offset": 3631.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "are iterating on your system. Right?",
      "offset": 3633.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "This is the same system prompt that you",
      "offset": 3635.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "would be able to see in cursor in your",
      "offset": 3637.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "code and that your agent built for you",
      "offset": 3640.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "or that your engineering team built. But",
      "offset": 3642.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "what you have here are variables.",
      "offset": 3645.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "And this is really important because",
      "offset": 3647.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "this agent is being able to take inputs",
      "offset": 3649.92,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "from the form for maybe hundreds,",
      "offset": 3652.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "thousands of your users and plum them in",
      "offset": 3655.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "to get a reliable system on the other",
      "offset": 3658,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "end which is taking your destination,",
      "offset": 3660.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "the week, you know, duration, the travel",
      "offset": 3662.48,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "style, your and then takes the inputs of",
      "offset": 3665.04,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "all of the other analysis and constructs",
      "offset": 3668.799,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "a finalized itinerary. So this is the",
      "offset": 3672.48,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "the sort of the step by steps of take",
      "offset": 3675.68,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "all of the other agent inputs and",
      "offset": 3679.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "construct that final itinerary that you",
      "offset": 3681.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "saw.",
      "offset": 3684,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "So why does this matter, right? Well, I",
      "offset": 3686.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "think you actually pointed out something",
      "offset": 3689.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "really uh useful, right? Like which is",
      "offset": 3691.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "this is kind of long. Like I don't I",
      "offset": 3693.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "don't know if I'm going to read all of",
      "offset": 3696.079,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this. It's it's really detailed, but",
      "offset": 3697.359,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "does it really need to be this detailed?",
      "offset": 3700.559,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "And is this really the tone that I want",
      "offset": 3704.319,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the agent to have? What if I wanted this",
      "offset": 3707.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "agent to offer a discount to users or",
      "offset": 3710.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "act extra friendly? Well, that's really",
      "offset": 3712.48,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "where prompt engineering comes in. Um,",
      "offset": 3715.119,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "and this is another kind of core part of",
      "offset": 3718.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "the the workflows we were talking about,",
      "offset": 3721.839,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "which is so we've done prototyping,",
      "offset": 3723.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "we've done observability. Now let's see",
      "offset": 3726.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "what parts of the agent stack we can",
      "offset": 3728.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "change and iterate on and what the",
      "offset": 3731.359,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "output looks like. And to that end we",
      "offset": 3733.599,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "have we have rag prompt engineering",
      "offset": 3736.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "fine-tuning. Right? And so we're going",
      "offset": 3739.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "to kind of go through each of those and",
      "offset": 3740.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "see what the impact is on the end output",
      "offset": 3742.4,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "of your agent. Okay. So so I've got um a",
      "offset": 3745.44,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "model here. I can change the model if I",
      "offset": 3749.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "want to. Let's try a slightly different",
      "offset": 3752.079,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "one.",
      "offset": 3753.76,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "40 mini. Yeah. Andre yesterday said",
      "offset": 3757.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "don't use ever. Right. Exactly. Yeah. I",
      "offset": 3759.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "think it's being deprecated. I'm",
      "offset": 3763.2,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "surprised. Uh, you know, maybe it still",
      "offset": 3764.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "works, but let's see. Um, uh, and that's",
      "offset": 3766.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the thing. I mean, that that's honestly",
      "offset": 3768.88,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "it's a really I know we're joke, but",
      "offset": 3770.24,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "like that's a really good point. Like",
      "offset": 3771.44,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "these models are going to change all the",
      "offset": 3772.559,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "time, right? Like I I love the like, oh,",
      "offset": 3774.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "this new model came out. Here's my",
      "offset": 3778,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "prompting guide for it. those prompting",
      "offset": 3779.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "guides a lot of them they do end up",
      "offset": 3781.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "getting out of date when there's a new",
      "offset": 3783.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "model or you know the old you know how",
      "offset": 3784.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "you work with these new models changes",
      "offset": 3787.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "so what you could do is say like I'm",
      "offset": 3789.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "changing to this new model how should I",
      "offset": 3791.359,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "prompt the system and you can generate a",
      "offset": 3792.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "new prompt based on this as well we",
      "offset": 3794.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually have a a tool that lets you",
      "offset": 3796.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "kind of generate um new prompts as well",
      "offset": 3798.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "um okay and in this in the in the",
      "offset": 3801.039,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "product but let's say I want to just",
      "offset": 3803.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "make some really specific tactical",
      "offset": 3804.799,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "changes to this so I'm going to go ahead",
      "offset": 3806.4,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "and say Um,",
      "offset": 3808.16,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "I feel like we don't need a detailed",
      "offset": 3812.24,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "day-by-day plan. Can we just delete that",
      "offset": 3813.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "part and make it more like a dayby-day",
      "offset": 3815.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "event summary or something like that?",
      "offset": 3818.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "It's a good point. So, what I'm doing",
      "offset": 3820.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "here is actually changing the the prompt",
      "offset": 3822,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "and um you can do is actually save uh",
      "offset": 3824.96,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "you know you could save this prompt and",
      "offset": 3828.559,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "say I want to iterate on it in the",
      "offset": 3830.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "system and say like this is my travel",
      "offset": 3832.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "agent prompt. Yeah, that's like the",
      "offset": 3834.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "detailed version. Exactly. Yeah. and and",
      "offset": 3836.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "then what we can do is sort of pull in",
      "offset": 3839.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that same travel agent prompt here. So",
      "offset": 3841.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "now I'm actually iterating on the same",
      "offset": 3844.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "prompt, but when I save it, I'll save it",
      "offset": 3846.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "as a new version. So let's go ahead and",
      "offset": 3848,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it's a good best practice. So we're",
      "offset": 3849.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "going to say instead of a dayby-day",
      "offset": 3852,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "plan, we're going to do um I think",
      "offset": 3854.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that's what I said before. We're going",
      "offset": 3856.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "to say uh give me give me a uh so so",
      "offset": 3857.76,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "actions",
      "offset": 3862.16,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "give me a daytoday plan. doesn't need to",
      "offset": 3865.119,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "be",
      "offset": 3868.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "super detailed, right? Because I don't",
      "offset": 3870.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "think we're planning out our lives like",
      "offset": 3872.559,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "day the hour to hour.",
      "offset": 3875.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "It's really helpful when you're doing",
      "offset": 3879.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "generation to also say because we're",
      "offset": 3880.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "giving all of this is context. This is",
      "offset": 3882.48,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "all rag to some degree of context that",
      "offset": 3884.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the agent is using. And we're going to",
      "offset": 3887.359,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "say, you know, max",
      "offset": 3890,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "1,00 characters because we don't want it",
      "offset": 3893.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "to go on super long. And when you say",
      "offset": 3895.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "rag, rag is retrieval augmented",
      "offset": 3897.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "generation, which means kind of like",
      "offset": 3900.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "condensing a lot of knowledge, right? Is",
      "offset": 3902.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "that what it's about? Yeah, good point.",
      "offset": 3904.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "So, yeah. So, in case you've heard this",
      "offset": 3907.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "term before and you're like, what is",
      "offset": 3909.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "that thing? Rag is retrieval augmented",
      "offset": 3910.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "generation. It is, uh, I like to think",
      "offset": 3913.359,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "of it as giving, you know, when you're",
      "offset": 3915.839,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "thinking about like doing a test or",
      "offset": 3918.559,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "let's say you you you go to a doctor,",
      "offset": 3921.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "uh, the doctor might be super",
      "offset": 3923.839,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "specialized. You can kind of think of",
      "offset": 3925.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "specialization as like fine-tuning. And",
      "offset": 3927.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "when the doctor is kind of answering",
      "offset": 3929.839,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "your questions, wouldn't it be great if",
      "offset": 3931.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "they just had access to like the",
      "offset": 3933.039,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "internet or to a textbook? And that's",
      "offset": 3934.799,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "what rag is. Rag is basically getting",
      "offset": 3937.119,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "access to a specific part of the data of",
      "offset": 3939.68,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "your overall data set that is useful to",
      "offset": 3943.599,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "answer an a question on the spot. So um",
      "offset": 3946.799,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "so that's like the context that helps",
      "offset": 3949.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "you answer a question basically or or",
      "offset": 3951.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "perform a task. Um okay. So it's like",
      "offset": 3953.76,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "think of it as like pulling out a page",
      "offset": 3956,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "from a notebook or a textbook.",
      "offset": 3957.359,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "Now it's really hard to find the right",
      "offset": 3961.039,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "page and that's a whole another area of",
      "offset": 3962.4,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "study but that's really what uh that's",
      "offset": 3963.839,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "really what rag is underneath the hood.",
      "offset": 3965.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "It's just like pulling out data and",
      "offset": 3967.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "using it. Um so another another few",
      "offset": 3968.96,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "things we can do is say um you know",
      "offset": 3971.92,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "always answer in a super friendly tone",
      "offset": 3975.359,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "because it kind of sounds robotic to me.",
      "offset": 3979.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "I feel like this itinerary like I don't",
      "offset": 3981.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "know if I would want to use this. I kind",
      "offset": 3983.039,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "of want like, you know, something that",
      "offset": 3984.48,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "might feel a little bit more",
      "offset": 3985.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "interactive. Um, and maybe we want to",
      "offset": 3986.72,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "build a product here or we want to use",
      "offset": 3989.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "this product to collect email addresses",
      "offset": 3991.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "as just a super simple first pass,",
      "offset": 3993.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "right? Like if you're a PM and you're",
      "offset": 3995.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "like, maybe this is really useful for me",
      "offset": 3996.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "to go get feedback from these users and",
      "offset": 3998.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "ask them more follow-up questions. You",
      "offset": 4001.44,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "could say, uh, ask the user for their",
      "offset": 4002.96,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "email and offer",
      "offset": 4007.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "a discount.",
      "offset": 4009.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Okay. Okay. So now we've done a couple",
      "offset": 4011.599,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "things, right? We're going to change",
      "offset": 4013.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this to 4.1. We're going to see how long",
      "offset": 4015.039,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "that takes as well. Um, and we're going",
      "offset": 4018.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "to run the two systems against each",
      "offset": 4022,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "other and see what the output looks",
      "offset": 4024,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "like. So we're actually we hit run all,",
      "offset": 4025.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "which is going to run the original",
      "offset": 4027.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "prompt we have against the new prompt",
      "offset": 4029.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "and take the models and actually compare",
      "offset": 4032.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the two against each other, too. Okay,",
      "offset": 4034.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "so that was that was faster. Um, so you",
      "offset": 4036.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "can see that, you know, it still took a",
      "offset": 4038.72,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "little bit, but it's looking like a",
      "offset": 4040.559,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "little bit more friendly here. In this",
      "offset": 4041.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "case, it's a trip to Marrakesh, but it",
      "offset": 4043.52,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "it loves to use emojis. Uh, we've got",
      "offset": 4045.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the day by day. Um, so let's let this",
      "offset": 4048.319,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "kind of generate here. It's still",
      "offset": 4050.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "generating this output. This is again",
      "offset": 4052.799,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "the inputs that we're using, and all of",
      "offset": 4054.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the research from the previous agents",
      "offset": 4055.92,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "goes into here. And now I've got, let me",
      "offset": 4058.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "kind of zoom in and make this a little",
      "offset": 4061.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "bit easier to see. We've got we still",
      "offset": 4062.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "have the original this is the original",
      "offset": 4065.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "prompt",
      "offset": 4067.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "which is you know I think it's it's",
      "offset": 4069.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "definitely taken out the hour by hour",
      "offset": 4071.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "which was uh I think we we changed that",
      "offset": 4073.68,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "hour by hour step here but this is still",
      "offset": 4075.92,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "uh a little bit more highle day one day",
      "offset": 4078.559,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "two day three day four and it's",
      "offset": 4081.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "definitely more friendly here and it",
      "offset": 4084.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "also says would you like me to continue",
      "offset": 4085.839,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "the rest of the two weeks also shoot me",
      "offset": 4087.52,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "your email and I can send you a nicely",
      "offset": 4088.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "formatted itinerary plus a cool discount",
      "offset": 4090.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "I mean this is way more helpful, right?",
      "offset": 4092.96,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "Like this is like something I would",
      "offset": 4094.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "definitely want to interact with a bit",
      "offset": 4096.159,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "more because it's a little bit more high",
      "offset": 4098,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "level and you can always tweak it to get",
      "offset": 4099.759,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "it to sound the way you want it to. This",
      "offset": 4101.679,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "is what prompt engineering really is is",
      "offset": 4103.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "it gives you think of it as like",
      "offset": 4107.12,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "sculpting a block of clay or stone into",
      "offset": 4109.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "getting it into the right shape that you",
      "offset": 4112.239,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "want. The amount of impact that you can",
      "offset": 4114.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "have from prompt engineering is huge",
      "offset": 4116.56,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "because you can, you know, make the",
      "offset": 4118.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "agent actually listen to your",
      "offset": 4120.719,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "instructions much more easily with text.",
      "offset": 4123.04,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "Um, so that's really what you're doing",
      "offset": 4125.359,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "here. Cool. So, basically we changed the",
      "offset": 4126.799,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "prompt that was sent to",
      "offset": 4130.64,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "OpenAI 4.1 mini, which we specified",
      "offset": 4133.359,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "here. Um, whereas the other one had 40",
      "offset": 4136.64,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "mini. They both actually used the same",
      "offset": 4140.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "input from the other three agents, but",
      "offset": 4142.239,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "it led to kind of dramatically different",
      "offset": 4143.92,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "result and dramatically different time",
      "offset": 4145.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "taken, right? Yeah, that's a really good",
      "offset": 4147.279,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "point, right? Like the time for 40 mini,",
      "offset": 4149.839,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "the same exact input, just slightly",
      "offset": 4152.719,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "changed prompt",
      "offset": 4155.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "is 32 seconds versus this is 8.9",
      "offset": 4157.52,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "seconds. And that's where you can do",
      "offset": 4161.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "things like change the model. And you",
      "offset": 4163.359,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "can even AB test even further. you could",
      "offset": 4164.96,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "keep the model the same and just add",
      "offset": 4166.719,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that character which was um basically",
      "offset": 4168.239,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "you know being able to uh you know",
      "offset": 4171.199,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "basically retain you know only max out",
      "offset": 4173.679,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "like a thousand tokens or thousand",
      "offset": 4175.839,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "characters for instance um so that's an",
      "offset": 4177.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "example of like the changes that you",
      "offset": 4179.679,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "make and what impact they have on your",
      "offset": 4182,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "system this is like I would view this as",
      "offset": 4183.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "try to change your model try to change",
      "offset": 4187.759,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "your prompt very low effort once you",
      "offset": 4189.44,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "have observability in place very high",
      "offset": 4193.04,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "impact act on the enduser experience.",
      "offset": 4195.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "So how do you set up the right eval to",
      "offset": 4199.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "start to like in an automated way",
      "offset": 4201.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "understand whether you should adopt the",
      "offset": 4203.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "latest and greatest prompt instead of",
      "offset": 4205.84,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "kind of just as a human looking at it",
      "offset": 4207.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "each time? Yeah, good question. Um so",
      "offset": 4209.04,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "eval",
      "offset": 4212.96,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "changes to your system and being able to",
      "offset": 4216.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "quantify. Okay, now I can I can kind of",
      "offset": 4219.199,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this is what you kind of call vibe",
      "offset": 4222.32,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "coding, right? We've kind of come up to",
      "offset": 4223.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "this point. I would say everything up",
      "offset": 4225.199,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "until this point is pretty much vibe",
      "offset": 4227.36,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "coding because you're kind of like",
      "offset": 4228.719,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "looking at the you're basically giving",
      "offset": 4230.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "text. You know, this whole time we've",
      "offset": 4232.56,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "been vioding. You've been giving text to",
      "offset": 4234.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "the agent. It's generating output. You",
      "offset": 4235.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "have an agent system. You've made tweaks",
      "offset": 4237.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to the prompt and you're like, &quot;Looks",
      "offset": 4239.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "good, looks fine.&quot; But I think that",
      "offset": 4241.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "going one step beyond that is actually",
      "offset": 4244,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "being able to run eval. And eval",
      "offset": 4246.08,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "quantify your system overall. So I I",
      "offset": 4251.199,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "like to joke it's like going from vibe",
      "offset": 4254.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "coding to thrive coding because you're",
      "offset": 4255.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "going one step deeper, right? So So what",
      "offset": 4257.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "we can do is take some of these examples",
      "offset": 4260.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and I I actually ran a few of these uh",
      "offset": 4262.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "yesterday on a similar agent same same",
      "offset": 4264.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "agent system",
      "offset": 4267.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and what I can do is actually build a",
      "offset": 4269.6,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "data set and a a very very common",
      "offset": 4272.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "workflow. I mean, look, we work, you",
      "offset": 4275.04,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "know, with some of the the leading like",
      "offset": 4276.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "companies in AI like Uber, Reddit,",
      "offset": 4278.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Instacart, Duolingo, all these",
      "offset": 4280.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "companies. And the reason that we're",
      "offset": 4282.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "building these tools to have a data set",
      "offset": 4285.199,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "is because you want to be able to make a",
      "offset": 4286.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "change to your system and know that, you",
      "offset": 4289.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "know, quantitatively what the impact",
      "offset": 4291.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that change is having with eval. So,",
      "offset": 4293.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "that was a long-winded way of saying I",
      "offset": 4294.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "basically constructed a couple of",
      "offset": 4296.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "examples here. And let's go ahead and",
      "offset": 4298,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "delete these um so that we can actually",
      "offset": 4299.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "just do this from scratch. I I don't",
      "offset": 4301.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "want to these are what we're going to",
      "offset": 4303.52,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "jump to later. So,",
      "offset": 4305.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "okay, cool. Okay, so what do we have",
      "offset": 4308.239,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "here? So, this is what's called a data",
      "offset": 4310.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "set of the same data that you saw",
      "offset": 4313.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "earlier and specifically I took the",
      "offset": 4316.159,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "itinerary step and I've constructed a",
      "offset": 4318.8,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "set of examples I'm going to use to",
      "offset": 4322.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "iterate on top of and that's really what",
      "offset": 4324.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "these are. So, if I go in, you can see",
      "offset": 4327.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "it was the same prompt that we were",
      "offset": 4329.679,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "editing in the prompt playground. And",
      "offset": 4331.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "what we're going to do is actually uh",
      "offset": 4334.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "run eval",
      "offset": 4337.28,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "system and see what if we're making the",
      "offset": 4339.199,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "system better or worse. And that's",
      "offset": 4342.719,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "really what you can think of eval",
      "offset": 4344.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "basically a way for you to oh um you can",
      "offset": 4346.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "think of eval as a way for you to uh",
      "offset": 4349.04,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "understand are you making your system",
      "offset": 4352.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "better or worse just very simply.",
      "offset": 4354.32,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "Okay. So, um, so what we're going to do",
      "offset": 4357.6,
      "duration": 7.96
    },
    {
      "lang": "en",
      "text": "is, uh, let me refresh this page.",
      "offset": 4360.4,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "Just kind of look here.",
      "offset": 4365.6,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "Okay. So, let's create our first",
      "offset": 4369.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "experiment. And we're going to go back",
      "offset": 4371.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "into that prompt playground. But now,",
      "offset": 4372.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "I'm actually pulling in the data that",
      "offset": 4374.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you just saw. So, I've picked and hands",
      "offset": 4377.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "sampled those examples that I want to",
      "offset": 4379.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "use for iteration.",
      "offset": 4381.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "I can take the same I can do the same",
      "offset": 4384.08,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "thing here which is it has the same",
      "offset": 4386,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "inputs and I have those those outputs.",
      "offset": 4388.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "And now what I want to do is I actually",
      "offset": 4391.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "made that change to that prompt that we",
      "offset": 4393.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "were talking about earlier and I saved",
      "offset": 4395.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "it to the to the prompt hub. And so I'm",
      "offset": 4397.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "going to pull in this latest version of",
      "offset": 4399.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the prompt. And you'll see this is the",
      "offset": 4400.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "same prompt we made edits to before. And",
      "offset": 4403.44,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "now what I can do is let me go ahead and",
      "offset": 4406.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "AB test this. And let's kind of make",
      "offset": 4409.52,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "this a little more authentic. We said",
      "offset": 4410.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "that this was GPT 40 mini. So we're",
      "offset": 4412.4,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "going to do an AB test apples to apples.",
      "offset": 4415.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "And we'll do the same thing of hitting",
      "offset": 4418.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "run all, but now instead of on one",
      "offset": 4420.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "example, we're generating this on a data",
      "offset": 4421.84,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "set of like 10 or 12 examples here. So",
      "offset": 4424.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "it's basically giving you an output that",
      "offset": 4427.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you can use for experimentation. So this",
      "offset": 4429.52,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "is generating a new output on that data.",
      "offset": 4432.56,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "Um, okay. Yeah. So to back up for a",
      "offset": 4435.199,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "second, you have your initial data set",
      "offset": 4439.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of examples that you've kind of built on",
      "offset": 4442.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "top of. Even if you don't have that",
      "offset": 4444.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "initial data set, it's really just I",
      "offset": 4446.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "could go in and I could go and just add",
      "offset": 4448.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "basically what I did was I just",
      "offset": 4450.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "reentered, you know, instead of going to",
      "offset": 4452.159,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Spain, I want to go to Tokyo and instead",
      "offset": 4454.4,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "of one week, I want to make it two",
      "offset": 4456.239,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "weeks. The budget could be like $500.",
      "offset": 4457.679,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "And a lot of times what you kind of call",
      "offset": 4460.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "this when you're building an application",
      "offset": 4462.719,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "is bootstrapping a data set. And it's",
      "offset": 4463.92,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "just a way for you to get started. You",
      "offset": 4465.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "can synthetically generate that data",
      "offset": 4467.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "too. Um so using an LLM if you wanted",
      "offset": 4469.6,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "to.",
      "offset": 4472.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Okay. And then now what we've done is",
      "offset": 4474.719,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "once we have that data set, we can pull",
      "offset": 4476.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "this in and we've regenerated the",
      "offset": 4479.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "prompts. And it looks like it actually",
      "offset": 4481.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "generated the experiments for this. So",
      "offset": 4483.199,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "let's go ahead and go back here. And so",
      "offset": 4485.28,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "those experiments are the outputs from",
      "offset": 4488.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "uh the the prompt playground that we had",
      "offset": 4491.76,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "before. So this is new outputs on the",
      "offset": 4493.92,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "original prompt and I can compare this",
      "offset": 4497.199,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "to uh the the sort of the change the",
      "offset": 4500.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "change prompt that I use as well. So",
      "offset": 4503.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I've got two prompts side by side next",
      "offset": 4505.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "to each other now. And again like if",
      "offset": 4507.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you're using the system it's kind of",
      "offset": 4510.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "hard to read. It's kind of hard to say",
      "offset": 4512.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "like is one better than the other? I",
      "offset": 4513.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "don't really know. So let's go ahead and",
      "offset": 4515.679,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "uh run some eval here.",
      "offset": 4518.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "So I've got these eval set up, but let's",
      "offset": 4521.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "let's go through the process of talking",
      "offset": 4524,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "through what an eval is. So there are",
      "offset": 4526.56,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "think of this as there are basically",
      "offset": 4530,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "three types of evalu.",
      "offset": 4532.159,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "And it's it's really important to go in",
      "offset": 4539.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and label this data yourself. And you",
      "offset": 4541.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "can go and actually go through the data",
      "offset": 4543.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "set and label the data. We'll kind of",
      "offset": 4545.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "talk through that. We'll come back to",
      "offset": 4547.679,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "that one. And that's really an important",
      "offset": 4548.88,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "role for an AIPM is to know when I'm",
      "offset": 4551.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "looking at an output, is this what I",
      "offset": 4554.719,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "want the LLM or the agent to actually",
      "offset": 4556.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "generate like is this good or bad?",
      "offset": 4559.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "Because you're ultimately determining",
      "offset": 4561.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the end user experience as a PM. You're",
      "offset": 4562.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "saying like good or bad and that's what",
      "offset": 4565.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the label is. The second option is to",
      "offset": 4567.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "use code and so you can do things like",
      "offset": 4569.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "checking code um basically to say uh",
      "offset": 4571.76,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "it's like a pythonbased eval which you",
      "offset": 4575.28,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "know python eval could be things like",
      "offset": 4578,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "check for instances of like is a",
      "offset": 4579.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "competitor referenced in the LLM's",
      "offset": 4581.84,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "output and those are really just think",
      "offset": 4584,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "of those as ways of you know writing",
      "offset": 4585.92,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "code to to generate eval. And then the",
      "offset": 4587.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "third option that we're going to be kind",
      "offset": 4590.719,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "of focusing on here is actually using an",
      "offset": 4591.84,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "LLM to check the work of the other",
      "offset": 4594.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "agent. And so you think of these as like",
      "offset": 4597.04,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "eval types of agent systems that are",
      "offset": 4599.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "really used to kind of scale up your",
      "offset": 4603.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "feedback. So this is what almost",
      "offset": 4605.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "everybody's using these days, these LLM",
      "offset": 4607.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "as judge systems where they create like",
      "offset": 4609.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "almost like numeric scores with various",
      "offset": 4611.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "dashboards to look at things. Exactly.",
      "offset": 4613.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Yeah. So great point. So when we say",
      "offset": 4615.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like you know there's there's a lot of",
      "offset": 4618.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "buzz around uh eval are the secret and",
      "offset": 4620.32,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "they're the moat. What people say when",
      "offset": 4623.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "they're saying like eval are the secret",
      "offset": 4626.239,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to a great AI product experience, what",
      "offset": 4628,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "they're saying is that you need a",
      "offset": 4630.239,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "reliable way to scale up the feedback on",
      "offset": 4632.32,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "your system. And the way that you can do",
      "offset": 4636,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "that is using LMS as a judge or a",
      "offset": 4638.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "greater on the output. So that's what an",
      "offset": 4641.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "eval as a judge or eval system looks",
      "offset": 4643.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "like with LLMs. And I'm going to break",
      "offset": 4646,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this down a little bit further for you,",
      "offset": 4648.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "which is what we can do is basically",
      "offset": 4650.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "give an eval template. And the same way",
      "offset": 4652.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "that we had an agent basically um going",
      "offset": 4655.6,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "in and saying like generate an itinerary",
      "offset": 4658.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "itinerary, generate a budget. What I'm",
      "offset": 4660.719,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "doing is actually creating an an eval",
      "offset": 4662.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "which sets the the role which is saying",
      "offset": 4665.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you are examining written context",
      "offset": 4667.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "content. Here's the text and then I've",
      "offset": 4669.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "given the text from that we just",
      "offset": 4672.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "generated as the output and we're",
      "offset": 4674.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "stuffing that into here as context. Then",
      "offset": 4676.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "I'm giving the agent a task which says",
      "offset": 4678.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "examine the text and determine whether",
      "offset": 4680.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the tone is friendly or not. Friendly",
      "offset": 4682.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "tone is defined and then I'm defining",
      "offset": 4684.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and giving an example of like here's",
      "offset": 4687.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "what I mean when I say evaluate for",
      "offset": 4689.84,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "friendliness. Um please focus heavily on",
      "offset": 4692.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "the concept of friendliness. Then I'm",
      "offset": 4695.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "going to give it an action which is",
      "offset": 4698,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "based on the information the context",
      "offset": 4700.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "give an output label of friendly or",
      "offset": 4704,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "robotic based on the information that",
      "offset": 4706.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "you have. So again we've we've set we've",
      "offset": 4709.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "given the agent a role we've given it",
      "offset": 4711.6,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "context. We've given it an example of",
      "offset": 4714.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "what is good or bad and then we've given",
      "offset": 4717.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "it the action to perform. And those four",
      "offset": 4719.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "steps are really all you need to get an",
      "offset": 4721.92,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "eval in place um to at least get",
      "offset": 4724.56,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "started. Now uh what I will kind of",
      "offset": 4727.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "caveat and say as we run this and so",
      "offset": 4730.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "once I've defined that I can actually",
      "offset": 4732.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "set these up here and I've got another",
      "offset": 4735.04,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "one here and we'll kind of quickly go",
      "offset": 4736.8,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "through this one. This is like checking",
      "offset": 4738.719,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "if we offered a discount to the user",
      "offset": 4740.159,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "based on the the email. So this is this",
      "offset": 4743.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "is text that says determine whether the",
      "offset": 4745.52,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "text contains an offer for a discount.",
      "offset": 4747.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "And this was might be something we want",
      "offset": 4750.239,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "to check for, right? Did we did we",
      "offset": 4751.6,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "actually accomplish that goal of giving",
      "offset": 4753.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "a discount to a user?",
      "offset": 4754.56,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "I can go ahead and just run these on the",
      "offset": 4756.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "system and say select the experiments.",
      "offset": 4759.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Those are the two experiments we have.",
      "offset": 4762.159,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "And I'm just going to hit run. And while",
      "offset": 4764,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that's going off, I'll kind of go back",
      "offset": 4765.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "here and this should run pretty fast.",
      "offset": 4768.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "But what I'm basically doing is getting",
      "offset": 4770.96,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "an LLM generated label on all of those",
      "offset": 4772.88,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "rows that you just saw. And that's",
      "offset": 4776.239,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "really helpful for me to then go one",
      "offset": 4779.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "level deeper and say, was my LLM correct",
      "offset": 4780.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "or was the judge correct? And I can",
      "offset": 4784,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "basically go in and fine-tune that even",
      "offset": 4785.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "further. So,",
      "offset": 4788,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "okay. And we did I I'll one small note",
      "offset": 4790.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "is we like flipped the order of",
      "offset": 4792.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "operations here because experiment uh",
      "offset": 4794.88,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "two. Okay. So, it looks like um",
      "offset": 4798,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "experiment two was like the second one",
      "offset": 4800.239,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "that generated and then experiment one",
      "offset": 4802.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "was the first one that finished which",
      "offset": 4804.8,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "was the better one. So, we're actually",
      "offset": 4806.4,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "thinking of this like backwards, this",
      "offset": 4807.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "chart, but this was like the one that",
      "offset": 4809.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "took a really long time. This was the",
      "offset": 4811.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "older prompt. Um, think of this as the",
      "offset": 4813.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "old prompt. And you can see, okay, it",
      "offset": 4815.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "was actually I guess the LLM as a judge",
      "offset": 4817.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "did note that as friendly uh instead of",
      "offset": 4819.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "robotic, but it looks like it offered a",
      "offset": 4822.56,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "discount 0% of the time. And then if I",
      "offset": 4825.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "go to the one that was faster, the new",
      "offset": 4828.96,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "updated prompt, the LLM judge actually",
      "offset": 4831.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "did mark uh all of the responses as",
      "offset": 4834.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "friendly and then it offered a discount",
      "offset": 4837.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "100% of the time. So it actually went in",
      "offset": 4839.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and checked the outputs and said, &quot;Did",
      "offset": 4841.36,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "you give a discount or not?&quot; Yep. What",
      "offset": 4843.6,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "if we did something like gave it like a",
      "offset": 4847.44,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "friendliness score? Maybe that'll give",
      "offset": 4848.719,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "us like more dispersion. Yeah, exactly.",
      "offset": 4850.159,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "So, so what we when we generate uh the",
      "offset": 4852.719,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "label",
      "offset": 4855.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "um when we generate the label, we",
      "offset": 4857.28,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "actually do also get a score with it as",
      "offset": 4859.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "well. So, but we've just assigned a one",
      "offset": 4861.679,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "or a zero as the output. And then you",
      "offset": 4863.84,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "could go in and say um give me a",
      "offset": 4866.239,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "friendly score from one through five.",
      "offset": 4869.199,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "Fun fact, Akash for people that are",
      "offset": 4871.44,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "listening to this uh this is a best",
      "offset": 4873.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "practice is actually to use text to",
      "offset": 4876.239,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "ground the output of the LLM judge. The",
      "offset": 4878.64,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "reason for that instead of numbers is",
      "offset": 4881.6,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "although this technology is amazing, LLM",
      "offset": 4884.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "are still really bad at being able to",
      "offset": 4887.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "understand numbers. Um, fun fact, just",
      "offset": 4889.92,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "from a tokens perspective. So I said,",
      "offset": 4892.159,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "yeah, if I say, you know, put a one or a",
      "offset": 4895.199,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "two, it won't really be able to give you",
      "offset": 4897.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the justification for why it picked one",
      "offset": 4900.64,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "versus two. But if I say score from uh",
      "offset": 4903.04,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "bad, good, very good, really really, you",
      "offset": 4906.719,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "know, if I give like more distinct text,",
      "offset": 4909.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that's a better way to generate a label",
      "offset": 4911.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "um from judge. Um so that's just text",
      "offset": 4914,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "labels over number labels. Yeah,",
      "offset": 4916.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "exactly. Use use labels. And then and",
      "offset": 4918.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "then let's go one level deeper, right?",
      "offset": 4921.04,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "So like I have this eval, but I I kind",
      "offset": 4922.8,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "of maybe want an explanation for why I",
      "offset": 4926.719,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "got a specific score. Well, the LLM as a",
      "offset": 4930.32,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "judge actually gives you an explanation.",
      "offset": 4932.639,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "So, it's giving me the justification for",
      "offset": 4935.679,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "why it gave a specific label. And this",
      "offset": 4937.84,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "is all of the reasoning of the LLM judge",
      "offset": 4940.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "as well. So, it's actually the chain of",
      "offset": 4943.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "thought of how it analyzed the text to",
      "offset": 4945.12,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "say, you know, should this be uh is this",
      "offset": 4949.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "considered friendly or not friendly? Um,",
      "offset": 4952.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "so that's that's really helpful as well",
      "offset": 4954.96,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "is make sure when you're generating eval",
      "offset": 4956.639,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "and understand one level further. Now,",
      "offset": 4961.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "you might disagree with the LLM judge",
      "offset": 4964,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and that's that's okay, right? Like that",
      "offset": 4967.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "means that that's a system. This is when",
      "offset": 4968.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "you think about your system, you have",
      "offset": 4971.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "your agents in your application, you",
      "offset": 4972.32,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "have your eval, but that doesn't mean",
      "offset": 4974.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that they're like perfect off the bat,",
      "offset": 4976.719,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "right? Like you might want to go in go",
      "offset": 4978.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "in and iterate on this LLM as a judge.",
      "offset": 4980,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "And to do that, that's where those human",
      "offset": 4983.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "labels and human annotations kind of",
      "offset": 4985.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "come in. So, what you can do is actually",
      "offset": 4987.36,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "take that same data set and go in and",
      "offset": 4990.56,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "actually label it as friendly or not and",
      "offset": 4993.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "use the same labels that you're using",
      "offset": 4996.88,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "for your LLM as a judge. And in here,",
      "offset": 4998.56,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "I've actually labeled I actually think a",
      "offset": 5002.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "lot of these responses are robotic. So,",
      "offset": 5003.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "this is an example of an AIPM basically",
      "offset": 5005.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "saying, &quot;Hey, I actually think the LLM",
      "offset": 5008.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "as a judge needs improvement.&quot; and I",
      "offset": 5011.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "want my team to go and improve on that",
      "offset": 5013.36,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "system. So, what you can do is add your",
      "offset": 5015.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "own label. And there's a there's a",
      "offset": 5019.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "really is kind of a note here of as we",
      "offset": 5020.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "get a little bit further like whose job",
      "offset": 5022.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "is it to generate the labels. I argue a",
      "offset": 5024.4,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "PM should be in the data and labeling",
      "offset": 5027.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and basically saying what's good and bad",
      "offset": 5030.159,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "so that you can give uh a metric for",
      "offset": 5032.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "your team to go and improve on. And I've",
      "offset": 5034.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "said these are bad like these I don't I",
      "offset": 5037.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "I went in and labeled those these uh as",
      "offset": 5038.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "I was generating these yesterday and I",
      "offset": 5041.28,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "was like I think these are pretty",
      "offset": 5042.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "robotic. Well, once you have that system",
      "offset": 5044.32,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "in place, you can actually take the same",
      "offset": 5048.159,
      "duration": 8.241
    },
    {
      "lang": "en",
      "text": "human labels and do another LLM, either",
      "offset": 5051.44,
      "duration": 8.16
    },
    {
      "lang": "en",
      "text": "an LLM or a codebased eval that says,",
      "offset": 5056.4,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "take that human label and match it to",
      "offset": 5059.6,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "the eval that was generated, and tell me",
      "offset": 5062.96,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "if my human label match the LLM as a",
      "offset": 5066.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "judge or not. And that's really helpful",
      "offset": 5068.719,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "to say is is what I'm saying the same",
      "offset": 5070.159,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "thing that the LLM as a judge is saying",
      "offset": 5073.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and if not I want to know why and I want",
      "offset": 5075.6,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "to go one level deeper. Okay. So we're",
      "offset": 5077.76,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "going to go ahead and run this eval",
      "offset": 5081.199,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "on the same experiments.",
      "offset": 5084.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "And this is what's called like a match",
      "offset": 5087.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "eval basically to say should I go ahead",
      "offset": 5088.56,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "and improve on my LLM as a judge. So",
      "offset": 5091.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it's actually going one level deeper. I",
      "offset": 5093.92,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "don't I don't see too many people",
      "offset": 5095.76,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "actually when they talk about eval",
      "offset": 5097.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "saying that you need to check the work",
      "offset": 5099.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "of the LLM as a judge, but this is this",
      "offset": 5100.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "is what that looks like is taking human",
      "offset": 5103.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "labels and comparing them to your LLM as",
      "offset": 5105.84,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "a judge. Yep.",
      "offset": 5108.159,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "Okay. Awesome. And so what what I have",
      "offset": 5113.84,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "here is this is an example of where I",
      "offset": 5116.4,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "actually need to go in and you can see",
      "offset": 5120.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "my in this case it was a discount check",
      "offset": 5122.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and it looks like my it it did always",
      "offset": 5124.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "offer a discount and here I also matched",
      "offset": 5127.04,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "100%. And so this kind of tells you okay",
      "offset": 5129.92,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "when I didn't match on a specific eval I",
      "offset": 5132.239,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "want to go in and figure out why that is",
      "offset": 5135.84,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "uh like why is my judge different than",
      "offset": 5138.48,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "my my label?",
      "offset": 5141.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "So, where am I seeing that it didn't",
      "offset": 5144.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "match? It looks like it didn't match on",
      "offset": 5146.56,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "the left side for friendliness. Is that",
      "offset": 5147.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "right? Yeah. So, I think this one was a",
      "offset": 5150.239,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "discount one, but we should we you know",
      "offset": 5152.32,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "what? Let's just make that a little bit",
      "offset": 5153.92,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "more let's just make this example a",
      "offset": 5155.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "little bit more concrete. Um, so I'm",
      "offset": 5156.8,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "going to go ahead and actually remove uh",
      "offset": 5159.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "let me let me go ahead and create this",
      "offset": 5161.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "eval one more time and just do this one",
      "offset": 5163.28,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "was a discount one. Let's go ahead and",
      "offset": 5165.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "do a friendliness one. I think that's",
      "offset": 5167.679,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "actually a better one, honestly. Okay.",
      "offset": 5169.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "So, we're just going to generate this on",
      "offset": 5173.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the fly. Again, it's not not super",
      "offset": 5174.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "complicated. Like, I'm basically saying",
      "offset": 5176.48,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "friendly. And you can see I have my like",
      "offset": 5179.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "type ahead here a little bit. Uh, so",
      "offset": 5183.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "we're going to use friendly.",
      "offset": 5186,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "And then we're going to do the same",
      "offset": 5188.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "thing over here.",
      "offset": 5190.239,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "And so, what am I doing here? I'm",
      "offset": 5193.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "basically using an LLM. I mean, it could",
      "offset": 5194.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "be code. This is definitely like you",
      "offset": 5197.04,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "have options here of like do you want to",
      "offset": 5198.88,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "do this with code or do you want to do",
      "offset": 5200.239,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "this with LLMs. We're going to do this",
      "offset": 5201.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "with an LM just because it's a little",
      "offset": 5203.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "faster for me. And I'm saying check if",
      "offset": 5204.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the eval label matches the annotation",
      "offset": 5206.56,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "label. This is a really lazy eval. Um",
      "offset": 5208.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "but you can, you know, if you were",
      "offset": 5212.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "actually doing this in production, you",
      "offset": 5213.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "would make this more specific. Um",
      "offset": 5215.36,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "and then the rails uh system is",
      "offset": 5219.28,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "basically just making sure that you get",
      "offset": 5221.679,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "a label that you can use for plotting",
      "offset": 5223.199,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "the chart. Okay. Okay. So, we're going",
      "offset": 5225.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "to do a friendly match as as you as you",
      "offset": 5227.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "just mentioned, like what am I actually",
      "offset": 5230.32,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "checking for here? I want to make sure",
      "offset": 5232.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that my friendly label matched or",
      "offset": 5233.52,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "didn't. And so, let's run this here.",
      "offset": 5235.6,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "It should only take a second to run.",
      "offset": 5242.56,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "The the point of a lot of this though,",
      "offset": 5246.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "while this is running, is that when you",
      "offset": 5248.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "think about your system as a whole,",
      "offset": 5251.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "okay, actually that ran faster than I",
      "offset": 5252.96,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "thought it would. So, let's just talk",
      "offset": 5254.56,
      "duration": 2.079
    },
    {
      "lang": "en",
      "text": "about that for a second. We'll come back",
      "offset": 5255.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "to the zoom out. So, you can see here my",
      "offset": 5256.639,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "friendly label matched 0%. Which means I",
      "offset": 5259.12,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "thought that all of those results were",
      "offset": 5262.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "not friendly. I thought that they were",
      "offset": 5265.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "robotic yesterday, but the LLM thought",
      "offset": 5266.4,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "that they were friendly, right? Like the",
      "offset": 5269.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "LLM as a judge was like, &quot;This is",
      "offset": 5271.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "friendly enough for me.&quot; That's an",
      "offset": 5273.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "example where I would go in and say,",
      "offset": 5275.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "&quot;Hey team, let's go iterate on our LLM",
      "offset": 5277.44,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "as a judge text and make it catch what's",
      "offset": 5280.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "friendly, not friendly better.&quot; So",
      "offset": 5283.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "that's what's really helpful is like my",
      "offset": 5285.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "LLM as a judge is totally misaligned",
      "offset": 5288,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "from my labels, my human labels. That's",
      "offset": 5290,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "what that's telling me. Got it. Yeah.",
      "offset": 5292.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "And then we could go in and we could how",
      "offset": 5295.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "would we iterate and improve that judge?",
      "offset": 5297.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Yeah. So that's a great great question.",
      "offset": 5300,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Why don't we just do that on the fly,",
      "offset": 5302.48,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "too? So we've got a friendly here. Let's",
      "offset": 5303.92,
      "duration": 8.279
    },
    {
      "lang": "en",
      "text": "go ahead and try to rerun this.",
      "offset": 5306.639,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "Like is there a way to give it our human",
      "offset": 5312.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "touch and then get it to like just learn",
      "offset": 5314.639,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that human labeling?",
      "offset": 5317.28,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "Well, now I I I think um",
      "offset": 5319.679,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "I'm like very I I would love to show the",
      "offset": 5327.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "workflow for that, but to be honest,",
      "offset": 5330.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "Akos, like uh the the truth is that",
      "offset": 5332.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that's coming out really soon on our",
      "offset": 5335.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "end. Um, so like if you check the by,",
      "offset": 5337.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you know, if by the time you're watching",
      "offset": 5339.84,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "this, the workflow will actually look",
      "offset": 5341.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "really different because we'll have a",
      "offset": 5344.239,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "button that says take the human labels",
      "offset": 5345.36,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "and optimize your prompts. Cool. Um, so",
      "offset": 5348.639,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "that's the part of like uh a little bit",
      "offset": 5352.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "of like when you think about how",
      "offset": 5354.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "self-driving cars or fine-tuning works,",
      "offset": 5356.159,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "it is actually taking those labels and",
      "offset": 5358.56,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "using that to iterate. We call that",
      "offset": 5362.239,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "prompt learning. And actually Andre",
      "offset": 5363.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Karpathy also tweeted about something",
      "offset": 5365.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "similar which is take your human labels",
      "offset": 5367.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and use them to iterate on your prompt.",
      "offset": 5369.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "Um so it's a little bit of the like",
      "offset": 5371.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "coming very soon. Uh the workflow is you",
      "offset": 5374.159,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "can do the workflow today which is take",
      "offset": 5377.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the eval and try to handtune it a little",
      "offset": 5379.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "bit based on the the uh the human label.",
      "offset": 5381.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "But yeah, wouldn't it be great if you",
      "offset": 5384.56,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "could just click a button and it updates",
      "offset": 5385.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "your prompts for you? So that's that's",
      "offset": 5387.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the product that we're we're working on",
      "offset": 5389.92,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "next.",
      "offset": 5391.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "So this is eval. I think where I want to",
      "offset": 5392.639,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "go next is start to break down some of",
      "offset": 5395.28,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "these terms. We talked a little bit",
      "offset": 5397.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "about rag, but fine-tuning and prompt",
      "offset": 5398.239,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "engineering and really understand how",
      "offset": 5400.56,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "they all fit together.",
      "offset": 5402,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "Yeah. So I think that like it it's",
      "offset": 5404.239,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "helpful to zoom out and see like what do",
      "offset": 5406.639,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "all of these things really mean when you",
      "offset": 5409.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "build a product? And to that I'm going",
      "offset": 5412.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "to go to just Excaladraw and just sort",
      "offset": 5414.08,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "of whiteboard some of this. Um,",
      "offset": 5416.96,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "by the way, uh, just as a note, do you",
      "offset": 5420.719,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "think we should start here or should we",
      "offset": 5423.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "go up to the cursor or like the bolt",
      "offset": 5424.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "example? Like what what do you feel like",
      "offset": 5426.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "would be more? Um, maybe we start with",
      "offset": 5428.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the bolt diagram. Yeah, perfect.",
      "offset": 5430.08,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Awesome. So, when you think about",
      "offset": 5432.08,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "pulling all of these concepts together,",
      "offset": 5434.239,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "I think it's really helpful to go from",
      "offset": 5437.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you've built this initial system, but",
      "offset": 5440,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "what does this look like in practice",
      "offset": 5442.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "when you go from prototype to",
      "offset": 5444.719,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "production? And I think it's helpful to",
      "offset": 5446.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "like look at great tools out there that",
      "offset": 5448.96,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "we all kind of have used or tried uh at",
      "offset": 5452.56,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "some at some point and like that are",
      "offset": 5455.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "really taking a lot of attention from",
      "offset": 5456.719,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "the AI product mindset and try to",
      "offset": 5458.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "understand how they work a little bit",
      "offset": 5461.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "more. Maybe we can use this as an",
      "offset": 5463.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "example to just go through like how Bolt",
      "offset": 5465.28,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "works at a really high level just to",
      "offset": 5467.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "pull all of this together.",
      "offset": 5468.719,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "Um, so if you haven't used Bolt yet or",
      "offset": 5470.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "or you know I I do this thing in person",
      "offset": 5473.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "like where I'll ask how many people have",
      "offset": 5476.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "heard of Bolt or Lovable, everyone",
      "offset": 5478.159,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "raises their hand. Okay, how many people",
      "offset": 5479.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "have like actually tried to use the tool",
      "offset": 5481.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and like half the hands go down? And I",
      "offset": 5482.88,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "think that's part of the problem. But I",
      "offset": 5484.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "do recommend like you know we jumped",
      "offset": 5486.719,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "into the deep end with cursor. If you",
      "offset": 5488.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "haven't tried Bolt yet, please go and",
      "offset": 5490,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "try it. It's really straightforward.",
      "offset": 5491.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "just ask it to do the same prompt we",
      "offset": 5493.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "just gave uh cursor and you'll get a",
      "offset": 5494.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "good AB test feeling of like what's",
      "offset": 5497.199,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "different between these systems. Um so",
      "offset": 5499.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "once we've built something in bolt, what",
      "offset": 5501.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "you'll kind of notice is it's it's a",
      "offset": 5503.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "workflow which also generates code and",
      "offset": 5505.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "gives you a UI as a prototype. It kind",
      "offset": 5507.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "of feels like magic, right? Like I don't",
      "offset": 5510.56,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "I I feel like you you know I had this",
      "offset": 5512.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "feeling when I first tried it. I was",
      "offset": 5514.719,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like wow holy cow. It just knows exactly",
      "offset": 5516,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "what to do and built this UI in like one",
      "offset": 5519.199,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "second with everything that I asked for.",
      "offset": 5521.679,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "But it's not magic. And let's talk about",
      "offset": 5525.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "what's going on underneath the hood a",
      "offset": 5528,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "little bit more. And I want to preface",
      "offset": 5529.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "and say like this is just from reading",
      "offset": 5530.88,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "the code. And that's why it's so",
      "offset": 5532.88,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "important to be able to read code so",
      "offset": 5534.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that you can interpret uh you know",
      "offset": 5535.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "what's going on with your AI product. So",
      "offset": 5538.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "what you can do is Bolt is uh has their",
      "offset": 5540.159,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "code hosted on GitHub like an open",
      "offset": 5543.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "source version and if you go in I",
      "offset": 5545.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "thought wow this is going to be really",
      "offset": 5547.199,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "sophisticated but really at a high level",
      "offset": 5548.32,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "Bolt contains a system prompt which you",
      "offset": 5551.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "we just saw what a prompt was with an",
      "offset": 5553.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "agent a system prompt you're going to",
      "offset": 5555.92,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "notice a lot of similarities here and",
      "offset": 5558.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you'll see you are Bolt an expert AI",
      "offset": 5560.159,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "assistant an exceptional senior software",
      "offset": 5562.56,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "developer with vast knowledge across",
      "offset": 5564.639,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "multiple programming languages So what",
      "offset": 5566.719,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "bolt really is is it's basically a",
      "offset": 5569.92,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "really big good prompt which is doing",
      "offset": 5573.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the same things we just talked about.",
      "offset": 5576.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "You're setting the role. You are a",
      "offset": 5578.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "developer. You're setting context.",
      "offset": 5580.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "You're saying you are operating in an",
      "offset": 5582.639,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "environment called a web container.",
      "offset": 5584.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "You're generating tools or implicit tool",
      "offset": 5586.719,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "calling. I call it implicit tool calling",
      "offset": 5589.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "because you're you're referencing the",
      "offset": 5591.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "tools in the context. you're not",
      "offset": 5593.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "explicitly calling a service externally,",
      "offset": 5595.199,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "but you're sort of setting uh you know,",
      "offset": 5597.92,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "here's what's available to you to be",
      "offset": 5600,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "able to implement something. So, it says",
      "offset": 5602.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "prefer using Vite, which is maybe just a",
      "offset": 5604,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "framework here instead of implementing a",
      "offset": 5606.159,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "custom web server. So, that's like",
      "offset": 5608.159,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "saying don't go off and use a tool",
      "offset": 5609.44,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "that's not vite. Um, and then you set",
      "offset": 5612.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "priorities in the instructions. So, you",
      "offset": 5615.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "can see literally the prompt contains",
      "offset": 5617.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "important, use valid markdown, ultra",
      "offset": 5619.679,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "important, do not be verbose. So you're",
      "offset": 5622,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "really setting what the output looks",
      "offset": 5625.04,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "like in your prompt. Very important.",
      "offset": 5626.8,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "You're then providing fshot examples of",
      "offset": 5629.84,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "what good looks like. Once Bolt contains",
      "offset": 5632.719,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "all of this information in the prompt,",
      "offset": 5636.719,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "really all that's going on is it's",
      "offset": 5639.92,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "taking this user input request and",
      "offset": 5641.76,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "that's being fed into the agent system",
      "offset": 5645.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "with the same context we just talked",
      "offset": 5648.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "about the system prompt, the user",
      "offset": 5651.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "prompt, and then access to all of those",
      "offset": 5653.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "tools in the prompt itself, which are",
      "offset": 5655.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "structuring the problem, picking the",
      "offset": 5657.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "right framework. There's a concept of a",
      "offset": 5659.28,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "terminal and then retrieving context",
      "offset": 5661.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "above and these are think of these are",
      "offset": 5663.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "just like components in your prompt",
      "offset": 5665.84,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "here. All of that goes into an LLM and",
      "offset": 5668.32,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "then you get generated code and that",
      "offset": 5672.239,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "generated code I thought this was going",
      "offset": 5675.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to be way more sophisticated like I you",
      "offset": 5676.719,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "know with cursor if you there's like a",
      "offset": 5678.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "three and a half hour like interview",
      "offset": 5680.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "with the cursor founders on Lex",
      "offset": 5683.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Freedman. It's fascinating. I was like,",
      "offset": 5684.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "&quot;Wow, cursor is a really sophisticated",
      "offset": 5686.8,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "problem uh to solve.&quot; And and then I was",
      "offset": 5688.4,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "shocked at like you can get such a good",
      "offset": 5690.719,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "result with Bolt and Lovable because",
      "offset": 5692.719,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "really all they're doing is generating",
      "offset": 5695.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "code and rendering that code. So it's",
      "offset": 5697.04,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "just going into basically an environment",
      "offset": 5699.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "which takes the code that's written and",
      "offset": 5702.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "is just able to run the code, executes",
      "offset": 5704.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "it, and if there's a problem, it will go",
      "offset": 5707.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "back and fix itself. Similar to the",
      "offset": 5709.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "agent that you just saw, but it's it's",
      "offset": 5710.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "really why is this important to note?",
      "offset": 5713.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Because",
      "offset": 5714.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Bolt is even simpler to some degree in",
      "offset": 5716.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "terms of the system you see here than",
      "offset": 5718.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the the agent that we wrote in cursor to",
      "offset": 5720.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "some degree because what what's really",
      "offset": 5722.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the secret sauce here is you can take",
      "offset": 5725.36,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "generated code break it up into files",
      "offset": 5727.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "and then render that code and you get an",
      "offset": 5730.239,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "you get a UI. Now, if you try to use",
      "offset": 5732.96,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "Bolt to make external API calls, for",
      "offset": 5736.96,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "instance, or call other services or",
      "offset": 5740.239,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "images, it gets a lot harder to do",
      "offset": 5743.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "because of what Bolt is wired up to.",
      "offset": 5745.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "It's a closed box basically. You can't",
      "offset": 5748.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "go in and plug in external things to it",
      "offset": 5750.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "very easily. And maybe just to recap",
      "offset": 5753.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "that, it's really just a system prompt",
      "offset": 5755.679,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "goes into reasoning to generate what do",
      "offset": 5757.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "I need to do? Let me make a plan. The",
      "offset": 5760.239,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "same thing we just saw with that a the",
      "offset": 5762,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "cursor agent. What tools do I have?",
      "offset": 5763.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Takes that context, generates code,",
      "offset": 5765.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "deploys it, and then renders that code",
      "offset": 5768.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and then based on user feedback, it can",
      "offset": 5770.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "you know iterate on that.",
      "offset": 5772.88,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "And what that really means is I like to",
      "offset": 5775.92,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "think about this as product principles",
      "offset": 5779.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "for a full stack coding agent where you",
      "offset": 5781.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "can pull together prompting your system",
      "offset": 5783.76,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "prompt prompt engineering reasoning in",
      "offset": 5786.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the form of agents re really it's like",
      "offset": 5789.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "agent-based reasoning or chain of",
      "offset": 5791.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "thought reasoning tool calling in this",
      "offset": 5793.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "case it's implicit tool calling and rag",
      "offset": 5795.84,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "which is the context from that you've",
      "offset": 5798.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "just provided the agent all of that goes",
      "offset": 5801.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "into an LLM and you get the generated",
      "offset": 5803.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "code. So, it's kind of constructing your",
      "offset": 5805.52,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "you could fine-tune the model more if",
      "offset": 5808.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you wanted to. The LLM layer, you can",
      "offset": 5810.239,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "update your rag and change what context",
      "offset": 5812.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "is provided. You can change your prompts",
      "offset": 5814.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and that's that's a huge component of",
      "offset": 5817.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this as well. Uh, and then you kind of",
      "offset": 5819.28,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "string all that together with eval,",
      "offset": 5821.52,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "you know, kind of slick generated code",
      "offset": 5826.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "on the other end. I actually put EV",
      "offset": 5828.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "valves in green because from what I",
      "offset": 5830.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "could tell, Bolt isn't running EV valves",
      "offset": 5832.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "on the fly. And that's actually an",
      "offset": 5834.88,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "opportunity. I think like this is an",
      "offset": 5836.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "example where if you're an AIPM, take",
      "offset": 5837.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "note of what are the opportunities in",
      "offset": 5840.56,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "the system where you can go and actually",
      "offset": 5842.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "improve on the system overall. For",
      "offset": 5845.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "instance, there could be a version of",
      "offset": 5847.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "Bolt that never makes mistakes. Like you",
      "offset": 5849.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "could have it running in Eval on the",
      "offset": 5851.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "fly. Right now, Bolt is uh when you're",
      "offset": 5853.119,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "when you're actually running Bolt, it",
      "offset": 5855.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "can break because it's making mistakes",
      "offset": 5857.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "in code. You could have an eval that's",
      "offset": 5859.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "run that checks is the code correct or",
      "offset": 5862.32,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "not. And that would be an example of",
      "offset": 5864.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "running eval to actually improve on the",
      "offset": 5866.719,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "system, make Bolt even more reliable.",
      "offset": 5868.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "And so those are all I think of this as",
      "offset": 5870.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "like tearing down a product out there",
      "offset": 5872.48,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "and thinking, oh, what are the",
      "offset": 5874,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "opportunities to make this better? And",
      "offset": 5875.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that's that's really helpful to pull all",
      "offset": 5877.04,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "of this together.",
      "offset": 5878.56,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "So if we go back then and we compare",
      "offset": 5882.719,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "those three terms that fine-tuning,",
      "offset": 5884.56,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "prompt engineering, rag, how do those",
      "offset": 5887.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "all compare and when do we use what?",
      "offset": 5889.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "Yeah, good question. So you've still got",
      "offset": 5892.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "this system here where this is all kind",
      "offset": 5894.08,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "of, you know, different components. When",
      "offset": 5895.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "should you use what? Right? That's sort",
      "offset": 5898.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "of your your the note of your question.",
      "offset": 5900.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Yeah. And I kind of um I think it's",
      "offset": 5902.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "helpful to have just like a really quick",
      "offset": 5904.32,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "diagram here of like what is each thing.",
      "offset": 5905.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "So let's look at prompt engineering. We",
      "offset": 5908.719,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "have a it kind of depends on what your",
      "offset": 5911.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "goal is. So if your goal is to adjust",
      "offset": 5913.6,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "the tone or the instructions, I think",
      "offset": 5916.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "prompt engineering is really helpful for",
      "offset": 5919.199,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "that. Uh so that's basically changing we",
      "offset": 5921.199,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "kind of did that just now on the fly",
      "offset": 5923.76,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "with our agent and with bolt. You can",
      "offset": 5925.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "see you can change the instructions and",
      "offset": 5926.719,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "the tone. That's both how bolt literally",
      "offset": 5928.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "works. With rag you can provide context",
      "offset": 5930.48,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "over a lot of data. So if you need to",
      "offset": 5933.84,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "give the agent access or the the tool",
      "offset": 5936.239,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "your AI uh application access to data",
      "offset": 5939.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "internally in your system that's when",
      "offset": 5942.239,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "you would use rag which is using that",
      "offset": 5944.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "data to create a generation on top with",
      "offset": 5947.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the context. So you're stuffing that",
      "offset": 5949.92,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "into the prompt. Fine-tuning is think of",
      "offset": 5951.36,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "this as adjusting the model layer a",
      "offset": 5955.199,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "little bit. So it's actually taking the",
      "offset": 5957.84,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "LLM and making it more specialized.",
      "offset": 5959.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "What's really useful for fine-tuning is",
      "offset": 5962.719,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "sort of style to make sure it always",
      "offset": 5964.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "responds a certain way, increases the",
      "offset": 5966.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "reliability. And then I put",
      "offset": 5968.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "distribution, but distribution is like",
      "offset": 5970.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "giving it more data in the LLM itself",
      "offset": 5972.239,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "that makes it more specific or",
      "offset": 5975.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "specialized.",
      "offset": 5976.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "It's useful uh I think you know when you",
      "offset": 5978.4,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "think about um it's it's useful to think",
      "offset": 5980.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "about like what's the effort of each of",
      "offset": 5983.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "these prompt engineering relative to",
      "offset": 5985.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "some of the others is really really low",
      "offset": 5987.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "effort actually. All you have to do is",
      "offset": 5989.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "have access to the prompts, change those",
      "offset": 5991.44,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "prompts, and then get the eval result to",
      "offset": 5993.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "understand are you making the system",
      "offset": 5996.239,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "better or worse. Rag is a little bit",
      "offset": 5997.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "more complicated where you have a",
      "offset": 6000.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "database now. So how you retrieve",
      "offset": 6002,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "information from the database can have",
      "offset": 6003.84,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "an impact on how much work this is",
      "offset": 6005.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "actually. And then thinking about like",
      "offset": 6008.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "fine-tuning, if you change the model",
      "offset": 6010.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "layer, you change this variable that",
      "offset": 6012.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "might have a lot more impact on the rest",
      "offset": 6015.04,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "of the system. And so I kind of view",
      "offset": 6017.119,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "this a little bit more as like medium to",
      "offset": 6018.719,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "high today um because it requires a bit",
      "offset": 6020.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "more sort of specialization to adjust",
      "offset": 6023.199,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "the model. That being said, the impact",
      "offset": 6025.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "is really important to think about too,",
      "offset": 6027.76,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "right? Like as as a PM, we're always",
      "offset": 6029.28,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "thinking what's the effort, what's the",
      "offset": 6030.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "impact. The impact of prompt engineering",
      "offset": 6032.159,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "is really high. Um and in fact, that",
      "offset": 6034.4,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "means that you know a small change to",
      "offset": 6037.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the prompt can get you 10, 20, 30, even",
      "offset": 6038.639,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "more percent gains on your eval scores.",
      "offset": 6041.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Uh think about it that way. Like if",
      "offset": 6044.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you're designing your AI product around",
      "offset": 6045.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "your eval like eval are your",
      "offset": 6048.159,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "requirements now then you really want to",
      "offset": 6050.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "think about how can you have the highest",
      "offset": 6052.719,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "impact on those and I think prompt",
      "offset": 6054.48,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "engineering is huge. Rag is another",
      "offset": 6056.08,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "really high impact way to improve on",
      "offset": 6058.639,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "your system. A lot of times this might",
      "offset": 6060.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "mean like adding rag to your system when",
      "offset": 6062.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "it doesn't have it already. So just",
      "offset": 6065.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "adding more context or adding better",
      "offset": 6067.04,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "context. And then I think fine-tuning it",
      "offset": 6068.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "sort of depends on what you're trying to",
      "offset": 6071.679,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "do. Fine-tuning is really helpful for",
      "offset": 6073.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "saving cost which might be a very",
      "offset": 6076.56,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "serious concern as you scale up or",
      "offset": 6078.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "reducing latency in your system. So if",
      "offset": 6080.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "you want the the model to be faster,",
      "offset": 6082.159,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "fine-tuning can be really useful for",
      "offset": 6084,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "that. Another helpful way to think about",
      "offset": 6085.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "this to some degree and this is not",
      "offset": 6088.239,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "perfect. So don't feel feel free to like",
      "offset": 6089.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "grill me in the comments that I got this",
      "offset": 6092,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "wrong but um but you know I'm this is my",
      "offset": 6093.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "mental model I use. I think of prompt",
      "offset": 6096.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "engineering as giving really clear",
      "offset": 6098.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "instructions to like an engineer or to",
      "offset": 6100.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "an employee because what you're trying",
      "offset": 6102.4,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "to do, the more specific you are, the",
      "offset": 6104.08,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "better result you're going to get. Like",
      "offset": 6105.679,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "in the beginning of this video, if I had",
      "offset": 6107.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "given clearer instructions to the agent,",
      "offset": 6108.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "I may have gotten my tool my product out",
      "offset": 6111.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "faster, but we wanted to see what it",
      "offset": 6113.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "looked like to just like try to",
      "offset": 6115.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "prototype with with not great",
      "offset": 6116.88,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "instructions. And that's that's the",
      "offset": 6118.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "output that you get. With Rag, I think",
      "offset": 6119.6,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "about this as like a doctor having",
      "offset": 6122.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "access to the medical textbook at all",
      "offset": 6124.239,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "times. Meaning it can, you know, this",
      "offset": 6126.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this agent can go and look things up to",
      "offset": 6128.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "get more information. Like if I copy",
      "offset": 6130.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "pasted a doc into cursor, it's going to",
      "offset": 6133.28,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "go to that website and read the doc to",
      "offset": 6135.76,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "try to understand what I'm asking it to",
      "offset": 6138.719,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "do. And that can be really helpful when",
      "offset": 6140.719,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you're asking it for stuff that it",
      "offset": 6142.719,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "doesn't know in its memory already. And",
      "offset": 6144.239,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "then sort of last but not least,",
      "offset": 6146.4,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "fine-tuning is sort of like going from",
      "offset": 6147.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "college to specializing in a career.",
      "offset": 6149.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "What's kind of interesting is that these",
      "offset": 6151.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "models are so good now at generalizing",
      "offset": 6152.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that you kind of trade off things when",
      "offset": 6155.52,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "you go to specialization. Like you know,",
      "offset": 6157.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "a lot of people view hallucinations as",
      "offset": 6160.639,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "things you want to remove, but I think",
      "offset": 6162.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "hallucinations are a feature, not a bug",
      "offset": 6164.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of these models. And so just note that",
      "offset": 6166.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "when you change the model architecture",
      "offset": 6168.4,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "by fine-tuning, you might be getting rid",
      "offset": 6170.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of some of the generalization that can",
      "offset": 6172.639,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "be really helpful. um for a a a",
      "offset": 6174.4,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "production application. So this is my",
      "offset": 6176.96,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "mental model for like prompt",
      "offset": 6178.719,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "engineering, rag, and fine-tuning and",
      "offset": 6180.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "how they all kind of come together when",
      "offset": 6182.239,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you're thinking about building an AI",
      "offset": 6184.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "product system.",
      "offset": 6186.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "Awesome. So we covered four of the five",
      "offset": 6188.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "skills. The final skill, and I don't",
      "offset": 6190.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "know if we'll need screen for share for",
      "offset": 6192.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this, you tell me, is working with AI",
      "offset": 6194.48,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "engineers and researchers, working on",
      "offset": 6196.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "these longer development timelines. How",
      "offset": 6198.719,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "can AIPMs master that?",
      "offset": 6201.36,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "Yeah. So I think this is where I'll come",
      "offset": 6204.56,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "back to like what are we what are we",
      "offset": 6208.32,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "kind of talking about when we say our",
      "offset": 6210.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "our job is changing as AIPMs.",
      "offset": 6212.719,
      "duration": 9.841
    },
    {
      "lang": "en",
      "text": "And I think about this as the the",
      "offset": 6216.56,
      "duration": 9.679
    },
    {
      "lang": "en",
      "text": "expectation on AIPMs is changing from",
      "offset": 6222.56,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "our stakeholders. And our stakeholders",
      "offset": 6226.239,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "when we think about who are they right",
      "offset": 6228.96,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "now, they're not necessarily just",
      "offset": 6230.719,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "engineers that were working in their own",
      "offset": 6234.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "way either. Like the way engineers are",
      "offset": 6236.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "working and how they're expected to work",
      "offset": 6238.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "is changing too. And if you're working",
      "offset": 6240.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "on AI products specifically, you might",
      "offset": 6242.96,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "have data scientists or AI engineers",
      "offset": 6245.84,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "that are also ramping up to using Gen AI",
      "offset": 6248.639,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "in their workflows as well. So they're",
      "offset": 6251.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "going to be using data to make",
      "offset": 6253.84,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "decisions. And I think the best way I",
      "offset": 6255.92,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "can think about here is your job now has",
      "offset": 6259.52,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "become to get a little bit more in the",
      "offset": 6263.28,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "details of what it actually takes to",
      "offset": 6265.84,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "ship an AI product by understanding the",
      "offset": 6268.639,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "core concepts and principles of what",
      "offset": 6271.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "goes into great AI products,",
      "offset": 6273.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "understanding how they work and when to",
      "offset": 6275.6,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "use what tools. And then sort of very",
      "offset": 6278.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "importantly, last but not least, when",
      "offset": 6280.639,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you work with an AI engineer is to know",
      "offset": 6282,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "what they're thinking, what they need",
      "offset": 6284.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "from you. So let's take an example of",
      "offset": 6285.679,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "what that means tactically. When when",
      "offset": 6288.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "we're thinking about evals, an AI",
      "offset": 6290.719,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "engineer might be looking at an example",
      "offset": 6293.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and saying like, was this the agent good",
      "offset": 6295.04,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "or bad in this case? Like you as an AIPM",
      "offset": 6298.08,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "should be able to answer that question",
      "offset": 6301.199,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "because you are representing what the",
      "offset": 6302.719,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "end sort of experience for a customer",
      "offset": 6305.28,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "looks like, right? like you are the",
      "offset": 6308,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "ultimately the person that's like on the",
      "offset": 6309.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "hook if the AI product is successful or",
      "offset": 6311.199,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "unsuccessful. And so I think I really",
      "offset": 6313.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "view it as you want to be in the details",
      "offset": 6316.239,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "of what the team is working on and how",
      "offset": 6318.8,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "it works. You want to be a little bit",
      "offset": 6320.8,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "more in the details of the data of is",
      "offset": 6322.719,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "the experience good or bad and can you",
      "offset": 6325.679,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "give that feedback back to the team to",
      "offset": 6327.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "know what to go and improve on. And then",
      "offset": 6329.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "I think last but not least, like being",
      "offset": 6332.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "able to",
      "offset": 6334.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "interact in the same platform and work",
      "offset": 6336.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "in the same the same tools as your AI",
      "offset": 6339.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "engineers is going to help that",
      "offset": 6341.6,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "communication much more. Like when I",
      "offset": 6343.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "talk to AI engineers, they're often like",
      "offset": 6344.719,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "they what they come back and tell me is,",
      "offset": 6347.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I can't believe my PM is still sending",
      "offset": 6349.119,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "me Google docs of PRDS and saying like",
      "offset": 6351.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "go and implement this thing. I wish that",
      "offset": 6354.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "they would just be able to look at the",
      "offset": 6356.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "system as a whole of like what the",
      "offset": 6358.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "agents actually look like and what",
      "offset": 6360.4,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "they're calling and be able to tell me",
      "offset": 6362.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "is this correct or not or I wish that",
      "offset": 6365.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "they were actually looking at customer",
      "offset": 6368,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "data and telling me what's good or bad.",
      "offset": 6369.44,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "And so I think that that's really",
      "offset": 6371.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "important is to speak the same language",
      "offset": 6373.119,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "as your engineering team now as they're",
      "offset": 6375.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "ramping up on building around AI as",
      "offset": 6377.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "well. And this is really an opportunity",
      "offset": 6379.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "for AIPMs to stand out, you know, from",
      "offset": 6381.199,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "other other sort of product managers",
      "offset": 6384.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that maybe haven't ramped up in that way",
      "offset": 6386.239,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "either. Like my I would argue that the",
      "offset": 6387.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "stronger you are at communicating with",
      "offset": 6390.48,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "data, communicating around what are the",
      "offset": 6392.159,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "concepts to implement in your product,",
      "offset": 6395.199,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "the more impact and sort of influence",
      "offset": 6397.52,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "you're going to have as an AI product",
      "offset": 6401.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "manager on your organization and on your",
      "offset": 6403.199,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "leadership. Because to be honest, you",
      "offset": 6405.44,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "might even be able to influence at a",
      "offset": 6408.159,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "higher level than even what you were",
      "offset": 6410.239,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "able to do before because you're able to",
      "offset": 6412.56,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "communicate around these terms more",
      "offset": 6414.159,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "powerfully. So, should PMS be writing",
      "offset": 6415.6,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "AIE eval? Oh, I think absolutely. I",
      "offset": 6418.639,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "think I think eval",
      "offset": 6422.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "would really reframe this as like you",
      "offset": 6425.04,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "know, we kind of mentioned eval are kind",
      "offset": 6427.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "of what tells you what's good or bad",
      "offset": 6429.679,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "about your system. But what if eval were",
      "offset": 6431.119,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "your requirements instead of your AI",
      "offset": 6433.119,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "product? So like you come back to the",
      "offset": 6436.239,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "team and instead of saying, you know,",
      "offset": 6438.159,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "when you think about a PRD product",
      "offset": 6439.84,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "requirements doc, what if that actually",
      "offset": 6441.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "looked like an eval requirements doc?",
      "offset": 6443.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "And instead of a doc, it's actually just",
      "offset": 6445.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "here's the data, here's the eval score.",
      "offset": 6447.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Now you guys go and improve on this eval",
      "offset": 6450.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and show me how you're improving on",
      "offset": 6453.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that. And that is a really interesting",
      "offset": 6454.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "position to be in because you can work",
      "offset": 6456.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "with your engineering team on getting",
      "offset": 6459.199,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "the right data in place. You can be",
      "offset": 6460.8,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "hands-on with them and you get to",
      "offset": 6462.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "determine like what's good and bad at",
      "offset": 6464.719,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "the end of the day, which is what the",
      "offset": 6466.56,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "end product experience actually looks",
      "offset": 6467.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and feels like. Um, and I guarantee you",
      "offset": 6469.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "like what we just saw a lot of the code",
      "offset": 6471.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "like AI engineers, they want to be",
      "offset": 6474.639,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "thinking about the right model. They",
      "offset": 6476.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "want to be thinking about context. They",
      "offset": 6478.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "want to be thinking about prompting. but",
      "offset": 6480,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "they're not necessarily always going to",
      "offset": 6482.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "be thinking about the enduser experience",
      "offset": 6484.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the same way that you will like they're",
      "offset": 6487.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "thinking about implementation. So they",
      "offset": 6489.36,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "need someone to give that feedback of",
      "offset": 6491.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "enduser experience and I think eval are",
      "offset": 6493.119,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "a really good way to represent that.",
      "offset": 6495.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Awesome.",
      "offset": 6498.56,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "So that's our mini crash course.",
      "offset": 6500.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "We've talked a little bit about how to",
      "offset": 6503.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "become an AIPM and in other places",
      "offset": 6505.119,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "you've talked in even more detail. What",
      "offset": 6508.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "should you not do?",
      "offset": 6510.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Yeah, that's a really good question. I",
      "offset": 6513.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "think I kind of view this as like what",
      "offset": 6515.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "are some of the things I see people",
      "offset": 6518.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "doing today that you know from an AIPM",
      "offset": 6520,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "like they could be doing like what are",
      "offset": 6522.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "people not doing today is one way to",
      "offset": 6525.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "look at this like where there's a set of",
      "offset": 6527.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "opportunities here.",
      "offset": 6529.28,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Um I think generally",
      "offset": 6531.52,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "if you are thinking about",
      "offset": 6535.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "what we just walked through from a",
      "offset": 6538.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "project project perspective,",
      "offset": 6540.56,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "imagine if you had side projects kind of",
      "offset": 6543.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "going all the time to help you kind of",
      "offset": 6546.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "use these tools. So very common mistake",
      "offset": 6548.8,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "I see is AIPMs don't you know I'll talk",
      "offset": 6551.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "to AIPMs and I'll say like what are you",
      "offset": 6555.119,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "working on on the side? That's actually,",
      "offset": 6557.04,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "by the way, like a bit of an interview",
      "offset": 6558.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "hack is like, it's actually like my",
      "offset": 6560.239,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "first interview is usually I ask like",
      "offset": 6562.239,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "aside from work, like what are you",
      "offset": 6563.84,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "building on the side? And the reason for",
      "offset": 6565.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that is you can immediately tell what",
      "offset": 6566.88,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "someone is interested in and you see",
      "offset": 6568.8,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "that they're curious. You see what their",
      "offset": 6572.56,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "interests are, but you also see that",
      "offset": 6574.159,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "they're taking initiative and they're",
      "offset": 6575.44,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "trying to build and use these tools on",
      "offset": 6577.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the side. So, you can immediately gauge",
      "offset": 6579.199,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like how close are they to actually",
      "offset": 6580.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "building products? How much do they",
      "offset": 6583.679,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "really care about building products? So,",
      "offset": 6584.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that's a very common mistake I think I",
      "offset": 6586.08,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "see is like, you know, if you don't have",
      "offset": 6588.48,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "side projects, you might kind of end up",
      "offset": 6592.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "having a bad time in the interview",
      "offset": 6595.119,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "process. And I think a classic example",
      "offset": 6596.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "of someone who does this really well and",
      "offset": 6597.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "posts about it is Claire um Claire Vo uh",
      "offset": 6599.44,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "like she has she had chat PRD, you know,",
      "offset": 6602.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "two years ago out, right? Like I",
      "offset": 6606.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "actually use an early version of that",
      "offset": 6608.32,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "system and I'm like it's not that great.",
      "offset": 6609.6,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "Like what's different about this than",
      "offset": 6611.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like talking to chat GPT? But then you",
      "offset": 6612.639,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "realize that she's been using this side",
      "offset": 6615.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "project to learn about the stack every",
      "offset": 6617.76,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "single week on her weekends. And so the",
      "offset": 6620.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "architecture has changed, the models",
      "offset": 6623.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "have changed. So very classic example",
      "offset": 6625.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "kind of building off of that is like you",
      "offset": 6627.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "don't have side projects. If you wait",
      "offset": 6629.199,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "until the models get better, you're",
      "offset": 6631.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "going to be left behind as well. So",
      "offset": 6633.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "Claire kind of took that project and",
      "offset": 6635.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "kind of kept iterating on it and",
      "offset": 6638.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "building on it. So now when the models",
      "offset": 6640.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "get really good, the product gets better",
      "offset": 6642,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "and you already have all of that",
      "offset": 6644.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "scaffolding and experience that you've",
      "offset": 6646.239,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "built up building the side projects to",
      "offset": 6648.639,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "take advantage of the newest models. So",
      "offset": 6650.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "just imagine like if you already have",
      "offset": 6653.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "some product ideas or problems that you",
      "offset": 6655.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "want to solve in your day-to-day life,",
      "offset": 6657.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "then you may as well start getting",
      "offset": 6659.6,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "building on them now so that when the",
      "offset": 6661.119,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "models do get better, you're not waiting",
      "offset": 6662.719,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "on that. You actually already have",
      "offset": 6664.719,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "something in place. to just kind of plug",
      "offset": 6666.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "and play the model. And then I'll kind",
      "offset": 6668.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "of take another sort of step back and",
      "offset": 6671.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "say like on the other end of the",
      "offset": 6673.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "spectrum, a very common mistake I think",
      "offset": 6675.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "I see AIPMs make is trying to automate",
      "offset": 6677.199,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "too much of their job off of the bat. So",
      "offset": 6680.4,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "what I mean by that is you want to use",
      "offset": 6683.84,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "AI as like a second brain to save costs",
      "offset": 6686.159,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "by doing things like analysis and deep",
      "offset": 6689.6,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "research and maybe even taking some",
      "offset": 6692,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "action on your behalf. But I would be",
      "offset": 6694.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "really careful about, you know,",
      "offset": 6696.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "automating too much right off of the",
      "offset": 6698.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "bat. So kind of leverage the fact that",
      "offset": 6700.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "these reasoning models are really good",
      "offset": 6703.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "at being able to do analysis and push",
      "offset": 6705.599,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "and poke your ideas a bit. So let me",
      "offset": 6708.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "give you an example of that. some of my",
      "offset": 6711.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "favorite prompts when I use a reasoning",
      "offset": 6712.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "model. And when I say reasoning model, I",
      "offset": 6715.28,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "mean like 03 or now the new cloud 4 as",
      "offset": 6716.8,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "well, which can basically run uh the LLM",
      "offset": 6720.239,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "sort of runs for longer and thinks about",
      "offset": 6723.599,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "what response to give you. And one",
      "offset": 6726.08,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "prompt I'll use really commonly is give",
      "offset": 6728.639,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "me five alternative solutions to what we",
      "offset": 6730.639,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "just talked about and rank them in order",
      "offset": 6733.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "of risk or ability to accomplish a goal",
      "offset": 6735.84,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "and then give me pros and cons of each.",
      "offset": 6738.56,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "So what that does is it helps me",
      "offset": 6741.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "interrogate my own thinking a bit",
      "offset": 6742.719,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "without trying to automate too much away",
      "offset": 6744.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "or just give get take the first solution",
      "offset": 6746.639,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "from the the LLM and try to go implement",
      "offset": 6748.639,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "it. So my recommendation is don't try to",
      "offset": 6750.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "automate too much and just take the",
      "offset": 6753.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "first recommendation like push back a",
      "offset": 6755.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "little bit and learn how to work with",
      "offset": 6757.599,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "your your LLM and agents to get more out",
      "offset": 6759.119,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "of them. Um, another example of that is",
      "offset": 6762.239,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "like help me simulate follow-up",
      "offset": 6764.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "questions from a customer or a vendor in",
      "offset": 6766.639,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "a space I might not be as experienced in",
      "offset": 6769.199,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and say, &quot;What are some of the questions",
      "offset": 6771.679,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "they might ask me? What are some",
      "offset": 6773.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "responses I should give? And then what",
      "offset": 6775.04,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "are some follow-up questions based on",
      "offset": 6776.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that?&quot; And so now you can actually show",
      "offset": 6778.32,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "up to an interview much more prepared",
      "offset": 6780.48,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "for what direction some some person",
      "offset": 6782.719,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "might take the questioning. And that's",
      "offset": 6784.719,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "like another recommendation of, you",
      "offset": 6787.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "know, you can't really automate that",
      "offset": 6788.8,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "because at the end of the day, you're",
      "offset": 6790.4,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "still going to be on the other side of",
      "offset": 6791.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the screen or or a conversation and you",
      "offset": 6792.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "should kind of be able to anticipate",
      "offset": 6795.28,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "what someone is going to say. So those",
      "offset": 6796.8,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "are a couple of examples. I'd say three",
      "offset": 6798.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "examples. You know, have side projects.",
      "offset": 6800.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "If you don't have side projects, that's",
      "offset": 6802.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "a really common mistake. Don't wait",
      "offset": 6804.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "until the models get better. Like now is",
      "offset": 6806.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "a great time to just start building",
      "offset": 6808.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "something and and swapping your",
      "offset": 6809.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "components in and out. And then don't",
      "offset": 6811.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "try to automate too much right off the",
      "offset": 6813.52,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "bat. Learn how to use AI as a second",
      "offset": 6815.36,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "brain to scale up your analysis and",
      "offset": 6818.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "research.",
      "offset": 6820.239,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Amazing.",
      "offset": 6822.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "So, a lot of that sounds like it could",
      "offset": 6824.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "be a lot of work, especially the side",
      "offset": 6826.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "projects. Yeah. But if somebody just has",
      "offset": 6828.08,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "two hours a week and they want to become",
      "offset": 6830.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "an EIPM, what are the exact steps they",
      "offset": 6832.639,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "should follow? Yeah, good question. And",
      "offset": 6834.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "I I feel this myself, right? Like we we",
      "offset": 6837.599,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "we have we have to, you know, we have",
      "offset": 6839.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "commitments. We have commitments to our",
      "offset": 6841.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "jobs, to our families, to other people",
      "offset": 6844.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "in our lives, and we can't, you know,",
      "offset": 6846.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "trying to ramp up here, it feels like a",
      "offset": 6849.119,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "lot, especially when the space is",
      "offset": 6851.52,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "changing so rapidly, and it's hard to",
      "offset": 6854.08,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "keep up. Definitely, the three things I",
      "offset": 6857.599,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "think about whenever I feel like there's",
      "offset": 6860.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "something new or something I'm trying to",
      "offset": 6862.719,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "ramp up on, when it comes to AI",
      "offset": 6864.639,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "specifically, it's really just three",
      "offset": 6866.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "steps. I'd recommend to try the tools",
      "offset": 6868.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "yourself firsthand.",
      "offset": 6871.599,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "I then recommend to build AI intuition",
      "offset": 6873.599,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "and then apply that AI intuition. And",
      "offset": 6877.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "let's kind of talk about each of those",
      "offset": 6879.679,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "in a little bit more uh depth. So when I",
      "offset": 6880.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "say try the tools, I don't mean like go",
      "offset": 6883.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and try to like implement them into your",
      "offset": 6885.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "company right off the bat. I don't mean",
      "offset": 6887.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "like go try and you know go back to your",
      "offset": 6889.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "CPO and say like we need an AI agent. I",
      "offset": 6892.159,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "mean just try the tools for your own",
      "offset": 6894.8,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "kind of use cases and and day-to-day",
      "offset": 6897.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "life. Like an example is you know I",
      "offset": 6899.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "wanted to build an AI storybook",
      "offset": 6901.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "generator um for someone in my life and",
      "offset": 6903.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "I was you know like for for a young",
      "offset": 6905.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "child and say let me build images",
      "offset": 6907.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "specific for this person based on a",
      "offset": 6909.84,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "theme and based on you know what uh what",
      "offset": 6911.84,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "I might be trying to like tell for like",
      "offset": 6915.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "a bedtime story or something like that,",
      "offset": 6917.36,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "right? Like really nice use case for for",
      "offset": 6918.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "a kid. And I think when I tried to use",
      "offset": 6920.719,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "the tools, I actually found where they",
      "offset": 6924.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "fell short and what was hard about them.",
      "offset": 6926.08,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "And so when I actually started using the",
      "offset": 6928.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "tools, I started realizing, huh, this is",
      "offset": 6930.639,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "what is possible and here's what's hard",
      "offset": 6932.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "about using these tools. So when you do",
      "offset": 6935.119,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "that, you kind of you gain a sense of AI",
      "offset": 6937.199,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "intuition a little bit of like what's",
      "offset": 6940.719,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "possible today and what's hard. The next",
      "offset": 6942.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "is I think trying to tear down AI",
      "offset": 6945.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "products with by building AI intuition",
      "offset": 6947.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "like we just did with Bolt. So when you",
      "offset": 6950,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "see an experience that feels magical,",
      "offset": 6951.92,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "try to go one level deeper and",
      "offset": 6954.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "understand how the system works a bit so",
      "offset": 6956.639,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you can see how these kind of buzzwords",
      "offset": 6958.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "like MCP, rag, like how they come",
      "offset": 6961.119,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "together to actually form the system you",
      "offset": 6963.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "just use and they feel a little bit less",
      "offset": 6966.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "like hypy and a little bit more real,",
      "offset": 6968.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "right? Like the same way we just said",
      "offset": 6970.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "with Bolt, like it's not using a ton of",
      "offset": 6971.679,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "complexity. It's actually just",
      "offset": 6973.76,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "prompting. We kind of learn that by",
      "offset": 6974.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "tearing the system down. You can do this",
      "offset": 6976.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "by watching YouTube videos, talking to",
      "offset": 6978.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "other AI PMs. You can try to look at",
      "offset": 6981.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "code as you get more proficient or copy",
      "offset": 6983.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "paste the code into an LLM and ask it to",
      "offset": 6985.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "explain it to you. And then you can just",
      "offset": 6988.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "try to recreate the product a little bit",
      "offset": 6990.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "yourself and see what's hard about that.",
      "offset": 6992.239,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "And then I think last but not least is",
      "offset": 6994.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "actually try to apply these two things.",
      "offset": 6996.159,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "is apply your curiosity and what you've",
      "offset": 6997.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "learned and try to build something that",
      "offset": 7000.239,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "you can keep going on the side as a side",
      "offset": 7002.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "project where you can actually try to",
      "offset": 7004.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "build your own product and that way",
      "offset": 7006.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you're always kind of motivated to try",
      "offset": 7009.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to try a new technology and see if it",
      "offset": 7011.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "makes your product better or worse. So",
      "offset": 7013.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "those are I think if you have two hours",
      "offset": 7014.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "a week you can at least try a tool pick",
      "offset": 7016.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "a tool whatever it might be. This week",
      "offset": 7020.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "for me it's going to be ve Veo3 because",
      "offset": 7021.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that one just launched and I want to go",
      "offset": 7023.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "and try and understand okay how good is",
      "offset": 7025.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this thing really can I build something",
      "offset": 7027.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "around it and then I'll kind of learn",
      "offset": 7029.84,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "what the boundaries are what the edges",
      "offset": 7031.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "are of the technology so that I know",
      "offset": 7033.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "okay here's what here's the",
      "offset": 7036.159,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "opportunities around that here's what I",
      "offset": 7037.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "can take back as a learning and the",
      "offset": 7039.119,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "whole goal is really just to keep",
      "offset": 7040.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "learning so that you can apply that in",
      "offset": 7042.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "your day job or for projects you might",
      "offset": 7044.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "be building",
      "offset": 7046.56,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "so I was really excited to have you on I",
      "offset": 7048.8,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "consider you, Tal, Colin, Pavle, like",
      "offset": 7050.719,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "four of the best AIPM creators, but",
      "offset": 7054.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "there's there's a little group that's",
      "offset": 7057.119,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "been criticizing us talking all about",
      "offset": 7058.88,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "AIPM, and what they keep saying is where",
      "offset": 7061.679,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "are the AIPM jobs? So, are there really",
      "offset": 7064.159,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "that many AIPM jobs out there? Yeah, I",
      "offset": 7067.36,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "think so.",
      "offset": 7070.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "I think part of it is like I'll be",
      "offset": 7072.719,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "honest, I don't know if the hiring",
      "offset": 7075.199,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "managers have like rebranded uh LinkedIn",
      "offset": 7076.56,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "jobs to say like AIPM just yet. What I",
      "offset": 7079.92,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "have been noticing is like you'll see PM",
      "offset": 7082.639,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "jobs that say product manager like AI",
      "offset": 7085.599,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "and that's that in my mind is sort of an",
      "offset": 7089.28,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "AIPM job. What I will say is that the",
      "offset": 7091.84,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "the space the the PM space is really",
      "offset": 7095.599,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "catching up here. So, we're a little bit",
      "offset": 7098.4,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "ahead of the curve and that's kind of",
      "offset": 7100.159,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "where you want to be a little bit from a",
      "offset": 7101.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "technology perspective is ahead of the",
      "offset": 7103.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "wave so that when the wave really comes",
      "offset": 7105.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "you're able to ride that wave just like",
      "offset": 7108,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "in surfing, right? Like you don't want",
      "offset": 7109.52,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "to be behind the wave you're going to",
      "offset": 7110.719,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "miss it. So think about here's a mental",
      "offset": 7111.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "model for you or like a you know sort of",
      "offset": 7114.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "a thought exercise is think about like",
      "offset": 7116.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "realistically what is the overall number",
      "offset": 7119.92,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "of PM jobs out there today and think",
      "offset": 7122.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "okay maybe it's in the thousands in your",
      "offset": 7125.84,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "local city wherever you might be living",
      "offset": 7127.599,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "but then think about in threeyear times",
      "offset": 7129.92,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "how many PM jobs like that will there be",
      "offset": 7132.8,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "and what's the ratio of AI PM today",
      "offset": 7136.4,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "relative to where we'll be in three",
      "offset": 7140.32,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "So when you think about that, you might",
      "offset": 7142.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "notice like in the headlines you'll see",
      "offset": 7144.719,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "companies are laying off entire teams,",
      "offset": 7147.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "entire orgs and PMs are sort of grouped",
      "offset": 7150.159,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "up into that. But it's really rare and",
      "offset": 7152.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "very I think like you know I almost",
      "offset": 7155.119,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "never see it where an AIPM team is going",
      "offset": 7157.92,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "to be laid off to some degree. And so",
      "offset": 7160.639,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "what you're trying to do is futureproof",
      "offset": 7163.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "your career a little bit by being ahead",
      "offset": 7164.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "by basically either taking an AIPM",
      "offset": 7167.599,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "position or positioning yourself as a",
      "offset": 7170.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "what could be an AIPM to fill that role",
      "offset": 7173.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "internally at your company because",
      "offset": 7175.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that's where companies are starting to",
      "offset": 7177.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "invest their resources when it comes to",
      "offset": 7179.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "product management headcount because of",
      "offset": 7181.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the opportunity around this technology.",
      "offset": 7184.32,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "So like coming back to an earlier point,",
      "offset": 7186.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "I don't think it's an eitheror. Like I",
      "offset": 7189.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "don't think it's like you know AIPM or",
      "offset": 7191.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "bust. I think it's like AI as an",
      "offset": 7193.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "opportunity that intersects with the",
      "offset": 7196.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "type of product management you might be",
      "offset": 7198.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "doing already like fintech healthcare",
      "offset": 7200.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "growth. And it's just that AI is another",
      "offset": 7202.56,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "way to leverage that up a bit more.",
      "offset": 7204.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "And to prove everybody who's getting mad",
      "offset": 7207.84,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "at us about these AIPM jobs, while Aman",
      "offset": 7210.8,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "was talking, I decided to search on",
      "offset": 7213.84,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "LinkedIn, right? AI product manager. And",
      "offset": 7216.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "like he said, it's that product manager,",
      "offset": 7219.44,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "AI. You're getting over a thousand",
      "offset": 7221.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "results just in New York City. So, this",
      "offset": 7223.119,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "is a real job out there. I've examined",
      "offset": 7226.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "the compensation of this in other",
      "offset": 7229.36,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "articles. These AIPMs are getting paid",
      "offset": 7230.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "20 to 30% more than regular PMs. We have",
      "offset": 7232.639,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "given you the full toolkit today. If",
      "offset": 7236.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "people want to go deeper, Aman, where",
      "offset": 7239.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "can they find you online? Tell us more",
      "offset": 7241.44,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "about what else you're doing outside of",
      "offset": 7243.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "appearing on podcasts and doing your day",
      "offset": 7245.199,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "job as a director of product. Yeah, for",
      "offset": 7246.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "sure. Well, so you can find me on uh",
      "offset": 7248.719,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "amman k.ai. That's my website. I'm also",
      "offset": 7250.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "on LinkedIn. If you just search for Aman",
      "offset": 7253.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Khan uh and Twitter, we can kind of plug",
      "offset": 7256.159,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "all the socials. Um, I think for for me",
      "offset": 7258.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "I really am trying to be as helpful as",
      "offset": 7261.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "possible to people that are trying to",
      "offset": 7263.199,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "make this transition in their careers as",
      "offset": 7264.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "well to going from product management to",
      "offset": 7267.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "either building around AI in their own",
      "offset": 7269.679,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "products or using AI in the day-to-day.",
      "offset": 7272.4,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "So my goal is really to try to just give",
      "offset": 7274.639,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "away as much for free, give away, you",
      "offset": 7276.639,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "know, as much as I possibly can to",
      "offset": 7279.119,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "people so that they can understand, you",
      "offset": 7280.719,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "know, how this technology is going to",
      "offset": 7283.199,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "impact their day job in the same way I",
      "offset": 7284.639,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "wish people were doing that for me in",
      "offset": 7286.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the past. And so my recommendation is",
      "offset": 7288.159,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "like pick you know content curators or",
      "offset": 7290,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "creators like yourself Akash you do such",
      "offset": 7293.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "an incredible job of bringing on like",
      "offset": 7295.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you know extremely talentrich people",
      "offset": 7297.44,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "that are you know able to share unique",
      "offset": 7300.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "perspectives and I learn something every",
      "offset": 7302.239,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "time I watch you know your your videos",
      "offset": 7304.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and read your content. And I think that",
      "offset": 7306.639,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "that's really what I'm I'm aiming to do",
      "offset": 7308.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "is just try to give my perspective of",
      "offset": 7310.4,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "being at the edge of building AI",
      "offset": 7312.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "products, what I see so that you can go",
      "offset": 7315.84,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "kind of build that into your own",
      "offset": 7318.56,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "companies or your own life. Kind of",
      "offset": 7320.239,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "taking like think of this as like taking",
      "offset": 7322.239,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "the bleeding edge of AI and trying to",
      "offset": 7323.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "make it more approachable for people a",
      "offset": 7325.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "bit more. Love it. And you also I'm just",
      "offset": 7327.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "looking you have a course on Maven.",
      "offset": 7330.08,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "What's that all about? Yeah, so this one",
      "offset": 7331.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "is a pretty recent addition actually to",
      "offset": 7333.199,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "the offering. So, um, I kind of view",
      "offset": 7335.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "this as a way for, you know, you can",
      "offset": 7338.4,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "think of this as like you could go get a",
      "offset": 7340.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "gym membership and like watch YouTube",
      "offset": 7342.719,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "videos. And I think that that's useful.",
      "offset": 7344.639,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "This is sort of more of like personal",
      "offset": 7347.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "training, uh, is how I view it. So, like",
      "offset": 7348.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you should really only take this course",
      "offset": 7350.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "to be honest if you are kind of you've",
      "offset": 7352.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "already you're in the early stages of",
      "offset": 7355.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "the curve and you've maybe gotten to a",
      "offset": 7357.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "point where you've built a prototype and",
      "offset": 7359.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "you feel a little bit comfortable in",
      "offset": 7361.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "cursor in some of the workflows we",
      "offset": 7363.599,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "showed. That's really going to be the",
      "offset": 7365.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "starting point for this course. So think",
      "offset": 7367.04,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "going from cursor prototype to a real",
      "offset": 7369.44,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "production application using eval and",
      "offset": 7372.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "some of the workflows we just showed.",
      "offset": 7375.199,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "The goal for me here is to give you an",
      "offset": 7377.28,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "H1 or H2 strategy doc that you can take",
      "offset": 7380.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "back to your leadership team for what an",
      "offset": 7383.36,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "AI product could look like in your",
      "offset": 7385.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "organization. And to do that, I want to",
      "offset": 7387.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "help you build the foundations of trying",
      "offset": 7389.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the products out at the early stages,",
      "offset": 7391.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "but really going into, you know,",
      "offset": 7393.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "day-to-day workflows of what AI product",
      "offset": 7395.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "management looks like when you're",
      "offset": 7397.44,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "building these products. So, yeah,",
      "offset": 7398.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "that's this the course is kicking off on",
      "offset": 7400.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "July 1st. Uh, it's going to be a",
      "offset": 7402.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "relatively small cohort to get started",
      "offset": 7404.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "with. Uh, and based on that, we're going",
      "offset": 7406.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "to try and run that more repeatably,",
      "offset": 7408.639,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "really as being sort of a way for you to",
      "offset": 7410.639,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "bounce ideas off of and really in a",
      "offset": 7413.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "structured way to kind of give you the",
      "offset": 7415.599,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "tools to build this H1 H2 AI strategy.",
      "offset": 7417.28,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "All right, guys. So, if you want to go",
      "offset": 7422,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "deeper, you can check out my code. It's",
      "offset": 7423.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "in the description to get a little bit",
      "offset": 7424.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of a discount off of Aman's course. I",
      "offset": 7426.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "can personally vouch this man knows his",
      "offset": 7429.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "stuff. Good luck to you on your AIPM",
      "offset": 7431.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "journey. Find both of us on LinkedIn if",
      "offset": 7434.08,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you need more and we'll see you next",
      "offset": 7435.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "time. Thanks for having me on, Akos.",
      "offset": 7437.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "This was awesome. I really hope you guys",
      "offset": 7439.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "enjoyed that episode. It would mean a",
      "offset": 7440.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "ton to me and the team if you could",
      "offset": 7443.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "please subscribe on YouTube, follow on",
      "offset": 7445.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Apple and Spotify podcasts and leave a",
      "offset": 7447.92,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "rating and review. Those ratings and",
      "offset": 7450.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "reviews really help grow the show and",
      "offset": 7453.199,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "help other people discover the show and",
      "offset": 7456,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "they help fund the production so that we",
      "offset": 7458.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "can do bigger and better productions.",
      "offset": 7460.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Can't wait to share the next episode",
      "offset": 7462.4,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "with you. Until then, see you later.",
      "offset": 7463.84,
      "duration": 5.16
    }
  ],
  "cleanText": "Companies are laying off entire teams, entire orgs, and PMs are sort of grouped up into that. I almost never see it where an AIPM team is going to be laid off to some degree. Can anyone become an AIPM? I think we're all kind of feeling it, right? Like as product managers, the expectations on us. We kind of know our role is changing. What is the right way to teach this material? What is the right sectioning of this material? And we've come up with five steps for you guys. So, we're going to go through AI prototyping, which is kind of the heart and soul of it all. We'll go into observability on top of our prototype, eval on our prototype, the difference between RAG, fine-tuning, and prompt engineering. And then we'll end with working with AI engineers, working with researchers. So let's hop into AI prototyping.\n\nSo for AIPMs, you'd really recommend they learn Cursor over the other tools. I would recommend getting familiar with it. Definitely. Yeah. When it comes to people creating AIPM content, Aman Khan is amongst the most insightful and informed. And that's because he's been an AIPM since 2019. He worked at Cruise on self-driving cars. He's worked with Spotify on their AI systems. And now he works at Arize, one of the leading observability and eval companies. So if we go back then and we compare those three terms that fine-tuning, prompt engineering, RAG, how do those all compare? I think it's helpful to have just like a really quick diagram here of like what is each thing. It kind of depends on what your goal is. So if your goal is to adjust the tone or the instructions, I think prompt engineering is really helpful for that. With RAG, you can provide context over a lot of data. Fine-tuning is think of this as adjusting the model layer a little bit. So it's actually taking the LLM and making it more specialized. Working with AI engineers and researchers, working on these longer development timelines, how can AIPMs master that? Yeah. So, I think this is where\n\nreally quickly I think a crazy stat is that more than 50% of you listening are not subscribed. If you can subscribe on YouTube, follow on Apple or Spotify podcasts, my commitment to you is that we'll continue to make this content better and better. And now on to today's episode.\n\nWelcome to the Podcast, Aman. Thanks so much for having me, Akash. It's great to be here. I'm I've been waiting for this one for a long time. I'm so excited to speak to you. So, yeah, I think that there's no better person to really give us a crash course in all of the key AIPM skills as they stand here in June 2025. But before we even get there, I need to know, can anyone become an AIPM? Yeah, I mean, I think the the whole narrative here of like, you know, I think we're all kind of feeling it, right? Like as product managers, the expectations on us, we we kind of know our role is changing. Our stakeholders are expecting more from us. Our customers are expecting more from us. And I think we're already feeling that role of AI in our day-to-day life more and more. I mean, that's the reason why that that narrative is really sticking. It's that, you know, can any PM become an AIPM? And I really think to just define what an AIPM is, it's really some flavor of either adopting AI in your day-to-day workflow. Think of this as like an AI powered PM or building AI into your product, which is you can think of that as like an AI product PM. And I really don't think that, you know, being an AI PM is not an either/or. I really view it more as an X. Meaning like you can think of yourself as a fintech X AIPM or a healthcare X AIPM. And the reason I say that is because AI is really powering your workflows as a product manager rather than taking the job you have away. You really want to be able to take that core insight and knowledge and specific industry uh sort of knowledge that you have and apply that towards the field using AI you know sort of to power those workflows. So that's really how I view it. I think I think every PM will become some flavor of AIPM either using those tools or building around them if you aren't already. And I wouldn't view it as mutually exclusive with the type of product management you you might already be doing. So that's kind of how I view it. Think of it as like more of an accelerator on top of the workflows you already have. Agreed. And I think that people often come up with the edge cases like, \"Hey, I'm an internal tools PM or I work in this really regulated industry.\" But in the last few weeks and months, I've been talking to exactly those types of PMs implementing AI. I talked to an experimentation PM who is dealing with the problem that everybody else has a slight variation on their PRD template by getting an LLM to convert that into a clear output of what the hypothesis is, what the Northstar metric is, what the Gorald Royal metrics is. So genius use case to standardize input into his experimentation system. I've been talking to people over in the financial industries. They're working on new credit models based on AI. So it seems like whatever exception you draw up, there's going to be a counterpoint to that exception. And just about every PM needs to learn how to build AI features. I think that's that's totally true. Like and I I think there's definitely a feeling where there's maybe some some amount of like hesitation or, you know, unsure of like wanting to brand or label yourself as like, oh, I'm an AIP. I'm like kind of worried you might be jumping on some sort of like hype train. that I really urge folks to think about what the market for product management looks like and what the roles and skill sets will require in the future. And that's really why I think that, you know, the sooner that you kind of think of yourself as an AI PM building in fintech, building in healthcare, the faster you'll kind of adopt those tools, the faster you'll become a leader in in your own space in that using using AI as well.\n\nSo, enough talking. Let's get into the five skills. You and I have been going back and forth on what is the right way to teach this material, what is the right sectioning of this material, and we've come up with five steps for you guys. So, we're going to go through AI prototyping, which is kind of the heart and soul of it all. We'll go into observability on top of our prototype, Eval on our prototype, the difference between RAG, fine-tuning, and prompt engineering. And then we'll end with working with AI engineers, working with researchers. All right, so now we're going to get into these skills starting with AI prototyping. So maybe even consider opening up your browser alongside Aman as we walk you through these key skills. Okay, so let's hop into AI prototyping. Um, so what we've got here, if you haven't seen this tool before, this is Cursor. Cursor is basically a fork of VS code which is a really common tool used by developers for actually you know has been used for many years to kind of write and iterate on code in an IDE which is an interactive developer environment. We're going to hop into using Cursor as our prototyping tool just because the amount of improvements that have been made to it in sort of the recent weeks and months have made it really my go-to tool for prototyping even relative to some of the others. right now. Um, you know, there's there and just to maybe linger on that point for a moment, there's a lot of tools out there like Lovable, Bolt, Replit, Vercel, Vzero, and I think they all have their place when it comes to prototyping. For instance, you know, Vercel is really strong at front end. Lovable and Bolt is really easy to deploy and get started with. Uh, Replit is really powerful for Python-based applications and having an agent built in. But the reason I really like Cursor is just because of the amount of control and flexibility it gives me to be able to iterate on specific components. Um, I completely admit like it there's a little bit of a learning curve to get started with using Cursor, but I promise you if you, you know, spend a little bit of time on being able to just be able to kind of feel comfortable with the interface, you're going to get a lot more out of the tool just because of the the sort of the features and components it has built into it from a usability perspective. Um, maybe just so for AIPMs, you'd really recommend they learn Cursor over the other tools. I would recommend getting familiar with it. Definitely. Yeah. I I think that the other tools are going to keep improving and they're really helpful for building a really quick and dirty mock uh you know you know to build like just a quick UI. But if you really want to get a little bit deeper than that and understand how do I implement let's say an agent next or uh can I have more control over the system, you're going to need a tool like Cursor. Um definitely. Okay, cool. Yeah, maybe we can prototype like a agentic system since that's what's hot. Yeah, absolutely. I think that's a great idea. So, let me go ahead and actually start uh here from scratch. So, when you first load up Cursor, you're going to get um you know the screen where you can either set up a repo or set up a directory. It doesn't really matter what you get started with here. I have a starting point of a of a workspace, but the two this the two commands that you want to kind of hit right off the bat on your laptop are command T, which pulls up your terminal. And don't worry, you can actually just type in natural language instructions here to get started with uh terminal commands as well. So that's actually running the code on your computer. and then command K, which is uh really how you spin up the the the agent um which which you're going to be using for uh oh, looks like that commands. Oh, sorry, not command K. Uh what you're going to want to do is actually hit command L to pull up the agent. And the agent is this new kind of some somewhat new feature in Cursor that allows you to uh go ahead and and actually it will write the code for you and actually run the code for you too. What I've been using recently is Claude 4 sonnet. Cloud 4 is just I think a massive improvement on top of previous models here when it comes to understanding commands and writing code. So really, I just go ahead and start typing in what I want this agent to do and it's able to kind of get started from there. Um, let's take an example. So when we were talking about agent-based systems, I kind of pulled this up. This is in our uh repo in Arize. It's a fully open source repo. It's a workflow for actually using Crew AI, which is a very kind of popular framework these days for setting up agent-based systems. Um, you can either use Crew AI. There's a ton of others out there. Uh, it doesn't really matter, but all I'm all I wanted to do is pull up some example context that I can use and plug in so that I kind of know what the output looks like. So, this is a notebook that just creates a Crew AI agent. Really just starts spinning up a workflow for research and deciding, you know, being able to do some market research. It doesn't matter, but it's mo more so just for grounding the the agent in the first place. And what I'm going to do is actually rebuild and rearchitect this system entirely on the fly just using this code example. So the instructions I'm going to give are build me a trip planner agents using instead of Crew AI use Langraph which is just another framework really just to show like it doesn't matter which agent framework you use you can be really flexible here. The trip planner should have a front end I can use as an application. So what I'm doing here is is basically defining I want this agent to have a UI that I can actually click and interact with further. So we've got kind of two components in here uh which is build me a trip planner agent. here's the framework to use and then if you need to, you know, you what you used to be able to do uh in the sort of before was actually use at web and um and at web allows the agent to go and sort of search the internet as well and take action actually search look at documents and take that information and apply it in the code. So let's go ahead and and hit enter here and see the agent sort of go off on its own and and see what it generates. And it's not a very complex prompt really. No. And that that's sort of the beauty of it. Like I I know that there's a ton of upfront work you can do to make that initial shot uh sort of what we kind of call in and prompting is like the first shot or zero shot better. But just know that the workflow I really promote in terms of people getting comfortable with these tools is just being able to iterate. And so knowing how to ask the right questions from the agent to give it what you want. So let's take a look here. So it says, I'll help you build a trip planner agent using Langraph instead of Crew AI with a front-end application. And so it'll actually go in and read the tutorial and understand what the components are. Great. and says, \"Okay, I'm going to go ahead and take a look at this implementation and create the Langraph trip planner.\" So, it's going to go ahead and create a new directory for me. So, see, it didn't even matter what my starting point was because the agent can actually create folders on your machine. It can create directories. It can pull in the right data and even import packages. So, it's actually going off and doing this live. It's creating the requirements for the agent in the first place. Today's episode is brought to you by Miro. Let me ask you something. How many tools are you juggling just to get a single project across the finish line? One for brainstorming, another for planning, something else for tracking tickets. That's where Miro comes in. It becomes an all-in-one collaboration workspace. Whether you're consolidating user research from several interviews, developing and synthesizing product briefs or a wireframe or project managing development, Miro brings everyone into the same space. It's fast, intuitive, and fully loaded with features like project templates, two-way Jira sync, and integration with software like draw.io and plant UML. Miro's AI features can be used to synthesize elements in a board to develop a\n\n\nReady-to-review product requirements document in seconds.\nIf you're tired of tab overload and scattered workflows, try Miro.\nHead to miro.com and see why over 90 million users choose Miro to guide from idea to outcome.\nToday's episode is brought to you by Jira product discovery.\nIf you're like most product managers, you're probably in Jira tracking tickets and managing the backlog.\nBut what about everything that happens before delivery?\nJira product discovery helps you move your discovery, prioritization, and even road mapping work out of spreadsheets and into a purpose-built tool designed for product teams.\nCapture insights, prioritize what matters, and create road maps you can easily tailor for any audience.\nAnd because it's built to work with Jira, everything stays connected from idea to delivery.\nUsed by product teams at Canva, Deliveroo, and even The Economist.\nCheck out why and try it for free today at atlasia.com/roduct-discovery.\nThat's atlasia.com/roduct-discovery.\nJurroduct discovery.\nBuild the right thing.\nThat chain of thought reasoning is really useful, too.\nIt seems like that's one of the important steps for people is to actually understand a little bit of what's going on and not just ignore that, but start learning.\nAnd as you do that 10, 20 times, then you really get used to it.\nAbsolutely.\nAnd being able to, you know, what's what's really cool about this is you can actually go in and see what are the files that it referenced.\nUm, be able to see, okay, here's what it's referencing.\nSo if you need to, you can always pause it, pause the agent and say, \"Hey, I actually want you to go take a look at this part of the code or this resource.\"\nAnd what's really cool and we can kind of we'll kind of show this is you can even paste in images and using those images, the agent can actually, you know, kind of infer, oh, this is what I want the UI to look like or not.\nSo it's a really really powerful multimodalbased uh agent that can write code.\nUm, so now it's actually writing the code of the file itself.\nAnd here what is going on behind the scenes?\nIt's using those websites and the Phoenix uh thing that we started off with or it's writing a lot of scratch code.\nWhat's going on?\nYeah.\nSo, so actually, you know, the repo I kind of gave was just a starting point and it can really just be any directory.\nWhat's going on underneath the hood is the agent has kicked off a search.\nIt well first it took the prompt and the context I gave the agent and it said let me build a plan and that's actually the first step in all of this is actually to generate a plan uh which you it doesn't show here but there is a a basically a chain of thought for the plan here so if you hit this uh thought for 4 seconds you'll see what the agent is thinking it should do and it says I should first look at the crew AI tutorial design a lang graphbased trip planner then build a front-end application and then integrate it all together.\nAnd so that's just like you would give this to an engineer if you were hopefully you're giving better requirements to an engineer, but you don't have to give really good requirements to your agent because the agent will just like make sense of whatever you've given it and try its best to figure it out.\nSo it's very robust to that.\nSo once you've got that plan, then the agent executes code on your machine to actually implement that plan.\nThe first thing it did was create a directory that it's writing code into.\nSo, it's actually created a new folder uh in my my workspace where it's actually writing code uh you know on my machine.\nAnd the code is really just text files.\nIn this case, it's Python.\nUm you can define different frameworks if you want to.\nI could have said use Python or use React, but in this case, I've just let the agent go off and do its thing.\nI wasn't super prescriptive.\nUm so, great.\nSo it actually built the back end here which you can see and now it's going to build the React front end.\nSo it's going and actually building uh you know building the UI components.\nAnd just to zoom out for a moment, to be able to do this even a year ago would have been really really challenging because you're just not going to get robust UI components and uh sort of an agent that understands what goes into building a React application with a degree of like confidence and understanding when there's errors, how to fix those errors.\nSo let me show you an example here.\nThe agent actually built a file and what it found was that there was an error in the file and on the fly it went back and it's rewriting parts of the file because the agent can actually see and read errors as they as they come up and can is able to go back and iterate on those same files uh all within the chat window as well.\nOkay, in this case, there's times when you as a human might need to intervene, particularly when there's files being deleted.\nSo, it might prompt you to either accept to do something or not.\nUm, I generally just let, you know, I'll I'll take a look at what the agent is asking me to review and then I'll either accept or reject based on that.\nAnd it can actually tweak its path based on whether or not you accept or reject the suggestion.\nOkay, great.\nSo now it's going ahead and creating a directory and installing all of the components for the UI right now.\nSo it seems like from 0 to one it might be a teeny bit slower than a lovable bolt or v 0ero but after 0 to one the power to edit more implement more cursor is allowing more potential.\nAbsolutely.\nI think that one way to think of it is like the application that we've given it is and I'm using a pretty capable model as well.\nI'm using cloud 4 which is a reasoning model.\nSo it's a little bit slower than some of the faster models out there.\nBut the reason that you you know one reason to actually start here is you just have complete control over the files.\nYou can go in and if you wanted to, one thing I do is actually I'll take a look at the file and I'll ask the agent.\nYou can reference a specific file here in the context window and you can actually say what is going on in this file and you can just have a conversation with the code uh you know with the agent on top of your code.\nSo even if you you know want to know do I really need this file?\nUm can you make this better?\nI noticed this one thing my engineer pointed something out.\nYou're just going to have a lot more control over that system using Cursor.\nSo, it's it's worthwhile to invest a little bit more time to get this thing set up on your machine.\nOkay.\nAnd is it possible to do those types of things in parallel or while it's working?\nWhile it's generating, you can't chat until this generation is done.\nYeah, I I think you know we could try actually.\nSo, I've started a new chat.\nLet's see.\nOkay.\nYeah.\nSo, so with Cursor, you actually Yeah, you can't have multiple I don't believe you can have multiple chat windows going at the same time.\nI think you can only do one chat, but maybe someone can prove me wrong there.\nSo now that it's done, you could chat with it though.\nYeah.\nLet's see.\nSo this one I think it I think we may have broken it actually continue building which is you know part of part of exploration.\nDid it actually finish or not?\nUh let's see.\nOkay.\nSo so what's funny is like the system is super robust, right?\nOh gosh.\nLike we we just broke it because I went to another tab and I came back and I'm like, \"Hey, you know what?\nI'm sorry for interrupting your work.\nJust keep doing what you were doing.\"\nAnd it's just like, \"Oh, okay.\nHere's what I was doing before.\nLet me just recap it for myself.\nI'm just going to keep going on my way.\"\nRight?\nIt's sort of like tapping an engineer on the shoulder.\nLike I'm not worried about breaking my code anymore or like changing one line because I know and I have so much confidence that the system is going to be able to recover from some of those mistakes when it comes from starting from scratch.\nFor sure.\nUm, I would say if you try to go to your like production codebase and you're like, \"Hey, can we start using Cursor all over the place like this?\"\nYou're going to get a lot of push back because I will say like with these types of agents, they're really good for going from zero to one and maybe even building something that gets you to production.\nBut when you already have a system that's using multiple dependencies, it gets a little bit harder to know are that like you really do want to make sure the changes that you're making are correct in the first place.\nSo I do recommend that you know at least when you're just getting started.\nUse this on like zero to one projects that you own entirely and not so much necessarily your production code base that you might be building on top of.\nYeah, I was worried that it was going to break when we were clicking around, but it just started right back up.\nYeah, I think that's part of where Look, I mean, I think I'll just say like from the perspective of a product manager today, being comfortable with the fact that this thing is writing code.\nIt's just going to go off and start doing things.\nYou should really just feel comfortable knowing how to interact with it.\nAnd that's I think part of that is just it's it's just a comfort level that comes with working with these tools.\nFor sure.\nLooks like can I edit some files?\nBut it'll just go out and continue on its own.\nAnd this read me, can we read that me read me and see what's going on behind the Yeah, absolutely.\nSo, it's actually when it's writing the file.\nSo, you used to be able to just see it like writing uh code in real time.\nI think with the agent um the agent mode you have to wait until the file is written but let's give it a sec to write that file and we can read what the read me is because I think it's often like a PRD style doc exactly and and and you you could you know I think that there's some really great examples if we were being more sophisticated I could have given it a better prompt as well but you're right it's it's basically here's what's going on underneath the system nice and it says this is what I did here are the fees that it has architecture backend, front end, and then written with full emojis.\nYeah, I don't know why uh LLMs really like to use emojis these days.\nUm um that's how you know somebody's LinkedIn post had some chat GPT editing.\nOh my gosh.\nI mean, that's I mean, for sure.\nYeah.\nChat GPT Claude were definitely trained on LinkedIn as well.\nSo So it kind of goes both ways, right?\nIt's like self-reinforcing with these models.\nYeah.\nOkay.\nSo, it's actually so tried to run the code.\nIt hit an example.\nIt hit a problem here and now it's actually creating the Docker file.\nWe don't necessarily need Docker, but it's helpful if you wanted to actually deploy this thing.\nDocker is a way for you to just wrap everything up and think of it as like a folder that you can deploy and put on the internet.\nUm.\nYep.\nOkay.\nSo, it's writing all this.\nUh, and what what we can actually do is it's given me enough information here where I can actually try to run this live.\nSo, uh, I don't need to have it finish the Docker file.\nUm, and it's sort of just running tests.\nSo, it actually knows to actually test the agent itself, make sure that the backend is working.\nAnd as long as it's working, then it'll actually move on to the next step.\nUm, let's go ahead and So, it's got local host.\nWe've got it here.\nI have a feeling that this might break.\nUh but we will try it because it didn't ask me for an open AI key.\nSo let's see what happens.\nOkay, let's first actually go to here.\nGo to the back end.\nAnd so all I've done now is I'm looking at the readme and it actually lays out the quick start steps for how to spin up the system.\nSo all you have to do is copy paste these lines of code.\nSo I can go to lane graph.\nUm, and the a little bit of like the terminal commands is helpful to know like cd dot dot to navigate your directory structure.\nUm, but we're going to go ahead and and dot dot like moves you up a level, right?\nExactly.\nDot dot moves you up a level and then ls lists the files in there.\nYeah.\nUm, so we're going to try to go to cd agent and cd is just change directory.\nDirectory.\nExactly.\nPIP uh is your Python.\nSo, um let's make sure we're in we're going to create a new Python um environment.\nSo, let's call this.\nSo, we created a workspace.\nWe set up a project.\nDo we have an environment?\nNo.\nSo, so one thing you definitely want to be careful of when you're running Python on your machine, every developer will have faced this at some point.\nIt's sort of a right of passage, is you don't want to be writing uh, you know, updating packages and installing packages to your Python locally.\nYou want to be using virtual environments uh because your system Python is sort of you want to kind of keep that protected um because that can really break things.\nSo what we've done is just created a virtual environment using a tool called cond.\nAnd if you have if you get stuck on that or you're like what is going on here?\nUh don't worry the agent will actually you can you can also specify use a virtual environment or you know how should I do this on my machine and it will help you out.\nIt'll guide you through those steps as well.\nOkay.\nYeah.\nOkay.\nSo now we've kind of done that.\nNow we're going to install our requirements.\nSo, we just we're in the right directory and now we're just going to hit pip install requirements.\nAnd if this works, it will actually install those requirements into my Python virtual environment.\nOkay, great.\nUm, set up environment variables.\nOkay, so let me go here uh and open up that file.\nSo, we actually want to uh name this env.\nSo, actually, let's see what environment variables it needs.\nI'm not even sure.\nSo, we're just going to run the Python main and see what pops up.\nSo, we'll go back and do the ENV variables after exactly.\nYeah, because I'm kind of curious.\nI, you know, I could go in and read it.\nOkay, module not found.\nSo, it looks like it hit\n\n\nA problem here.\nThis is great.\nUm, because what that means is like I can go in and just copy that error and say, \"Hey, you hit this error.\nLet's see what Let's see how it fixes that.\"\nHit skip.\nStop.\nAnd all I mostly do as my workflow is copy the terminal, paste it in and say, you know, just literally just give it back to it and say, \"Hey, there's this bug here.\"\nAnd it will read the terminal lines and understand what's going on and try and infer that.\nNice.\nSo, this is what I mean where I'm like where I say don't be scared about things breaking.\nThey're going to break.\nWhat matters is how you can work with the agent to fix your problems.\nYep.\nToday's episode is brought to you by Maven.\nIf you're enjoying this episode with Aman, you'll love his course on Maven, today's podcast sponsor.\nThe problem with most courses online like Udemy is there's no live component and the instructors aren't experts in their fields.\nThey're professors.\nAt Maven, you get direct live access to experts and operators from the world's best tech companies.\nYou can't get that access anywhere else in any university and you usually can't find them on YouTube either.\nI've featured so many of Maven's experts in the newsletter and podcast for that reason.\nTo help you out, I've put together a collection of courses I recommend at maven.com/x/ashos.\nThis includes courses like AI prototyping for PMs, product sense for PMs, and getting an AIPM certification.\nVisit it now at mavve.comx aka.\nToday's episode is brought to you by Amplitude.\nReplays of mobile user engagement are critical to building better products and experiences, but many session replay tools don't capture the full picture.\nSome tools take screenshots every second, leading to choppy replays and high storage costs from enormous capture sizes.\nOthers use wireframes.\nBut key moments go missing, creating gaps in your understanding.\nNeither approach gives you a truly mobile experience.\nAmplitude does things differently.\nTheir mobile replays capture the full experience.\nEvery tap, every scroll, and every gesture with no lag, and no performance hit.\nIt's the most accurate way to understand mobile behavior.\nSee the full story with amplitude and also setting aside enough time to just persevere.\nDefinitely.\nYeah.\nOkay, now it's going to actually try to run these commands.\nLet's see if that works.\nOkay, so I have to enter in OpenAI key.\nThat's what I was kind of expecting.\nSo it actually built this file.\nAnd great.\nLet me go ahead and insert an open AI key.\nHopefully this works.\nUm I'm going to go ahead and move this to different window so I don't blast this on the internet.\nOkay.\nYeah.\nDon't share your open AI keys or your keys, you know, widely.\nUh that's definitely something to keep in mind.\nUm that'll be expensive fast.\nYeah.\nOkay.\nPress enter.\nOkay.\nPort is already in use.\nGo ahead.\nToday's episode is brought to you by Amplitude.\nReplays of mobile user engagement are critical to being I had something working in the background.\nMany session replay tools don't capture the full picture.\nSome tools take screenshots every second leading to choppy replays, high storage costs from enormous capture.\nOthers use wireframes, but key moments go missing, creating gaps in your understanding.\nNeither approach gives you a truly mobile experience does things different.\nTheir mobile replays capture the full experience every tap every gesture with no lag and no performance.\nIt's the most accurate way to understand mobile behavior.\nSee the full story with and also setting aside enough time to just persevere.\nDefinitely.\nOkay.\nNow it's going to actually try to run these commands.\nLet's see if that works.\nOkay, so I have to enter in OpenAI key.\nThat's what I was kind of expecting.\nSo it actually built this ENV file.\nAnd great.\nLet me go ahead and insert an open AI key.\nHopefully this works.\nUm I'm going to go ahead and move this to different window so I don't blast this on the internet.\nOkay.\nYeah.\nDon't share your OpenAI keys or your keys, you know, widely.\nUh that's definitely something to keep in mind.\nUm that'll be expensive fast.\nYeah.\nOkay.\nPress enter.\nOkay.\nPort is already in use.\nGo ahead.\nNot a big deal.\nI I had something working in the background and it's going to um kill that process.\nOkay, I added my OpenAI key.\nGreat.\nAnd now it says it's built.\nLet's go ahead and navigate to that and see where it's running.\nI I feel like I didn't see the UI.\nUh it it looks like it ran the back end.\nOkay.\nAnd now it says in a new terminal do this.\nSo let's go ahead and do that.\nSo we're going to go ahead and run this.\nWe're going to try this again.\nSee if it actually fixed the problems before.\nStill hitting this problem.\nExisting virtual environment with an old incompatible version.\nOkay, that's okay.\nI mean, we'll just try that again.\nWe're going to uninstall those old versions.\nSo, some of the steps that has you do Oh, you could have hit run actually.\nYeah, I can hit run in uh the terminal environment on the right or the one on the left.\nUm for me, I just wanted to to kind of take a look at it here.\nUm so, I'm going to run it over here.\nOkay.\nOkay.\nLet's try this again.\nSo, we're going to install a fresh virtual environment.\nOkay.\nAnd when we see those errors there, what are those like ignored the following yanked version?\nYeah, I think um so some of these are uh if some of those versions or those uh packages existed already um then you know it kind of looks a little bit scary because it's like all in red or versions are mismatching.\nAgain, I would just say like if you hit a bug or a problem, you can always pass those back off to the agent to go and fix.\nOkay.\nSo, in this case, it looks like it's trying to uh in use a version that doesn't exist.\nSo, that might be part of the problem here is it's uh actually trying to use a version for a package that doesn't exist.\nOkay.\nYeah, I think there we go.\nIt noticed the same thing.\nSo, it's going to work with the current package.\nSo here it's saying okay you know what let me just try to create a more simple version of this uh this uh this agent and see if that works.\nSo let's see if this works in the first place just to get something off the ground.\nSo even the the agent is sort of realizing you know what I may have overbuilt this first version.\nLet me go ahead and build a simple version.\nProbably PMs can relate with their PRDs.\nMaybe you overbuilt the first Yeah.\nbuild a simpler MVP, right?\nHappened to me certainly.\nSo, I'm just trying to read the code here.\nOkay, it's generating.\nYeah.\nSo, we can we can go ahead and read through what's going on here actually a little bit as well.\nFeels like co being able to read this code is just a key skill.\nYou know, the best part is the reason I like to work in Python is it is it is very readable and the agent does a pretty good job of commenting as well what it's trying to do uh in the code.\nSo you can see okay so it's importing a bunch of packages loading environment variables.\nUh all that means is it's like loading up the state that it needs to get started and then it starts defining classes and functions to actually execute on the code.\nSo let's go ahead and see what it's done here.\nSo okay, so we've created a simplified version Let's try this and see if it works.\nAnd if it doesn't, then we're back to square one.\nOkay.\nSo, okay.\nSo, it might just need this package.\nSo, I'm just going to go ahead and paste in those those errors again.\nI remember doing all this without an agent.\nIt was like a lot of looking up Stack Overflow and stuff.\nAt least you have somebody to talk to now.\nYeah.\nLet's exactly let's try on this uh let's try on this this window and see if this is working.\nSo okay so there's a version conflict.\nSo it's because I think it actually created like um two versions of the requirements file and they were sort of sitting on top of each other.\nThat's okay.\nLet's try this minimal version.\nYeah and we see like requirements minimal requirements simple requirements.\nYeah exactly.\nRight?\nThis is really bad practice that it implemented and you can always go back and be like hey some you know fix up the problems that you have uh in your codebase and it will also be able to go and simplify and remove extraneous files.\nSo I think that's like a pretty common um occurrence like if you're testing with Python it's very likely you're going to have package and version dependency uh problems.\nYeah.\nYeah.\nAnd so just I think just accepting that that's like part of working with Python through again you're getting you're getting one level deeper than like bolt and lovable right so you you a little bit of that comfort of there's a little bit more code here but knowing that you can just kind of again mostly what I'm doing is copy pasting the errors and letting the agent figure things out.\nI could go in and read the code and try to understand things better and that's worthwhile to do when you're building something um to production.\nBut to just get something off of the ground, I kind of let the agent define, you know, here's the right environment for me to work in.\nYep.\nLet's test if the simplified version works.\nOkay.\nServer because it's actually testing if the server has started and seeing what's the problem with the server.\nOkay, well we have a server up now.\nAll right, look at that.\nSo, it actually figured out, okay, you know what?\nI might be on the wrong port.\nLet me see if I should try to run this thing differently.\nAnd here we go.\nSo you can actually see this is a Python server that it started and this is a backend server that actually just routes the calls that we're going to be using for our trip planner agent.\nSo this is a this is a backend that's up.\nNow what do you want to change about the backend?\nThe backend is basically a way to route calls to open to open AI or to other services.\nUm so it's actually uh you know kind of doing this um in real time like it it just built this back end for us.\nNice.\nAnd what is it working on now?\nIt's a good question.\nIt looks like it has Okay, let's try to hit skip here.\nYou know what?\nLet's see.\nOkay, so it wanted to test the back end and in the in the Okay, so this is interesting.\nThat's actually really good example you just pointed out, Akash.\nSometimes when the agent is trying to run code in the terminal, if it's a longstanding process, it can get stuck.\nUh and so you might need to hit you know move to background or skip just to have it move on to the next step.\nOkay.\nSo let's try to actually run this now.\nRun the end to end application for me.\nAnd remind me what's the difference between this right side and the m the bottom middle the terminal you mean or the uh yeah okay so so on the right side this is think of this as like the agent environment it can interact with your terminal or you can have multiple terminals up so you you'll see it actually the terminal is these are the idees consist of different windows that you can reconfigure in different ways that you want to so like I have a terminal running in here.\nIt actually pulled up the terminal in this area.\nYou can have a terminal down here, but it's really just wherever you're executing code on the machine.\nOkay.\nSo, the right is the chat and it can go in and do terminal commands.\nAnd sometimes you're doing manual terminal commands in the bottom middle.\nThat's right.\nExactly.\nExactly.\nThat's that's that's definitely correct.\nOkay.\nNow, it's starting the front end.\nLet's see what it looks like.\nOh, it noticed there's a package dependency.\nNow it's going to go back, read that file, and let's look at it in real time.\nIt's removing the problematic dependency.\nBut what's great is that the back end is up.\nThe backend server is working here.\nOkay, let's work on dependencies.\nYeah, if anyone's ever tried to teach themselves Python before, they probably face this as well.\nThis is like a lot of versioning type issues.\nThere's there's definitely this like upfront work when you go from a rapid prototyping tool like Bolt and Lovable to Cursor, but the amount of control it's going to give you and flexibility and and that, you know, it's it's it's it's a worthwhile investment, I think, to be able to read the code uh and understand what's going on.\nSo, what are these like unsupported engine warnings that we're seeing here?\nSo, let's see what's going on.\nLooks like it might be hitting a problem with the packages it decided to use.\nSee if it can figure it out.\nI might hit skip here just to have it keep moving.\nSee what happens.\nWow.\nI feel like we hit like every possible thing that can go wrong with the versions of no in this one.\nSo, it's a really extensive demo, but what it realiz is like it's using a version of Node that actually has problems with some of the other packages.\nSo, it's going to go and and uh reinstall uh the the front end environment.\nCool.\nAgain, you know, it's going to happen.\nis just accepting that there's going to be this, you know, sort of a little bit of friction of like is the agent doing the right thing and it's just kind of making it move along and figure it out.\nI feel like we got the agent today on an off day.\nUh like it has didn't have its morning coffee or something, you know?\nIt's like making a a bunch more mistakes, but um that's okay.\nAnd node for people who don't know, that's like a runtime environment.\nWhat does that do for us?\nSo this gives you your uh your front end.\nSo this is actually able to uh accept and take requests make requests to the to the backend server which was your Python code and serve you a UI or front end.\nSo it's sort of think of this is like when you go to any website like what the the UI that you see is.\nOkay.\nOkay.\nSo it says both services are running.\nLet me check the status.\nSo it's going to go ahead and check.\nIt looks like things are have wow agent is stoked today.\nUm, so all right.\nSo we've got a front end.\nLet's go ahead and take a look at what that front end front end looks like.\nSo it even says here's how to use your trip planner agent.\nOkay, now we're going to go back.\nAll right, that was a\n\n\nDeep dive. Boom. Oh, wow. So that is the application you just built. Um, we just built it and all it took was giving a couple of examples, persevering through the Python dependencies that we hit. And we have a real prototype here. You have a UI that can point to the back end and actually, uh, you know, actually service, serve up requests that we want to make. So that's a real prototype. Let's go ahead and test it now. What do you think Akash? Yeah, let's see it. And let's also just explain, like, we were trying to create an agentic system. So where are the agents involved here? Yeah, so great question. So, we went ahead and, um, it's funny, it actually, it does list them out here in the UI, but you can specify whatever agents you want. Some of these were actually determined in the example that I gave, but let's go ahead and and kind of break down, like, what are the agents here. So, the agents that we've built in, and again, this is fully customizable. So, you can give different agents for more specific tasks. The agents here are a research specialist. So that's an agent that's like an expert on doing research on a specific geography like climate, you know, the attractions, etc. You have a planner agent that can plan day by day. So for a specific day, what, what should we do for, uh, you know, for this trip? You have a budget advisor and a local curator. So budget adviser just takes a budget and actually, you know, does analysis on that to, to based on the user's input here, which you're going to, you're going to put in your budget. And then a local curator to kind of find, um, you know, maybe off the beaten path things. But these are these agents. You can kind of think of them as LLMs and prompts and contexts that you've packaged and wrapped together to perform a specific task. It's a lot like saying I'm an expert on a specific area and I'm just going to go ahead and focus on giving the best possible output for that specific thing. Like the budget agent is going to be really good at budgeting. The planner agent is going to be really good at making plans. So, that's kind of how I would view these different systems a little bit. Cool. So, let's go ahead and give this a shot. So, we're gonna say we're gonna go to Spain. Um, you know, let's say we're going to do like a quick Euro trip. I know you, you recently did like a summer trip to Europe. Uh, let's go ahead and click Spain. We can say, um, let's type in we're going for one week. We're going to give a budget of, let's just say like $1,000. And maybe some interest we can give our food. And then we can even click the travel style. So let's say we want to go a little bit more adventure. And these are, this form is fully programmatic, right? So if I wanted to, I could go back here and say, um, you know, change the form color, change the form fields. This is too long. Change how it looks and feels. But you've given something that kind of, uh, is a good starting point, um, for, for, you know, a prototype you might want to build for yourself. Okay. I'm going to click plan my trip.\nAnd what's going on in the background, and you know, this, this loading state's not great, and that's probably something I could ask the, you know, the agent to go and improve on the loading state. But what it's actually going to do is build an itinerary for me here. And, uh, and it's going to take the inputs I have. Great. And it says here's a 7-day itinerary for Spain, food, and adventure. And it's actually given me a day-to-day sort of hour-to-hour level analysis of what I could be doing in different cities.\nNice. As well as days. Yeah. So, but it was pretty detailed. It's faster than a real human planner would have been for sure. You reading up 10 Google search results. Right. Right. Or even if you pasted, like, think of this interface here, right? Like what you've basically done is you've wrapped those prompts of plan me a trip to Spain for one week with a budget of $1,000, interest or food, and in this range, and you've created something that's a lot more programmatic on top of that. You've created a prototype that you could actually go and deploy. And you can build so much more on top of this, right? You can have it reference, like, maybe you want to use a specific API to help you book the flight or suggest flights. You can hook it up to that. You can give it access to search. And so it's a fully programmatic system that you can really go in and and tweak on the fly in your Cursor environment as well.\nOkay. So we've gotten, we've gotten, uh, an output here. Now this is really helpful to just get started, but I think we want to go one level deeper, right? Like as a product manager, just being able to look at this, like, I'm not, I'm not really sure what's going underneath the hood unless I go and read the code. And that's kind of takes us to what observability is. And observability is sort of a, a key part of being able to understand your AI application. So let's go ahead and and hop to that. So yes, so what we did when we actually built the system is we've, we've added what's called tracing. And tracing is a really standard way of looking at the calls that your server is making. Um, that's actually, uh, related to the tool that I, I'm kind of working on, which, which helps with observability and with, with, uh, with sort of tracing applications. Um, and so let's go ahead and look at some specific examples here. So, um, so these are some requests that I've made, which are basically to this agent-based system, and, um, this is one we just made, which was, uh, Spain, one week. In this case, I clicked sailing, um, and adventure. This diagram is really cool. What are we seeing here on the bottom left? Yeah. So, this is, uh, actually the same agent that you just built in code represented graphically. So, uh, so what you actually have is a, a way for you to visually see what is your agent-based system doing. And remember we, we were, you asked a great question, which was like, what agents can we build? We have a research agent, we have a local experiences agent, we have a budget agent, and all of that goes into an itinerary, and that's what the output is. And so what's, what's really helpful looking at this is when you are thinking about going one step further from your AI prototype to building a prototyped agent or an agent application, being able to visually see what are the paths that the agent is taking to accomplish a goal. You can see what happens here is when I give the input, it kicks off three different agents in parallel to generate an output, and all of those go into the itinerary. Remember, I didn't even really define this. I gave this to Cursor to go write, and I said, Cursor, go ahead and build an agent-based system, and this is the architecture it developed and came back to me, and, uh, and that's what, what gives you the output that you get on the other end. And so what I'd gotten is one level deeper on Cursor. And that's actually a really key point, which is it's, it's kind of tough to do this with like Bolt-on level. You're not going to get this representation the same way. And so if you want to see what's going on underneath the hood, you kind of need to use, you have to be a little bit more in the code to be able to define how to get those outputs. And you could probably use Win Surf too, right? That's right. Yeah. So as long as you, as long, really what matters is that you can edit the code. Um, so whether that's Win Surf for Cursor, um, you know, being able to add to the code, uh, tracing is really what matters, and you know, I work on this tool, but there's a lot of other tools out there for tracing as well. I think what matters is, like, what's your workflow, so I'm, you know, don't, don't take my word for it. Go out and try a tool and implement tracing or ask your work with your engineer to implement tracing, and you'll be able to kind of get a visualization like this, um, at the end of the day. And what was the steps involved with implementing tracing? Yeah. So, um, to that, I think it's probably easier to just kind of show what that looks like here, which is this is our docs for Arize, and, um, so we actually have a whole section on tracing. Tracing is, think of this as like the units of work that your code is making. And it's, it's actually, because this is, you know, we're taking software best practices and applying them to this, like, AI agent world. It's actually fairly straightforward these days. All you really have to do is install a tracing package and wrap your code in a sort of a decorator that is a fancy word for saying take this process or this function and call that a span or a trace so that when you're actually running that code, it picks up that unit and it puts it into what you see here, which is the UI for each of the steps that the agent is taking. So it's, it's really the short answer, Akash, is like, it's a line of code that you, uh, that you implement on top of, um, on, on top of your functions. So you could probably just point the agent to this doc and it would figure it out. Totally. That's actually how I did it as well. Yeah. So like, and, and so, so that's where the example that I kind of gave it had tracing in it already as a starting point. But what you can do is, is just literally copy paste this, type it in here, and I could say, you know, implement tracing. I, I won't need to do that now because it already has it, but it will be able to go and infer. Okay, here are the steps I need to go and implement the traces.\nNice. And then you get that awesome thing that we were looking at. Can you break down the top left what we're reading as well? It looks like there's like multiple levels there. So, it's like budget. Then what are we seeing after that? Yeah, exactly. So, these are the agents that we've defined now, right? This is a multi-agent system using Langraph, and I've got a budget here, which is you can look at the the input. Let's take a look at the input really quick. So this isn't a chat-based agent, right? Like, uh, I think everyone, a lot of people, it makes sense, right? You want to build something with chat, but what if you just take a form and take these inputs and actually put them into here? That's what this looks like. Spain, one week, the budget, let's, in this case, it's sailing, and then the advent, the travel style, and those are inputs to the system, and then those get kicked out to each of these agents. Let's go ahead and take a look at what's going on. And this is really the budget agent, the local experiences agent, research agent. That agent has its own sort of tool that it has access to here. And let's go ahead and and go one level deeper at the prompt. So this is the system prompt of the agent. The system prompt says analyze budget requirements for a one-week trip to Spain. And here's the budget. So it actually plumbed in the the budget from the form. And it says this is what you should do. Include a breakdown of all of these things. These are all things that you would think about when you're developing a budget. Like what would I spend money on when I'm traveling? And so the agent has actually defined for itself in the system prompt. How should I take this thousand dollars and best allocate it for accommodations? And what's interesting is it, it's, you know, it's actually kind of gone and done a pretty wide search for different tiers of options because it's not really making a decision on what, uh, you know, what is the, um, the range of the type of trip I want to take. It's offloading that to another agent to make that decision. All it's doing is saying, &quot;I have $1,000. What can I do with $1,000? How should I think about spending that money and let the other agents decide how to best, uh, pull that together? So then that goes into what's called this like analyzing this budget, uh, tool, which takes that destination, the week, and the budget, and that's, that's basically, think of this as like pulling out the a structured JSON that goes into the into the system prompt. So these tools are basically ways for you to get data from an unstructured way or from some one format and put it into another format. And it's really important to think about tools or functions as ways for you to get, uh, you know, sort of think of them as like API calls or ways to get data from a system for your agent to use. And that's what this little icon kind of represents here, um, is a, is a tool. And then this is, uh, the actual LLM call. And this is the top-level agent which wraps all of that together. And, and you'll notice, like, this, this kind of looks complex if this is the first time you are seeing a system like this, right? Like, what are all of these lines? There's all these boxes and colors, but I would really stress, like, this type of system is, is truly an MVP in today's world of agents. So if your team or you're an AIPM and you're thinking about building an agent-based system, your first starting point would probably look something like this. It's not really going to look a ton simpler to be honest for a for multiple agents. It's more likely that there will be multiple calls being made to different services and taking data out of that and putting them back in to then use for LLM calls. So just wanted to set that kind of context, which is like your starting point is to see what's going on underneath the hood and try to understand LLMs, LLM calls, tool calls, agents, and how they all sort of ladder up into this overall system, and we even get the time. So we were saying, like, oh, this might be a little bit slow, but this is break down if you wanted to observe it, which is what we're talking about here. This is how you can break down. Okay, maybe we chip off some time with the budgeting one, and then you could go in and you could work on that.\nAbsolutely. I mean, and think about it this way, like, you know, if I'm using a model, how do I know if I want to change to a different model? Um, you know, so like, let's say OpenAI launches a new model tomorrow, is that a good thing for me to implement into my system? Well, you should probably be able to see an AB test, just like you would AB test an end-user experience. You can now AB test different models. You can AB test different prompts, and the fact is that you probably want to, you know, in your tool that you're actually using for observability, you should think about ways to be able to do that. So let's actually take one of those examples here. This is\n\n\nThis is a good one where it took a really long time to generate this itinerary. Um, and what we can do is actually go and, you know, from here, we can actually go into a prompt playground. So this is what it looks like when you are iterating on your system, right? This is the same system prompt that you would be able to see in Cursor in your code and that your agent built for you or that your engineering team built. But what you have here are variables. And this is really important because this agent is being able to take inputs from the form for maybe hundreds, thousands of your users and plum them in to get a reliable system on the other end, which is taking your destination, the week, you know, duration, the travel style, your and then takes the inputs of all of the other analysis and constructs a finalized itinerary. So this is the the sort of the step by steps of take all of the other agent inputs and construct that final itinerary that you saw. So why does this matter, right? Well, I think you actually pointed out something really uh useful, right? Like which is this is kind of long. Like I don't I don't know if I'm going to read all of this. It's it's really detailed, but does it really need to be this detailed? And is this really the tone that I want the agent to have? What if I wanted this agent to offer a discount to users or act extra friendly? Well, that's really where prompt engineering comes in. Um, and this is another kind of core part of the the workflows we were talking about, which is so we've done prototyping, we've done observability. Now let's see what parts of the agent stack we can change and iterate on and what the output looks like. And to that end we have we have RAG, prompt engineering, fine-tuning. Right? And so we're going to kind of go through each of those and see what the impact is on the end output of your agent. Okay. So so I've got um a model here. I can change the model if I want to. Let's try a slightly different one. 40 mini. Yeah. Andre yesterday said don't use ever. Right. Exactly. Yeah. I think it's being deprecated. I'm surprised. Uh, you know, maybe it still works, but let's see. Um, uh, and that's the thing. I mean, that that's honestly it's a really I know we're joke, but like that's a really good point. Like these models are going to change all the time, right? Like I I love the like, oh, this new model came out. Here's my prompting guide for it. those prompting guides a lot of them they do end up getting out of date when there's a new model or you know the old you know how you work with these new models changes so what you could do is say like I'm changing to this new model how should I prompt the system and you can generate a new prompt based on this as well. We actually have a a tool that lets you kind of generate um new prompts as well um okay and in this in the in the product, but let's say I want to just make some really specific tactical changes to this. So I'm going to go ahead and say, Um, I feel like we don't need a detailed day-by-day plan. Can we just delete that part and make it more like a dayby-day event summary or something like that? It's a good point. So, what I'm doing here is actually changing the the prompt and um you can do is actually save uh you know you could save this prompt and say I want to iterate on it in the system and say like this is my travel agent prompt. Yeah, that's like the detailed version. Exactly. Yeah. and and then what we can do is sort of pull in that same travel agent prompt here. So now I'm actually iterating on the same prompt, but when I save it, I'll save it as a new version. So let's go ahead and it's a good best practice. So we're going to say instead of a dayby-day plan, we're going to do um I think that's what I said before. We're going to say uh give me give me a uh so so actions give me a daytoday plan. doesn't need to be super detailed, right? Because I don't think we're planning out our lives like day the hour to hour. It's really helpful when you're doing generation to also say because we're giving all of this is context. This is all RAG to some degree of context that the agent is using. And we're going to say, you know, max 1,000 characters because we don't want it to go on super long. And when you say RAG, RAG is retrieval augmented generation, which means kind of like condensing a lot of knowledge, right? Is that what it's about? Yeah, good point. So, yeah. So, in case you've heard this term before and you're like, what is that thing? RAG is retrieval augmented generation. It is, uh, I like to think of it as giving, you know, when you're thinking about like doing a test or let's say you you you go to a doctor, uh, the doctor might be super specialized. You can kind of think of specialization as like fine-tuning. And when the doctor is kind of answering your questions, wouldn't it be great if they just had access to like the internet or to a textbook? And that's what RAG is. RAG is basically getting access to a specific part of the data of your overall data set that is useful to answer an a question on the spot. So um so that's like the context that helps you answer a question basically or or perform a task. Um okay. So it's like think of it as like pulling out a page from a notebook or a textbook. Now it's really hard to find the right page and that's a whole another area of study, but that's really what uh that's really what RAG is underneath the hood. It's just like pulling out data and using it. Um so another another few things we can do is say um you know always answer in a super friendly tone because it kind of sounds robotic to me. I feel like this itinerary like I don't know if I would want to use this. I kind of want like, you know, something that might feel a little bit more interactive. Um, and maybe we want to build a product here or we want to use this product to collect email addresses as just a super simple first pass, right? Like if you're a PM and you're like, maybe this is really useful for me to go get feedback from these users and ask them more follow-up questions. You could say, uh, ask the user for their email and offer a discount. Okay. Okay. So now we've done a couple things, right? We're going to change this to 4.1. We're going to see how long that takes as well. Um, and we're going to run the two systems against each other and see what the output looks like. So we're actually we hit run all, which is going to run the original prompt we have against the new prompt and take the models and actually compare the two against each other, too. Okay, so that was that was faster. Um, so you can see that, you know, it still took a little bit, but it's looking like a little bit more friendly here. In this case, it's a trip to Marrakesh, but it it loves to use emojis. Uh, we've got the day by day. Um, so let's let this kind of generate here. It's still generating this output. This is again the inputs that we're using, and all of the research from the previous agents goes into here. And now I've got, let me kind of zoom in and make this a little bit easier to see. We've got we still have the original this is the original prompt which is you know I think it's it's definitely taken out the hour by hour which was uh I think we we changed that hour by hour step here but this is still uh a little bit more highle day one day two day three day four and it's definitely more friendly here and it also says would you like me to continue the rest of the two weeks also shoot me your email and I can send you a nicely formatted itinerary plus a cool discount. I mean this is way more helpful, right? Like this is like something I would definitely want to interact with a bit more because it's a little bit more high level and you can always tweak it to get it to sound the way you want it to. This is what prompt engineering really is is it gives you think of it as like sculpting a block of clay or stone into getting it into the right shape that you want. The amount of impact that you can have from prompt engineering is huge because you can, you know, make the agent actually listen to your instructions much more easily with text. Um, so that's really what you're doing here. Cool. So, basically we changed the prompt that was sent to OpenAI 4.1 mini, which we specified here. Um, whereas the other one had 40 mini. They both actually used the same input from the other three agents, but it led to kind of dramatically different result and dramatically different time taken, right? Yeah, that's a really good point, right? Like the time for 40 mini, the same exact input, just slightly changed prompt is 32 seconds versus this is 8.9 seconds. And that's where you can do things like change the model. And you can even AB test even further. you could keep the model the same and just add that character which was um basically you know being able to uh you know basically retain you know only max out like a thousand tokens or thousand characters for instance um so that's an example of like the changes that you make and what impact they have on your system. This is like I would view this as try to change your model, try to change your prompt, very low effort once you have observability in place, very high impact act on the enduser experience. So how do you set up the right eval to start to like in an automated way understand whether you should adopt the latest and greatest prompt instead of kind of just as a human looking at it each time? Yeah, good question. Um so eval changes to your system and being able to quantify. Okay, now I can I can kind of this is what you kind of call vibe coding, right? We've kind of come up to this point. I would say everything up until this point is pretty much vibe coding because you're kind of like looking at the you're basically giving text. You know, this whole time we've been vioding. You've been giving text to the agent. It's generating output. You have an agent system. You've made tweaks to the prompt and you're like, \"Looks good, looks fine.\" But I think that going one step beyond that is actually being able to run eval and eval quantify your system overall. So I I like to joke it's like going from vibe coding to thrive coding because you're going one step deeper, right? So So what we can do is take some of these examples and I I actually ran a few of these uh yesterday on a similar agent same same agent system and what I can do is actually build a data set and a a very very common workflow. I mean, look, we work, you know, with some of the the leading like companies in AI like Uber, Reddit, Instacart, Duolingo, all these companies. And the reason that we're building these tools to have a data set is because you want to be able to make a change to your system and know that, you know, quantitatively what the impact that change is having with eval. So, that was a long-winded way of saying I basically constructed a couple of examples here. And let's go ahead and delete these um so that we can actually just do this from scratch. I I don't want to these are what we're going to jump to later. So, okay, cool. Okay, so what do we have here? So, this is what's called a data set of the same data that you saw earlier and specifically I took the itinerary step and I've constructed a set of examples I'm going to use to iterate on top of and that's really what these are. So, if I go in, you can see it was the same prompt that we were editing in the prompt playground. And what we're going to do is actually uh run eval system and see what if we're making the system better or worse. And that's really what you can think of eval basically a way for you to oh um you can think of eval as a way for you to uh understand are you making your system better or worse just very simply. Okay. So, um, so what we're going to do is, uh, let me refresh this page. Just kind of look here. Okay. So, let's create our first experiment. And we're going to go back into that prompt playground. But now, I'm actually pulling in the data that you just saw. So, I've picked and hands sampled those examples that I want to use for iteration. I can take the same I can do the same thing here which is it has the same inputs and I have those those outputs. And now what I want to do is I actually made that change to that prompt that we were talking about earlier and I saved it to the to the prompt hub. And so I'm going to pull in this latest version of the prompt. And you'll see this is the same prompt we made edits to before. And now what I can do is let me go ahead and AB test this. And let's kind of make this a little more authentic. We said that this was GPT 40 mini. So we're going to do an AB test apples to apples. And we'll do the same thing of hitting run all, but now instead of on one example, we're generating this on a data set of like 10 or 12 examples here. So it's basically giving you an output that you can use for experimentation. So this is generating a new output on that data. Um, okay. Yeah. So to back up for a second, you have your initial data set of examples that you've kind of built on top of. Even if you don't have that initial data set, it's really just I could go in and I could go and just add basically what I did was I just reentered, you know, instead of going to Spain, I want to go to Tokyo and instead of one week, I want to make it two weeks. The budget could be like $500. And a lot of times what you kind of call this when you're building an application is bootstrapping a data set. And it's just a way for you to get started. You can synthetically generate that data too. Um so using an LLM if you wanted to. Okay. And then now what we've done is once we have that data set, we can pull this in and we've regenerated the prompts. And it looks like it actually generated the experiments for this. So let's go ahead and go back here. And so those experiments are the outputs from uh the the prompt playground that we had before. So this is new outputs on the original prompt and I can compare this to uh the the sort of the\n\n\nChange the prompt that I use as well.\nSo I've got two prompts side by side next to each other now.\nAnd again, like if you're using the system, it's kind of hard to read.\nIt's kind of hard to say, like, is one better than the other?\nI don't really know.\nSo let's go ahead and uh run some eval here.\nSo I've got these eval set up, but let's let's go through the process of talking through what an eval is.\nSo there are think of this as there are basically three types of evalu.\nAnd it's it's really important to go in and label this data yourself.\nAnd you can go and actually go through the data set and label the data.\nWe'll kind of talk through that.\nWe'll come back to that one.\nAnd that's really an important role for an AI PM is to know when I'm looking at an output, is this what I want the LLM or the agent to actually generate, like is this good or bad?\nBecause you're ultimately determining the end user experience as a PM.\nYou're saying like good or bad, and that's what the label is.\nThe second option is to use code, and so you can do things like checking code um basically to say uh it's like a Python-based eval, which you know, Python eval could be things like check for instances of like is a competitor referenced in the LLM's output, and those are really just think of those as ways of you know, writing code to to generate eval.\nAnd then the third option that we're going to be kind of focusing on here is actually using an LLM to check the work of the other agent.\nAnd so you think of these as like eval types of agent systems that are really used to kind of scale up your feedback.\nSo this is what almost everybody's using these days, these LLM as judge systems where they create like almost like numeric scores with various dashboards to look at things.\nExactly.\nYeah.\nSo great point.\nSo when we say like, you know, there's there's a lot of buzz around uh eval are the secret and they're the moat.\nWhat people say when they're saying like eval are the secret to a great AI product experience, what they're saying is that you need a reliable way to scale up the feedback on your system.\nAnd the way that you can do that is using LLMs as a judge or a greater on the output.\nSo that's what an eval as a judge or eval system looks like with LLMs.\nAnd I'm going to break this down a little bit further for you, which is what we can do is basically give an eval template.\nAnd the same way that we had an agent basically um going in and saying like generate an itinerary itinerary, generate a budget.\nWhat I'm doing is actually creating an an eval which sets the the role which is saying you are examining written context content.\nHere's the text, and then I've given the text from that we just generated as the output, and we're stuffing that into here as context.\nThen I'm giving the agent a task which says examine the text and determine whether the tone is friendly or not.\nFriendly tone is defined, and then I'm defining and giving an example of like here's what I mean when I say evaluate for friendliness.\nUm please focus heavily on the concept of friendliness.\nThen I'm going to give it an action which is based on the information the context give an output label of friendly or robotic based on the information that you have.\nSo again, we've we've set we've given the agent a role, we've given it context.\nWe've given it an example of what is good or bad, and then we've given it the action to perform.\nAnd those four steps are really all you need to get an eval in place um to at least get started.\nNow uh what I will kind of caveat and say as we run this, and so once I've defined that, I can actually set these up here, and I've got another one here, and we'll kind of quickly go through this one.\nThis is like checking if we offered a discount to the user based on the the email.\nSo this is this is text that says determine whether the text contains an offer for a discount.\nAnd this was might be something we want to check for, right?\nDid we did we actually accomplish that goal of giving a discount to a user?\nI can go ahead and just run these on the system and say select the experiments.\nThose are the two experiments we have.\nAnd I'm just going to hit run.\nAnd while that's going off, I'll kind of go back here, and this should run pretty fast.\nBut what I'm basically doing is getting an LLM generated label on all of those rows that you just saw.\nAnd that's really helpful for me to then go one level deeper and say, was my LLM correct or was the judge correct?\nAnd I can basically go in and fine-tune that even further.\nSo, okay.\nAnd we did I I'll one small note is we like flipped the order of operations here because experiment uh two.\nOkay.\nSo, it looks like um experiment two was like the second one that generated, and then experiment one was the first one that finished, which was the better one.\nSo, we're actually thinking of this like backwards, this chart, but this was like the one that took a really long time.\nThis was the older prompt.\nUm, think of this as the old prompt.\nAnd you can see, okay, it was actually I guess the LLM as a judge did note that as friendly uh instead of robotic, but it looks like it offered a discount 0% of the time.\nAnd then if I go to the one that was faster, the new updated prompt, the LLM judge actually did mark uh all of the responses as friendly, and then it offered a discount 100% of the time.\nSo it actually went in and checked the outputs and said, &quot;Did you give a discount or not?&quot;\nYep.\nWhat if we did something like gave it like a friendliness score?\nMaybe that'll give us like more dispersion.\nYeah, exactly.\nSo, so what we when we generate uh the label um when we generate the label, we actually do also get a score with it as well.\nSo, but we've just assigned a one or a zero as the output.\nAnd then you could go in and say um give me a friendly score from one through five.\nFun fact, Akash, for people that are listening to this uh this is a best practice is actually to use text to ground the output of the LLM judge.\nThe reason for that instead of numbers is although this technology is amazing, LLMs are still really bad at being able to understand numbers.\nUm, fun fact, just from a tokens perspective.\nSo I said, yeah, if I say, you know, put a one or a two, it won't really be able to give you the justification for why it picked one versus two.\nBut if I say score from uh bad, good, very good, really really, you know, if I give like more distinct text, that's a better way to generate a label um from judge.\nUm so that's just text labels over number labels.\nYeah, exactly.\nUse use labels.\nAnd then and then let's go one level deeper, right?\nSo like I have this eval, but I I kind of maybe want an explanation for why I got a specific score.\nWell, the LLM as a judge actually gives you an explanation.\nSo, it's giving me the justification for why it gave a specific label.\nAnd this is all of the reasoning of the LLM judge as well.\nSo, it's actually the chain of thought of how it analyzed the text to say, you know, should this be uh is this considered friendly or not friendly?\nUm, so that's that's really helpful as well is make sure when you're generating eval and understand one level further.\nNow, you might disagree with the LLM judge, and that's that's okay, right?\nLike that means that that's a system.\nThis is when you think about your system, you have your agents in your application, you have your eval, but that doesn't mean that they're like perfect off the bat, right?\nLike you might want to go in go in and iterate on this LLM as a judge.\nAnd to do that, that's where those human labels and human annotations kind of come in.\nSo, what you can do is actually take that same data set and go in and actually label it as friendly or not and use the same labels that you're using for your LLM as a judge.\nAnd in here, I've actually labeled I actually think a lot of these responses are robotic.\nSo, this is an example of an AIPM basically saying, &quot;Hey, I actually think the LLM as a judge needs improvement.&quot; and I want my team to go and improve on that system.\nSo, what you can do is add your own label.\nAnd there's a there's a really is kind of a note here of as we get a little bit further, like whose job is it to generate the labels.\nI argue a PM should be in the data and labeling and basically saying what's good and bad so that you can give uh a metric for your team to go and improve on.\nAnd I've said these are bad, like these I don't I I went in and labeled those these uh as I was generating these yesterday, and I was like I think these are pretty robotic.\nWell, once you have that system in place, you can actually take the same human labels and do another LLM, either an LLM or a code-based eval that says, take that human label and match it to the eval that was generated, and tell me if my human label match the LLM as a judge or not.\nAnd that's really helpful to say is is what I'm saying the same thing that the LLM as a judge is saying, and if not, I want to know why, and I want to go one level deeper.\nOkay.\nSo we're going to go ahead and run this eval on the same experiments.\nAnd this is what's called like a match eval basically to say should I go ahead and improve on my LLM as a judge.\nSo it's actually going one level deeper.\nI don't I don't see too many people actually when they talk about eval saying that you need to check the work of the LLM as a judge, but this is this is what that looks like is taking human labels and comparing them to your LLM as a judge.\nYep.\nOkay.\nAwesome.\nAnd so what what I have here is this is an example of where I actually need to go in, and you can see my in this case it was a discount check, and it looks like my it it did always offer a discount, and here I also matched 100%.\nAnd so this kind of tells you okay when I didn't match on a specific eval, I want to go in and figure out why that is uh like why is my judge different than my my label?\nSo, where am I seeing that it didn't match?\nIt looks like it didn't match on the left side for friendliness.\nIs that right?\nYeah.\nSo, I think this one was a discount one, but we should we you know what?\nLet's just make that a little bit more let's just make this example a little bit more concrete.\nUm, so I'm going to go ahead and actually remove uh let me let me go ahead and create this eval one more time and just do this one was a discount one.\nLet's go ahead and do a friendliness one.\nI think that's actually a better one, honestly.\nOkay.\nSo, we're just going to generate this on the fly.\nAgain, it's not not super complicated.\nLike, I'm basically saying friendly.\nAnd you can see I have my like type ahead here a little bit.\nUh, so we're going to use friendly.\nAnd then we're going to do the same thing over here.\nAnd so, what am I doing here?\nI'm basically using an LLM.\nI mean, it could be code.\nThis is definitely like you have options here of like do you want to do this with code or do you want to do this with LLMs.\nWe're going to do this with an LM just because it's a little faster for me.\nAnd I'm saying check if the eval label matches the annotation label.\nThis is a really lazy eval.\nUm but you can, you know, if you were actually doing this in production, you would make this more specific.\nUm and then the rails uh system is basically just making sure that you get a label that you can use for plotting the chart.\nOkay.\nOkay.\nSo, we're going to do a friendly match as as you as you just mentioned, like what am I actually checking for here?\nI want to make sure that my friendly label matched or didn't.\nAnd so, let's run this here.\nIt should only take a second to run.\nThe the point of a lot of this though, while this is running, is that when you think about your system as a whole, okay, actually that ran faster than I thought it would.\nSo, let's just talk about that for a second.\nWe'll come back to the zoom out.\nSo, you can see here my friendly label matched 0%.\nWhich means I thought that all of those results were not friendly.\nI thought that they were robotic yesterday, but the LLM thought that they were friendly, right?\nLike the LLM as a judge was like, &quot;This is friendly enough for me.&quot;\nThat's an example where I would go in and say, &quot;Hey team, let's go iterate on our LLM as a judge text and make it catch what's friendly, not friendly better.&quot;\nSo that's what's really helpful is like my LLM as a judge is totally misaligned from my labels, my human labels.\nThat's what that's telling me.\nGot it.\nYeah.\nAnd then we could go in and we could how would we iterate and improve that judge?\nYeah.\nSo that's a great great question.\nWhy don't we just do that on the fly, too?\nSo we've got a friendly here.\nLet's go ahead and try to rerun this.\nLike is there a way to give it our human touch and then get it to like just learn that human labeling?\nWell, now I I I think um I'm like very I I would love to show the workflow for that, but to be honest, Akos, like uh the the truth is that that's coming out really soon on our end.\nUm, so like if you check the by, you know, if by the time you're watching this, the workflow will actually look really different because we'll have a button that says take the human labels and optimize your prompts.\nCool.\nUm, so that's the part of like uh a little bit of like when you think about how self-driving cars or fine-tuning works, it is actually taking those labels and using that to iterate.\nWe call that prompt learning.\nAnd actually Andre Karpathy also tweeted about something similar which is take your human labels and use them to iterate on your prompt.\nUm so it's a little bit of the like coming very soon.\nUh the workflow is you can do the workflow today which is take the eval and try to handtune it a little bit based on the the uh the human label.\nBut yeah, wouldn't it be great if you could just click a button and it updates your prompts for you?\nSo that's that's the product that we're we're working on next.\nSo this is eval.\nI think where I want to go next is start to\n\n\nBreak down some of these terms. We talked a little bit about RAG, but fine-tuning and prompt engineering and really understand how they all fit together.\n\nYeah. So I think that like it it's helpful to zoom out and see like what do all of these things really mean when you build a product? And to that I'm going to go to just Excaladraw and just sort of whiteboard some of this. Um, by the way, uh, just as a note, do you think we should start here or should we go up to the Cursor or like the Bolt example? Like what what do you feel like would be more? Um, maybe we start with the Bolt diagram. Yeah, perfect.\n\nAwesome. So, when you think about pulling all of these concepts together, I think it's really helpful to go from you've built this initial system, but what does this look like in practice when you go from prototype to production? And I think it's helpful to like look at great tools out there that we all kind of have used or tried uh at some at some point and like that are really taking a lot of attention from the AI product mindset and try to understand how they work a little bit more. Maybe we can use this as an example to just go through like how Bolt works at a really high level just to pull all of this together.\n\nUm, so if you haven't used Bolt yet or or you know I I do this thing in person like where I'll ask how many people have heard of Bolt or Lovable, everyone raises their hand. Okay, how many people have like actually tried to use the tool and like half the hands go down? And I think that's part of the problem. But I do recommend like you know we jumped into the deep end with Cursor. If you haven't tried Bolt yet, please go and try it. It's really straightforward. Just ask it to do the same prompt we just gave uh Cursor and you'll get a good AB test feeling of like what's different between these systems. Um so once we've built something in Bolt, what you'll kind of notice is it's it's a workflow which also generates code and gives you a UI as a prototype. It kind of feels like magic, right? Like I don't I I feel like you you know I had this feeling when I first tried it. I was like wow holy cow. It just knows exactly what to do and built this UI in like one second with everything that I asked for. But it's not magic. And let's talk about what's going on underneath the hood a little bit more. And I want to preface and say like this is just from reading the code. And that's why it's so important to be able to read code so that you can interpret uh you know what's going on with your AI product. So what you can do is Bolt is uh has their code hosted on GitHub like an open source version and if you go in I thought wow this is going to be really sophisticated but really at a high level Bolt contains a system prompt which you we just saw what a prompt was with an agent a system prompt you're going to notice a lot of similarities here and you'll see you are Bolt an expert AI assistant an exceptional senior software developer with vast knowledge across multiple programming languages So what Bolt really is is it's basically a really big good prompt which is doing the same things we just talked about. You're setting the role. You are a developer. You're setting context. You're saying you are operating in an environment called a web container. You're generating tools or implicit tool calling. I call it implicit tool calling because you're you're referencing the tools in the context. you're not explicitly calling a service externally, but you're sort of setting uh you know, here's what's available to you to be able to implement something. So, it says prefer using Vite, which is maybe just a framework here instead of implementing a custom web server. So, that's like saying don't go off and use a tool that's not Vite. Um, and then you set priorities in the instructions. So, you can see literally the prompt contains important, use valid markdown, ultra important, do not be verbose. So you're really setting what the output looks like in your prompt. Very important. You're then providing fshot examples of what good looks like. Once Bolt contains all of this information in the prompt, really all that's going on is it's taking this user input request and that's being fed into the agent system with the same context we just talked about the system prompt, the user prompt, and then access to all of those tools in the prompt itself, which are structuring the problem, picking the right framework. There's a concept of a terminal and then retrieving context above and these are think of these are just like components in your prompt here. All of that goes into an LLM and then you get generated code and that generated code I thought this was going to be way more sophisticated like I you know with Cursor if you there's like a three and a half hour like interview with the Cursor founders on Lex Freedman. It's fascinating. I was like, &quot;Wow, Cursor is a really sophisticated problem uh to solve.&quot; And and then I was shocked at like you can get such a good result with Bolt and Lovable because really all they're doing is generating code and rendering that code. So it's just going into basically an environment which takes the code that's written and is just able to run the code, executes it, and if there's a problem, it will go back and fix itself. Similar to the agent that you just saw, but it's it's really why is this important to note? Because Bolt is even simpler to some degree in terms of the system you see here than the the agent that we wrote in Cursor to some degree because what what's really the secret sauce here is you can take generated code break it up into files and then render that code and you get an you get a UI. Now, if you try to use Bolt to make external API calls, for instance, or call other services or images, it gets a lot harder to do because of what Bolt is wired up to. It's a closed box basically. You can't go in and plug in external things to it very easily. And maybe just to recap that, it's really just a system prompt goes into reasoning to generate what do I need to do? Let me make a plan. The same thing we just saw with that a the Cursor agent. What tools do I have? Takes that context, generates code, deploys it, and then renders that code and then based on user feedback, it can you know iterate on that.\n\nAnd what that really means is I like to think about this as product principles for a full stack coding agent where you can pull together prompting your system prompt prompt engineering reasoning in the form of agents re really it's like agent-based reasoning or chain of thought reasoning tool calling in this case it's implicit tool calling and RAG which is the context from that you've just provided the agent all of that goes into an LLM and you get the generated code. So, it's kind of constructing your you could fine-tune the model more if you wanted to. The LLM layer, you can update your RAG and change what context is provided. You can change your prompts and that's that's a huge component of this as well. Uh, and then you kind of string all that together with eval, you know, kind of slick generated code on the other end. I actually put EV valves in green because from what I could tell, Bolt isn't running EV valves on the fly. And that's actually an opportunity. I think like this is an example where if you're an AIPM, take note of what are the opportunities in the system where you can go and actually improve on the system overall. For instance, there could be a version of Bolt that never makes mistakes. Like you could have it running in Eval on the fly. Right now, Bolt is uh when you're when you're actually running Bolt, it can break because it's making mistakes in code. You could have an eval that's run that checks is the code correct or not. And that would be an example of running eval to actually improve on the system, make Bolt even more reliable. And so those are all I think of this as like tearing down a product out there and thinking, oh, what are the opportunities to make this better? And that's that's really helpful to pull all of this together.\n\nSo if we go back then and we compare those three terms that fine-tuning, prompt engineering, RAG, how do those all compare and when do we use what?\n\nYeah, good question. So you've still got this system here where this is all kind of, you know, different components. When should you use what? Right? That's sort of your your the note of your question.\n\nYeah. And I kind of um I think it's helpful to have just like a really quick diagram here of like what is each thing. So let's look at prompt engineering. We have a it kind of depends on what your goal is. So if your goal is to adjust the tone or the instructions, I think prompt engineering is really helpful for that. Uh so that's basically changing we kind of did that just now on the fly with our agent and with Bolt. You can see you can change the instructions and the tone. That's both how Bolt literally works. With RAG you can provide context over a lot of data. So if you need to give the agent access or the the tool your AI uh application access to data internally in your system that's when you would use RAG which is using that data to create a generation on top with the context. So you're stuffing that into the prompt. Fine-tuning is think of this as adjusting the model layer a little bit. So it's actually taking the LLM and making it more specialized. What's really useful for fine-tuning is sort of style to make sure it always responds a certain way, increases the reliability. And then I put distribution, but distribution is like giving it more data in the LLM itself that makes it more specific or specialized.\n\nIt's useful uh I think you know when you think about um it's it's useful to think about like what's the effort of each of these prompt engineering relative to some of the others is really really low effort actually. All you have to do is have access to the prompts, change those prompts, and then get the eval result to understand are you making the system better or worse. RAG is a little bit more complicated where you have a database now. So how you retrieve information from the database can have an impact on how much work this is actually. And then thinking about like fine-tuning, if you change the model layer, you change this variable that might have a lot more impact on the rest of the system. And so I kind of view this a little bit more as like medium to high today um because it requires a bit more sort of specialization to adjust the model. That being said, the impact is really important to think about too, right? Like as as a PM, we're always thinking what's the effort, what's the impact. The impact of prompt engineering is really high. Um and in fact, that means that you know a small change to the prompt can get you 10, 20, 30, even more percent gains on your eval scores. Uh think about it that way. Like if you're designing your AI product around your eval like eval are your requirements now then you really want to think about how can you have the highest impact on those and I think prompt engineering is huge. RAG is another really high impact way to improve on your system. A lot of times this might mean like adding RAG to your system when it doesn't have it already. So just adding more context or adding better context. And then I think fine-tuning it sort of depends on what you're trying to do. Fine-tuning is really helpful for saving cost which might be a very serious concern as you scale up or reducing latency in your system. So if you want the the model to be faster, fine-tuning can be really useful for that. Another helpful way to think about this to some degree and this is not perfect. So don't feel feel free to like grill me in the comments that I got this wrong but um but you know I'm this is my mental model I use. I think of prompt engineering as giving really clear instructions to like an engineer or to an employee because what you're trying to do, the more specific you are, the better result you're going to get. Like in the beginning of this video, if I had given clearer instructions to the agent, I may have gotten my tool my product out faster, but we wanted to see what it looked like to just like try to prototype with with not great instructions. And that's that's the output that you get. With RAG, I think about this as like a doctor having access to the medical textbook at all times. Meaning it can, you know, this this agent can go and look things up to get more information. Like if I copy pasted a doc into Cursor, it's going to go to that website and read the doc to try to understand what I'm asking it to do. And that can be really helpful when you're asking it for stuff that it doesn't know in its memory already. And then sort of last but not least, fine-tuning is sort of like going from college to specializing in a career. What's kind of interesting is that these models are so good now at generalizing that you kind of trade off things when you go to specialization. Like you know, a lot of people view hallucinations as things you want to remove, but I think hallucinations are a feature, not a bug of these models. And so just note that when you change the model architecture by fine-tuning, you might be getting rid of some of the generalization that can be really helpful. um for a a a production application. So this is my mental model for like prompt engineering, RAG, and fine-tuning and how they all kind of come together when you're thinking about building an AI product system.\n\nAwesome. So we covered four of the five skills. The final skill, and I don't know if we'll need screen for share for this, you tell me, is working with AI engineers and researchers, working on these longer development timelines. How can AIPMs master that?\n\nYeah. So I think this is where I'll come back to like what are we what are we kind of talking about when we say our our job is changing as AIPMs.\n\nAnd I think about this as the the expectation on AIPMs is changing from our stakeholders. And our stakeholders when we think about who are they right now, they're not necessarily just engineers that were working in their own way either. Like the way engineers are working and how they're expected to work is changing too. And if you're working on AI products specifically, you might have data scientists or AI engineers that are also ramping up to using Gen AI in their workflows as well. So they're going to be using data to make decisions. And I think the best way I can think about here is your job now has become to get a little bit more in the details of what it actually takes to ship an AI product by understanding the core concepts and principles of what goes into great AI products, understanding how they work and when to\n\n\nUse what tools. And then, sort of very importantly, last but not least, when you work with an AI engineer, is to know what they're thinking, what they need from you. So let's take an example of what that means tactically. When we're thinking about evals, an AI engineer might be looking at an example and saying, \"Was this the agent good or bad in this case?\" Like you, as an AIPM, should be able to answer that question because you are representing what the end sort of experience for a customer looks like, right? Like you are ultimately the person that's on the hook if the AI product is successful or unsuccessful. And so I think I really view it as you want to be in the details of what the team is working on and how it works. You want to be a little bit more in the details of the data of is the experience good or bad, and can you give that feedback back to the team to know what to go and improve on? And then I think last but not least, like being able to interact in the same platform and work in the same tools as your AI engineers is going to help that communication much more. Like when I talk to AI engineers, they're often like, they what they come back and tell me is, \"I can't believe my PM is still sending me Google Docs of PRDs and saying, 'Go and implement this thing.' I wish that they would just be able to look at the system as a whole of like what the agents actually look like and what they're calling and be able to tell me is this correct or not, or I wish that they were actually looking at customer data and telling me what's good or bad.\" And so I think that that's really important is to speak the same language as your engineering team now as they're ramping up on building around AI as well. And this is really an opportunity for AIPMs to stand out, you know, from other sort of product managers that maybe haven't ramped up in that way either. Like, I would argue that the stronger you are at communicating with data, communicating around what are the concepts to implement in your product, the more impact and sort of influence you're going to have as an AI product manager on your organization and on your leadership. Because to be honest, you might even be able to influence at a higher level than even what you were able to do before because you're able to communicate around these terms more powerfully. So, should PMs be writing AI evals? Oh, I think absolutely. I think eval would really reframe this as like, you know, we kind of mentioned eval are kind of what tells you what's good or bad about your system. But what if eval were your requirements instead of your AI product? So like you come back to the team and instead of saying, you know, when you think about a PRD product requirements doc, what if that actually looked like an eval requirements doc? And instead of a doc, it's actually just here's the data, here's the eval score. Now you guys go and improve on this eval and show me how you're improving on that. And that is a really interesting position to be in because you can work with your engineering team on getting the right data in place. You can be hands-on with them, and you get to determine like what's good and bad at the end of the day, which is what the end product experience actually looks and feels like. Um, and I guarantee you, like what we just saw a lot of the code, like AI engineers, they want to be thinking about the right model. They want to be thinking about context. They want to be thinking about prompting, but they're not necessarily always going to be thinking about the end-user experience the same way that you will. Like they're thinking about implementation. So they need someone to give that feedback of end-user experience, and I think eval are a really good way to represent that.\n\nAwesome.\n\nSo that's our mini crash course. We've talked a little bit about how to become an AIPM, and in other places you've talked in even more detail. What should you not do?\n\nYeah, that's a really good question. I think I kind of view this as like what are some of the things I see people doing today that, you know, from an AIPM, like they could be doing, like what are people not doing today is one way to look at this, like where there's a set of opportunities here.\n\nUm, I think generally, if you are thinking about what we just walked through from a project project perspective, imagine if you had side projects kind of going all the time to help you kind of use these tools. So very common mistake I see is AIPMs don't, you know, I'll talk to AIPMs and I'll say like, \"What are you working on on the side?\" That's actually, by the way, like a bit of an interview hack is like, it's actually like my first interview is usually I ask like, aside from work, like what are you building on the side? And the reason for that is you can immediately tell what someone is interested in, and you see that they're curious. You see what their interests are, but you also see that they're taking initiative and they're trying to build and use these tools on the side. So, you can immediately gauge like how close are they to actually building products? How much do they really care about building products? So, that's a very common mistake I think I see is like, you know, if you don't have side projects, you might kind of end up having a bad time in the interview process. And I think a classic example of someone who does this really well and posts about it is Claire, um, Claire Vo, uh, like she has, she had Chat PRD, you know, two years ago out, right? Like I actually use an early version of that system and I'm like, \"It's not that great. Like what's different about this than like talking to chat GPT?\" But then you realize that she's been using this side project to learn about the stack every single week on her weekends. And so the architecture has changed, the models have changed. So very classic example kind of building off of that is like you don't have side projects. If you wait until the models get better, you're going to be left behind as well. So Claire kind of took that project and kind of kept iterating on it and building on it. So now when the models get really good, the product gets better and you already have all of that scaffolding and experience that you've built up building the side projects to take advantage of the newest models. So just imagine like if you already have some product ideas or problems that you want to solve in your day-to-day life, then you may as well start getting building on them now so that when the models do get better, you're not waiting on that. You actually already have something in place to just kind of plug and play the model. And then I'll kind of take another sort of step back and say like on the other end of the spectrum, a very common mistake I think I see AIPMs make is trying to automate too much of their job off of the bat. So what I mean by that is you want to use AI as like a second brain to save costs by doing things like analysis and deep research and maybe even taking some action on your behalf. But I would be really careful about, you know, automating too much right off of the bat. So kind of leverage the fact that these reasoning models are really good at being able to do analysis and push and poke your ideas a bit. So let me give you an example of that. Some of my favorite prompts when I use a reasoning model. And when I say reasoning model, I mean like 03 or now the new cloud 4 as well, which can basically run uh the LLM sort of runs for longer and thinks about what response to give you. And one prompt I'll use really commonly is give me five alternative solutions to what we just talked about and rank them in order of risk or ability to accomplish a goal and then give me pros and cons of each. So what that does is it helps me interrogate my own thinking a bit without trying to automate too much away or just give get take the first solution from the the LLM and try to go implement it. So my recommendation is don't try to automate too much and just take the first recommendation, like push back a little bit and learn how to work with your your LLM and agents to get more out of them. Um, another example of that is like help me simulate follow-up questions from a customer or a vendor in a space I might not be as experienced in and say, \"What are some of the questions they might ask me? What are some responses I should give? And then what are some follow-up questions based on that?\" And so now you can actually show up to an interview much more prepared for what direction some some person might take the questioning. And that's like another recommendation of, you know, you can't really automate that because at the end of the day, you're still going to be on the other side of the screen or or a conversation and you should kind of be able to anticipate what someone is going to say. So those are a couple of examples. I'd say three examples. You know, have side projects. If you don't have side projects, that's a really common mistake. Don't wait until the models get better. Like now is a great time to just start building something and and swapping your components in and out. And then don't try to automate too much right off the bat. Learn how to use AI as a second brain to scale up your analysis and research.\n\nAmazing.\n\nSo, a lot of that sounds like it could be a lot of work, especially the side projects. Yeah. But if somebody just has two hours a week and they want to become an EIPM, what are the exact steps they should follow? Yeah, good question. And I I feel this myself, right? Like we we we have we have to, you know, we have commitments. We have commitments to our jobs, to our families, to other people in our lives, and we can't, you know, trying to ramp up here, it feels like a lot, especially when the space is changing so rapidly, and it's hard to keep up. Definitely, the three things I think about whenever I feel like there's something new or something I'm trying to ramp up on, when it comes to AI specifically, it's really just three steps. I'd recommend to try the tools yourself firsthand. I then recommend to build AI intuition and then apply that AI intuition. And let's kind of talk about each of those in a little bit more uh depth. So when I say try the tools, I don't mean like go and try to like implement them into your company right off the bat. I don't mean like go try and you know go back to your CPO and say like we need an AI agent. I mean just try the tools for your own kind of use cases and and day-to-day life. Like an example is you know I wanted to build an AI storybook generator um for someone in my life and I was you know like for for a young child and say let me build images specific for this person based on a theme and based on you know what uh what I might be trying to like tell for like a bedtime story or something like that, right? Like really nice use case for for a kid. And I think when I tried to use the tools, I actually found where they fell short and what was hard about them. And so when I actually started using the tools, I started realizing, \"Huh, this is what is possible and here's what's hard about using these tools.\" So when you do that, you kind of you gain a sense of AI intuition a little bit of like what's possible today and what's hard. The next is I think trying to tear down AI products with by building AI intuition like we just did with Bolt. So when you see an experience that feels magical, try to go one level deeper and understand how the system works a bit so you can see how these kind of buzzwords like MCP, RAG, like how they come together to actually form the system you just use and they feel a little bit less like hypy and a little bit more real, right? Like the same way we just said with Bolt, like it's not using a ton of complexity. It's actually just prompting. We kind of learn that by tearing the system down. You can do this by watching YouTube videos, talking to other AI PMs. You can try to look at code as you get more proficient or copy paste the code into an LLM and ask it to explain it to you. And then you can just try to recreate the product a little bit yourself and see what's hard about that. And then I think last but not least is actually try to apply these two things. is apply your curiosity and what you've learned and try to build something that you can keep going on the side as a side project where you can actually try to build your own product and that way you're always kind of motivated to try to try a new technology and see if it makes your product better or worse. So those are I think if you have two hours a week you can at least try a tool, pick a tool, whatever it might be. This week for me it's going to be Veo3 because that one just launched and I want to go and try and understand okay how good is this thing really, can I build something around it, and then I'll kind of learn what the boundaries are, what the edges are of the technology so that I know okay here's what here's the opportunities around that, here's what I can take back as a learning, and the whole goal is really just to keep learning so that you can apply that in your day job or for projects you might be building.\n\nSo I was really excited to have you on. I consider you, Tal, Colin, Pavle, like four of the best AIPM creators, but there's there's a little group that's been criticizing us talking all about AIPM, and what they keep saying is, \"Where are the AIPM jobs?\" So, are there really that many AIPM jobs out there? Yeah, I think so.\n\nI think part of it is like, I'll be honest, I don't know if the hiring managers have like rebranded LinkedIn jobs to say like AIPM just yet. What I have been noticing is like you'll see PM jobs that say product manager like AI, and that's that in my mind is sort of an AIPM job. What I will say is that the the space, the the PM space is really catching up here. So, we're a little bit ahead of the curve, and that's kind of where you want to be a little bit from a technology perspective is ahead of the wave so that when the wave really comes, you're able to ride that wave, just like in surfing, right? Like you don't want to be behind the wave, you're going to miss it. So think about here's a mental model for you or like a you know sort of a thought exercise is think about like realistically what is the overall number of PM jobs out there today and think okay maybe it's in the thousands in your local city wherever you might be living, but then think about in three-year times how many PM jobs like that will there be and what's the ratio of AI PM today relative to where we'll\n\n\nBe in three.\n\nSo when you think about that, you might notice, like, in the headlines, you'll see companies are laying off entire teams, entire orgs, and PMs are sort of grouped up into that. But it's really rare, and very, I think, like, you know, I almost never see it where an AI PM team is going to be laid off to some degree. And so what you're trying to do is futureproof your career a little bit by being ahead, by basically either taking an AI PM position or positioning yourself as a what could be an AI PM to fill that role internally at your Company because that's where Companies are starting to invest their resources when it comes to product management headcount because of the opportunity around this technology.\n\nSo, like, coming back to an earlier point, I don't think it's an either/or. Like, I don't think it's like, you know, AI PM or bust. I think it's like AI as an opportunity that intersects with the type of product management you might be doing already, like fintech, healthcare, growth. And it's just that AI is another way to leverage that up a bit more.\n\nAnd to prove everybody who's getting mad at us about these AIPM jobs, while Aman was talking, I decided to search on LinkedIn, right? AI product manager. And like he said, it's that product manager, AI. You're getting over a thousand results just in New York City. So, this is a real job out there. I've examined the compensation of this in other articles. These AI PMs are getting paid 20 to 30% more than regular PMs. We have given you the full toolkit today. If people want to go deeper, Aman, where can they find you online? Tell us more about what else you're doing outside of appearing on podcasts and doing your day job as a director of product.\n\nYeah, for sure. Well, so you can find me on uh amman k.ai. That's my website. I'm also on LinkedIn. If you just search for Aman Khan uh and Twitter, we can kind of plug all the socials. Um, I think for me, I really am trying to be as helpful as possible to people that are trying to make this transition in their careers as well to going from product management to either building around AI in their own products or using AI in the day-to-day. So my goal is really to try to just give away as much for free, give away, you know, as much as I possibly can to people so that they can understand, you know, how this technology is going to impact their day job in the same way I wish people were doing that for me in the past. And so my recommendation is like pick you know content curators or creators like yourself Akash, you do such an incredible job of bringing on like you know extremely talentrich people that are you know able to share unique perspectives and I learn something every time I watch you know your your videos and read your content. And I think that that's really what I'm I'm aiming to do is just try to give my perspective of being at the edge of building AI products, what I see so that you can go kind of build that into your own Companies or your own life. Kind of taking like think of this as like taking the bleeding edge of AI and trying to make it more approachable for people a bit more.\n\nLove it. And you also, I'm just looking, you have a course on Maven. What's that all about? Yeah, so this one is a pretty recent addition actually to the offering. So, um, I kind of view this as a way for, you know, you can think of this as like you could go get a gym membership and like watch YouTube videos. And I think that that's useful. This is sort of more of like personal training, uh, is how I view it. So, like, you should really only take this course to be honest if you are kind of you've already you're in the early stages of the curve and you've maybe gotten to a point where you've built a prototype and you feel a little bit comfortable in Cursor in some of the workflows we showed. That's really going to be the starting point for this course. So think going from Cursor prototype to a real production application using eval and some of the workflows we just showed. The goal for me here is to give you an H1 or H2 strategy doc that you can take back to your leadership team for what an AI product could look like in your organization. And to do that, I want to help you build the foundations of trying the products out at the early stages, but really going into, you know, day-to-day workflows of what AI product management looks like when you're building these products. So, yeah, that's this the course is kicking off on July 1st. Uh, it's going to be a relatively small cohort to get started with. Uh, and based on that, we're going to try and run that more repeatably, really as being sort of a way for you to bounce ideas off of and really in a structured way to kind of give you the tools to build this H1 H2 AI strategy.\n\nAll right, guys. So, if you want to go deeper, you can check out my code. It's in the description to get a little bit of a discount off of Aman's course. I can personally vouch this man knows his stuff. Good luck to you on your AI PM journey. Find both of us on LinkedIn if you need more and we'll see you next time. Thanks for having me on, Akos. This was awesome. I really hope you guys enjoyed that episode. It would mean a ton to me and the team if you could please subscribe on YouTube, follow on Apple and Spotify podcasts and leave a rating and review. Those ratings and reviews really help grow the show and help other people discover the show and they help fund the production so that we can do bigger and better productions. Can't wait to share the next episode with you. Until then, see you later.\n",
  "dumpedAt": "2025-07-21T18:43:25.988Z"
}