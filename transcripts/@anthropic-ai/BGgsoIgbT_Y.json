{
  "episodeId": "BGgsoIgbT_Y",
  "channelSlug": "@anthropic-ai",
  "title": "How Cursor is building the future of AI coding with Claude",
  "publishedAt": "2025-06-10T15:04:50.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "- I think like every facet",
      "offset": 0.09,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "of producing software",
      "offset": 1.56,
      "duration": 1.11
    },
    {
      "lang": "en",
      "text": "I think will be kind of changed",
      "offset": 2.67,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "to use AI in some way.",
      "offset": 4.56,
      "duration": 1.623
    },
    {
      "lang": "en",
      "text": "- Very excited to have you guys out today.",
      "offset": 7.35,
      "duration": 1.59
    },
    {
      "lang": "en",
      "text": "Looking forward to this\nconversation for a while.",
      "offset": 8.94,
      "duration": 2.13
    },
    {
      "lang": "en",
      "text": "As you know, I'm Alex.",
      "offset": 11.07,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "I lead our Claude Relations\nhere at Anthropic.",
      "offset": 12.51,
      "duration": 2.73
    },
    {
      "lang": "en",
      "text": "- I'm Lukas, I work on\nagentic systems at Cursor.",
      "offset": 15.24,
      "duration": 3.339
    },
    {
      "lang": "en",
      "text": "- I'm Aman.",
      "offset": 18.579,
      "duration": 0.861
    },
    {
      "lang": "en",
      "text": "I'm one of the founders and I work on ML",
      "offset": 19.44,
      "duration": 2.468
    },
    {
      "lang": "en",
      "text": "and retrieval at Cursor.",
      "offset": 21.908,
      "duration": 2.092
    },
    {
      "lang": "en",
      "text": "- My name's Jacob Jackson,",
      "offset": 24,
      "duration": 1.11
    },
    {
      "lang": "en",
      "text": "I work on ML at Cursor.",
      "offset": 25.11,
      "duration": 2.04
    },
    {
      "lang": "en",
      "text": "- I'm very, very excited\nfor this conversation",
      "offset": 27.15,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "and to talk a little bit about Cursor,",
      "offset": 28.92,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "what you guys are building",
      "offset": 30.36,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "and also how you're using Claude.",
      "offset": 31.56,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "It's been a big year for Cursor,",
      "offset": 33.18,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "pretty obvious to anyone",
      "offset": 34.86,
      "duration": 1.14
    },
    {
      "lang": "en",
      "text": "that's been following\nalong the AI industry.",
      "offset": 36,
      "duration": 2.07
    },
    {
      "lang": "en",
      "text": "You guys have scaled now to\nover $300 million revenue",
      "offset": 38.07,
      "duration": 2.58
    },
    {
      "lang": "en",
      "text": "in just over a year.",
      "offset": 40.65,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "Pretty crazy millions of developers",
      "offset": 42.3,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "are now using Cursor.",
      "offset": 43.83,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "What's changed in your opinion",
      "offset": 45.81,
      "duration": 1.83
    },
    {
      "lang": "en",
      "text": "and how is today in the version",
      "offset": 47.64,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "of Cursor today different\nthan it was a year ago?",
      "offset": 50.1,
      "duration": 2.97
    },
    {
      "lang": "en",
      "text": "- Yeah, I think there a few\nbig things that have changed.",
      "offset": 53.07,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "I mean there's always been\nthis massive overhang in,",
      "offset": 57.69,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "given the current level\nof the language models,",
      "offset": 61.53,
      "duration": 3.63
    },
    {
      "lang": "en",
      "text": "how much you can do with them",
      "offset": 65.16,
      "duration": 1.38
    },
    {
      "lang": "en",
      "text": "and I think Cursor was probably",
      "offset": 66.54,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "one of the first companies\nat least in coding",
      "offset": 68.19,
      "duration": 2.1
    },
    {
      "lang": "en",
      "text": "to be able to close that gap a bit",
      "offset": 70.29,
      "duration": 1.8
    },
    {
      "lang": "en",
      "text": "with a number of different features.",
      "offset": 72.09,
      "duration": 1.59
    },
    {
      "lang": "en",
      "text": "And then in turn,",
      "offset": 73.68,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "you've also seen these models get much,",
      "offset": 74.513,
      "duration": 1.477
    },
    {
      "lang": "en",
      "text": "much better at coding",
      "offset": 75.99,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "and I think 3.5 Sonnet was like",
      "offset": 76.823,
      "duration": 1.507
    },
    {
      "lang": "en",
      "text": "the first clear example of this",
      "offset": 78.33,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "or this kind of step function\nbetter in programming.",
      "offset": 80.34,
      "duration": 3.15
    },
    {
      "lang": "en",
      "text": "And so before then,",
      "offset": 83.49,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "Cursor is really useful at things like",
      "offset": 84.93,
      "duration": 2.07
    },
    {
      "lang": "en",
      "text": "tab completion, right,\npredicting your next edit.",
      "offset": 87,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "And that alone was,",
      "offset": 88.68,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "you know, growing fairly quickly",
      "offset": 89.513,
      "duration": 1.597
    },
    {
      "lang": "en",
      "text": "and then editing within single files.",
      "offset": 91.11,
      "duration": 1.74
    },
    {
      "lang": "en",
      "text": "But we did see",
      "offset": 92.85,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "that when you kind of mix the intelligence",
      "offset": 93.683,
      "duration": 1.717
    },
    {
      "lang": "en",
      "text": "of a model like 3.5\nSonnet with a few other",
      "offset": 95.4,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "kind of custom models we use for retrieval",
      "offset": 98.46,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "and then applying the edits\nmade by this larger model,",
      "offset": 100.17,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "you now have the ability",
      "offset": 102.39,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "to do kind of multi file edits.",
      "offset": 103.223,
      "duration": 1.447
    },
    {
      "lang": "en",
      "text": "I think that was kind of the step function",
      "offset": 104.67,
      "duration": 1.86
    },
    {
      "lang": "en",
      "text": "that resulted in mass adoption of Cursor",
      "offset": 106.53,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "and since then it's been a mix",
      "offset": 108.42,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "of the models getting\nbetter than us trying",
      "offset": 110.19,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "to under the hood get better",
      "offset": 111.66,
      "duration": 3.63
    },
    {
      "lang": "en",
      "text": "and better with like how far\nwe can push these models.",
      "offset": 115.29,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "- And was that a natural progression,",
      "offset": 117.51,
      "duration": 1.74
    },
    {
      "lang": "en",
      "text": "something that kind of just arose",
      "offset": 119.25,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "or did you guys notice when 3.5 Sonnet",
      "offset": 120.9,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "that first one came out",
      "offset": 124.02,
      "duration": 0.99
    },
    {
      "lang": "en",
      "text": "that, holy cow, now we can all",
      "offset": 125.01,
      "duration": 1.8
    },
    {
      "lang": "en",
      "text": "of a sudden do all these different things",
      "offset": 126.81,
      "duration": 1.74
    },
    {
      "lang": "en",
      "text": "that weren't possible before?",
      "offset": 128.55,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "What did that kind of look like?",
      "offset": 130.56,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "- It did feel somewhat gradual.",
      "offset": 132.33,
      "duration": 2.34
    },
    {
      "lang": "en",
      "text": "Like there are these\nsteps in model quality,",
      "offset": 134.67,
      "duration": 2.28
    },
    {
      "lang": "en",
      "text": "but you saw hints of it with you know,",
      "offset": 136.95,
      "duration": 2.1
    },
    {
      "lang": "en",
      "text": "the prior state of the art model.",
      "offset": 139.05,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "In fact, we've been notoriously bad",
      "offset": 140.97,
      "duration": 2.73
    },
    {
      "lang": "en",
      "text": "at taste testing these",
      "offset": 143.7,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "models just because you know,",
      "offset": 145.14,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "the way we use them is very different",
      "offset": 146.49,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "than when you put it",
      "offset": 148.5,
      "duration": 0.9
    },
    {
      "lang": "en",
      "text": "out into the world to\nsee how others use it.",
      "offset": 149.4,
      "duration": 1.83
    },
    {
      "lang": "en",
      "text": "But there are just hints",
      "offset": 151.23,
      "duration": 0.87
    },
    {
      "lang": "en",
      "text": "of over time each kind of new model",
      "offset": 152.1,
      "duration": 1.8
    },
    {
      "lang": "en",
      "text": "that came out was better",
      "offset": 153.9,
      "duration": 0.87
    },
    {
      "lang": "en",
      "text": "and better at being able to reason,",
      "offset": 154.77,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "do more agentic types of coding",
      "offset": 157.53,
      "duration": 1.95
    },
    {
      "lang": "en",
      "text": "and then it's a lot of tinkering",
      "offset": 159.48,
      "duration": 1.95
    },
    {
      "lang": "en",
      "text": "and trying lots of\nthings, seeing what works,",
      "offset": 161.43,
      "duration": 2.07
    },
    {
      "lang": "en",
      "text": "seeing what fails.",
      "offset": 163.5,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "Yeah, I think Sonnet was\nprobably the first one",
      "offset": 164.82,
      "duration": 2.25
    },
    {
      "lang": "en",
      "text": "where we were able to make the multi-file",
      "offset": 167.07,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "kinda interaction really work well.",
      "offset": 168.72,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "And since then there's been a number",
      "offset": 170.28,
      "duration": 1.38
    },
    {
      "lang": "en",
      "text": "of step functions including\nlike tool use, right?",
      "offset": 171.66,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "And then you can actually",
      "offset": 174.06,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "have these models act like",
      "offset": 174.893,
      "duration": 0.877
    },
    {
      "lang": "en",
      "text": "real agents within the editor.",
      "offset": 175.77,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "- Hmm, I see.",
      "offset": 176.97,
      "duration": 0.87
    },
    {
      "lang": "en",
      "text": "So the progression of the new models,",
      "offset": 177.84,
      "duration": 1.86
    },
    {
      "lang": "en",
      "text": "new capabilities over time kind of allows",
      "offset": 179.7,
      "duration": 2.79
    },
    {
      "lang": "en",
      "text": "for further tinkering, exploring,",
      "offset": 182.49,
      "duration": 1.86
    },
    {
      "lang": "en",
      "text": "which then rolls back\ninto your product in some",
      "offset": 184.35,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "degree and allows you\nto build new features.",
      "offset": 186.24,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "- Yeah.",
      "offset": 188.46,
      "duration": 0.87
    },
    {
      "lang": "en",
      "text": "- That's interesting",
      "offset": 189.33,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "and kind of parlays into\nthis next question I want",
      "offset": 190.163,
      "duration": 1.927
    },
    {
      "lang": "en",
      "text": "to hit at which is I've heard many stories",
      "offset": 192.09,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "of how your team is using\nCursor to build Cursor,",
      "offset": 194.49,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "it's in this like self-improving",
      "offset": 198.27,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "recursive feedback loop.",
      "offset": 200.19,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "First off, maybe you can dive",
      "offset": 201.54,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "into a little bit of how",
      "offset": 203.04,
      "duration": 0.93
    },
    {
      "lang": "en",
      "text": "that looks and on a day-to-day,",
      "offset": 203.97,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "what does that look like within Cursors",
      "offset": 205.74,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "you guys are working on",
      "offset": 207.09,
      "duration": 1.02
    },
    {
      "lang": "en",
      "text": "building new features?",
      "offset": 208.11,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "- Yeah, I think it very much depends",
      "offset": 209.67,
      "duration": 1.29
    },
    {
      "lang": "en",
      "text": "on the individual like",
      "offset": 210.96,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "yeah use cases for each employee",
      "offset": 212.31,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "and I think it also very\nmuch depends on what part",
      "offset": 213.75,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "of the product you might be working on",
      "offset": 216.39,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "and what kind of stage that part is in.",
      "offset": 217.83,
      "duration": 2.25
    },
    {
      "lang": "en",
      "text": "So I think for like initially",
      "offset": 220.08,
      "duration": 1.11
    },
    {
      "lang": "en",
      "text": "laying out some code base,",
      "offset": 221.19,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "some new feature, it's very, very useful",
      "offset": 222.51,
      "duration": 1.74
    },
    {
      "lang": "en",
      "text": "to just like use the Agent\nfeature to kind of get",
      "offset": 224.25,
      "duration": 2.37
    },
    {
      "lang": "en",
      "text": "that started and then to maybe use",
      "offset": 226.62,
      "duration": 2.07
    },
    {
      "lang": "en",
      "text": "the thinking models",
      "offset": 228.69,
      "duration": 1.05
    },
    {
      "lang": "en",
      "text": "to like look at individual\nbox that you might be facing",
      "offset": 229.74,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "and then for making\nlike very precise edits,",
      "offset": 232.92,
      "duration": 2.07
    },
    {
      "lang": "en",
      "text": "I think that's,",
      "offset": 234.99,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "it's a lot of tap also",
      "offset": 235.823,
      "duration": 2.347
    },
    {
      "lang": "en",
      "text": "and then when initially getting\nstarted with a code base",
      "offset": 238.17,
      "duration": 2.13
    },
    {
      "lang": "en",
      "text": "that one might not be too\nknowledgeable about that",
      "offset": 240.3,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "using kind of the QA\nfeatures a lot using a lot",
      "offset": 243.18,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "of search and I think\nthat's also something",
      "offset": 245.58,
      "duration": 2.07
    },
    {
      "lang": "en",
      "text": "that Claude 3.7",
      "offset": 247.65,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "and 3.5 also has been excelling at",
      "offset": 249.54,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "doing research in a code base",
      "offset": 252.06,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "and figuring out how certain",
      "offset": 253.38,
      "duration": 1.41
    },
    {
      "lang": "en",
      "text": "things interact with each other.",
      "offset": 254.79,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "- I see, so using these features",
      "offset": 256.11,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "to explore your code bases makes",
      "offset": 257.46,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "the process easier then you",
      "offset": 259.38,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "learn as you're using these features",
      "offset": 260.94,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "that oh there's a deficiency in this area,",
      "offset": 262.65,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "we should go work on that.",
      "offset": 264.3,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "- Yeah, easier I think Cursor's",
      "offset": 265.5,
      "duration": 1.38
    },
    {
      "lang": "en",
      "text": "it's very much driven by",
      "offset": 266.88,
      "duration": 0.96
    },
    {
      "lang": "en",
      "text": "kind of solving our own problems",
      "offset": 267.84,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "and kind of figuring out",
      "offset": 269.49,
      "duration": 1.08
    },
    {
      "lang": "en",
      "text": "where we struggle solving problems",
      "offset": 270.57,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "and making Cursor better",
      "offset": 272.55,
      "duration": 1.38
    },
    {
      "lang": "en",
      "text": "and then yeah, figuring\nout what we can do there",
      "offset": 273.93,
      "duration": 2.04
    },
    {
      "lang": "en",
      "text": "and then experimenting a lot.",
      "offset": 275.97,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "We very much have this philosophy",
      "offset": 277.44,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "of like everybody can just try things",
      "offset": 278.97,
      "duration": 2.34
    },
    {
      "lang": "en",
      "text": "and try adding new features to the product",
      "offset": 281.31,
      "duration": 2.73
    },
    {
      "lang": "en",
      "text": "and then see internally how they are used",
      "offset": 284.04,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "and what kind of feedback they gather.",
      "offset": 286.5,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "- Do you think there on maybe",
      "offset": 288.48,
      "duration": 1.29
    },
    {
      "lang": "en",
      "text": "of a more meta level there's an advantage",
      "offset": 289.77,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "to being your own best\ncustomer internally?",
      "offset": 291.66,
      "duration": 3.15
    },
    {
      "lang": "en",
      "text": "- I think 100%.",
      "offset": 294.81,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "I think that's how we're able",
      "offset": 296.13,
      "duration": 1.74
    },
    {
      "lang": "en",
      "text": "to move really quickly\nin building new features",
      "offset": 297.87,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "and then throwing away things\nthat clearly don't work",
      "offset": 299.79,
      "duration": 2.28
    },
    {
      "lang": "en",
      "text": "because we can be really\nhonest to ourselves",
      "offset": 302.07,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "of whether we find it useful",
      "offset": 304.83,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "and then not have to ship it\nout to users, kind of track",
      "offset": 306.36,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "how people use it before deciding",
      "offset": 309.54,
      "duration": 1.8
    },
    {
      "lang": "en",
      "text": "to go ahead with a feature",
      "offset": 311.34,
      "duration": 0.96
    },
    {
      "lang": "en",
      "text": "and I think it just speeds\nup the iteration loop",
      "offset": 312.3,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "for for building features.",
      "offset": 314.76,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "Yeah, going back to overall\nhow we use AI to program,",
      "offset": 316.41,
      "duration": 3.57
    },
    {
      "lang": "en",
      "text": "it feels like, I mean there's a lot",
      "offset": 319.98,
      "duration": 1.23
    },
    {
      "lang": "en",
      "text": "of diversity within the company",
      "offset": 321.21,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "and how different people use it.",
      "offset": 322.77,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "I think it differs first in like",
      "offset": 324.33,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "the kind of work you're doing.",
      "offset": 325.89,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "So, you know, there are a\nnumber of people that will",
      "offset": 327.51,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "for example, be working in pieces",
      "offset": 330.39,
      "duration": 2.19
    },
    {
      "lang": "en",
      "text": "of the code base they're\nreally familiar with, right?",
      "offset": 332.58,
      "duration": 1.83
    },
    {
      "lang": "en",
      "text": "And at that point when you\nhave it all in your head,",
      "offset": 334.41,
      "duration": 2.613
    },
    {
      "lang": "en",
      "text": "it's often faster for you",
      "offset": 338.67,
      "duration": 1.05
    },
    {
      "lang": "en",
      "text": "to kind of convey intent just",
      "offset": 339.72,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "by kind of typing code",
      "offset": 341.28,
      "duration": 2.1
    },
    {
      "lang": "en",
      "text": "and then for that Tab is really",
      "offset": 343.38,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "useful 'cause kind of speeds you up there.",
      "offset": 345.09,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "But then when you're in places",
      "offset": 346.29,
      "duration": 1.02
    },
    {
      "lang": "en",
      "text": "where you're less familiar",
      "offset": 347.31,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "or you need to write out a lot of code,",
      "offset": 349.32,
      "duration": 1.95
    },
    {
      "lang": "en",
      "text": "you can kind offload a lot of that",
      "offset": 351.27,
      "duration": 2.197
    },
    {
      "lang": "en",
      "text": "and often some of the reasoning",
      "offset": 353.467,
      "duration": 1.793
    },
    {
      "lang": "en",
      "text": "to these models and then, you know,",
      "offset": 355.26,
      "duration": 1.95
    },
    {
      "lang": "en",
      "text": "as you got to places",
      "offset": 357.21,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "where you're really unfamiliar",
      "offset": 358.043,
      "duration": 0.877
    },
    {
      "lang": "en",
      "text": "with Lukas is describing",
      "offset": 358.92,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "and you're kind of coming\ninto a new code base,",
      "offset": 360.27,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "it's just there's this\nmassive step function",
      "offset": 361.8,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "that you get from using these models",
      "offset": 364.2,
      "duration": 1.486
    },
    {
      "lang": "en",
      "text": "and what we kind of see is over time",
      "offset": 365.686,
      "duration": 1.364
    },
    {
      "lang": "en",
      "text": "as the models get better is",
      "offset": 367.05,
      "duration": 1
    },
    {
      "lang": "en",
      "text": "and as Cursor gets better",
      "offset": 368.05,
      "duration": 1.28
    },
    {
      "lang": "en",
      "text": "using these models you do a better",
      "offset": 369.33,
      "duration": 1.74
    },
    {
      "lang": "en",
      "text": "and better job of when you're more",
      "offset": 371.07,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "in flowing when you have",
      "offset": 372.69,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "more knowledge of the code base.",
      "offset": 373.523,
      "duration": 1.147
    },
    {
      "lang": "en",
      "text": "- So there's a variation",
      "offset": 374.67,
      "duration": 0.99
    },
    {
      "lang": "en",
      "text": "in when a feature is most",
      "offset": 375.66,
      "duration": 1.41
    },
    {
      "lang": "en",
      "text": "applicable to like your use case",
      "offset": 377.07,
      "duration": 1.41
    },
    {
      "lang": "en",
      "text": "and it kinda is like almost",
      "offset": 378.48,
      "duration": 1.29
    },
    {
      "lang": "en",
      "text": "a spectrum to some degree.",
      "offset": 379.77,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "- Yeah like the spectrum on one end is Tab",
      "offset": 381.09,
      "duration": 2.04
    },
    {
      "lang": "en",
      "text": "for when you're completely in control",
      "offset": 383.13,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "and you know what you're doing",
      "offset": 385.14,
      "duration": 1.41
    },
    {
      "lang": "en",
      "text": "then it goes to Command K",
      "offset": 386.55,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "where you're editing\na single given region,",
      "offset": 387.9,
      "duration": 1.74
    },
    {
      "lang": "en",
      "text": "maybe a whole file",
      "offset": 389.64,
      "duration": 1.23
    },
    {
      "lang": "en",
      "text": "and then at the other end you have Agent",
      "offset": 390.87,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "which is quite good for, you know,",
      "offset": 392.52,
      "duration": 1.95
    },
    {
      "lang": "en",
      "text": "editing multiple files",
      "offset": 394.47,
      "duration": 1.59
    },
    {
      "lang": "en",
      "text": "and then at the very end you get",
      "offset": 396.06,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "kind of have this background agent",
      "offset": 397.77,
      "duration": 1.17
    },
    {
      "lang": "en",
      "text": "which we've been working on",
      "offset": 398.94,
      "duration": 0.87
    },
    {
      "lang": "en",
      "text": "and that can be useful for\nbasically doing entire prs.",
      "offset": 399.81,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "- You guys just released a preview",
      "offset": 404.01,
      "duration": 1.05
    },
    {
      "lang": "en",
      "text": "of background agent.",
      "offset": 405.06,
      "duration": 1.23
    },
    {
      "lang": "en",
      "text": "What is background agent?",
      "offset": 406.29,
      "duration": 1.17
    },
    {
      "lang": "en",
      "text": "- I think it's clear",
      "offset": 407.46,
      "duration": 0.87
    },
    {
      "lang": "en",
      "text": "that the models are getting better",
      "offset": 408.33,
      "duration": 1.29
    },
    {
      "lang": "en",
      "text": "and better at doing end-to-end tasks",
      "offset": 409.62,
      "duration": 2.736
    },
    {
      "lang": "en",
      "text": "but they're not quite at 100%",
      "offset": 412.356,
      "duration": 1.504
    },
    {
      "lang": "en",
      "text": "and I think it'll take a while",
      "offset": 413.86,
      "duration": 1.4
    },
    {
      "lang": "en",
      "text": "to get to 100%.",
      "offset": 415.26,
      "duration": 1.02
    },
    {
      "lang": "en",
      "text": "So the way you speed up developers,",
      "offset": 416.28,
      "duration": 2.1
    },
    {
      "lang": "en",
      "text": "right, is you let them do",
      "offset": 418.38,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "these things in parallel but as opposed",
      "offset": 419.213,
      "duration": 1.632
    },
    {
      "lang": "en",
      "text": "to kind of letting it just go",
      "offset": 420.845,
      "duration": 2.155
    },
    {
      "lang": "en",
      "text": "in the background then spin up a PR",
      "offset": 423,
      "duration": 2.04
    },
    {
      "lang": "en",
      "text": "that you look at in\nGitHub if it's only 90%",
      "offset": 425.04,
      "duration": 2.55
    },
    {
      "lang": "en",
      "text": "of the way there you want",
      "offset": 427.59,
      "duration": 1.02
    },
    {
      "lang": "en",
      "text": "to go in and then take control",
      "offset": 428.61,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "and do the rest of it and\nthen you want to use you know,",
      "offset": 430.17,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "the features of Cursor\nin order to do that.",
      "offset": 432.99,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "So really being able to quickly",
      "offset": 434.52,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "move between the background",
      "offset": 436.29,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "and the foreground is really important",
      "offset": 437.82,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "and I think like, you know,",
      "offset": 440.04,
      "duration": 0.93
    },
    {
      "lang": "en",
      "text": "we're in the early innings of this feature",
      "offset": 440.97,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "and I can imagine that there\nare lots of interesting ways",
      "offset": 443.67,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "of being able to operate\nfor example on three",
      "offset": 447.03,
      "duration": 3.15
    },
    {
      "lang": "en",
      "text": "or four changes at the same time",
      "offset": 450.18,
      "duration": 1.047
    },
    {
      "lang": "en",
      "text": "and then quickly kind of\npopping them to the background",
      "offset": 451.227,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "and then moving them into the foreground.",
      "offset": 452.787,
      "duration": 2.643
    },
    {
      "lang": "en",
      "text": "It'll be interesting\nto see how this changes",
      "offset": 455.43,
      "duration": 2.37
    },
    {
      "lang": "en",
      "text": "how people use Cursor and just like",
      "offset": 457.8,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "develop the software in general.",
      "offset": 459.42,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "- I mean we see background\nagents basically",
      "offset": 461.1,
      "duration": 1.41
    },
    {
      "lang": "en",
      "text": "as a new primitive that we can use in like",
      "offset": 462.51,
      "duration": 1.67
    },
    {
      "lang": "en",
      "text": "so many different places\nand the current way",
      "offset": 464.18,
      "duration": 2.5
    },
    {
      "lang": "en",
      "text": "of exposing it is quite straightforward",
      "offset": 466.68,
      "duration": 1.83
    },
    {
      "lang": "en",
      "text": "where you can just get a prompt",
      "offset": 468.51,
      "duration": 2.25
    },
    {
      "lang": "en",
      "text": "and push it to the background",
      "offset": 470.76,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "and then it independently\niterates on that.",
      "offset": 472.2,
      "duration": 2.37
    },
    {
      "lang": "en",
      "text": "But there can be like\nmany more integrations",
      "offset": 474.57,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "how these things can be spawned off",
      "offset": 476.46,
      "duration": 1.8
    },
    {
      "lang": "en",
      "text": "and I think there's a lot of product",
      "offset": 478.26,
      "duration": 2.04
    },
    {
      "lang": "en",
      "text": "that you want can make from that.",
      "offset": 480.3,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "- So is this taking your code base",
      "offset": 482.19,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "and putting it in a virtual machine",
      "offset": 483.69,
      "duration": 2.58
    },
    {
      "lang": "en",
      "text": "or what exactly is that\ntransfer that's happening?",
      "offset": 486.27,
      "duration": 2.97
    },
    {
      "lang": "en",
      "text": "- Exactly, yeah.\n- Okay.",
      "offset": 489.24,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "- We have small enough\nindependent environments",
      "offset": 490.073,
      "duration": 1.867
    },
    {
      "lang": "en",
      "text": "that have all the developer\nenvironment utilities",
      "offset": 491.94,
      "duration": 3.93
    },
    {
      "lang": "en",
      "text": "already installed",
      "offset": 495.87,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "and then the agent can use those",
      "offset": 496.703,
      "duration": 1.417
    },
    {
      "lang": "en",
      "text": "and it has all the VS code extensions",
      "offset": 498.12,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "that are available",
      "offset": 500.94,
      "duration": 0.99
    },
    {
      "lang": "en",
      "text": "and through that it can get et cetera.",
      "offset": 501.93,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "- I know we're kind of\nwitnessing this trend",
      "offset": 503.94,
      "duration": 2.13
    },
    {
      "lang": "en",
      "text": "of asynchronous tasks,",
      "offset": 506.07,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "background tasks across many\ndifferent things from coding",
      "offset": 507.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "to like research, in your view,",
      "offset": 511.08,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "what does that look like",
      "offset": 513,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "as this progresses to where\nwe might have thousands",
      "offset": 514.32,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "of these agents potentially going off",
      "offset": 517.5,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "and you could see like whole teams",
      "offset": 519.96,
      "duration": 1.26
    },
    {
      "lang": "en",
      "text": "of agents attacking a problem\nall in the background.",
      "offset": 521.22,
      "duration": 2.31
    },
    {
      "lang": "en",
      "text": "What does that future look like?",
      "offset": 523.53,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "- I think the next bottleneck you'll run",
      "offset": 525.3,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "into is verification of software,",
      "offset": 527.01,
      "duration": 2.67
    },
    {
      "lang": "en",
      "text": "verification of code,",
      "offset": 529.68,
      "duration": 1.38
    },
    {
      "lang": "en",
      "text": "models getting really,",
      "offset": 531.06,
      "duration": 1.02
    },
    {
      "lang": "en",
      "text": "really good at generating writing lots",
      "offset": 532.08,
      "duration": 2.31
    },
    {
      "lang": "en",
      "text": "of code but let's say developers spend,",
      "offset": 534.39,
      "duration": 4.77
    },
    {
      "lang": "en",
      "text": "I'll throwout some random-ish numbers,",
      "offset": 539.16,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "but 30% of their time writing code",
      "offset": 540.66,
      "duration": 2.58
    },
    {
      "lang": "en",
      "text": "or 30% of their time reviewing code,",
      "offset": 543.24,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "70% of their time writing code.",
      "offset": 544.86,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "If you completely solve\nwriting code you still haven't",
      "offset": 546.48,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "really sped up software engineering",
      "offset": 548.88,
      "duration": 1.14
    },
    {
      "lang": "en",
      "text": "by more than a factor of three.",
      "offset": 550.02,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "Yeah, so I think we're going",
      "offset": 551.58,
      "duration": 2.04
    },
    {
      "lang": "en",
      "text": "to need to figure out how",
      "offset": 553.62,
      "duration": 1.26
    },
    {
      "lang": "en",
      "text": "to make it easier for\npeople to review code",
      "offset": 554.88,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "and how to be confident",
      "offset": 557.7,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "that the agent's making the changes",
      "offset": 559.17,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "that are not just correct,\n'cause correct can",
      "offset": 560.73,
      "duration": 1.29
    },
    {
      "lang": "en",
      "text": "be vague, right?",
      "offset": 562.02,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "It may just be in the thing you specified,",
      "offset": 563.22,
      "duration": 1.95
    },
    {
      "lang": "en",
      "text": "it was under specified enough",
      "offset": 565.17,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "that it actually did like\nthe best that was possible",
      "offset": 566.88,
      "duration": 2.28
    },
    {
      "lang": "en",
      "text": "for even you know, the best\nhuman programmers to do",
      "offset": 569.16,
      "duration": 2.55
    },
    {
      "lang": "en",
      "text": "but what it actually",
      "offset": 571.71,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "what you had in your mind's eye",
      "offset": 573.21,
      "duration": 1.8
    },
    {
      "lang": "en",
      "text": "and so making the process for you much,",
      "offset": 575.01,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "much better I think will be\nreally, really important.",
      "offset": 577.77,
      "duration": 1.86
    },
    {
      "lang": "en",
      "text": "And it's something",
      "offset": 579.63,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "that we're really interested in as well.",
      "offset": 580.463,
      "duration": 1.837
    },
    {
      "lang": "en",
      "text": "- Any early ideas there\non what that looks like?",
      "offset": 582.3,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "- I think there are a few floating",
      "offset": 584.76,
      "duration": 1.23
    },
    {
      "lang": "en",
      "text": "around from various people at the company.",
      "offset": 585.99,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "One that Michael, our CEO who really,",
      "offset": 588.45,
      "duration": 3.45
    },
    {
      "lang": "en",
      "text": "really likes is the idea",
      "offset": 591.9,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "of operating in a different",
      "offset": 593.22,
      "duration": 2.13
    },
    {
      "lang": "en",
      "text": "representation of the code base.",
      "offset": 595.35,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "So maybe it looks like pseudo code",
      "offset": 596.85,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "and if you can represent changes",
      "offset": 599.55,
      "duration": 3.203
    },
    {
      "lang": "en",
      "text": "in this really concise way",
      "offset": 602.753,
      "duration": 1.777
    },
    {
      "lang": "en",
      "text": "and you have guarantees",
      "offset": 604.53,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "that it maps cleanly",
      "offset": 605.73,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "onto the actual changes made",
      "offset": 606.563,
      "duration": 1.957
    },
    {
      "lang": "en",
      "text": "in the real software,",
      "offset": 608.52,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "that should shorten the\ntime of verification a ton.",
      "offset": 610.2,
      "duration": 2.67
    },
    {
      "lang": "en",
      "text": "But that's one possible route.",
      "offset": 612.87,
      "duration": 1.38
    },
    {
      "lang": "en",
      "text": "I think, so like the\nreason why quote unquote",
      "offset": 614.25,
      "duration": 2.04
    },
    {
      "lang": "en",
      "text": "vibe coding works often",
      "offset": 616.29,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "is because the process",
      "offset": 617.73,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "of verification is like really easy",
      "offset": 619.29,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "since all it is just",
      "offset": 621.51,
      "duration": 1.17
    },
    {
      "lang": "en",
      "text": "kind of playing with the software, right?",
      "offset": 622.68,
      "duration": 2.13
    },
    {
      "lang": "en",
      "text": "You make a change and you actually play",
      "offset": 624.81,
      "duration": 1.8
    },
    {
      "lang": "en",
      "text": "with whatever software you've built.",
      "offset": 626.61,
      "duration": 1.59
    },
    {
      "lang": "en",
      "text": "I think it's just gonna be\nreally hard to do for real",
      "offset": 628.2,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "production code bases",
      "offset": 631.62,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "and cracking that problem\nis really important.",
      "offset": 632.94,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "- That's a good question\naround the difference",
      "offset": 635.1,
      "duration": 2.43
    },
    {
      "lang": "en",
      "text": "between like a standalone\nthing they might be vibe coding",
      "offset": 637.53,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "versus a production code\nbase that has millions",
      "offset": 640.65,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and millions of lines of files.",
      "offset": 644.25,
      "duration": 1.86
    },
    {
      "lang": "en",
      "text": "How do you guys see the difference",
      "offset": 646.11,
      "duration": 0.96
    },
    {
      "lang": "en",
      "text": "between those two in your",
      "offset": 647.07,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "mind and where are we at in terms",
      "offset": 647.903,
      "duration": 2.677
    },
    {
      "lang": "en",
      "text": "of like working within\nthem with current models?",
      "offset": 650.58,
      "duration": 2.61
    },
    {
      "lang": "en",
      "text": "- I think that's something\nwe've thought about a lot",
      "offset": 653.19,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "with background agent",
      "offset": 654.81,
      "duration": 2.13
    },
    {
      "lang": "en",
      "text": "because something that's really simple",
      "offset": 656.94,
      "duration": 2.49
    },
    {
      "lang": "en",
      "text": "and obviously should be very easy",
      "offset": 659.43,
      "duration": 2.31
    },
    {
      "lang": "en",
      "text": "with these models is\nI have this test here,",
      "offset": 661.74,
      "duration": 2.643
    },
    {
      "lang": "en",
      "text": "the test is currently failing,",
      "offset": 665.79,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "can you fix the code so that it passes",
      "offset": 667.26,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "and it's like okay how\ndo we make that happen?",
      "offset": 669.72,
      "duration": 2.55
    },
    {
      "lang": "en",
      "text": "Well the model needs to\nbe able to run the test",
      "offset": 672.27,
      "duration": 2.49
    },
    {
      "lang": "en",
      "text": "and if you have a very simple repository,",
      "offset": 674.76,
      "duration": 2.91
    },
    {
      "lang": "en",
      "text": "that's very simple,",
      "offset": 677.67,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "but when you start getting",
      "offset": 678.503,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "to these larger enterprise code bases,",
      "offset": 679.336,
      "duration": 2.594
    },
    {
      "lang": "en",
      "text": "it can be complex",
      "offset": 681.93,
      "duration": 1.05
    },
    {
      "lang": "en",
      "text": "to get the dependencies set up properly so",
      "offset": 682.98,
      "duration": 3.03
    },
    {
      "lang": "en",
      "text": "that the model can run the tests.",
      "offset": 686.01,
      "duration": 1.59
    },
    {
      "lang": "en",
      "text": "But this is something we've thought about",
      "offset": 687.6,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "with background agent a lot is",
      "offset": 689.04,
      "duration": 1.23
    },
    {
      "lang": "en",
      "text": "how do you make this\nprocess straightforward",
      "offset": 690.27,
      "duration": 3.87
    },
    {
      "lang": "en",
      "text": "for the developer to\ncreate this environment",
      "offset": 694.14,
      "duration": 2.79
    },
    {
      "lang": "en",
      "text": "where the agent can run the test",
      "offset": 696.93,
      "duration": 3.15
    },
    {
      "lang": "en",
      "text": "and then make it repeatable\nso you can snapshot it",
      "offset": 700.08,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "and you can quickly update it",
      "offset": 702.48,
      "duration": 1.14
    },
    {
      "lang": "en",
      "text": "when your code state changes",
      "offset": 703.62,
      "duration": 2.49
    },
    {
      "lang": "en",
      "text": "and this unlocks the ability to, you know,",
      "offset": 706.11,
      "duration": 2.73
    },
    {
      "lang": "en",
      "text": "spin off a VM in the background,",
      "offset": 708.84,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "have the model make experiments, you know,",
      "offset": 711.48,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "and some of them will make it pass",
      "offset": 713.94,
      "duration": 1.59
    },
    {
      "lang": "en",
      "text": "and some of them won't.",
      "offset": 715.53,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "And then eventually you\nas the developer only have",
      "offset": 716.363,
      "duration": 1.897
    },
    {
      "lang": "en",
      "text": "to worry about the case where it succeeded",
      "offset": 718.26,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "and there's just a lot\nof infrastructure there",
      "offset": 720.78,
      "duration": 3.09
    },
    {
      "lang": "en",
      "text": "and a lot of user experience",
      "offset": 723.87,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "that is important to get right.",
      "offset": 725.22,
      "duration": 1.38
    },
    {
      "lang": "en",
      "text": "- Mm hmm, mm hmm.",
      "offset": 726.6,
      "duration": 1.05
    },
    {
      "lang": "en",
      "text": "- Yeah. And then I think there are other",
      "offset": 727.65,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "fundamental problems.",
      "offset": 729.33,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "So one way is you get the model to try",
      "offset": 730.77,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "to pass the test, right?",
      "offset": 734.37,
      "duration": 1.14
    },
    {
      "lang": "en",
      "text": "That's how you can kind\nof guarantee maybe,",
      "offset": 735.51,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "some sort of correctness.",
      "offset": 737.43,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "But with these large code bases,",
      "offset": 739.05,
      "duration": 1.95
    },
    {
      "lang": "en",
      "text": "you're often dealing",
      "offset": 741,
      "duration": 0.96
    },
    {
      "lang": "en",
      "text": "with things that almost\nlook like their own language",
      "offset": 741.96,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "where they have these kind of DSLs",
      "offset": 744.78,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "within some languages",
      "offset": 746.34,
      "duration": 1.38
    },
    {
      "lang": "en",
      "text": "and everything is done\nin this particular way",
      "offset": 747.72,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "and it's really sprawled out\nacross millions of files,",
      "offset": 750.12,
      "duration": 3.99
    },
    {
      "lang": "en",
      "text": "which is hundreds of millions",
      "offset": 754.11,
      "duration": 1.08
    },
    {
      "lang": "en",
      "text": "of tokens potentially maybe more.",
      "offset": 755.19,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "We've done a number of things",
      "offset": 757.08,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "to make this much better,",
      "offset": 758.55,
      "duration": 1.11
    },
    {
      "lang": "en",
      "text": "which include training retrieval models",
      "offset": 759.66,
      "duration": 2.13
    },
    {
      "lang": "en",
      "text": "and then integrating other\nsources of context as well.",
      "offset": 761.79,
      "duration": 3.03
    },
    {
      "lang": "en",
      "text": "For example, you can imagine there's a lot",
      "offset": 764.82,
      "duration": 1.29
    },
    {
      "lang": "en",
      "text": "of richness in the recent changes",
      "offset": 766.11,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "that you've made,",
      "offset": 768.81,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "when editing your code\nit kind of indicates",
      "offset": 770.01,
      "duration": 1.623
    },
    {
      "lang": "en",
      "text": "what you're working towards.",
      "offset": 771.633,
      "duration": 1.347
    },
    {
      "lang": "en",
      "text": "There could be richness in the changes",
      "offset": 772.98,
      "duration": 1.86
    },
    {
      "lang": "en",
      "text": "that other people on your team",
      "offset": 774.84,
      "duration": 1.23
    },
    {
      "lang": "en",
      "text": "have made in your code base,",
      "offset": 776.07,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "especially recently and\nusing those as hints.",
      "offset": 778.05,
      "duration": 2.91
    },
    {
      "lang": "en",
      "text": "But I do think it's still\nthis really hard fundamental",
      "offset": 780.96,
      "duration": 2.28
    },
    {
      "lang": "en",
      "text": "problem of you know,",
      "offset": 783.24,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "just giving the model access",
      "offset": 785.16,
      "duration": 1.29
    },
    {
      "lang": "en",
      "text": "to really good retrieval\nfeels insufficient",
      "offset": 786.45,
      "duration": 2.49
    },
    {
      "lang": "en",
      "text": "for having the model really\nunderstand the code base.",
      "offset": 788.94,
      "duration": 3.51
    },
    {
      "lang": "en",
      "text": "I think it's a problem",
      "offset": 792.45,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "we're really interested in solving.",
      "offset": 793.283,
      "duration": 1.417
    },
    {
      "lang": "en",
      "text": "- Mm hmm.",
      "offset": 794.7,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "Probably through some combination",
      "offset": 795.533,
      "duration": 1.567
    },
    {
      "lang": "en",
      "text": "of like memory plus long context and.",
      "offset": 797.1,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "- Yeah.\n- Other things.",
      "offset": 800.58,
      "duration": 1.08
    },
    {
      "lang": "en",
      "text": "- I think memory is one interesting",
      "offset": 801.66,
      "duration": 2.37
    },
    {
      "lang": "en",
      "text": "approach people have taken",
      "offset": 804.03,
      "duration": 1.11
    },
    {
      "lang": "en",
      "text": "to get the model to kind of learn",
      "offset": 805.14,
      "duration": 1.95
    },
    {
      "lang": "en",
      "text": "from your usage of it",
      "offset": 807.09,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "but it also feels like, you know,",
      "offset": 808.56,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "it's a small boost in performance",
      "offset": 810.18,
      "duration": 2.07
    },
    {
      "lang": "en",
      "text": "and it feels fairly primitive relative",
      "offset": 812.25,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "to like where we need to\nbe in order to get things",
      "offset": 814.02,
      "duration": 1.83
    },
    {
      "lang": "en",
      "text": "that are excellent at large code bases.",
      "offset": 815.85,
      "duration": 2.43
    },
    {
      "lang": "en",
      "text": "- Yeah and large code basis,",
      "offset": 818.28,
      "duration": 1.02
    },
    {
      "lang": "en",
      "text": "it's not only just about",
      "offset": 819.3,
      "duration": 0.99
    },
    {
      "lang": "en",
      "text": "getting the test to pass",
      "offset": 820.29,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "but it also is about\ndoing it the right way.",
      "offset": 821.49,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "Like looking at the existing code",
      "offset": 823.47,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "and making that match the new code",
      "offset": 825.69,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "and bringing it into the correct structure",
      "offset": 827.7,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "and kind of using all\nthe guidelines correctly",
      "offset": 829.71,
      "duration": 2.1
    },
    {
      "lang": "en",
      "text": "and like we've been trying\nvery hard to kind of make",
      "offset": 831.81,
      "duration": 2.49
    },
    {
      "lang": "en",
      "text": "that happen through Cursor rules,",
      "offset": 834.3,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "through integrating different\ntypes of context, et cetera.",
      "offset": 836.22,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "- Hmm.\n- Yeah, like I could write",
      "offset": 838.38,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "a deep bounce function from",
      "offset": 839.94,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "scratch and just use that and\nthat would make the test pass",
      "offset": 841.56,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "but that's not the right way to do it.",
      "offset": 843.78,
      "duration": 1.05
    },
    {
      "lang": "en",
      "text": "You should use one of the DeBounces",
      "offset": 844.83,
      "duration": 1.557
    },
    {
      "lang": "en",
      "text": "and maybe there's three",
      "offset": 846.387,
      "duration": 1.143
    },
    {
      "lang": "en",
      "text": "or four DeBounce functions\nused across the code base.",
      "offset": 847.53,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "How do you know what\nthe right one is to use?",
      "offset": 849.75,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "Maybe the only reason\nlike someone knows is",
      "offset": 851.91,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "because they message someone on",
      "offset": 853.62,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "Slack that this is how you do it.",
      "offset": 855.3,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "And so I think yeah it\ngets really, really hard",
      "offset": 856.8,
      "duration": 3.63
    },
    {
      "lang": "en",
      "text": "to solve these problems",
      "offset": 860.43,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "with extremely large code bases.",
      "offset": 861.63,
      "duration": 2.19
    },
    {
      "lang": "en",
      "text": "- That's interesting.",
      "offset": 863.82,
      "duration": 1.38
    },
    {
      "lang": "en",
      "text": "So there's also kind of an element",
      "offset": 865.2,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "to the org knowledge that lives outside",
      "offset": 866.67,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "of the code base itself",
      "offset": 870.21,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "and that like plays a major\nfactor sometimes in some",
      "offset": 871.71,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "of these decisions,",
      "offset": 873.69,
      "duration": 0.84
    },
    {
      "lang": "en",
      "text": "especially as you're operating on-",
      "offset": 874.53,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "- Yeah.\n- Large code bases.",
      "offset": 876.15,
      "duration": 1.41
    },
    {
      "lang": "en",
      "text": "- I don't think that's\nthe bottleneck today",
      "offset": 877.56,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "but I think if you solve,",
      "offset": 880.26,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "like if you made models like perfect",
      "offset": 881.79,
      "duration": 2.43
    },
    {
      "lang": "en",
      "text": "and kind of knowing the code base,",
      "offset": 884.22,
      "duration": 1.39
    },
    {
      "lang": "en",
      "text": "- Yeah.",
      "offset": 885.61,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "- I think you'll immediately,\nlike you'll maybe get like a",
      "offset": 886.443,
      "duration": 1.666
    },
    {
      "lang": "en",
      "text": "5x maybe 10x improvement",
      "offset": 888.109,
      "duration": 2.351
    },
    {
      "lang": "en",
      "text": "but you can't get farther than that",
      "offset": 890.46,
      "duration": 1.08
    },
    {
      "lang": "en",
      "text": "because now it's\ncompletely bottlenecked by,",
      "offset": 891.54,
      "duration": 2.19
    },
    {
      "lang": "en",
      "text": "how much does it know these things",
      "offset": 893.73,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "that are never ever explicitly mentioned",
      "offset": 895.62,
      "duration": 2.34
    },
    {
      "lang": "en",
      "text": "or shown in like the PRs",
      "offset": 897.96,
      "duration": 1.83
    },
    {
      "lang": "en",
      "text": "and the actual state of the code.",
      "offset": 899.79,
      "duration": 1.83
    },
    {
      "lang": "en",
      "text": "- Mm hmm.",
      "offset": 901.62,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "- And then there also\njust outside concerns",
      "offset": 902.453,
      "duration": 1.645
    },
    {
      "lang": "en",
      "text": "from the business side\nfrom sales, et cetera.",
      "offset": 904.098,
      "duration": 2.682
    },
    {
      "lang": "en",
      "text": "And those kind of have",
      "offset": 906.78,
      "duration": 1.14
    },
    {
      "lang": "en",
      "text": "to be brought into\nCursor to make that work.",
      "offset": 907.92,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "- Right.",
      "offset": 910.62,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "So some future version of Cursor then has",
      "offset": 911.453,
      "duration": 2.137
    },
    {
      "lang": "en",
      "text": "to plug into many more systems-",
      "offset": 913.59,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "- Yeah.\n- And things.",
      "offset": 915.3,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "- To be clear I think like, you know,",
      "offset": 916.133,
      "duration": 1.197
    },
    {
      "lang": "en",
      "text": "that's like still some ways a way for",
      "offset": 917.33,
      "duration": 2.26
    },
    {
      "lang": "en",
      "text": "that to be like really, really",
      "offset": 919.59,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "critical relative to the other things.",
      "offset": 921.36,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "I think we have a long ways\nto go still on just using",
      "offset": 922.68,
      "duration": 2.43
    },
    {
      "lang": "en",
      "text": "the interactions users have like details",
      "offset": 925.11,
      "duration": 1.944
    },
    {
      "lang": "en",
      "text": "of their code base",
      "offset": 927.054,
      "duration": 1.686
    },
    {
      "lang": "en",
      "text": "and commits made in order",
      "offset": 928.74,
      "duration": 1.14
    },
    {
      "lang": "en",
      "text": "to make Cursor much better.",
      "offset": 929.88,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "- One interesting thing I've started",
      "offset": 931.41,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "to notice at least with\nlike webpages and content,",
      "offset": 932.88,
      "duration": 2.97
    },
    {
      "lang": "en",
      "text": "is people trying to now think about how",
      "offset": 935.85,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "to optimize the page",
      "offset": 937.53,
      "duration": 2.1
    },
    {
      "lang": "en",
      "text": "for an LLM reading and browsing it.",
      "offset": 939.63,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "Do you think we're gonna\nsee something similar maybe",
      "offset": 942.39,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "with code and in that code could transform",
      "offset": 944.07,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "how it usually is written",
      "offset": 947.19,
      "duration": 1.08
    },
    {
      "lang": "en",
      "text": "and what it looks like if you're writing",
      "offset": 948.27,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "for primarily human reviewers",
      "offset": 949.92,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "and humans working within\na code base to models?",
      "offset": 951.84,
      "duration": 3.933
    },
    {
      "lang": "en",
      "text": "- I think that's totally the case already.",
      "offset": 956.73,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "I mean API design is\nalready adjusting such",
      "offset": 958.17,
      "duration": 3.03
    },
    {
      "lang": "en",
      "text": "that LMS are more comfortable with that.",
      "offset": 961.2,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "For example, changing not only",
      "offset": 962.88,
      "duration": 2.31
    },
    {
      "lang": "en",
      "text": "the version number internal",
      "offset": 965.19,
      "duration": 1.38
    },
    {
      "lang": "en",
      "text": "but making it like very\nvisible to the model",
      "offset": 966.57,
      "duration": 2.04
    },
    {
      "lang": "en",
      "text": "that this is a new version\nof some software just",
      "offset": 968.61,
      "duration": 2.34
    },
    {
      "lang": "en",
      "text": "to make sure that the\nAPI is used correctly.",
      "offset": 970.95,
      "duration": 3.03
    },
    {
      "lang": "en",
      "text": "And I think that the same also holds,",
      "offset": 973.98,
      "duration": 2.333
    },
    {
      "lang": "en",
      "text": "for like normal code basis",
      "offset": 976.313,
      "duration": 1.717
    },
    {
      "lang": "en",
      "text": "and internal libraries as well",
      "offset": 978.03,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "where like structuring the code in a way",
      "offset": 979.65,
      "duration": 2.28
    },
    {
      "lang": "en",
      "text": "where one doesn't have to\ngo through like end level",
      "offset": 981.93,
      "duration": 2.412
    },
    {
      "lang": "en",
      "text": "of interactions but maybe\njust through two levels",
      "offset": 984.342,
      "duration": 2.317
    },
    {
      "lang": "en",
      "text": "of interaction makes, yeah,",
      "offset": 986.659,
      "duration": 2.768
    },
    {
      "lang": "en",
      "text": "LLM models better",
      "offset": 989.427,
      "duration": 1.173
    },
    {
      "lang": "en",
      "text": "at working with that code base.",
      "offset": 990.6,
      "duration": 1.683
    },
    {
      "lang": "en",
      "text": "- Right.",
      "offset": 992.283,
      "duration": 1.347
    },
    {
      "lang": "en",
      "text": "- But I think ultimately the principles",
      "offset": 993.63,
      "duration": 2.94
    },
    {
      "lang": "en",
      "text": "of clean software are not",
      "offset": 996.57,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "that different when you want it",
      "offset": 998.79,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "to be read by people and by models.",
      "offset": 1000.35,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "You know, when you are trying",
      "offset": 1004.19,
      "duration": 2.19
    },
    {
      "lang": "en",
      "text": "to write clean code you want to,",
      "offset": 1006.38,
      "duration": 1.08
    },
    {
      "lang": "en",
      "text": "you know, not repeat yourself,",
      "offset": 1007.46,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "not make things more complicated\nthan they need to be.",
      "offset": 1008.93,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "And that is just important for models",
      "offset": 1012.11,
      "duration": 2.14
    },
    {
      "lang": "en",
      "text": "as it is for people.",
      "offset": 1014.25,
      "duration": 2.66
    },
    {
      "lang": "en",
      "text": "And I think taste in code",
      "offset": 1016.91,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "and what's a clean solution",
      "offset": 1019.61,
      "duration": 2.04
    },
    {
      "lang": "en",
      "text": "that's not more complicated than it needs",
      "offset": 1021.65,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "to be is actually gonna\nbecome even more important",
      "offset": 1022.97,
      "duration": 2.55
    },
    {
      "lang": "en",
      "text": "as these models get better",
      "offset": 1025.52,
      "duration": 1.29
    },
    {
      "lang": "en",
      "text": "because it will be easier\nto write more and more code",
      "offset": 1026.81,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "and so it'll be more",
      "offset": 1029.69,
      "duration": 1.26
    },
    {
      "lang": "en",
      "text": "and more important to\nstructure it in a tasteful way.",
      "offset": 1030.95,
      "duration": 3.75
    },
    {
      "lang": "en",
      "text": "- That's a really good point on taste.",
      "offset": 1034.7,
      "duration": 2.61
    },
    {
      "lang": "en",
      "text": "Taste is kind of this thing",
      "offset": 1037.31,
      "duration": 1.05
    },
    {
      "lang": "en",
      "text": "that I feel like maybe\nsome people are born",
      "offset": 1038.36,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "with more taste than others,",
      "offset": 1040.25,
      "duration": 1.14
    },
    {
      "lang": "en",
      "text": "but generally you kind of\ndevelop taste through experience",
      "offset": 1041.39,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "and learning what works\nand seeing failures",
      "offset": 1044.75,
      "duration": 2.85
    },
    {
      "lang": "en",
      "text": "and seeing successes.",
      "offset": 1047.6,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "In a world where we're\nhaving AI write more",
      "offset": 1049.13,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "and more of our code,",
      "offset": 1053.09,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "there's been real pushback against",
      "offset": 1053.923,
      "duration": 1.747
    },
    {
      "lang": "en",
      "text": "some that say, oh you're\ngonna make programmers lazy",
      "offset": 1055.67,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "or you're not gonna give\njuniors a chance to learn",
      "offset": 1058.43,
      "duration": 3.085
    },
    {
      "lang": "en",
      "text": "what it actually looks like",
      "offset": 1061.515,
      "duration": 1.445
    },
    {
      "lang": "en",
      "text": "to work within a large code\nbase and do all these things.",
      "offset": 1062.96,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "How do you think about balancing",
      "offset": 1065.72,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "this sort of automation",
      "offset": 1067.4,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "or assistance in this case",
      "offset": 1069.17,
      "duration": 1.05
    },
    {
      "lang": "en",
      "text": "with also preserving the\ncore engineering skills",
      "offset": 1070.22,
      "duration": 2.91
    },
    {
      "lang": "en",
      "text": "that maybe a software\nengineer has to go through,",
      "offset": 1073.13,
      "duration": 1.83
    },
    {
      "lang": "en",
      "text": "those like trials and tribulations?",
      "offset": 1074.96,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "- I think these tools are\nvery good educationally",
      "offset": 1077.42,
      "duration": 4.41
    },
    {
      "lang": "en",
      "text": "as well and they can help you\nbecome a great programmer.",
      "offset": 1081.83,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "You know, if you have a question",
      "offset": 1084.29,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "about how something works,",
      "offset": 1085.82,
      "duration": 1.05
    },
    {
      "lang": "en",
      "text": "if you want some concept explained to you,",
      "offset": 1086.87,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "now you can just,",
      "offset": 1089.33,
      "duration": 0.87
    },
    {
      "lang": "en",
      "text": "you know, press command L",
      "offset": 1090.2,
      "duration": 1.23
    },
    {
      "lang": "en",
      "text": "and ask Claude, you know, what is this?",
      "offset": 1091.43,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "How does it work? Can\nyou explain it to me?",
      "offset": 1093.44,
      "duration": 1.703
    },
    {
      "lang": "en",
      "text": "And I think that's very valuable.",
      "offset": 1095.143,
      "duration": 2.707
    },
    {
      "lang": "en",
      "text": "It does make it easier to write more code",
      "offset": 1097.85,
      "duration": 2.85
    },
    {
      "lang": "en",
      "text": "and do more stuff and\nthat can result in higher",
      "offset": 1100.7,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "and lower quality code being out there.",
      "offset": 1105.08,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "That is true, but I think\nin general it's a very,",
      "offset": 1107.96,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "very powerful tool that\nwill raise the bar.",
      "offset": 1111.92,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "- I think quality comes\nvery much from iterating",
      "offset": 1114.98,
      "duration": 2.79
    },
    {
      "lang": "en",
      "text": "quickly, making mistakes,",
      "offset": 1117.77,
      "duration": 1.29
    },
    {
      "lang": "en",
      "text": "figuring out why certain things fail.",
      "offset": 1119.06,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "And I think models vastly accelerate",
      "offset": 1120.62,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "this iteration process",
      "offset": 1122.6,
      "duration": 1.29
    },
    {
      "lang": "en",
      "text": "and can actually through\nthat make you learn more",
      "offset": 1123.89,
      "duration": 2.19
    },
    {
      "lang": "en",
      "text": "quickly what works and what doesn't.",
      "offset": 1126.08,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "So I think in the long term,",
      "offset": 1127.52,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "it's a super helpful tool for",
      "offset": 1128.87,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "developers just getting\nstarted and working on bigger",
      "offset": 1131.09,
      "duration": 2.55
    },
    {
      "lang": "en",
      "text": "and bigger projects",
      "offset": 1133.64,
      "duration": 1.11
    },
    {
      "lang": "en",
      "text": "and figuring out what\nworks and what doesn't.",
      "offset": 1134.75,
      "duration": 1.86
    },
    {
      "lang": "en",
      "text": "- Yeah, I think it'll be\nreally interesting to see",
      "offset": 1136.61,
      "duration": 2.43
    },
    {
      "lang": "en",
      "text": "how programming evolves.",
      "offset": 1139.04,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "I think you'll still for\na very long time need",
      "offset": 1141.44,
      "duration": 2.97
    },
    {
      "lang": "en",
      "text": "to have the engineers that\nknow the details right,",
      "offset": 1144.41,
      "duration": 3.27
    },
    {
      "lang": "en",
      "text": "can go into the weeds.",
      "offset": 1147.68,
      "duration": 2.04
    },
    {
      "lang": "en",
      "text": "I wonder how much you'll\nstart to see people",
      "offset": 1149.72,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "that are now learning\nprogramming who don't know many",
      "offset": 1152.78,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "of the details but can\nstill be fairly effective.",
      "offset": 1155.42,
      "duration": 1.8
    },
    {
      "lang": "en",
      "text": "I think today you still do",
      "offset": 1157.22,
      "duration": 1.86
    },
    {
      "lang": "en",
      "text": "need to know a lot of the details.",
      "offset": 1159.08,
      "duration": 1.08
    },
    {
      "lang": "en",
      "text": "I think over time you might have a class",
      "offset": 1160.16,
      "duration": 2.13
    },
    {
      "lang": "en",
      "text": "of software engineers\nthat need to know very few",
      "offset": 1162.29,
      "duration": 1.83
    },
    {
      "lang": "en",
      "text": "of like the low level details",
      "offset": 1164.12,
      "duration": 1.08
    },
    {
      "lang": "en",
      "text": "and it still operate at a higher level",
      "offset": 1165.2,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "and maybe it looks a lot\nmore like kind of thinking",
      "offset": 1166.91,
      "duration": 2.07
    },
    {
      "lang": "en",
      "text": "through like the taste is like more",
      "offset": 1168.98,
      "duration": 1.86
    },
    {
      "lang": "en",
      "text": "in kind of UX taste, right?",
      "offset": 1170.84,
      "duration": 1.683
    },
    {
      "lang": "en",
      "text": "Like let's say you're trying",
      "offset": 1173.57,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "to build something like a notion, right?",
      "offset": 1174.403,
      "duration": 1.837
    },
    {
      "lang": "en",
      "text": "At the end of the day,",
      "offset": 1176.24,
      "duration": 1.17
    },
    {
      "lang": "en",
      "text": "I don't think you can offload",
      "offset": 1177.41,
      "duration": 1.05
    },
    {
      "lang": "en",
      "text": "that entire thing to the language model.",
      "offset": 1178.46,
      "duration": 2
    },
    {
      "lang": "en",
      "text": "You need to kind of describe like,",
      "offset": 1181.379,
      "duration": 1.101
    },
    {
      "lang": "en",
      "text": "okay when I do this type",
      "offset": 1182.48,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "of interaction then I expect it",
      "offset": 1184.01,
      "duration": 2.19
    },
    {
      "lang": "en",
      "text": "to pop up in this particular way, right?",
      "offset": 1186.2,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "Maybe you don't have to get to the details",
      "offset": 1187.91,
      "duration": 1.41
    },
    {
      "lang": "en",
      "text": "of writing pure software that does that,",
      "offset": 1189.32,
      "duration": 1.83
    },
    {
      "lang": "en",
      "text": "but still describing those interactions,",
      "offset": 1191.15,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "describing the way",
      "offset": 1193.13,
      "duration": 1.11
    },
    {
      "lang": "en",
      "text": "this thing roughly works.",
      "offset": 1194.24,
      "duration": 1.29
    },
    {
      "lang": "en",
      "text": "That is a form of programming.",
      "offset": 1195.53,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "- Switching gears a little\nbit on the topic of models,",
      "offset": 1196.88,
      "duration": 2.63
    },
    {
      "lang": "en",
      "text": "so we just recently,",
      "offset": 1199.51,
      "duration": 1.78
    },
    {
      "lang": "en",
      "text": "by the time this video comes out,",
      "offset": 1201.29,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "Claude Opus 4",
      "offset": 1202.76,
      "duration": 1.29
    },
    {
      "lang": "en",
      "text": "and Claude Sonnet 4 will\nbe out into the world.",
      "offset": 1204.05,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "Love to hear your guys'\nthoughts on the new models",
      "offset": 1206.93,
      "duration": 2.43
    },
    {
      "lang": "en",
      "text": "and how you're starting to think about",
      "offset": 1209.36,
      "duration": 1.11
    },
    {
      "lang": "en",
      "text": "integrating them within Cursor.",
      "offset": 1210.47,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "- I mean we've really\nenjoyed the new models.",
      "offset": 1212.18,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "I think we were pretty shocked\ntrying out the new Sonnet",
      "offset": 1215.6,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "because I think 3.7 is a fantastic model.",
      "offset": 1218.36,
      "duration": 3.63
    },
    {
      "lang": "en",
      "text": "It was better at agentic coating",
      "offset": 1221.99,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "but everyone knew it kind\nof had these deficits right,",
      "offset": 1223.97,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "where it would maybe be a little bit",
      "offset": 1226.67,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "too overeager-\n- Like to do a lot.",
      "offset": 1228.17,
      "duration": 2.093
    },
    {
      "lang": "en",
      "text": "- Yeah it did.",
      "offset": 1230.263,
      "duration": 1.747
    },
    {
      "lang": "en",
      "text": "Would like to change",
      "offset": 1232.01,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "the test sometimes,",
      "offset": 1232.843,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "that they passed.\n- Yeah, yeah.",
      "offset": 1233.676,
      "duration": 1.124
    },
    {
      "lang": "en",
      "text": "- We found that Sonnet\n4 has effectively fixed",
      "offset": 1234.8,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "all those, it is much better",
      "offset": 1239.24,
      "duration": 1.05
    },
    {
      "lang": "en",
      "text": "and then the intelligence",
      "offset": 1240.29,
      "duration": 1.02
    },
    {
      "lang": "en",
      "text": "has also been a big step up",
      "offset": 1241.31,
      "duration": 1.14
    },
    {
      "lang": "en",
      "text": "where you know, you've seen other models",
      "offset": 1242.45,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "that are kind of steps up in intelligence,",
      "offset": 1245.81,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "maybe not as like strong as",
      "offset": 1247.46,
      "duration": 2.04
    },
    {
      "lang": "en",
      "text": "agentic coding but like you know,",
      "offset": 1249.5,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "O3 is an example",
      "offset": 1251.21,
      "duration": 1.14
    },
    {
      "lang": "en",
      "text": "and we found it goes toe-to-toe with",
      "offset": 1252.35,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "that despite being you know,",
      "offset": 1253.91,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "a much cheaper model.",
      "offset": 1255.44,
      "duration": 1.23
    },
    {
      "lang": "en",
      "text": "And so we're extremely excited for Opus",
      "offset": 1256.67,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "because we think it'll be a fantastic",
      "offset": 1258.83,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "agent to use in the background.",
      "offset": 1261.23,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "- Yeah, that's awesome\nto hear the test writing",
      "offset": 1262.79,
      "duration": 3.45
    },
    {
      "lang": "en",
      "text": "and overeagerness things",
      "offset": 1266.24,
      "duration": 1.11
    },
    {
      "lang": "en",
      "text": "are things that we were trying",
      "offset": 1267.35,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "to tackle pretty intensely\nwith these models",
      "offset": 1268.67,
      "duration": 2.31
    },
    {
      "lang": "en",
      "text": "and concept of like\nreward hacking in which",
      "offset": 1270.98,
      "duration": 3.81
    },
    {
      "lang": "en",
      "text": "the models will find some way",
      "offset": 1274.79,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "to basically take a shortcut",
      "offset": 1276.71,
      "duration": 1.8
    },
    {
      "lang": "en",
      "text": "to get to the final reward in rl.",
      "offset": 1278.51,
      "duration": 2.39
    },
    {
      "lang": "en",
      "text": "So we've done a lot of\nwork to cut that down.",
      "offset": 1280.9,
      "duration": 1.6
    },
    {
      "lang": "en",
      "text": "I think we cut it down",
      "offset": 1282.5,
      "duration": 0.99
    },
    {
      "lang": "en",
      "text": "to like 80% in these new models.",
      "offset": 1283.49,
      "duration": 2.277
    },
    {
      "lang": "en",
      "text": "- I'm really curious to hear",
      "offset": 1285.767,
      "duration": 1.203
    },
    {
      "lang": "en",
      "text": "how did 3.5 Sonnet come about,",
      "offset": 1286.97,
      "duration": 2.37
    },
    {
      "lang": "en",
      "text": "'cause that felt like\nthe first kind of punch",
      "offset": 1289.34,
      "duration": 1.59
    },
    {
      "lang": "en",
      "text": "of like this is like a really good coding",
      "offset": 1290.93,
      "duration": 2.1
    },
    {
      "lang": "en",
      "text": "model for Anthropic.",
      "offset": 1293.03,
      "duration": 1.26
    },
    {
      "lang": "en",
      "text": "- How did it come about?",
      "offset": 1294.29,
      "duration": 1.38
    },
    {
      "lang": "en",
      "text": "We trained it.",
      "offset": 1295.67,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "Just, it was good.",
      "offset": 1297.02,
      "duration": 1.083
    },
    {
      "lang": "en",
      "text": "Yeah, I think we have always\nknown for a while that,",
      "offset": 1299.72,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "I mean probably since the\ngenesis of the company",
      "offset": 1303.86,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "that we've wanted to make\nmodels really good at coding,",
      "offset": 1305.54,
      "duration": 2.42
    },
    {
      "lang": "en",
      "text": "it just seems important",
      "offset": 1307.96,
      "duration": 1.12
    },
    {
      "lang": "en",
      "text": "for everything else that you do,",
      "offset": 1309.08,
      "duration": 1.41
    },
    {
      "lang": "en",
      "text": "especially as you make more models.",
      "offset": 1310.49,
      "duration": 2.91
    },
    {
      "lang": "en",
      "text": "3.5 Sonnet was,",
      "offset": 1313.4,
      "duration": 1.893
    },
    {
      "lang": "en",
      "text": "I wouldn't, I mean I think 3-Opus",
      "offset": 1316.49,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "was a really good coding model",
      "offset": 1317.99,
      "duration": 0.99
    },
    {
      "lang": "en",
      "text": "as well, especially for its time.",
      "offset": 1318.98,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "But 3.5 Sonnet was the first time",
      "offset": 1320.6,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "that we really put a\nstrong dedicated effort",
      "offset": 1322.04,
      "duration": 2.43
    },
    {
      "lang": "en",
      "text": "to, hey, let's get these\nmodels good at coding,",
      "offset": 1324.47,
      "duration": 2.31
    },
    {
      "lang": "en",
      "text": "but not just specifically coding,",
      "offset": 1326.78,
      "duration": 1.17
    },
    {
      "lang": "en",
      "text": "this sort of longer horizon\ncoding where it's having",
      "offset": 1327.95,
      "duration": 3.75
    },
    {
      "lang": "en",
      "text": "to do these things like\nyou're mentioning earlier",
      "offset": 1331.7,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "in the conversation",
      "offset": 1333.41,
      "duration": 1.26
    },
    {
      "lang": "en",
      "text": "around making edits on different files,",
      "offset": 1334.67,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "going off and like taking a command here,",
      "offset": 1337.07,
      "duration": 2.1
    },
    {
      "lang": "en",
      "text": "calling a tool and then going",
      "offset": 1339.17,
      "duration": 1.369
    },
    {
      "lang": "en",
      "text": "and making a change somewhere else.",
      "offset": 1340.539,
      "duration": 2.111
    },
    {
      "lang": "en",
      "text": "That was the first model in which",
      "offset": 1342.65,
      "duration": 1.08
    },
    {
      "lang": "en",
      "text": "we could kind of put all\nthese things together",
      "offset": 1343.73,
      "duration": 2.1
    },
    {
      "lang": "en",
      "text": "and I think it just turned out really well",
      "offset": 1345.83,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "and kind of set the stage for what",
      "offset": 1348.29,
      "duration": 1.11
    },
    {
      "lang": "en",
      "text": "our future models would be.",
      "offset": 1349.4,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "- And how do you guys think",
      "offset": 1350.93,
      "duration": 1.11
    },
    {
      "lang": "en",
      "text": "about code versus other areas",
      "offset": 1352.04,
      "duration": 2.31
    },
    {
      "lang": "en",
      "text": "where you want Sonnet to excel?",
      "offset": 1354.35,
      "duration": 1.95
    },
    {
      "lang": "en",
      "text": "- Yeah",
      "offset": 1356.3,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "- And Opus to excel.",
      "offset": 1357.133,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "- I mean code is one of the primary areas,",
      "offset": 1359.3,
      "duration": 2.67
    },
    {
      "lang": "en",
      "text": "but I think it's not the only area.",
      "offset": 1361.97,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "I think there is a good amount of transfer",
      "offset": 1363.86,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "that you see from models\ngetting really good at code",
      "offset": 1365.78,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "to them just getting better",
      "offset": 1368,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "at reasoning over taking many",
      "offset": 1369.32,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "actions and working in\nthis sort of agentic way.",
      "offset": 1371.72,
      "duration": 2.67
    },
    {
      "lang": "en",
      "text": "And that carryover",
      "offset": 1374.39,
      "duration": 2.85
    },
    {
      "lang": "en",
      "text": "is pretty nice as you're dealing",
      "offset": 1377.24,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "with applications that might mix in code",
      "offset": 1378.86,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "but also have to go retrieve\nknowledge from other",
      "offset": 1381.62,
      "duration": 2.19
    },
    {
      "lang": "en",
      "text": "places or do research.",
      "offset": 1383.81,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "Generally we're about just\npushing the frontier as much",
      "offset": 1385.49,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "as we can with our models.",
      "offset": 1388.31,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "Of course there is like\nconsiderations that we make",
      "offset": 1389.66,
      "duration": 2.13
    },
    {
      "lang": "en",
      "text": "around safety and making sure",
      "offset": 1391.79,
      "duration": 1.11
    },
    {
      "lang": "en",
      "text": "that the models are in line",
      "offset": 1392.9,
      "duration": 0.99
    },
    {
      "lang": "en",
      "text": "with what you as a user want",
      "offset": 1393.89,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "and also what we believe\nthe model should be doing.",
      "offset": 1395.54,
      "duration": 2.91
    },
    {
      "lang": "en",
      "text": "But generally we want to keep pushing",
      "offset": 1398.45,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "the limits of what these models can do",
      "offset": 1400.91,
      "duration": 2.19
    },
    {
      "lang": "en",
      "text": "and kind of show developers\nin the world this is",
      "offset": 1403.1,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "what models are capable of.",
      "offset": 1405.98,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "So things like computer use,",
      "offset": 1407.33,
      "duration": 2.19
    },
    {
      "lang": "en",
      "text": "when we unveiled that back in October,",
      "offset": 1409.52,
      "duration": 2.28
    },
    {
      "lang": "en",
      "text": "that was like another\ndirection in which we're really",
      "offset": 1411.8,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "pushing forward in terms",
      "offset": 1413.45,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "of how can a model be good",
      "offset": 1414.89,
      "duration": 1.41
    },
    {
      "lang": "en",
      "text": "at actually navigating something",
      "offset": 1416.3,
      "duration": 1.8
    },
    {
      "lang": "en",
      "text": "that is a primarily a\nhuman interface, right?",
      "offset": 1418.1,
      "duration": 2.49
    },
    {
      "lang": "en",
      "text": "So it's not in the world of like APIs",
      "offset": 1420.59,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "or tool calls or anything like that.",
      "offset": 1422.6,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "It's literally just looking",
      "offset": 1424.28,
      "duration": 1.05
    },
    {
      "lang": "en",
      "text": "at an image as a human would",
      "offset": 1425.33,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "and then having to direct",
      "offset": 1427.22,
      "duration": 1.14
    },
    {
      "lang": "en",
      "text": "an action onto that screen.",
      "offset": 1428.36,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "There's also a strong part",
      "offset": 1430.04,
      "duration": 1.38
    },
    {
      "lang": "en",
      "text": "to how we think about\nthese models character,",
      "offset": 1431.42,
      "duration": 2.28
    },
    {
      "lang": "en",
      "text": "as it's known now, Amanda Askell",
      "offset": 1433.7,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "is one of our lead\nresearchers on this effort,",
      "offset": 1435.14,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "kind of crafting Claude's character",
      "offset": 1437.12,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "and we put a lot of thought",
      "offset": 1439.1,
      "duration": 0.84
    },
    {
      "lang": "en",
      "text": "and consideration into what Claude",
      "offset": 1439.94,
      "duration": 1.86
    },
    {
      "lang": "en",
      "text": "should feel like and sound like",
      "offset": 1441.8,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "and what does it mean for an AI",
      "offset": 1443.69,
      "duration": 2.25
    },
    {
      "lang": "en",
      "text": "to play a really prominent\nrole in somebody's life.",
      "offset": 1445.94,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "Not as just a coding agent,",
      "offset": 1448.16,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "but as kind of like their\nconfidant in a sense",
      "offset": 1449.48,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "and an entity",
      "offset": 1452.3,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "that you're gonna be spending",
      "offset": 1453.8,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "a lot of time talking to.",
      "offset": 1455,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "So that's also really factored",
      "offset": 1456.47,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "into all the decisions we",
      "offset": 1457.79,
      "duration": 1.08
    },
    {
      "lang": "en",
      "text": "make around these models\nand how we train 'em.",
      "offset": 1458.87,
      "duration": 2.04
    },
    {
      "lang": "en",
      "text": "- How does Anthropic\nas a whole think about",
      "offset": 1460.91,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "where things are going both",
      "offset": 1462.89,
      "duration": 2.37
    },
    {
      "lang": "en",
      "text": "in terms of software engineering",
      "offset": 1465.26,
      "duration": 1.02
    },
    {
      "lang": "en",
      "text": "and then in terms of like research,",
      "offset": 1466.28,
      "duration": 2.34
    },
    {
      "lang": "en",
      "text": "like in terms of how much",
      "offset": 1468.62,
      "duration": 1.38
    },
    {
      "lang": "en",
      "text": "like these models will augment, replace,",
      "offset": 1470,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "do a lot of this work?",
      "offset": 1473.66,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "- Yeah, it can speak personally here.",
      "offset": 1475.16,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "So personally I think",
      "offset": 1476.81,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "that we're not gonna be replacing,",
      "offset": 1478.28,
      "duration": 2.13
    },
    {
      "lang": "en",
      "text": "as we've been talked about earlier,",
      "offset": 1480.41,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "there's just like so\nmuch more you can do now",
      "offset": 1482.18,
      "duration": 3.45
    },
    {
      "lang": "en",
      "text": "that you have like models",
      "offset": 1485.63,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "that can do all this, you know,",
      "offset": 1486.463,
      "duration": 2.107
    },
    {
      "lang": "en",
      "text": "nuts and bolts like typing",
      "offset": 1488.57,
      "duration": 1.41
    },
    {
      "lang": "en",
      "text": "of the code basically for you.",
      "offset": 1489.98,
      "duration": 1.8
    },
    {
      "lang": "en",
      "text": "I see this with myself too.",
      "offset": 1491.78,
      "duration": 1.14
    },
    {
      "lang": "en",
      "text": "Like I studied computer science in college",
      "offset": 1492.92,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "and did software engineering",
      "offset": 1495.14,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "and now I feel like I'm at the point",
      "offset": 1496.91,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "where the models are like better",
      "offset": 1498.35,
      "duration": 2.13
    },
    {
      "lang": "en",
      "text": "at producing code than I am,",
      "offset": 1500.48,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "like if I were to just like think",
      "offset": 1501.98,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "about doing like a lead",
      "offset": 1503.18,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "code problem or anything like that,",
      "offset": 1504.53,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "where it's like a contained environment",
      "offset": 1506.24,
      "duration": 1.74
    },
    {
      "lang": "en",
      "text": "and the model has to write code,",
      "offset": 1507.98,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "it's gonna like beat me",
      "offset": 1509.63,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "and yet I feel like I\ncan do more than ever.",
      "offset": 1511.16,
      "duration": 2.37
    },
    {
      "lang": "en",
      "text": "I can make prototypes of anything.",
      "offset": 1513.53,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "I can like spin up demos super,",
      "offset": 1515.24,
      "duration": 1.29
    },
    {
      "lang": "en",
      "text": "super fast if I wanna like\nshow off a new concept.",
      "offset": 1516.53,
      "duration": 2.94
    },
    {
      "lang": "en",
      "text": "It's felt very empowering\nin that sense than like",
      "offset": 1519.47,
      "duration": 2.98
    },
    {
      "lang": "en",
      "text": "taking away or dismissive\nof what I've been doing.",
      "offset": 1523.4,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "And it is similar to\nwhere I feel like just",
      "offset": 1526.4,
      "duration": 2.61
    },
    {
      "lang": "en",
      "text": "because I have that knowledge",
      "offset": 1529.01,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "of software engineering from the past,",
      "offset": 1530.33,
      "duration": 2.25
    },
    {
      "lang": "en",
      "text": "I can actually exploit it much better",
      "offset": 1532.58,
      "duration": 2.13
    },
    {
      "lang": "en",
      "text": "and I can use the model,",
      "offset": 1534.71,
      "duration": 1.08
    },
    {
      "lang": "en",
      "text": "I can push it farther",
      "offset": 1535.79,
      "duration": 1.08
    },
    {
      "lang": "en",
      "text": "than if I just still didn't have any",
      "offset": 1536.87,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "idea about what code is.",
      "offset": 1538.58,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "Maybe on that getting more into like",
      "offset": 1540.23,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "the sort of fun future speculation I want",
      "offset": 1541.67,
      "duration": 2.43
    },
    {
      "lang": "en",
      "text": "to ask like maybe a practical\nquestion in a few years we can",
      "offset": 1544.1,
      "duration": 2.753
    },
    {
      "lang": "en",
      "text": "come back to this one and\nsee how we turned out.",
      "offset": 1546.853,
      "duration": 3.067
    },
    {
      "lang": "en",
      "text": "January 1st, 2027,",
      "offset": 1549.92,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "so what is that a little\nless than two years from now?",
      "offset": 1551.69,
      "duration": 3.51
    },
    {
      "lang": "en",
      "text": "What percentage of code",
      "offset": 1555.2,
      "duration": 1.14
    },
    {
      "lang": "en",
      "text": "do you think will be AI generated",
      "offset": 1556.34,
      "duration": 2.67
    },
    {
      "lang": "en",
      "text": "and following that, what\ndoes the day in the life",
      "offset": 1559.01,
      "duration": 2.28
    },
    {
      "lang": "en",
      "text": "of somebody that's\nconsidering themselves a",
      "offset": 1561.29,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "developer now look like?",
      "offset": 1563.93,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "- I think it's similar to going back to,",
      "offset": 1565.94,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "let's say before I was born,",
      "offset": 1568.4,
      "duration": 1.59
    },
    {
      "lang": "en",
      "text": "but you know, 1995",
      "offset": 1569.99,
      "duration": 1.8
    },
    {
      "lang": "en",
      "text": "and asking a lawyer in\nthe future what percentage",
      "offset": 1571.79,
      "duration": 4.77
    },
    {
      "lang": "en",
      "text": "of legal documents will be\nword processor generated",
      "offset": 1576.56,
      "duration": 3.27
    },
    {
      "lang": "en",
      "text": "and the answer is 100%",
      "offset": 1579.83,
      "duration": 2.73
    },
    {
      "lang": "en",
      "text": "or you know, close to 100%",
      "offset": 1582.56,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "in that AI will be involved in almost all",
      "offset": 1584.48,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "of the code that gets written.",
      "offset": 1587.18,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "But still your role as a lawyer",
      "offset": 1588.89,
      "duration": 3.69
    },
    {
      "lang": "en",
      "text": "or as a developer in understanding",
      "offset": 1592.58,
      "duration": 2.19
    },
    {
      "lang": "en",
      "text": "what the code needs to do",
      "offset": 1594.77,
      "duration": 0.96
    },
    {
      "lang": "en",
      "text": "and having taste",
      "offset": 1595.73,
      "duration": 0.84
    },
    {
      "lang": "en",
      "text": "and guiding what is done\nwith the software is going",
      "offset": 1596.57,
      "duration": 3.38
    },
    {
      "lang": "en",
      "text": "to be more important than ever.",
      "offset": 1599.95,
      "duration": 2.023
    },
    {
      "lang": "en",
      "text": "- I mean already at Cursor",
      "offset": 1603.11,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "it's probably 90% plus,",
      "offset": 1604.46,
      "duration": 2.07
    },
    {
      "lang": "en",
      "text": "but that's because a large fraction",
      "offset": 1606.53,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "of it is using more higher\nlevel features like Agent.",
      "offset": 1608.99,
      "duration": 3.93
    },
    {
      "lang": "en",
      "text": "- Yeah.\n- And Command K and whatnot.",
      "offset": 1612.92,
      "duration": 1.17
    },
    {
      "lang": "en",
      "text": "But then a lot of it is you're typing",
      "offset": 1614.09,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "and then Tab will as you type",
      "offset": 1615.65,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "do 70% of that.\n- Right.",
      "offset": 1618.83,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "- So in the cases where\nyou're actually going in",
      "offset": 1620.99,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "and doing it manually yourself,",
      "offset": 1622.67,
      "duration": 1.11
    },
    {
      "lang": "en",
      "text": "Tab is still doing most of those changes,",
      "offset": 1623.78,
      "duration": 1.83
    },
    {
      "lang": "en",
      "text": "- Right, so the actual\nletters typed is like a very,",
      "offset": 1625.61,
      "duration": 3.749
    },
    {
      "lang": "en",
      "text": "very low percent.\n- Yeah.",
      "offset": 1629.359,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "But I think like every facet",
      "offset": 1630.192,
      "duration": 1.226
    },
    {
      "lang": "en",
      "text": "of producing software I\nthink will be kind of changed",
      "offset": 1631.418,
      "duration": 3.342
    },
    {
      "lang": "en",
      "text": "to use AI in some way.\n- Do you think we ever get",
      "offset": 1634.76,
      "duration": 2.633
    },
    {
      "lang": "en",
      "text": "to a world in which you basically",
      "offset": 1637.393,
      "duration": 1.357
    },
    {
      "lang": "en",
      "text": "have software on demand?",
      "offset": 1638.75,
      "duration": 1.473
    },
    {
      "lang": "en",
      "text": "What does that look like?",
      "offset": 1641.15,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "- I think you're going",
      "offset": 1642.92,
      "duration": 0.96
    },
    {
      "lang": "en",
      "text": "to see people building software,",
      "offset": 1643.88,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "people in organizational\nfunctions, building software",
      "offset": 1647.6,
      "duration": 2.19
    },
    {
      "lang": "en",
      "text": "who are not previously building software.",
      "offset": 1649.79,
      "duration": 2.07
    },
    {
      "lang": "en",
      "text": "You know, like people in sales",
      "offset": 1651.86,
      "duration": 1.8
    },
    {
      "lang": "en",
      "text": "who would not have built their own tools",
      "offset": 1653.66,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "before will now be building, for example,",
      "offset": 1655.19,
      "duration": 2.28
    },
    {
      "lang": "en",
      "text": "dashboards to track\nwhat's important to them.",
      "offset": 1657.47,
      "duration": 2.73
    },
    {
      "lang": "en",
      "text": "And going back to how taste",
      "offset": 1660.2,
      "duration": 2.13
    },
    {
      "lang": "en",
      "text": "becomes more important\nthan ever, you know,",
      "offset": 1662.33,
      "duration": 1.74
    },
    {
      "lang": "en",
      "text": "now you can build the dashboard,",
      "offset": 1664.07,
      "duration": 1.74
    },
    {
      "lang": "en",
      "text": "but you still need to decide",
      "offset": 1665.81,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "what metrics the dashboard is gonna show.",
      "offset": 1667.49,
      "duration": 2.61
    },
    {
      "lang": "en",
      "text": "It doesn't prevent you\nfrom having to decide that.",
      "offset": 1670.1,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "I think you're going\nto see many more people",
      "offset": 1673.16,
      "duration": 4.3
    },
    {
      "lang": "en",
      "text": "building their own software,",
      "offset": 1678.86,
      "duration": 1.26
    },
    {
      "lang": "en",
      "text": "but it will be bottlenecked\non having a unique thing",
      "offset": 1680.12,
      "duration": 3.87
    },
    {
      "lang": "en",
      "text": "that you want to do with the software",
      "offset": 1683.99,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "that isn't properly\nserved by existing needs.",
      "offset": 1685.61,
      "duration": 2.49
    },
    {
      "lang": "en",
      "text": "- One example I like to\ntell people is we've a guy,",
      "offset": 1688.1,
      "duration": 3.354
    },
    {
      "lang": "en",
      "text": "our comms team who's actually",
      "offset": 1691.454,
      "duration": 2.226
    },
    {
      "lang": "en",
      "text": "been like shipping bug fixes to Claude.ai,",
      "offset": 1693.68,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "which is just like absolutely insane.",
      "offset": 1696.32,
      "duration": 1.95
    },
    {
      "lang": "en",
      "text": "Like he's in a completely\ndifferent part of the org,",
      "offset": 1698.27,
      "duration": 2.13
    },
    {
      "lang": "en",
      "text": "he's not touching product at all",
      "offset": 1700.4,
      "duration": 1.38
    },
    {
      "lang": "en",
      "text": "and yet he pops in with like a PR",
      "offset": 1701.78,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "and he's like asking for a stamp",
      "offset": 1703.4,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "and you're like, what are you doing?",
      "offset": 1705.02,
      "duration": 1.74
    },
    {
      "lang": "en",
      "text": "And it's like, yeah, he's\nusing, you know, Claude code",
      "offset": 1706.76,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "or some coding tool with Claude",
      "offset": 1709.46,
      "duration": 2.1
    },
    {
      "lang": "en",
      "text": "has the base model there",
      "offset": 1711.56,
      "duration": 1.02
    },
    {
      "lang": "en",
      "text": "to like fix bugs in a\nproduction code base.",
      "offset": 1712.58,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "I think that's amazing as well.",
      "offset": 1716.66,
      "duration": 1.41
    },
    {
      "lang": "en",
      "text": "And it ties back into\nthis like general, hey,",
      "offset": 1718.07,
      "duration": 2.91
    },
    {
      "lang": "en",
      "text": "if you have taste, if\nyou have good intuitions,",
      "offset": 1720.98,
      "duration": 1.8
    },
    {
      "lang": "en",
      "text": "like you're just gonna\nbe able to do a lot.",
      "offset": 1722.78,
      "duration": 2.19
    },
    {
      "lang": "en",
      "text": "That's kind of how I see the\nworld keeping progressing.",
      "offset": 1724.97,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "I think things will change",
      "offset": 1728.03,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "and like roles will look\nmuch different in five years,",
      "offset": 1729.23,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "10 years, but generally",
      "offset": 1731.75,
      "duration": 2.25
    },
    {
      "lang": "en",
      "text": "like I'm very much in favor of like,",
      "offset": 1734,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "if you can do more with these things,",
      "offset": 1735.89,
      "duration": 2.07
    },
    {
      "lang": "en",
      "text": "like that's generally always\ngonna be a good thing.",
      "offset": 1737.96,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "- Yeah, I feel like there are a lot",
      "offset": 1739.97,
      "duration": 1.23
    },
    {
      "lang": "en",
      "text": "of interesting paths that this could take.",
      "offset": 1741.2,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "One is just completely",
      "offset": 1742.91,
      "duration": 2.43
    },
    {
      "lang": "en",
      "text": "on the fly on demand software",
      "offset": 1745.34,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "where I am using my own version some app",
      "offset": 1746.81,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "and just like as I use it, you know,",
      "offset": 1750.35,
      "duration": 2.13
    },
    {
      "lang": "en",
      "text": "this interaction I don't really like",
      "offset": 1752.48,
      "duration": 1.41
    },
    {
      "lang": "en",
      "text": "and it just changes for me",
      "offset": 1753.89,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "that's one kind of crazy\nfuture you could imagine",
      "offset": 1755.45,
      "duration": 2.37
    },
    {
      "lang": "en",
      "text": "where it's not even you\nkind of actively doing it,",
      "offset": 1757.82,
      "duration": 1.8
    },
    {
      "lang": "en",
      "text": "but just based on your\ninteractions with it,",
      "offset": 1759.62,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "the software, whatever you're using,",
      "offset": 1761.24,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "changes to kind of fit you.",
      "offset": 1762.59,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "That's like a cool potential path forward",
      "offset": 1764.06,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "where I don't know if everyone",
      "offset": 1766.07,
      "duration": 1.95
    },
    {
      "lang": "en",
      "text": "in the world is going to want",
      "offset": 1768.02,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "to like, I don't know if the\ntotal size of like people",
      "offset": 1770,
      "duration": 3.27
    },
    {
      "lang": "en",
      "text": "who want to kind of\nbuild their own software",
      "offset": 1773.27,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "is like that large.\n- Right.",
      "offset": 1774.59,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "- But I think the people",
      "offset": 1775.423,
      "duration": 1.237
    },
    {
      "lang": "en",
      "text": "who could benefit from software",
      "offset": 1776.66,
      "duration": 1.26
    },
    {
      "lang": "en",
      "text": "that kind of fits their needs",
      "offset": 1777.92,
      "duration": 2.19
    },
    {
      "lang": "en",
      "text": "is potentially the entire world.",
      "offset": 1780.11,
      "duration": 1.83
    },
    {
      "lang": "en",
      "text": "- All right, maybe one last thing to just",
      "offset": 1781.94,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "kind of close this off here.",
      "offset": 1783.56,
      "duration": 2.19
    },
    {
      "lang": "en",
      "text": "For all the people watching this,",
      "offset": 1785.75,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "if you're a talented engineer out there,",
      "offset": 1787.31,
      "duration": 2.79
    },
    {
      "lang": "en",
      "text": "and you're thinking about\nmaking your next move",
      "offset": 1790.1,
      "duration": 2.31
    },
    {
      "lang": "en",
      "text": "or you wanna get more\ninvolved in the industry",
      "offset": 1792.41,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "and you're trying to\ndecide between maybe going",
      "offset": 1794.3,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "to a larger company or joining more",
      "offset": 1796.07,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "of a faster pace startup\nlike a Cursor or Anthropic,",
      "offset": 1797.6,
      "duration": 3.21
    },
    {
      "lang": "en",
      "text": "what would you tell\nsomeone in those shoes?",
      "offset": 1800.81,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "- Yeah, I think startups have",
      "offset": 1802.82,
      "duration": 1.08
    },
    {
      "lang": "en",
      "text": "an advantage these days like",
      "offset": 1803.9,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "with Anthropic and with Cursor",
      "offset": 1805.67,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "and getting like really\nexcellent talent in a way",
      "offset": 1807.14,
      "duration": 1.95
    },
    {
      "lang": "en",
      "text": "that like when you're at a bigger company,",
      "offset": 1809.09,
      "duration": 1.26
    },
    {
      "lang": "en",
      "text": "a lot of people, you know,\na lot of the best people",
      "offset": 1810.35,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "in the world find that\nless exciting, right?",
      "offset": 1812.24,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "And some people do,",
      "offset": 1814.22,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "and certainly like large companies have",
      "offset": 1815.053,
      "duration": 1.687
    },
    {
      "lang": "en",
      "text": "great people, but the density of",
      "offset": 1816.74,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "that talent tends to be much lower.",
      "offset": 1818.24,
      "duration": 2.04
    },
    {
      "lang": "en",
      "text": "And I get a startup,",
      "offset": 1820.28,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "you can get this really high talent",
      "offset": 1821.113,
      "duration": 1.747
    },
    {
      "lang": "en",
      "text": "density and that makes it\nreally enjoyable to work",
      "offset": 1822.86,
      "duration": 2.1
    },
    {
      "lang": "en",
      "text": "with a bunch of other\nexcellent colleagues.",
      "offset": 1824.96,
      "duration": 1.38
    },
    {
      "lang": "en",
      "text": "You can work on really\nimpactful things in this",
      "offset": 1826.34,
      "duration": 1.74
    },
    {
      "lang": "en",
      "text": "incredibly small team, right?",
      "offset": 1828.08,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "Building a product that kind of,",
      "offset": 1829.64,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "and building models that change the way",
      "offset": 1831.11,
      "duration": 2.37
    },
    {
      "lang": "en",
      "text": "that the world writes software.",
      "offset": 1833.48,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "And you can be a one of like,",
      "offset": 1835.7,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "you know, tens, hundreds,",
      "offset": 1837.38,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "or thousands of people working on",
      "offset": 1838.88,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "that and that's really cool.",
      "offset": 1840.23,
      "duration": 2.196
    },
    {
      "lang": "en",
      "text": "- Yeah.",
      "offset": 1842.426,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "That's great.",
      "offset": 1843.259,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "Well thank you guys.",
      "offset": 1844.092,
      "duration": 0.833
    },
    {
      "lang": "en",
      "text": "This has been awesome conversation.",
      "offset": 1844.925,
      "duration": 1.515
    },
    {
      "lang": "en",
      "text": "- Thank you.\n- Thank you.",
      "offset": 1846.44,
      "duration": 0.833
    }
  ],
  "cleanText": "- I think like every facet of producing software, I think will be kind of changed to use AI in some way.\n- Very excited to have you guys out today. Looking forward to this conversation for a while. As you know, I'm Alex. I lead our Claude Relations here at Anthropic.\n- I'm Lukas, I work on agentic systems at Cursor.\n- I'm Aman. I'm one of the founders and I work on ML and retrieval at Cursor.\n- My name's Jacob Jackson, I work on ML at Cursor.\n- I'm very, very excited for this conversation and to talk a little bit about Cursor, what you guys are building and also how you're using Claude. It's been a big year for Cursor, pretty obvious to anyone that's been following along the AI industry. You guys have scaled now to over $300 million revenue in just over a year. Pretty crazy. Millions of developers are now using Cursor. What's changed in your opinion and how is today in the version of Cursor today different than it was a year ago?\n- Yeah, I think there a few big things that have changed. I mean there's always been this massive overhang in, given the current level of the language models, how much you can do with them and I think Cursor was probably one of the first companies at least in coding to be able to close that gap a bit with a number of different features. And then in turn, you've also seen these models get much, much better at coding and I think 3.5 Sonnet was like the first clear example of this or this kind of step function better in programming. And so before then, Cursor is really useful at things like tab completion, right, predicting your next edit. And that alone was, you know, growing fairly quickly and then editing within single files. But we did see that when you kind of mix the intelligence of a model like 3.5 Sonnet with a few other kind of custom models we use for retrieval and then applying the edits made by this larger model, you now have the ability to do kind of multi file edits. I think that was kind of the step function that resulted in mass adoption of Cursor and since then it's been a mix of the models getting better than us trying to under the hood get better and better with like how far we can push these models.\n- And was that a natural progression, something that kind of just arose or did you guys notice when 3.5 Sonnet, that first one came out, that, holy cow, now we can all of a sudden do all these different things that weren't possible before? What did that kind of look like?\n- It did feel somewhat gradual. Like there are these steps in model quality, but you saw hints of it with you know, the prior state of the art model. In fact, we've been notoriously bad at taste testing these models just because you know, the way we use them is very different than when you put it out into the world to see how others use it. But there are just hints of over time each kind of new model that came out was better and better at being able to reason, do more agentic types of coding and then it's a lot of tinkering and trying lots of things, seeing what works, seeing what fails. Yeah, I think Sonnet was probably the first one where we were able to make the multi-file kinda interaction really work well. And since then there's been a number of step functions including like tool use, right? And then you can actually have these models act like real agents within the editor.\n- Hmm, I see. So the progression of the new models, new capabilities over time kind of allows for further tinkering, exploring, which then rolls back into your product in some degree and allows you to build new features.\n- Yeah.\n- That's interesting and kind of parlays into this next question I want to hit at which is I've heard many stories of how your team is using Cursor to build Cursor, it's in this like self-improving recursive feedback loop. First off, maybe you can dive into a little bit of how that looks and on a day-to-day, what does that look like within Cursors you guys are working on building new features?\n- Yeah, I think it very much depends on the individual like yeah use cases for each employee and I think it also very much depends on what part of the product you might be working on and what kind of stage that part is in. So I think for like initially laying out some code base, some new feature, it's very, very useful to just like use the Agent feature to kind of get that started and then to maybe use the thinking models to like look at individual box that you might be facing and then for making like very precise edits, I think that's, it's a lot of tap also and then when initially getting started with a code base that one might not be too knowledgeable about that using kind of the QA features a lot using a lot of search and I think that's also something that Claude 3.7 and 3.5 also has been excelling at doing research in a code base and figuring out how certain things interact with each other.\n- I see, so using these features to explore your code bases makes the process easier then you learn as you're using these features that oh there's a deficiency in this area, we should go work on that.\n- Yeah, easier I think Cursor's it's very much driven by kind of solving our own problems and kind of figuring out where we struggle solving problems and making Cursor better and then yeah, figuring out what we can do there and then experimenting a lot. We very much have this philosophy of like everybody can just try things and try adding new features to the product and then see internally how they are used and what kind of feedback they gather.\n- Do you think there on maybe of a more meta level there's an advantage to being your own best customer internally?\n- I think 100%. I think that's how we're able to move really quickly in building new features and then throwing away things that clearly don't work because we can be really honest to ourselves of whether we find it useful and then not have to ship it out to users, kind of track how people use it before deciding to go ahead with a feature and I think it just speeds up the iteration loop for for building features. Yeah, going back to overall how we use AI to program, it feels like, I mean there's a lot of diversity within the company and how different people use it. I think it differs first in like the kind of work you're doing. So, you know, there are a number of people that will for example, be working in pieces of the code base they're really familiar with, right? And at that point when you have it all in your head, it's often faster for you to kind of convey intent just by kind of typing code and then for that Tab is really useful 'cause kind of speeds you up there. But then when you're in places where you're less familiar or you need to write out a lot of code, you can kind offload a lot of that and often some of the reasoning to these models and then, you know, as you got to places where you're really unfamiliar with Lukas is describing and you're kind of coming into a new code base, it's just there's this massive step function that you get from using these models and what we kind of see is over time as the models get better is and as Cursor gets better using these models you do a better and better job of when you're more in flowing when you have more knowledge of the code base.\n- So there's a variation in when a feature is most applicable to like your use case and it kinda is like almost a spectrum to some degree.\n- Yeah like the spectrum on one end is Tab for when you're completely in control and you know what you're doing then it goes to Command K where you're editing a single given region, maybe a whole file and then at the other end you have Agent which is quite good for, you know, editing multiple files and then at the very end you get kind of have this background agent which we've been working on and that can be useful for basically doing entire prs.\n- You guys just released a preview of background agent. What is background agent?\n- I think it's clear that the models are getting better and better at doing end-to-end tasks but they're not quite at 100% and I think it'll take a while to get to 100%. So the way you speed up developers, right, is you let them do these things in parallel but as opposed to kind of letting it just go in the background then spin up a PR that you look at in GitHub if it's only 90% of the way there you want to go in and then take control and do the rest of it and then you want to use you know, the features of Cursor in order to do that. So really being able to quickly move between the background and the foreground is really important and I think like, you know, we're in the early innings of this feature and I can imagine that there are lots of interesting ways of being able to operate for example on three or four changes at the same time and then quickly kind of popping them to the background and then moving them into the foreground. It'll be interesting to see how this changes how people use Cursor and just like develop the software in general.\n- I mean we see background agents basically as a new primitive that we can use in like so many different places and the current way of exposing it is quite straightforward where you can just get a prompt and push it to the background and then it independently iterates on that. But there can be like many more integrations how these things can be spawned off and I think there's a lot of product that you want can make from that.\n- So is this taking your code base and putting it in a virtual machine or what exactly is that transfer that's happening?\n- Exactly, yeah.\n- Okay.\n- We have small enough independent environments that have all the developer environment utilities already installed and then the agent can use those and it has all the VS code extensions that are available and through that it can get et cetera.\n- I know we're kind of witnessing this trend of asynchronous tasks, background tasks across many different things from coding to like research, in your view, what does that look like as this progresses to where we might have thousands of these agents potentially going off and you could see like whole teams of agents attacking a problem all in the background. What does that future look like?\n- I think the next bottleneck you'll run into is verification of software, verification of code, models getting really, really good at generating writing lots of code but let's say developers spend, I'll throwout some random-ish numbers, but 30% of their time writing code or 30% of their time reviewing code, 70% of their time writing code. If you completely solve writing code you still haven't really sped up software engineering by more than a factor of three. Yeah, so I think we're going to need to figure out how to make it easier for people to review code and how to be confident that the agent's making the changes that are not just correct, 'cause correct can be vague, right? It may just be in the thing you specified, it was under specified enough that it actually did like the best that was possible for even you know, the best human programmers to do but what it actually what you had in your mind's eye and so making the process for you much, much better I think will be really, really important. And it's something that we're really interested in as well.\n- Any early ideas there on what that looks like?\n- I think there are a few floating around from various people at the company. One that Michael, our CEO who really, really likes is the idea of operating in a different representation of the code base. So maybe it looks like pseudo code and if you can represent changes in this really concise way and you have guarantees that it maps cleanly onto the actual changes made in the real software, that should shorten the time of verification a ton. But that's one possible route. I think, so like the reason why quote unquote vibe coding works often is because the process of verification is like really easy since all it is just kind of playing with the software, right? You make a change and you actually play with whatever software you've built. I think it's just gonna be really hard to do for real production code bases and cracking that problem is really important.\n- That's a good question around the difference between like a standalone thing they might be vibe coding versus a production code base that has millions and millions of lines of files. How do you guys see the difference between those two in your mind and where are we at in terms of like working within them with current models?\n- I think that's something we've thought about a lot with background agent because something that's really simple and obviously should be very easy with these models is I have this test here, the test is currently failing, can you fix the code so that it passes and it's like okay how do we make that happen? Well the model needs to be able to run the test and if you have a very simple repository, that's very simple, but when you start getting to these larger enterprise code bases, it can be complex to get the dependencies set up properly so that the model can run the tests. But this is something we've thought about with background agent a lot is how do you make this process straightforward for the developer to create this environment where the agent can run the test and then make it repeatable so you can snapshot it and you can quickly update it when your code state changes and this unlocks the ability to, you know, spin off a VM in the background, have the model make experiments, you know, and some of them will make it pass and some of them won't. And then eventually you as the developer only have to worry about the case where it succeeded and there's just a lot of infrastructure there and a lot of user experience that is important to get right.\n- Mm hmm, mm hmm.\n- Yeah. And then I think there are other fundamental problems. So one way is you get the model to try to pass the test, right? That's how you can kind of guarantee maybe, some sort of correctness. But with these large code bases, you're often dealing with things that almost look like their own language where they have these kind of DSLs within some languages and everything is done in this particular way and it's really sprawled out across millions of files, which is hundreds of millions of tokens potentially maybe more. We've done a number of things to make this much better, which include training retrieval models and then integrating other sources of context as well. For example, you can imagine there's a lot of richness in the recent changes that you've made, when editing your code it kind of indicates what you're working towards. There could be richness in the changes that other people on your team have made in your code base, especially recently and using those as hints\n\n\nBut I do think it's still this really hard fundamental problem of, you know, just giving the model access to really good retrieval feels insufficient for having the model really understand the code base.\nI think it's a problem we're really interested in solving.\n- Mm hmm.\nProbably through some combination of like memory plus long context and.\n- Yeah.\n- Other things.\n- I think memory is one interesting approach people have taken to get the model to kind of learn from your usage of it, but it also feels like, you know, it's a small boost in performance and it feels fairly primitive relative to like where we need to be in order to get things that are excellent at large code bases.\n- Yeah, and large code bases, it's not only just about getting the test to pass, but it also is about doing it the right way.\nLike looking at the existing code and making that match the new code and bringing it into the correct structure and kind of using all the guidelines correctly, and like we've been trying very hard to kind of make that happen through Cursor rules, through integrating different types of context, et cetera.\n- Hmm.\n- Yeah, like I could write a deep bounce function from scratch and just use that, and that would make the test pass, but that's not the right way to do it.\nYou should use one of the DeBounces, and maybe there's three or four DeBounce functions used across the code base.\nHow do you know what the right one is to use?\nMaybe the only reason someone knows is because they message someone on Slack that this is how you do it.\nAnd so I think, yeah, it gets really, really hard to solve these problems with extremely large code bases.\n- That's interesting.\nSo there's also kind of an element to the org knowledge that lives outside of the code base itself, and that like plays a major factor sometimes in some of these decisions, especially as you're operating on-\n- Yeah.\n- Large code bases.\n- I don't think that's the bottleneck today, but I think if you solve, like if you made models like perfect and kind of knowing the code base,\n- Yeah.\n- I think you'll immediately, like you'll maybe get like a 5x, maybe 10x improvement, but you can't get farther than that because now it's completely bottlenecked by, how much does it know these things that are never ever explicitly mentioned or shown in like the PRs and the actual state of the code.\n- Mm hmm.\n- And then there also just outside concerns from the business side, from sales, et cetera.\nAnd those kind of have to be brought into Cursor to make that work.\n- Right.\nSo some future version of Cursor then has to plug into many more systems-\n- Yeah.\n- And things.\n- To be clear, I think like, you know, that's like still some ways a way for that to be like really, really critical relative to the other things.\nI think we have a long ways to go still on just using the interactions users have, like details of their code base and commits made in order to make Cursor much better.\n- One interesting thing I've started to notice at least with like webpages and content, is people trying to now think about how to optimize the page for an LLM reading and browsing it.\nDo you think we're gonna see something similar maybe with code and in that code could transform how it usually is written and what it looks like if you're writing for primarily human reviewers and humans working within a code base to models?\n- I think that's totally the case already.\nI mean API design is already adjusting such that LLMs are more comfortable with that.\nFor example, changing not only the version number internal, but making it like very visible to the model that this is a new version of some software just to make sure that the API is used correctly.\nAnd I think that the same also holds for like normal code bases and internal libraries as well, where like structuring the code in a way where one doesn't have to go through like end level of interactions, but maybe just through two levels of interaction makes, yeah, LLM models better at working with that code base.\n- Right.\n- But I think ultimately the principles of clean software are not that different when you want it to be read by people and by models.\nYou know, when you are trying to write clean code, you want to, you know, not repeat yourself, not make things more complicated than they need to be.\nAnd that is just as important for models as it is for people.\nAnd I think taste in code and what's a clean solution that's not more complicated than it needs to be is actually gonna become even more important as these models get better because it will be easier to write more and more code, and so it'll be more and more important to structure it in a tasteful way.\n- That's a really good point on taste.\nTaste is kind of this thing that I feel like maybe some people are born with more taste than others, but generally you kind of develop taste through experience and learning what works and seeing failures and seeing successes.\nIn a world where we're having AI write more and more of our code, there's been real pushback against some that say, oh, you're gonna make programmers lazy or you're not gonna give juniors a chance to learn what it actually looks like to work within a large code base and do all these things.\nHow do you think about balancing this sort of automation or assistance in this case with also preserving the core engineering skills that maybe a software engineer has to go through, those like trials and tribulations?\n- I think these tools are very good educationally as well, and they can help you become a great programmer.\nYou know, if you have a question about how something works, if you want some concept explained to you, now you can just, you know, press command L and ask Claude, you know, what is this?\nHow does it work?\nCan you explain it to me?\nAnd I think that's very valuable.\nIt does make it easier to write more code and do more stuff, and that can result in higher and lower quality code being out there.\nThat is true, but I think in general it's a very, very powerful tool that will raise the bar.\n- I think quality comes very much from iterating quickly, making mistakes, figuring out why certain things fail.\nAnd I think models vastly accelerate this iteration process and can actually through that make you learn more quickly what works and what doesn't.\nSo I think in the long term, it's a super helpful tool for developers just getting started and working on bigger and bigger projects and figuring out what works and what doesn't.\n- Yeah, I think it'll be really interesting to see how programming evolves.\nI think you'll still for a very long time need to have the engineers that know the details, right, can go into the weeds.\nI wonder how much you'll start to see people that are now learning programming who don't know many of the details but can still be fairly effective.\nI think today you still do need to know a lot of the details.\nI think over time you might have a class of software engineers that need to know very few of like the low level details and it still operate at a higher level, and maybe it looks a lot more like kind of thinking through like the taste is like more in kind of UX taste, right?\nLike let's say you're trying to build something like a notion, right?\nAt the end of the day, I don't think you can offload that entire thing to the language model.\nYou need to kind of describe like, okay, when I do this type of interaction, then I expect it to pop up in this particular way, right?\nMaybe you don't have to get to the details of writing pure software that does that, but still describing those interactions, describing the way this thing roughly works.\nThat is a form of programming.\n- Switching gears a little bit on the topic of models, so we just recently, by the time this video comes out, Claude 4 and Claude Sonnet 4 will be out into the world.\nLove to hear your guys' thoughts on the new models and how you're starting to think about integrating them within Cursor.\n- I mean, we've really enjoyed the new models.\nI think we were pretty shocked trying out the new Sonnet because I think 3.7 is a fantastic model.\nIt was better at agentic coding, but everyone knew it kind of had these deficits, right, where it would maybe be a little bit too overeager-\n- Like to do a lot.\n- Yeah, it did.\nWould like to change the test sometimes, that they passed.\n- Yeah, yeah.\n- We found that Sonnet 4 has effectively fixed all those, it is much better, and then the intelligence has also been a big step up where, you know, you've seen other models that are kind of steps up in intelligence, maybe not as like strong as agentic coding, but like, you know, O3 is an example, and we found it goes toe-to-toe with that despite being, you know, a much cheaper model.\nAnd so we're extremely excited for Opus because we think it'll be a fantastic agent to use in the background.\n- Yeah, that's awesome to hear the test writing and overeagerness things are things that we were trying to tackle pretty intensely with these models and concept of like reward hacking in which the models will find some way to basically take a shortcut to get to the final reward in RL.\nSo we've done a lot of work to cut that down.\nI think we cut it down to like 80% in these new models.\n- I'm really curious to hear how did 3.5 Sonnet come about, 'cause that felt like the first kind of punch of like this is like a really good coding model for Anthropic.\n- How did it come about?\nWe trained it.\nJust, it was good.\nYeah, I think we have always known for a while that, I mean probably since the genesis of the company, that we've wanted to make models really good at coding, it just seems important for everything else that you do, especially as you make more models.\n3.5 Sonnet was, I wouldn't, I mean I think 3-Opus was a really good coding model as well, especially for its time.\nBut 3.5 Sonnet was the first time that we really put a strong dedicated effort to, hey, let's get these models good at coding, but not just specifically coding, this sort of longer horizon coding where it's having to do these things like you're mentioning earlier in the conversation around making edits on different files, going off and like taking a command here, calling a tool and then going and making a change somewhere else.\nThat was the first model in which we could kind of put all these things together, and I think it just turned out really well and kind of set the stage for what our future models would be.\n- And how do you guys think about code versus other areas where you want Sonnet to excel?\n- Yeah.\n- And Opus to excel.\n- I mean code is one of the primary areas, but I think it's not the only area.\nI think there is a good amount of transfer that you see from models getting really good at code to them just getting better at reasoning over taking many actions and working in this sort of agentic way.\nAnd that carryover is pretty nice as you're dealing with applications that might mix in code but also have to go retrieve knowledge from other places or do research.\nGenerally we're about just pushing the frontier as much as we can with our models.\nOf course there is like considerations that we make around safety and making sure that the models are in line with what you as a user want and also what we believe the model should be doing.\nBut generally we want to keep pushing the limits of what these models can do and kind of show developers in the world this is what models are capable of.\nSo things like computer use, when we unveiled that back in October, that was like another direction in which we're really pushing forward in terms of how can a model be good at actually navigating something that is a primarily a human interface, right?\nSo it's not in the world of like APIs or tool calls or anything like that.\nIt's literally just looking at an image as a human would and then having to direct an action onto that screen.\nThere's also a strong part to how we think about these models character, as it's known now, Amanda Askell is one of our lead researchers on this effort, kind of crafting Claude's character, and we put a lot of thought and consideration into what Claude should feel like and sound like and what does it mean for an AI to play a really prominent role in somebody's life.\nNot as just a coding agent, but as kind of like their confidant in a sense and an entity that you're gonna be spending a lot of time talking to.\nSo that's also really factored into all the decisions we make around these models and how we train 'em.\n- How does Anthropic as a whole think about where things are going both in terms of software engineering and then in terms of like research, like in terms of how much like these models will augment, replace, do a lot of this work?\n- Yeah, it can speak personally here.\nSo personally I think that we're not gonna be replacing, as we've been talked about earlier, there's just like so much more you can do now that you have like models that can do all this, you know, nuts and bolts like typing of the code basically for you.\nI see this with myself too.\nLike I studied computer science in college and did software engineering, and now I feel like I'm at the point where the models are like better at producing code than I am, like if I were to just like think about doing like a lead code problem or anything like that, where it's like a contained environment and the model has to write code, it's gonna like beat me, and yet I feel like I can do more than ever.\nI can make prototypes of anything.\nI can like spin up demos super, super fast if I wanna like show off a new concept.\nIt's felt very empowering in that sense than like taking away or dismissive of what I've been doing.\nAnd it is similar to where I feel like just because I have that knowledge of software engineering from the past, I can actually exploit it much better, and I can use the model, I can push it farther than if I just still didn't have any idea about what code is.\nMaybe on that getting more into like the sort of fun future speculation, I want to ask like maybe a practical question in a few years we can come back to this one and see how we turned out.\nJanuary 1st, 2027, so what is that a little less than two years from now?\nWhat percentage of code do you think will be AI generated, and following that, what does the day in the life of somebody that's considering themselves a developer now look like?\n- I think it's similar to going back to, let's say before I was born, but you know, 1995 and asking a lawyer in the future what percentage of legal documents will be word\n\n\nProcessor generated, and the answer is 100%, or, you know, close to 100%, in that AI will be involved in almost all of the code that gets written. But still, your role as a lawyer or as a developer in understanding what the code needs to do and having taste and guiding what is done with the software is going to be more important than ever.\n- I mean, already at Cursor, it's probably 90% plus, but that's because a large fraction of it is using more higher-level features like Agent.\n- Yeah.\n- And Command K and whatnot. But then a lot of it is you're typing, and then Tab will, as you type, do 70% of that.\n- Right.\n- So in the cases where you're actually going in and doing it manually yourself, Tab is still doing most of those changes.\n- Right, so the actual letters typed is like a very, very low percent.\n- Yeah. But I think like every facet of producing software, I think will be kind of changed to use AI in some way.\n- Do you think we ever get to a world in which you basically have software on demand? What does that look like?\n- I think you're going to see people building software, people in organizational functions, building software who are not previously building software. You know, like people in sales who would not have built their own tools before will now be building, for example, dashboards to track what's important to them. And going back to how taste becomes more important than ever, you know, now you can build the dashboard, but you still need to decide what metrics the dashboard is gonna show. It doesn't prevent you from having to decide that. I think you're going to see many more people building their own software, but it will be bottlenecked on having a unique thing that you want to do with the software that isn't properly served by existing needs.\n- One example I like to tell people is we've a guy, our comms team, who's actually been like shipping bug fixes to Claude.ai, which is just like absolutely insane. Like he's in a completely different part of the org, he's not touching product at all, and yet he pops in with like a PR, and he's like asking for a stamp, and you're like, what are you doing? And it's like, yeah, he's using, you know, Claude code or some coding tool with Claude has the base model there to like fix bugs in a production code base. I think that's amazing as well. And it ties back into this like general, hey, if you have taste, if you have good intuitions, like you're just gonna be able to do a lot. That's kind of how I see the world keeping progressing. I think things will change and like roles will look much different in five years, 10 years, but generally like I'm very much in favor of like, if you can do more with these things, like that's generally always gonna be a good thing.\n- Yeah, I feel like there are a lot of interesting paths that this could take. One is just completely on the fly on demand software where I am using my own version some app, and just like as I use it, you know, this interaction I don't really like, and it just changes for me. That's one kind of crazy future you could imagine where it's not even you kind of actively doing it, but just based on your interactions with it, the software, whatever you're using, changes to kind of fit you. That's like a cool potential path forward where I don't know if everyone in the world is going to want to like, I don't know if the total size of like people who want to kind of build their own software is like that large.\n- Right.\n- But I think the people who could benefit from software that kind of fits their needs is potentially the entire world.\n- All right, maybe one last thing to just kind of close this off here. For all the people watching this, if you're a talented engineer out there, and you're thinking about making your next move or you wanna get more involved in the industry and you're trying to decide between maybe going to a larger company or joining more of a faster pace startup like a Cursor or Anthropic, what would you tell someone in those shoes?\n- Yeah, I think startups have an advantage these days like with Anthropic and with Cursor and getting like really excellent talent in a way that like when you're at a bigger company, a lot of people, you know, a lot of the best people in the world find that less exciting, right? And some people do, and certainly like large companies have great people, but the density of that talent tends to be much lower. And I get a startup, you can get this really high talent density, and that makes it really enjoyable to work with a bunch of other excellent colleagues. You can work on really impactful things in this incredibly small team, right? Building a product that kind of, and building models that change the way that the world writes software. And you can be a one of like, you know, tens, hundreds, or thousands of people working on that, and that's really cool.\n- Yeah. That's great. Well, thank you guys. This has been awesome conversation.\n- Thank you.\n- Thank you.\n",
  "dumpedAt": "2025-07-21T18:43:25.550Z"
}