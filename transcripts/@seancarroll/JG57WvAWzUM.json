{
  "episodeId": "JG57WvAWzUM",
  "channelSlug": "@seancarroll",
  "title": "Mindscape 315 | Branden Fitelson on the Logic and Use of Probability",
  "publishedAt": "2025-05-19T12:24:38.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Hello everyone and welcome to the",
      "offset": 0.24,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "Mindscape podcast. I'm your host Sean",
      "offset": 1.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Carroll. One of the things that I always",
      "offset": 3.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "like to say about science and how it",
      "offset": 5.12,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "gets done is that science never proves",
      "offset": 7.279,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "things. This is something that is an",
      "offset": 10.519,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "important feature of science especially",
      "offset": 13.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "in the modern world where what science",
      "offset": 15.759,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "does, how it reaches conclusions, how",
      "offset": 18.16,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "trustworthy it is, these are all under",
      "offset": 20.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "contestation by different parts of",
      "offset": 23.24,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "society. So, it's important to",
      "offset": 25.76,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "understand what science is and how it",
      "offset": 27.039,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "actually reaches its conclusions. And",
      "offset": 28.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the claim that science never proves",
      "offset": 31.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "things, which is something that most",
      "offset": 33.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "scientists would go along with me on",
      "offset": 34.88,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "comes from a comparison to real proof in",
      "offset": 37.6,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "mathematics or for that matter in logic.",
      "offset": 41.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "You know, most scientists have taken",
      "offset": 44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "some math classes, at least enough to",
      "offset": 45.52,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "know what it means to prove something in",
      "offset": 48,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "the old-fashioned sense of Uklid and",
      "offset": 50.399,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "geometry or Aristotle and logic, proving",
      "offset": 52.6,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "a conclusion from some well articulated",
      "offset": 56.239,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "premises. Uh, in the philosophical study",
      "offset": 59.399,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "of logic, this is known as deductive",
      "offset": 63.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "reasoning. You have some premises and",
      "offset": 65.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "you reach a conclusion. And science just",
      "offset": 67.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "doesn't go that way, right? Uh, science",
      "offset": 69.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "looks at the world. It looks at all",
      "offset": 72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "sorts of things in the world and it",
      "offset": 73.92,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "tries to figure out what the patterns",
      "offset": 76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "are that the world follows. Always",
      "offset": 78.159,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "knowing that tomorrow you might do a new",
      "offset": 80.96,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "experiment that will overturn your best",
      "offset": 83.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "guess as to what the pattern was. Or",
      "offset": 85.439,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "maybe someone will do something as",
      "offset": 87.28,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "simple as just thinking of a better",
      "offset": 88.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "pattern, right? A theoretical physicist",
      "offset": 90.24,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "coming up with a better idea for what",
      "offset": 92.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the laws of physics really are. So if",
      "offset": 93.759,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "science doesn't prove things, if it just",
      "offset": 96.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "sort of comes closer and closer in some",
      "offset": 98.96,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "sense to getting it right, then what is",
      "offset": 102.24,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "what's going on? Uh you know, one very",
      "offset": 105.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "common idea about what's going on is",
      "offset": 107.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "inductive logic rather than deductive",
      "offset": 110.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "logic. And inductive logic, we begin to",
      "offset": 112.96,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "see a pattern. You know, A B CDE E FG.",
      "offset": 115.52,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "The next one is probably going to be H,",
      "offset": 118.479,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "right? uh because we think that probably",
      "offset": 120.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "you're just mentioning the alphabet in",
      "offset": 122.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "alphabetical order. But there's all",
      "offset": 124.64,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "sorts of paradoxes that come up when you",
      "offset": 127.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "do inductive logic. Like how do you know",
      "offset": 128.959,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "that it's not ABCDE E F? That's a that's",
      "offset": 131.36,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "a sequence of letters that that you",
      "offset": 134.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "could have. My old math teacher in",
      "offset": 136.239,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "college used to hate those SAT questions",
      "offset": 137.84,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "or standardized test questions that",
      "offset": 141.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "would give you a series of numbers and",
      "offset": 143.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "ask you to guess the next one because he",
      "offset": 144.959,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "said, I can I can make any number I",
      "offset": 146.64,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "want. I can come with a formula that",
      "offset": 148.08,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "would give you any number I want after",
      "offset": 149.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the ones that you already showed me. So",
      "offset": 151.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "philosophers unsurprisingly are very",
      "offset": 154.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "interested in making as rigorous and",
      "offset": 156.4,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "careful as possible this idea of either",
      "offset": 159.36,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "induction or whatever should replace",
      "offset": 162.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "induction as the logic of understanding",
      "offset": 164.319,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "things in science. The names attached",
      "offset": 166.72,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "here go from old school names like David",
      "offset": 169.68,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "Hume and John Stewart Mill to relatively",
      "offset": 173.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "newer ones like Rudolph Carnap, Carl",
      "offset": 175.519,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "Hemple Hemple, um Carl Pauper, for",
      "offset": 178.4,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "example. Uh and it's still an ongoing",
      "offset": 181.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "thing. So this is something that lives",
      "offset": 183.519,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "at the intersection of how we think",
      "offset": 185.04,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "about science, but also how we think",
      "offset": 186.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "about probability, what probability is,",
      "offset": 187.92,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "um how conditional probabilities work,",
      "offset": 191.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "basian logic, all that stuff. And that's",
      "offset": 194.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "what we're going to be talking about",
      "offset": 196.8,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "today. Today's guest is Brandon Fidelson",
      "offset": 198.08,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "who is a philosopher at Northeastern",
      "offset": 200.08,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "University. And it's, you know, it's",
      "offset": 203.239,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "it's eye openening to me as someone who",
      "offset": 205.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "is now part-time in a philosophy",
      "offset": 207.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "department. Just a huge range of stuff",
      "offset": 209.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "that gets characterized as philosophy,",
      "offset": 212.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "right? Like some philosophers are",
      "offset": 215.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "saying, \"What is the good?\" Others are",
      "offset": 216.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "saying, \"What happens when an",
      "offset": 219.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "observation is made in quantum",
      "offset": 221.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "mechanics?\" and others are like doing",
      "offset": 222.4,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "pretty hardcore mathy logic and um well",
      "offset": 225.12,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "there's mathematical logic but there's",
      "offset": 229.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "also just big picture questions about",
      "offset": 230.959,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "logic. How does logic how do probability",
      "offset": 233.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "uh how do these things get used both in",
      "offset": 235.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "a perfectly rational world and also in",
      "offset": 238.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "the slightly irrational world in which",
      "offset": 240.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "we live. We're going to be talking about",
      "offset": 242.319,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "both of those things and I think it's",
      "offset": 244,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "intrinsically interesting to understand",
      "offset": 245.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "probability and logic better but also",
      "offset": 247.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "super important to thinking about how",
      "offset": 250.08,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "science works. So, let's go.",
      "offset": 251.76,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 257.54,
      "duration": 3.979
    },
    {
      "lang": "en",
      "text": "Brendan Vitalson, welcome to the",
      "offset": 270,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "Mindscape podcast. Thank you so much for",
      "offset": 271.199,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "having me, Sean. I'm a big fan. I think",
      "offset": 273.759,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "what you're doing here is super",
      "offset": 276.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "important, especially nowadays. I hope",
      "offset": 277.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you still think those things after we",
      "offset": 279.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "are done talking, but I I hope to make",
      "offset": 281.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "it true. So, we're talking about stuff",
      "offset": 283.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that is dear to my heart. Um, we're",
      "offset": 285.6,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "talking about increasing the probability",
      "offset": 288.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that something is right. We're talking",
      "offset": 291.04,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "about what probability is, how it fits",
      "offset": 292.32,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "in with uh learning about things.",
      "offset": 293.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "Obviously, science cares about this a",
      "offset": 295.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "lot. So, let's start at the very high",
      "offset": 297.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "level and you tell me what probability",
      "offset": 300.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "really is.",
      "offset": 302.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "What probability really is? Well,",
      "offset": 305.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "there's many kinds of probabilities. So,",
      "offset": 307.44,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "there's probabilities in science. So for",
      "offset": 310.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "instance, biology has its own conception",
      "offset": 313.199,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "of probability uh which shows up in the",
      "offset": 316.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "theory of natural selection especially",
      "offset": 319.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "and genetics. Um physics of course as",
      "offset": 320.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "you know better than I has uh lots to",
      "offset": 323.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "say about probability both in classical",
      "offset": 325.919,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "and quantum physics.",
      "offset": 328.4,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "Um yeah so and in economics uh we also",
      "offset": 330.919,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "use probability and in in many other",
      "offset": 334.8,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "special",
      "offset": 336.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "sciences. My interest in probability I",
      "offset": 338.039,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "started out as a physicist. So I started",
      "offset": 340.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "out in interested in probability and",
      "offset": 342.4,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "physics. That's how I got into it. But",
      "offset": 344.24,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "over the years I became more and more",
      "offset": 346.479,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "interested in the role probability plays",
      "offset": 348.639,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "in thinking about evidence and how",
      "offset": 350.639,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "strong arguments are. That is how strong",
      "offset": 354.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "something is as a reason for believing",
      "offset": 356.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "something else. And uh that's kind of",
      "offset": 358.4,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "the application of probability that I'm",
      "offset": 361.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "most interested in nowadays. And in that",
      "offset": 363.759,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "context, there's still many kinds of",
      "offset": 366.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "probabilities because when you're",
      "offset": 367.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "assessing the strength of an argument,",
      "offset": 369.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "it really depends on the context. So if",
      "offset": 371.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you're playing a game of chance, say,",
      "offset": 374.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and you're, you know, like poker, and a",
      "offset": 376.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "certain card comes up, and you're",
      "offset": 379.28,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "wondering, well, what effect does that",
      "offset": 380.56,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "have on my probability of winning this",
      "offset": 382.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "hand? Well, now you know what",
      "offset": 383.96,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "probabilities to use. They're given by,",
      "offset": 386.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "you know, the probabilities of a game of",
      "offset": 388,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "chance. Each card is equally likely to",
      "offset": 390,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "be drawn. And that allows you then to",
      "offset": 391.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "calculate the probability of any hand",
      "offset": 393.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "given, you know, what's left in the deck",
      "offset": 396,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and so on. And so there it's very clear",
      "offset": 397.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "what probabilities to use to assess the",
      "offset": 399.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "strength of that as a reason for",
      "offset": 402.16,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "believing say that you'll win or lose",
      "offset": 404,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "the hand. In other contexts, it's much",
      "offset": 405.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "more difficult to say which",
      "offset": 408.319,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "probabilities are the appropriate ones.",
      "offset": 410,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "So for instance, if we're wondering",
      "offset": 412.479,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "whether a certain scientific theory is",
      "offset": 414.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "true, in fact, we might even be worried",
      "offset": 416.08,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "about whether a certain scientific",
      "offset": 418.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "theory of probability is true.",
      "offset": 419.599,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "And you might have two competing",
      "offset": 422.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "theories of what probability in a",
      "offset": 423.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "certain scientific context is like.",
      "offset": 425.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Well, there how are you going to",
      "offset": 428.4,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "adjudicate how strong the arguments are?",
      "offset": 430.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Well, you can't. It would be question",
      "offset": 432.479,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "begging to assume a notion of",
      "offset": 434.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "probability that say one of the theories",
      "offset": 436.08,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "adopts but the other rejects. That would",
      "offset": 437.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "just be question begging. So what you",
      "offset": 440.319,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "need is some more general notion of",
      "offset": 441.919,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "probability uh that will allow you to",
      "offset": 444.28,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "evaluate arguments even in those",
      "offset": 446.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "contexts. And as a philosopher, I want",
      "offset": 448.16,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "to go even more broad than that. I want",
      "offset": 450.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to be able to assess arguments for the",
      "offset": 451.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "existence of God maybe or for ethical",
      "offset": 454.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "claims and so on. And as you get more",
      "offset": 456.96,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "and more abstract and these contexts get",
      "offset": 459.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "further and further away, say from games",
      "offset": 461.199,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "of chance, which is kind of the easiest",
      "offset": 463.28,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "case, it gets more and more",
      "offset": 465.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "controversial. What kinds of",
      "offset": 467.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "probabilities are the relevant ones?",
      "offset": 469,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "But, you know, I think of this like any",
      "offset": 471.199,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "other science, Sean. I think probability",
      "offset": 472.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "theory, it's a theory. And then uh what",
      "offset": 475.84,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "you do when you're faced with a certain",
      "offset": 478.319,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "situation is you have to construct",
      "offset": 479.759,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "models of the theory. And okay, that's a",
      "offset": 481.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "very complicated process which involves",
      "offset": 483.44,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "making all kinds of assumptions and",
      "offset": 486,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "idealizations. Um and that's okay. Uh",
      "offset": 488.28,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "and the goal there is to try to come up",
      "offset": 491.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "with the best account of which",
      "offset": 493.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "probabilities we should use. Uh so that",
      "offset": 496.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "we're adjudicating this question of how",
      "offset": 498.72,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "strong the arguments are in a way that's",
      "offset": 500.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "not that's fair and reasonable. And uh",
      "offset": 502.479,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "that's really a case-byase thing I",
      "offset": 506.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "think. So I was just a couple weeks ago",
      "offset": 508,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "at the uh retirement celebration",
      "offset": 510.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "conference for Barry Ler, former",
      "offset": 512.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Mindscape guest, and there was a talk by",
      "offset": 514.64,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "David Albert, former Mindscape guest.",
      "offset": 517.68,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "And uh in in part in response to things",
      "offset": 520.159,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "that I and others have been saying about",
      "offset": 523.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "quantum mechanics and self-locating",
      "offset": 526,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "probabilities, and David, you know, he",
      "offset": 528.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "was just unapologetically old school",
      "offset": 530.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "about it. He says the only sensible use",
      "offset": 533.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "of probability is when you have a",
      "offset": 535.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "frequency of something happening over",
      "offset": 536.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "and over again and you can sort of",
      "offset": 538.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "imagine taking a limit of it happening",
      "offset": 540.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "infinite number of times that and the",
      "offset": 542.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "ratio of the number of times where it",
      "offset": 543.68,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "looks like x rather than y that's the",
      "offset": 545.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "probability and you know I tried to say",
      "offset": 547.399,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "but okay come on we we certainly use",
      "offset": 549.6,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "probability in a much broader sense than",
      "offset": 552.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "that we talk about the probability of a",
      "offset": 555.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "sports team winning a thing even though",
      "offset": 557.2,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "we're not going to do it infinite number",
      "offset": 558.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "of times or even twice. Um, so I is",
      "offset": 559.76,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "there a consensus about this very basic",
      "offset": 563.12,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "question about the relationship between",
      "offset": 566.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "frequencies and probabilities versus",
      "offset": 568.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "just a more epistemic like this is my",
      "offset": 570.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "best guess kind of thing,",
      "offset": 572.959,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "right? Okay, good. Yeah. So there's lots",
      "offset": 575.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "of, you know, what used to be called",
      "offset": 577.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "interpretations of probability, but I",
      "offset": 579.12,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "would just call them theories of",
      "offset": 580.88,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "probability. There, as I say, there are",
      "offset": 581.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "many. The frequency theory, well, it's a",
      "offset": 583.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "very strange theory actually. I mean it",
      "offset": 586.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "started off um as an actual finite",
      "offset": 588.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "frequency theory where you know the",
      "offset": 590.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "probability of some event is actually",
      "offset": 593.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "just given by the actual frequency of",
      "offset": 596,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "some event in some population. So for",
      "offset": 598.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "instance suppose you have a coin and",
      "offset": 600.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it's been tossed exactly five times",
      "offset": 602.399,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "three heads and two tails and then it's",
      "offset": 605.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "destroyed. Well according to the actual",
      "offset": 607.399,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "frequency theory the probability is uh",
      "offset": 610,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "you know three fifths that it's heads.",
      "offset": 613.36,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "Wow. Um and in fact if there's any odd",
      "offset": 616.56,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "number of tosses actual odd number of to",
      "offset": 619.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "then you can't get an even you can't get",
      "offset": 622.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "one half. So even if you have a fair",
      "offset": 624.079,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "coin if it's tossed an odd number of",
      "offset": 625.839,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "times then according to the actual",
      "offset": 627.519,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "frequency view uh the probability it",
      "offset": 628.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "isn't fair. It can't so so the actual",
      "offset": 630.959,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "frequency view was a non-starter right",
      "offset": 633.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that's not going to work so also you",
      "offset": 635.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "can't get irrational values you can't",
      "offset": 637.12,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "get you know you can only get rational",
      "offset": 638.88,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "values and that seems wrong because",
      "offset": 640.399,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "physics has all kinds of irrational",
      "offset": 641.839,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "value problem. Okay. So then people",
      "offset": 643.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "said, \"Well, okay, maybe what we'll do",
      "offset": 645.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "is we'll talk about hypothetical",
      "offset": 647.92,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "infinite extensions of the actual",
      "offset": 649.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "experiment.\" Okay. Well, what what does",
      "offset": 652.12,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "that mean? Uh they say think they say",
      "offset": 654.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "things like, \"Well, it's what would have",
      "offset": 656.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "happened had you continued indefinitely",
      "offset": 658.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that initial sequence of five tosses.\"",
      "offset": 660.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "And I want to say well here's that's",
      "offset": 663.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "very hard to understand because there's",
      "offset": 665.04,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "uncountably many such extensions and on",
      "offset": 667.36,
      "duration": 7.56
    },
    {
      "lang": "en",
      "text": "almost all of them there's no limiting",
      "offset": 671.68,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "frequency. So it's true that for any",
      "offset": 674.92,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "real number you can get that as the",
      "offset": 678.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "limiting frequency of an infinite",
      "offset": 681.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "sequence but it's also true that almost",
      "offset": 682.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "all of the sequences don't have they",
      "offset": 684.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "diverge in their in their limiting",
      "offset": 687.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "frequency. And sorry, sorry. This is uh",
      "offset": 689.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "this sounds like you're paraphrasing",
      "offset": 691.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "some technical result with the use of",
      "offset": 693.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the idea of almost all. That's a that's",
      "offset": 695.12,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "a technical math term. Yes, that's",
      "offset": 697.44,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "right. I I just mean uh well, it's not",
      "offset": 700.079,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "all. There's like a there's like a",
      "offset": 703.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "relatively small number of sequences",
      "offset": 706.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that will converge. But it's sort of",
      "offset": 708,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "like it's sort of like if you pick a",
      "offset": 710.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "real number at random, it's it's like",
      "offset": 712.399,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "what are the chances of getting a",
      "offset": 713.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "rational number? Pretty small. there",
      "offset": 714.88,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "most of them are not rational um by any",
      "offset": 718.32,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "reasonable measure of most and the same",
      "offset": 721.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "thing is true here you have all these",
      "offset": 723.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "sequences well which one um and so then",
      "offset": 724.959,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you've got to say well which",
      "offset": 728.079,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "hypothetical infinite extensions are the",
      "offset": 729.279,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "ones that actually give you the real",
      "offset": 731.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "probability and I just think this is the",
      "offset": 732.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "wrong this is just the wrong way to go",
      "offset": 734.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "my view is I like to make an analogy uh",
      "offset": 737.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "with measurement in general say in",
      "offset": 740.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "physics so you might think you might ask",
      "offset": 742.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "yourself what is mass say it Suppose",
      "offset": 745.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "just for the sake of argument that we're",
      "offset": 747.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "in a Newtonian universe and mass just",
      "offset": 748.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "behaves the way Newton thought it did.",
      "offset": 751.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Just for the sake of argument and then",
      "offset": 753.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you think well what is mass anyway? Well",
      "offset": 754.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "my view about what mass is in such",
      "offset": 757.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "universe is it's whatever the theory",
      "offset": 759.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "says it is. It's it's the functional",
      "offset": 760.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "role played by that concept and all the",
      "offset": 762.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "laws and that's a very complicated",
      "offset": 764.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "thing. There's no easy way to summarize.",
      "offset": 766.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "It's just whatever Newton's theory says",
      "offset": 768.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "it is. But you might be tempted by a",
      "offset": 769.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "different view. We might think, well,",
      "offset": 772.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "wait, maybe it's just frequencies. Maybe",
      "offset": 774.24,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "it's just what you do is you make",
      "offset": 777.2,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "measurements and then you take an",
      "offset": 779.24,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "average and maybe if you take infinitely",
      "offset": 782.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "many",
      "offset": 785.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "measurements and you take the limiting",
      "offset": 786.04,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "value of the average, maybe that's what",
      "offset": 788.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the mass of the object is. No. No. If",
      "offset": 790.399,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "you're lucky, that is if you're most of",
      "offset": 793.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "if you're lucky, then if you were to do",
      "offset": 795.44,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "that, of course you can't do it, but if",
      "offset": 797.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "you were to do that, then if you're",
      "offset": 798.399,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "lucky, you would get something very",
      "offset": 800,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "close to the actual mass. But that isn't",
      "offset": 801.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "what the mass is. And I want to say the",
      "offset": 803.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "same thing about probability. Suppose",
      "offset": 805.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you're doing some quantum mechanical",
      "offset": 808,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "experiment, right? You can make",
      "offset": 809.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "measurements. That's what you do. You",
      "offset": 811.44,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "make me you make a lot of measurements",
      "offset": 812.88,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "and you take averages and you do",
      "offset": 814.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "statistics and that's how you estimate",
      "offset": 815.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the probability that something will be",
      "offset": 818.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "observed in a quantum mechanical system.",
      "offset": 820.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "But that's not what the probability is.",
      "offset": 821.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "The probability is what the theory says",
      "offset": 824,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "it is and whatever that is. So one",
      "offset": 826,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "property it has is you know you use",
      "offset": 828.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Bourne's rule to calculate what the",
      "offset": 830.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "probability is. Okay, that's a really",
      "offset": 832.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "complicated theoretical story. But the",
      "offset": 834.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "but the probability isn't any sequence",
      "offset": 836.16,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "of measurements. It's not any limiting",
      "offset": 838.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "frequency that's a symptom of this",
      "offset": 840.12,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "property of probability. But the",
      "offset": 843.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "property is what the theory says it is.",
      "offset": 844.639,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "So I just think the frequency views got",
      "offset": 846.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "everything backwards. frequencies are",
      "offset": 848.399,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "just the way we maybe know about",
      "offset": 850.32,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "probabilities, but they're not what the",
      "offset": 852,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "probabilities are. So that that's my",
      "offset": 853.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "view. Oh, I I'm very sympathetic to",
      "offset": 856.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "that. How is that how does that view fit",
      "offset": 858.079,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "in with the sort of classic divide",
      "offset": 860.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "between thinking that probabilities are",
      "offset": 862.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "mostly epistemic? They're about our",
      "offset": 864.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "knowledge versus that probabilities",
      "offset": 866.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "latch on to some objective chances out",
      "offset": 869.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "there in the world. Oh, I think",
      "offset": 871.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "certainly there are objective",
      "offset": 873.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "probabilities. As I said, I think not",
      "offset": 875.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "just in physics but also in biology. I",
      "offset": 877.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "think each theory has its own concept of",
      "offset": 879.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "probability in it. At least the",
      "offset": 882.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "probabilistic theories do. And what",
      "offset": 883.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "probability is in those systems is",
      "offset": 885.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "whatever the theory says it is. It's",
      "offset": 888.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "just like mass. Um so that's I have a",
      "offset": 889.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "very flatfooted view of that. And so in",
      "offset": 892.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "quantum mechanics, well, we know how to",
      "offset": 894.88,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "calculate probabilities. The theory",
      "offset": 896.48,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "tells us to. You know, in statistical",
      "offset": 897.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "mechanics, we can also calculate",
      "offset": 899.519,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "probabilities as well. Um and we can we",
      "offset": 901.44,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "can do that as well you know but uh and",
      "offset": 905.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "now you might wonder about the",
      "offset": 908.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "interpretation of those probabilities",
      "offset": 910.079,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "but you can certainly calculate things",
      "offset": 911.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "which obey the laws of probability in",
      "offset": 913.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "statistical mechanics and so in that",
      "offset": 914.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "sense at least they are probabilities",
      "offset": 916.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "they satisfy the formal principles of",
      "offset": 917.92,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "probability um and so yeah I mean I I so",
      "offset": 920,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "I want to say certainly there are",
      "offset": 924.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "objective probabilities no no question",
      "offset": 925.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "I'm a scientific realist so you know if",
      "offset": 927.92,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "a theor if I accept a theory and the",
      "offset": 929.519,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "theory says there's a thing then there's",
      "offset": 930.959,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "that thing. That's it. So I I'm I I'm a",
      "offset": 932.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "realist. So I don't have any problem",
      "offset": 935.04,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "with that.",
      "offset": 936.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "However, the problem is and you know",
      "offset": 937.8,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "where things get really tricky I think",
      "offset": 940.8,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "and this is what got me really",
      "offset": 942.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "interested in in other notions of",
      "offset": 943.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "probability. The tricky thing is as I",
      "offset": 945.36,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "said suppose there's a dispute about the",
      "offset": 947.6,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "nature of probability in some physical",
      "offset": 950.639,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "context right there's a dispute about",
      "offset": 953.079,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "that. You have two theories. One theory",
      "offset": 955.68,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "says probability behaves like this.",
      "offset": 957.199,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "Another theory says behaves like that.",
      "offset": 958.399,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "And then you do experiments. Okay. And",
      "offset": 959.759,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "you try to use that data to adjudicate,",
      "offset": 962.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "you know, does the evidence favor the",
      "offset": 964.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "one theory of probability over the",
      "offset": 966.079,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "other.",
      "offset": 968.079,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "Well, whatever probability you can",
      "offset": 969.32,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "you're using there, you got to be very",
      "offset": 971.6,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "careful because you don't want to beg",
      "offset": 973.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "any questions. So, you don't want to use",
      "offset": 974.639,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the probability that the one theory says",
      "offset": 976.72,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "is correct, but the other says it's",
      "offset": 978.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "incorrect to do the very calculations of",
      "offset": 979.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "how strong the arguments are. That would",
      "offset": 982.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "be question begging. So, I think what",
      "offset": 984.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you in those settings, you need some",
      "offset": 986.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "other notion of probability. And that's",
      "offset": 988.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "where I think the epistemic notion comes",
      "offset": 990.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "in. I think you need it in at least",
      "offset": 993.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "these contexts where uh you you're",
      "offset": 996.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "actually trying to adjudicate different",
      "offset": 998.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "physical theories of probability say you",
      "offset": 1000,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "can't use what one theory says to",
      "offset": 1002.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "adjudicate because that would just beg",
      "offset": 1005.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "the question against the other theory.",
      "offset": 1006.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "And so I think in those context at least",
      "offset": 1009.199,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "you're going to need some other notion",
      "offset": 1011.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "of probability something neutral like a",
      "offset": 1012.079,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "like a judge is impartial. So you need",
      "offset": 1014.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "some impartial notion of probability.",
      "offset": 1016.639,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "And I think this is the kind of notion",
      "offset": 1018.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that statisticians have been trying to",
      "offset": 1019.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "come up with uh you know ever since that",
      "offset": 1022,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "early work in genetics which is where it",
      "offset": 1024.64,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "all really started with Fiser and and",
      "offset": 1026.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Haldane and all those kinds of people um",
      "offset": 1029.199,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "and Pearson. Um so but I this is where I",
      "offset": 1031.52,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "think basianism is helpful the the",
      "offset": 1036.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "basian approach because at least in",
      "offset": 1039.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "these contexts where we're not sure",
      "offset": 1041.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "we're uncertain what the correct theory",
      "offset": 1043.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "of probability is. We need something",
      "offset": 1045.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that's it feels like it's got to be",
      "offset": 1048.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "epistemic at least it's got to be",
      "offset": 1050.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "neutral and it's got to be something you",
      "offset": 1052.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "can use to adjudicate does the evidence",
      "offset": 1054.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "favor one theory of probability say over",
      "offset": 1056.799,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "another and uh and for that matter like",
      "offset": 1059.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "I said you want to adjudicate debates in",
      "offset": 1061.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "other areas where who knows what the",
      "offset": 1063.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "probability of Newton's theory is I mean",
      "offset": 1066,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "even if there even if there are",
      "offset": 1067.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "objective physical probabilities it's",
      "offset": 1069.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "hard to imagine how they would tell us",
      "offset": 1071.28,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "what the probability is that Newton's",
      "offset": 1072.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "theory is true good or I mean it's just",
      "offset": 1074.24,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "what would that mean? So, so I think in",
      "offset": 1077.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "those contexts where we're adjudicating",
      "offset": 1079.679,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "physical theory, say Newton versus",
      "offset": 1081.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "Einstein or two different versions of",
      "offset": 1082.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "quantum theory or something else, we're",
      "offset": 1085.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "going to need a some other notion of",
      "offset": 1087.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "probability. And that's where I think",
      "offset": 1089.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the basian approach is. You kind of need",
      "offset": 1090.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "something like that because you need",
      "offset": 1093.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "something neutral.",
      "offset": 1095.28,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "I think I would have said uh 15 minutes",
      "offset": 1097.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "ago that I don't believe that there is",
      "offset": 1099.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "any such thing as objective probability",
      "offset": 1102.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "in the world. I think that uh there's",
      "offset": 1104.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the world and we describe the world the",
      "offset": 1106.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "best we can and maybe we uh have",
      "offset": 1109.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "incomplete information so we appeal to",
      "offset": 1111.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "some probability but there's some exact",
      "offset": 1113.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "description of it also but and of course",
      "offset": 1114.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "if you're judging between different",
      "offset": 1118.32,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "theories of the world then you have some",
      "offset": 1119.679,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "epistemic view of probability but now",
      "offset": 1121.039,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "you're pointing out that okay but",
      "offset": 1123.039,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "there's a notion of a thing that appears",
      "offset": 1124.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "in a theory uh whether it's quantum",
      "offset": 1127.679,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "mechanics or genetics or whatever and",
      "offset": 1130.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that thing obeys the laws a probability",
      "offset": 1133.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it adds up to one and whatever and we",
      "offset": 1135.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "might as well call that objective.",
      "offset": 1137.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. I mean just like I would",
      "offset": 1140.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "want to call mass objective. Um I would",
      "offset": 1142.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "say the probability in quantum mechanics",
      "offset": 1145.039,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "that's delivered by you know the borne",
      "offset": 1146.559,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "rule or whatever however you calculate",
      "offset": 1148.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "it whatever that is. Um it's some real",
      "offset": 1149.44,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "thing. It's just as real as mass or any",
      "offset": 1152.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "other theoretical quantity. It seems to",
      "offset": 1154.559,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "me that theory that the theory",
      "offset": 1156.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "implicitly defines through its laws. So",
      "offset": 1157.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "yeah, I mean again I'm a realist though,",
      "offset": 1160.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "so I have to just fuss up to that. Um",
      "offset": 1162.48,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "but but as I say, even if you're not a",
      "offset": 1164.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "realist, even if you think okay, maybe",
      "offset": 1166.36,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "there's different kinds of",
      "offset": 1169.44,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "probabilities, but none of them is",
      "offset": 1170.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "objective in in the relevant sense.",
      "offset": 1172.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Still, if you want to know whether some",
      "offset": 1174,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "evidence favors one of those theories",
      "offset": 1176,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "over another one, and you want that to",
      "offset": 1177.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "be a probabilistic inference, which is",
      "offset": 1179.679,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "it is because it's not going to be",
      "offset": 1181.2,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "deductive. I mean, after all, EV",
      "offset": 1182.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "scientific evidence doesn't entail the",
      "offset": 1184.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "answer to these questions. It doesn't",
      "offset": 1186.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "deductively guarantee that one theory is",
      "offset": 1187.44,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "true and the other is false. It just at",
      "offset": 1189.679,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "best makes it favors one over another.",
      "offset": 1191.96,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "And that's going to have to be I think",
      "offset": 1195.2,
      "duration": 2.599
    },
    {
      "lang": "en",
      "text": "the best way to model that is",
      "offset": 1196.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "probabilistically. But then you need a",
      "offset": 1197.799,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "general framework of probability that's",
      "offset": 1199.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "going to have to be I don't know",
      "offset": 1201.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "epistemic or or something less objective",
      "offset": 1203.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "in that sense because otherwise it would",
      "offset": 1206.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it would run the risk of just begging",
      "offset": 1208.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the question. So good. This leads us",
      "offset": 1210.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "right into where I wanted to go which is",
      "offset": 1212.24,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "the uh idea of induction and how in the",
      "offset": 1214.4,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "early days people tried to hope that",
      "offset": 1219.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "inductive reasoning you know looking at",
      "offset": 1221.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "many many examples and generalizing",
      "offset": 1223.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "would be a kind of logic that would fit",
      "offset": 1225.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "the scientific process and then other",
      "offset": 1227.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "people point out that there are problems",
      "offset": 1230.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "with induction. So I mean pretend we're",
      "offset": 1232.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "in the philosophy 101 class like what",
      "offset": 1234.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "are the problems that people have with",
      "offset": 1236,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "induction?",
      "offset": 1237.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Well, of course, in philosophy, you",
      "offset": 1239.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "know, in epistemology generally, you",
      "offset": 1241.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "generally start out with the really",
      "offset": 1243.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "really hard problems like skepticism and",
      "offset": 1245.039,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and induction is no is no different. Uh",
      "offset": 1247.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "when you're studying philosophy of",
      "offset": 1250.159,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "induction, you tend to start with these",
      "offset": 1251.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "skeptical arguments. Um you know, like",
      "offset": 1252.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "David Hume was was had a kind of",
      "offset": 1255.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "skeptical arguments. He's like, well,",
      "offset": 1257.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "okay, you say there are these arguments",
      "offset": 1259.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "that are, you know, that don't guarantee",
      "offset": 1262.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the truth of their conclusions if their",
      "offset": 1264,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "premises are true. well, their",
      "offset": 1266.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "conclusions maybe they're quote unquote",
      "offset": 1268.52,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "probably true, but they're not",
      "offset": 1270.72,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "guaranteed to be true like in",
      "offset": 1271.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "mathematics. And he he gave this",
      "offset": 1273.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "dilemma. He said, well, let's think",
      "offset": 1275.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "about how that would actually work. So",
      "offset": 1277.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "suppose, you know, you've observed the",
      "offset": 1279.44,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "sun rising a, you know, a million times",
      "offset": 1281.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "and you infer that on the basis of that",
      "offset": 1284.559,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "ev historical evidence that the sun will",
      "offset": 1287.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "rise tomorrow.",
      "offset": 1289.679,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "He points Hume points out that well that",
      "offset": 1292.32,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "argument assumes some kind of principle",
      "offset": 1296.159,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of regularity of nature that you know",
      "offset": 1298.32,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "the past the future will resemble the",
      "offset": 1301.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "past. And now if you ask how are you",
      "offset": 1303.559,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "going to justify that premise that the",
      "offset": 1306.24,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "future will resemble the past? Well, you",
      "offset": 1308.4,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "can't give a deductive argument for it",
      "offset": 1311.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "because how would you do that? I mean",
      "offset": 1313.72,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "nothing you've observed is going to",
      "offset": 1315.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "entail that the future will resemble the",
      "offset": 1317.36,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "past. In other words, there'll always be",
      "offset": 1319.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "some chance that you can't rule out with",
      "offset": 1321.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "certainty that the future won't resemble",
      "offset": 1323.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "the past. Uh so it won't be a deductive",
      "offset": 1325.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "argument. And then if it's an inductive,",
      "offset": 1327.919,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "it just feels like now it's going to beg",
      "offset": 1329.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the question because well wait, what are",
      "offset": 1331.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you going to do? Reason as follows. In",
      "offset": 1333.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the past the future has resembled the",
      "offset": 1335.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "past. So therefore in the future the and",
      "offset": 1337.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "now you're just it's now you're just",
      "offset": 1341.2,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "circular. But now it's just a circular",
      "offset": 1342.96,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "argument because you're assuming the",
      "offset": 1344.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "very principle that you mean to justify",
      "offset": 1345.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "in order to justify the argument. So you",
      "offset": 1347.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "know philosophy always starts with these",
      "offset": 1350.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "skeptical arguments. I mean but you you",
      "offset": 1352.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "don't have to worry about induction. I",
      "offset": 1354.24,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "mean this happens in every field. Like",
      "offset": 1355.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "why believe there's an external world?",
      "offset": 1356.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "After all you can't rule out with",
      "offset": 1358.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "certainty that there's an evil demon or",
      "offset": 1360.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that you're in a simulation or etc etc",
      "offset": 1362,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "etc you know. So what you I think what",
      "offset": 1364.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you got to do uh when you're doing",
      "offset": 1366.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "philosophy the sort of the first thing",
      "offset": 1368.08,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you have to do in any of these domains",
      "offset": 1369.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "is figure out how you're going to",
      "offset": 1371.2,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "respond to the skeptic that",
      "offset": 1373.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "is what are you going what are you going",
      "offset": 1374.6,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "to say why do you think that there's an",
      "offset": 1376.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "external world for let's start there and",
      "offset": 1378.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "then we'll get to induction well why do",
      "offset": 1380.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you think there's an external world well",
      "offset": 1382,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "um I can only speak for myself the",
      "offset": 1385.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "reason I think there's an external world",
      "offset": 1386.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "is when I think about everything that I",
      "offset": 1388.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "take myself to know you know everything",
      "offset": 1390.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I take to be evidence about the world",
      "offset": 1392.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "you all my observations, you know,",
      "offset": 1394.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "everything I take to be true. And I",
      "offset": 1396.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "think, well, what's the best explanation",
      "offset": 1398.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "of all of that? To me, I don't see any",
      "offset": 1400,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "way to plausibly explain all that stuff",
      "offset": 1403.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "without postulating the existence of an",
      "offset": 1405.44,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "external world that is mind independent",
      "offset": 1408.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "in many ways. Uh, and that's why I think",
      "offset": 1410.159,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "there's a mind-ended external world. Uh,",
      "offset": 1412.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "and now I want to take the same",
      "offset": 1415.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "anti-skeepical view about induction.",
      "offset": 1417.679,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "I think well how do you explain say the",
      "offset": 1421.76,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "success of science or what appears to be",
      "offset": 1425.679,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "the progress of",
      "offset": 1428.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "science? Well uh I don't know but it",
      "offset": 1430.6,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "seems hard for me to be able to explain",
      "offset": 1433.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "that unless there weren't some",
      "offset": 1436.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "principles of when evidence actually",
      "offset": 1439.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "does favor one scientific theory over",
      "offset": 1442.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "another uh and does provide reason to",
      "offset": 1444.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "believe one rather than the other. uh",
      "offset": 1447.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and so what I tend to do is think about",
      "offset": 1449.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "historical cases of that look like real",
      "offset": 1451.12,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "scientific progress and then what's the",
      "offset": 1453.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "best way to explain that so for instance",
      "offset": 1456.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "when uh when Einstein's general",
      "offset": 1458.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "relativity of general relativity",
      "offset": 1461.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "overtook Newton's theory of celestial",
      "offset": 1463.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "motion there were a lot of experiments",
      "offset": 1465.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that were crucial one was the motion of",
      "offset": 1466.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Mercury the motion of Mercury Mercury",
      "offset": 1468.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "moves in this very strange way around",
      "offset": 1471.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "the sun and it was known that was known",
      "offset": 1473.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "for a long time that it had this strange",
      "offset": 1476,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "motion",
      "offset": 1477.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Well, uh, the Newtonians tried their",
      "offset": 1479.039,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "best to give explanations of that and,",
      "offset": 1481.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "uh, in the past they had had similar",
      "offset": 1484.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "episodes, but they were able to explain",
      "offset": 1486.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "it by some missing mass that they found,",
      "offset": 1487.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you know, that was in the universe that",
      "offset": 1490.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "they didn't know about. And but",
      "offset": 1492.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "eventually they realized now there's no",
      "offset": 1493.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "there isn't going to be the right hidden",
      "offset": 1495.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "mass here. It's Newton's theory is just",
      "offset": 1496.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "not going to be able to predict this.",
      "offset": 1499.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "Uh, this is just a a thing that Newton's",
      "offset": 1500.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "theory can't explain, can't predict. And",
      "offset": 1503.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "then Einstein comes along and gives a",
      "offset": 1505.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "theory that explains all the stuff",
      "offset": 1507.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Newton's theory could explain and this",
      "offset": 1508.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "thing too and a bunch of other stuff",
      "offset": 1511.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that it couldn't explain. I that just",
      "offset": 1512.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "now I want to say well that just seems",
      "offset": 1515.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "to make it more probable that Einstein's",
      "offset": 1517.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "story is true or at least more probable",
      "offset": 1519.84,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "that you know that would be the better",
      "offset": 1522.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "bet to make that would be the more",
      "offset": 1525.039,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "acceptable theory. And I I think a",
      "offset": 1526.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "probabilistic way of modeling that is",
      "offset": 1529.679,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "just the best way that I know to model",
      "offset": 1531.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "it. And so again, I just think, well,",
      "offset": 1533.279,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "what's the best explanation of these",
      "offset": 1535.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "episodes of scientific progress? And to",
      "offset": 1536.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "me, part of that has to be, well, there",
      "offset": 1539.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "just must be cases where the evidence",
      "offset": 1540.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "really does favor one theory over",
      "offset": 1543.36,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "another. Not that it guarantees that",
      "offset": 1544.96,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "one's true, the other is false or",
      "offset": 1546.559,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "anything like that, but it sort of",
      "offset": 1547.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "raises the probability of one more than",
      "offset": 1549.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the other. And I just think I don't know",
      "offset": 1552,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "how else to explain science episodes of",
      "offset": 1553.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "scientific progress unless something",
      "offset": 1556.08,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "like that is true. Um, so I so I believe",
      "offset": 1557.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that something like that is true. Now",
      "offset": 1561.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the details of it are difficult to to",
      "offset": 1562.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "work out but I think this is what",
      "offset": 1564.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "statistitians as I said have largely",
      "offset": 1566.559,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "been trying to figure out uh how those",
      "offset": 1568.48,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "inferences work like when we have an",
      "offset": 1571.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "experiment and we think the evidence",
      "offset": 1573.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "favors one theory of another what's the",
      "offset": 1575.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "right way to use probability right to",
      "offset": 1577.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "model that and there's a lot of",
      "offset": 1579.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "disagreement of course in statistics",
      "offset": 1580.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "between basians and classical stat",
      "offset": 1583.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "there's all kinds of different schools",
      "offset": 1585.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "but one thing they all agree on is there",
      "offset": 1587.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "are episodes where the evidence favors",
      "offset": 1589.679,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "one theory over another and probability",
      "offset": 1591.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "is an is an indispensable part of the",
      "offset": 1594.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "explanation why I do think they all",
      "offset": 1596.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "agree on that much it might be unfair of",
      "offset": 1598.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "me but I do think that it's a very",
      "offset": 1601.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "common phase in an individual's",
      "offset": 1603.679,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "philosophical maturation to realize that",
      "offset": 1606.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "not everything can be established on",
      "offset": 1609.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "rockh hard foundations that you agree",
      "offset": 1612.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "with 100% like sometimes you just got to",
      "offset": 1614.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "say this is the best we can do with what",
      "offset": 1617.2,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "we got",
      "offset": 1618.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "absolutely Absolutely. I think most of",
      "offset": 1620.799,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "the time we're kind of in that in that",
      "offset": 1622.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "situation and that's okay. So I think",
      "offset": 1624.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "but you know that's the nature of these",
      "offset": 1626.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "inferences. As I said it's not like",
      "offset": 1628.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "deduction. You don't have the certainty",
      "offset": 1630.96,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "of mathematics in these kinds of",
      "offset": 1632.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "inferences. So you know there's going to",
      "offset": 1634.52,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "be something that's underdetermined. You",
      "offset": 1637.44,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "know it's not going to exactly determine",
      "offset": 1640.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "completely what our attitude should be.",
      "offset": 1642.44,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "There's going to be some wiggle room,",
      "offset": 1644.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "some leeway. So in a way you're always",
      "offset": 1646.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "making something of a leap of faith when",
      "offset": 1648.32,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "you do one of these amplitative or",
      "offset": 1650.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "inductive inferences. And I just think",
      "offset": 1651.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "you kind of have to live with that, you",
      "offset": 1653.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "know, and do the best you can. And this",
      "offset": 1655.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "leads us right into you're very good at",
      "offset": 1657.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "this. You're just bringing us along on",
      "offset": 1659.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the logical train of thought that we",
      "offset": 1661.36,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "need to be on um the idea of",
      "offset": 1662.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "confirmation. Uh to try what we're",
      "offset": 1665,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "trying to do is to formalize this idea",
      "offset": 1667.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "like you just said that you know",
      "offset": 1669.039,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Einstein's theory is simple. It fits the",
      "offset": 1670.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "data. Newton's theory doesn't fit the",
      "offset": 1672.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "data in some sense. Einstein has now",
      "offset": 1674.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "become more probably right than Newton.",
      "offset": 1677.52,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "What sense is that? And confirmation is",
      "offset": 1679.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "one of the words that gets batted",
      "offset": 1683.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "around. I want you to really sort of",
      "offset": 1684.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "carefully explain to us what that's",
      "offset": 1686.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "supposed to mean because I think many",
      "offset": 1687.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "people informally think that if you've",
      "offset": 1689.44,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "confirmed something, you know it's true",
      "offset": 1691.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "100%. And that's not how philosophers",
      "offset": 1694.399,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "use the word.",
      "offset": 1696.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "No, that's right. That's right. So yeah,",
      "offset": 1698.799,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "in in ordinary language, the word",
      "offset": 1700.559,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "confiration has very strong",
      "offset": 1702.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "connotations, but in the philosophy of",
      "offset": 1704.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "induction, confirmation is actually a",
      "offset": 1706.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "very weak, it's actually a very weak",
      "offset": 1707.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "claim. And um I think a helpful I like",
      "offset": 1709.44,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "to use simple examples. I think a nice",
      "offset": 1713.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "nice example to use is one of diagnostic",
      "offset": 1715.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "testing. I I always like this example",
      "offset": 1719.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and in a and in a way I think it's kind",
      "offset": 1721.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "of fully general because in a way you",
      "offset": 1723.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "can think of scientific experiments as a",
      "offset": 1724.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "kind of diagnostic test where you're",
      "offset": 1727.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "testing the world to see whether some",
      "offset": 1729.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "hypothesis is true or false. And so when",
      "offset": 1731.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you design an experiment you really are",
      "offset": 1733.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "in a way designing a diagnostic test. Um",
      "offset": 1735.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "and so but let's think about diagnostic",
      "offset": 1738.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "testing. So for instance um there are",
      "offset": 1740.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "many diagnostic tests that are very",
      "offset": 1742.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "reliable that you can buy in the store",
      "offset": 1744.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "now. So, for instance, you could you",
      "offset": 1746,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "could buy a pregnancy test or an HIV",
      "offset": 1747.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "test. Um, any of these tests that you",
      "offset": 1749.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "buy, if you read the box, you you'll",
      "offset": 1751.919,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "notice something very interesting on the",
      "offset": 1754.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "box. There's things they tell you and",
      "offset": 1757.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "there's things they don't tell you. So,",
      "offset": 1758.799,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "one thing they tell you for sure is what",
      "offset": 1761.44,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "they call the true positive rate and the",
      "offset": 1764.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "false positive rate of the test. Right?",
      "offset": 1766.559,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "So, the true positive rate is something",
      "offset": 1768.799,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "like this. Suppose that you have the",
      "offset": 1771.279,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "disease. then how probable would it be",
      "offset": 1774.12,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "that you would get a positive result",
      "offset": 1777.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "from this test and then on the other the",
      "offset": 1778.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "false positive rate is suppose you don't",
      "offset": 1781.36,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "have disease then how probable is a",
      "offset": 1782.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "positive result and the great thing",
      "offset": 1784.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "about these diagnostic tests is you can",
      "offset": 1786.799,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "determine those those error rates in the",
      "offset": 1788.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "laboratory you don't need to know",
      "offset": 1791.559,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "anything about the subjects the",
      "offset": 1793.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "particular subjects that are using it",
      "offset": 1795.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "and so on and that's why they can put",
      "offset": 1796.64,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "that information on the box it's very",
      "offset": 1798.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "reliably known well that ratio of the",
      "offset": 1799.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "true positive rate to the false positive",
      "offset": 1802.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "rate is called a baze factor. It's also",
      "offset": 1804.159,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "called a likelihood ratio. And it",
      "offset": 1806.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "doesn't determine how probable the h the",
      "offset": 1809.039,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "hypothesis is given a positive result.",
      "offset": 1812.24,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "It doesn't determine that. In order to",
      "offset": 1815.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "know that how probable it is that you",
      "offset": 1817.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "have the disease, you have to plug in",
      "offset": 1820.08,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "what's called a prior probability. Uh an",
      "offset": 1821.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "a priori probability philosophers call",
      "offset": 1824.399,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "it. And what is that? Well, that's",
      "offset": 1826.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "something like the probability you how",
      "offset": 1828.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "probable you think it is before looking",
      "offset": 1830.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "at the evidence.",
      "offset": 1832,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Okay. Well, what that what is that?",
      "offset": 1834.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Well, of course, um the guys who design",
      "offset": 1836.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the test, they can't tell you what that",
      "offset": 1838.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "is. That's going to depend very sensibly",
      "offset": 1840.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "on things about you. So, for instance,",
      "offset": 1842.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "suppose it's a pregnancy test. Um and if",
      "offset": 1844.399,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "someone takes a pregnancy test and they",
      "offset": 1847.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "get a positive result, well, they'll",
      "offset": 1848.559,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "know the likelihood ratio. They'll know",
      "offset": 1850.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the the error rates, you know, uh false",
      "offset": 1852.399,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "positive and true positive. So, they'll",
      "offset": 1854.72,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "know how reliable the test is in that",
      "offset": 1856,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "sense. But to get how probable it is",
      "offset": 1857.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that they're pregnant, well, they need",
      "offset": 1860.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to know a lot about maybe their own",
      "offset": 1862.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "behavior in recent days and so on, which",
      "offset": 1864.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "of course the designers of the",
      "offset": 1866.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "experiment can't know and and should and",
      "offset": 1868.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "don't need to know in order to know the",
      "offset": 1870.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "error rates, right? So for just just to",
      "offset": 1872.48,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "put an example on this um so if there is",
      "offset": 1874.96,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "a pregnancy test that the the likelihood",
      "offset": 1877.919,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "is very high like you know it's it is",
      "offset": 1881.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "claimed that uh if if it comes out",
      "offset": 1883.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "positive the likelihood you're pregnant",
      "offset": 1886.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "is very is very large but if I took a",
      "offset": 1888.159,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "pregnancy test of that form I am",
      "offset": 1891.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "biologically incapable of becoming",
      "offset": 1893.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "pregnant I know that pretty with pretty",
      "offset": 1894.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "high probability so if I happen to get a",
      "offset": 1896.559,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "a",
      "offset": 1899.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "positive I would not conclude that my",
      "offset": 1899.96,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "probability in being pregnant is high",
      "offset": 1902.559,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "because my prior is so low.",
      "offset": 1904.24,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "Exactly. Exactly. In fact, it might even",
      "offset": 1907.32,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "be zero, you know, depending on the",
      "offset": 1910.559,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "case, but it'll be very close to zero.",
      "offset": 1911.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "And that's exactly the distinction that",
      "offset": 1913.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "I want to make. This distinction between",
      "offset": 1915.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "that base factor that how reliable the",
      "offset": 1917.519,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "test is, which is just the ratio really",
      "offset": 1920.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "of those two error rates, that could be",
      "offset": 1921.679,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "really high, but all that tells you is",
      "offset": 1924.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "what to multiply the prior by to get the",
      "offset": 1926.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "posterior. Basically, it's like a",
      "offset": 1929.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "multiplier. So if you start off low but",
      "offset": 1930.88,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "not that low and then you get a really",
      "offset": 1934.64,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "reliable test, well maybe it's a",
      "offset": 1936.159,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "multiplier by a factor of a thousand,",
      "offset": 1937.679,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "well then you're going to have a",
      "offset": 1939.12,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "reasonably high probability. But if you",
      "offset": 1940.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "start really really low, then even if",
      "offset": 1942.159,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "you have a pretty high factor, a",
      "offset": 1944.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "multiplicative base factor, still you're",
      "offset": 1946.88,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "going to end up low. And this people are",
      "offset": 1948.88,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "very bad at making these inferences.",
      "offset": 1952.559,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "This is something that Conor and Tverki",
      "offset": 1954.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "discovered back uh in the 80s. They",
      "offset": 1956.159,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "called it the base rate fallacy. And",
      "offset": 1958.399,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "when people are given uh an example like",
      "offset": 1960.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this where okay so you have a reliable",
      "offset": 1963.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "test for a rare disease they're told the",
      "offset": 1965.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "disease is rare like one in a thousand",
      "offset": 1968.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "and then they're given pretty good error",
      "offset": 1970.32,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "rates and they say well and then they're",
      "offset": 1971.679,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "asked how probable is it that the person",
      "offset": 1973.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "has disease and often people give a very",
      "offset": 1974.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "high number and in fact interestingly",
      "offset": 1977.44,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "the numbers tend to cluster",
      "offset": 1980.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "around basically the baze factor if you",
      "offset": 1983.48,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "normalize it to a 0 to1 scale and I",
      "offset": 1986.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "don't think this is a coincidence",
      "offset": 1989.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "I think what's happening here is you",
      "offset": 1990.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "have two factors. There are two things",
      "offset": 1992.32,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "that are relevant here. There's how",
      "offset": 1994.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "probable it is that you have disease,",
      "offset": 1996.12,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "the probability of the disease and then",
      "offset": 1998.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "there's the how confirmation. There's",
      "offset": 1999.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "how much the evidence confirms and",
      "offset": 2002.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "that's just how much does it change? How",
      "offset": 2004.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "much does it raise the probability? And",
      "offset": 2006.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "I think in these cases what you have is",
      "offset": 2009.2,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "low probability but high confirmation.",
      "offset": 2011.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "That can be very confusing, right?",
      "offset": 2014.159,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "Because both of these things are",
      "offset": 2015.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "relevant to quote unquote how strong the",
      "offset": 2017.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "argument is, but that is how strong the",
      "offset": 2018.96,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "evidence is as a reason to believe that",
      "offset": 2022.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the disease is present. But they go in",
      "offset": 2024.559,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "different directions. So it can be very",
      "offset": 2027.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "confusing. And then you might there's",
      "offset": 2029.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "still a residual question. Well, why",
      "offset": 2031.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "would people defer to the relevance to",
      "offset": 2033.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "the confirmation number right when",
      "offset": 2035.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "they're asked about probability? Um I",
      "offset": 2037.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "think this is not a crazy thing to do at",
      "offset": 2040.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "all. As we said, those error rates are",
      "offset": 2042.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "objective and invariant in a really",
      "offset": 2046.32,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "important sense. You can just discover",
      "offset": 2048.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "them in laboratories. Uh you could just",
      "offset": 2049.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "by working with the causal structure of",
      "offset": 2052.399,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "the test and the chemicals you're",
      "offset": 2053.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "looking for, you can be pretty confident",
      "offset": 2055.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "about those error rates independently of",
      "offset": 2057.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "the prior probability. And so there's",
      "offset": 2060.32,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "something more objective yeah about",
      "offset": 2062.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "those numbers. And you know there's",
      "offset": 2065.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "something really ironic about the",
      "offset": 2067.44,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "conventi research because if you read",
      "offset": 2069.52,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "their own paper well that's a scientific",
      "offset": 2073.119,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "paper and so what do scientific papers",
      "offset": 2076,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "do? Well they generally design an",
      "offset": 2078.159,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "experiment and then perform an",
      "offset": 2080,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "experiment and the experiment generates",
      "offset": 2081.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "evidence. What do they tell you about",
      "offset": 2084.919,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "the experiment? What do they tell you",
      "offset": 2087.28,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "about how to interpret that evidence? Do",
      "offset": 2088.639,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "they tell you how probable their",
      "offset": 2090.079,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "hypothesis is to be true given the",
      "offset": 2091.359,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "evidence? Of course they don't. Just",
      "offset": 2092.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like the diagnostic test maker can't",
      "offset": 2094.879,
      "duration": 4.001
    },
    {
      "lang": "en",
      "text": "tell you how probable it is that you",
      "offset": 2096.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "have disease. That relies on this prior",
      "offset": 2098.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "information that they don't know.",
      "offset": 2101.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Science is the same way. When you design",
      "offset": 2103.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "an experiment, what you're really doing",
      "offset": 2105.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "is trying to get maximum confirmational",
      "offset": 2107.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "power out of the experiment. You want it",
      "offset": 2110.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "to be as much of a multiplier of that",
      "offset": 2112.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "prior probability as you can. Uh either",
      "offset": 2115.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "either a multiplier or a divider. If",
      "offset": 2118.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "it's if it's evidence against then okay",
      "offset": 2120.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "then it's kind of a divider of how",
      "offset": 2122.16,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "probabilities it makes it smaller makes",
      "offset": 2123.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "the probability smaller but the point is",
      "offset": 2124.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "it's not probability that you're you you",
      "offset": 2126.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "can't maximize the probability that your",
      "offset": 2129.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "hypothesis is true that depends on the",
      "offset": 2131.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "prior and different scientists are going",
      "offset": 2133.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to have different priors when they when",
      "offset": 2135.28,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "they look at",
      "offset": 2137.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "experiments. So all you can tell people",
      "offset": 2138.2,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "basically is what the likelihood ratio",
      "offset": 2140.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "what that base factor is of your",
      "offset": 2142.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "experiment including Conan Tverki's own",
      "offset": 2144.079,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "experiment. So there's this real irony.",
      "offset": 2146.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "They're implicitly criticizing human",
      "offset": 2149.359,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "beings for being bad at doing a thing",
      "offset": 2151.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "that their own paper doesn't require",
      "offset": 2154.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "scientists reading the paper to do. In",
      "offset": 2156.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the big picture, I I was a little",
      "offset": 2159.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "cheeky. I I put this idea as um",
      "offset": 2160.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "everyone's entitled to their own priors.",
      "offset": 2163.359,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "No one's entitled to their own",
      "offset": 2165.119,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "likelihoods.",
      "offset": 2166.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Exactly. And I think that's exactly",
      "offset": 2168.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "right. And so I think there's something",
      "offset": 2169.92,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "not irrational here about deferring to",
      "offset": 2172.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the likelihood information. After all,",
      "offset": 2175.119,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "that's the objective. That's the",
      "offset": 2177.119,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "invariant information that we can know.",
      "offset": 2178.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "And uh and that's how science works,",
      "offset": 2181.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "right? Scientific papers, they basically",
      "offset": 2184,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "report base factors or something about",
      "offset": 2185.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "whether the evidence favors one theory",
      "offset": 2187.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "over another. They don't tell you how",
      "offset": 2189.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "probable it is that one theory is true",
      "offset": 2191.839,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "or the other theory is true. They know",
      "offset": 2193.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "that's going to depend on these priors.",
      "offset": 2194.96,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "And they don't know the prior",
      "offset": 2196.88,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "probabilities of their readership.",
      "offset": 2198.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "Depends on what their readership knows.",
      "offset": 2199.359,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "And so our self-appointed task is to",
      "offset": 2201.839,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "come up with a formal understanding of",
      "offset": 2205.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "this idea of confirmation. Like clearly",
      "offset": 2207.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "it's important. I mean maybe you have",
      "offset": 2208.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "your own priors. Uh maybe you disagree",
      "offset": 2210.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "or maybe you agree about them. But we",
      "offset": 2212.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "should be able to quantify how much the",
      "offset": 2214.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "new evidence is confirming uh our",
      "offset": 2217.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "theories. And it's also like you say,",
      "offset": 2219.44,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "but maybe it's worth emphasizing. It's",
      "offset": 2221.359,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "weaker than entailment than from",
      "offset": 2223.56,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "deductive logic. We're familiar from",
      "offset": 2227.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "high school uh P and if P then Q",
      "offset": 2229.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "therefore Q like that sounds solid that",
      "offset": 2232.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "sounds logic to us and we want a logic",
      "offset": 2234.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "of confirmation.",
      "offset": 2237.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Yes. Yes. And and we can have one and",
      "offset": 2240.24,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and basically those base factors they",
      "offset": 2242.56,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "give it to you. Um one thing that's",
      "offset": 2245.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "really interesting about this literature",
      "offset": 2247.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and is this is really what my this is",
      "offset": 2250.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "what I really got interested in when I",
      "offset": 2252.56,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "was in graduate school. I wrote my",
      "offset": 2253.839,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "dissertation on this. If you look in the",
      "offset": 2254.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "literature on probability statistics,",
      "offset": 2256.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "basianism, any of that literature,",
      "offset": 2258.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "there's lots of measures of this",
      "offset": 2261.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "confirmation. There's lots of measures",
      "offset": 2263.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "of say degree of correlation. So",
      "offset": 2265.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "correlation is another word for",
      "offset": 2266.8,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "confirmation. It's just when one thing",
      "offset": 2268,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "raises the probability of another,",
      "offset": 2269.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "right? Um there's lots of measures of",
      "offset": 2271.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "how strong that confirmation is. One",
      "offset": 2274.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "thing you could do is just take the",
      "offset": 2276.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "posterior probability and subtract off",
      "offset": 2277.76,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "the prior probability. And you could",
      "offset": 2279.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "say, well, how that's one way of",
      "offset": 2281.359,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "measuring how much of a difference the",
      "offset": 2282.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "evidence made to the hypothesis. But",
      "offset": 2284.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "there's many ways to do it because it",
      "offset": 2286.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "turns out that you can define",
      "offset": 2289.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "correlation in in many equivalent ways.",
      "offset": 2291.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "So one way is the the posterior is",
      "offset": 2294.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "greater than the prior. That's one way.",
      "offset": 2296.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "But another way is that the true",
      "offset": 2298.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "positive rate is greater than the false",
      "offset": 2301.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "positive rate.",
      "offset": 2302.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Right. Uh or greater than one minus the",
      "offset": 2304.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "false pro. So the probability of the",
      "offset": 2307.68,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "evidence given the hypothesis is greater",
      "offset": 2308.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "than the probability evidence given the",
      "offset": 2310.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "denial of the hypothesis. Yeah. And",
      "offset": 2312,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that's equivalent qualitatively. Those",
      "offset": 2314.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "are going to be true at this. But if you",
      "offset": 2316.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "define measures based on those",
      "offset": 2318.56,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "inequalities, they're actually",
      "offset": 2320,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "different. They don't agree on which",
      "offset": 2321.44,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "thing is better confirmed than which.",
      "offset": 2323.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "They actually disagree on orderings of",
      "offset": 2325.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "how well confirmed hypotheses are. So",
      "offset": 2327.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "they can't be measuring the same",
      "offset": 2329.44,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "directionction. It's it's either it's",
      "offset": 2330.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "being confirmed or disisconfirmed, but",
      "offset": 2332.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "they don't agree on how much. Exactly.",
      "offset": 2333.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "And so if you want to measure it, which",
      "offset": 2336,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "of course we do, we want to know how",
      "offset": 2337.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "much. Uh then you've got to pick one of",
      "offset": 2339.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "these many and there's dozens of",
      "offset": 2342.079,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "measures and they all disagree and I and",
      "offset": 2343.44,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "I this is what I survey in my",
      "offset": 2344.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "dissertation. Um and so you've got to",
      "offset": 2346.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "pick one. Now the the good news is that",
      "offset": 2348.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "if you're an inductive logician, which",
      "offset": 2351.839,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "is a certain tradition that I'm a member",
      "offset": 2354.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of, you've got you actually have a",
      "offset": 2356.44,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "criterion that allows you to narrow",
      "offset": 2358.96,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "things down to a unique measure. And it",
      "offset": 2360.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "turns out to be the base factor, the",
      "offset": 2361.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "same thing that people report on the",
      "offset": 2363.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "boxes of the diagnostic tests. And it's",
      "offset": 2365.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "a very simple criterion. The criterion",
      "offset": 2368.24,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "is however we're measuring this",
      "offset": 2370.16,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "confirmation, it should be such that it",
      "offset": 2373.88,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "generalizes entailment in the following",
      "offset": 2376.48,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "sense. If the evidence did entail the",
      "offset": 2378.8,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "hypothesis, if it guaranteed that the",
      "offset": 2382.92,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "hypothesis was true, then that should",
      "offset": 2385.119,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "receive a maximal value of confirmation.",
      "offset": 2387.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "And if it refuted the hypothesis,",
      "offset": 2390.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "entailed that it was false, falsified",
      "offset": 2392.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "it, then that should be a minimal value.",
      "offset": 2394.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "just add that as a criterion and you're",
      "offset": 2397.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "basically uniquely down to this base",
      "offset": 2399.68,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "factor. Good. And so that gives us if",
      "offset": 2401.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "we're in the framework of inductive",
      "offset": 2405.28,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "logic now we actually do have a unique",
      "offset": 2406.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "way of measuring and it just turns out",
      "offset": 2408.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "and I'm not sure this is a coincidence",
      "offset": 2409.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "but it turns out it's the very same base",
      "offset": 2411.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "factor that they tell you when you buy a",
      "offset": 2413.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "diagnostic test. Good. Yeah. I'm now",
      "offset": 2415.839,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "going to look in stores for diagnostic",
      "offset": 2418.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "tests that tell me what my priors should",
      "offset": 2420.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "be. But Right. That's right. It's a",
      "offset": 2422.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "probability 9/10en that you're pregnant",
      "offset": 2425.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "no matter who you are.",
      "offset": 2427.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "So just this might be a tiny little",
      "offset": 2429.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "aside but I remember when I was young",
      "offset": 2431.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "and taking my first philosophy of",
      "offset": 2434,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "science course um when we came to Carl",
      "offset": 2435.599,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "Pauper uh we were taught that his notion",
      "offset": 2438.96,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "of",
      "offset": 2442.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "falsification was supposed to be a",
      "offset": 2443.16,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "better thing to think than the",
      "offset": 2445.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "oldfashioned logical positivist notion",
      "offset": 2448.119,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "of confirmation. I I know now that we",
      "offset": 2450.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "weren't actually told what that",
      "offset": 2453.28,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "old-fashioned logical positivist notion",
      "offset": 2454.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "of confirmation actually was or at least",
      "offset": 2456.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "it didn't become clear to me. But what",
      "offset": 2457.76,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "is the difference between those two",
      "offset": 2459.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "ideas? Yeah. So this is that's a great",
      "offset": 2460.8,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "question. So there so I think Pa was",
      "offset": 2463.44,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "right in a sense. There is an important",
      "offset": 2466.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "asymmetry when you think about degrees",
      "offset": 2469.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "of confirmation. So let's think about",
      "offset": 2471.599,
      "duration": 7.961
    },
    {
      "lang": "en",
      "text": "how strongly does something that",
      "offset": 2475.44,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "refutes what's the confirmational impact",
      "offset": 2479.56,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "of that versus something that's that",
      "offset": 2482.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "doesn't refute. Well, as I just said,",
      "offset": 2484.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "our criterion requires reputation to be",
      "offset": 2487.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "that's the worst that's the most",
      "offset": 2489.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "negatively relevant you can be. And so",
      "offset": 2491.839,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "in this sense, this is the kernel of",
      "offset": 2493.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "truth of what Popper said. Refuting",
      "offset": 2495.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "evidence is more powerful than",
      "offset": 2497.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "non-refuting evidence. Good. uh as a",
      "offset": 2499.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "negative evidence and that's absolutely",
      "offset": 2502.72,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "true. He's absolutely right about that.",
      "offset": 2504.4,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "That's in fact one of the criteria that",
      "offset": 2505.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we use to get down to a unique the base",
      "offset": 2507.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "factor measure. So I think Popper what",
      "offset": 2509.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "he what he wasn't right about was that",
      "offset": 2512.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "all there is is reputation. So Paer had",
      "offset": 2515.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this weird view that there's no such",
      "offset": 2517.599,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "thing as inductive arguments here. I",
      "offset": 2519.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "think he was influenced by Hume. I think",
      "offset": 2521.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "he really got hooked on that uh",
      "offset": 2523.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "skeptical argument and he thought well",
      "offset": 2525.359,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "the only arguments that could be",
      "offset": 2527.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "compelling must be deductive. So there",
      "offset": 2528.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "aren't any inductive arguments. So well",
      "offset": 2530.8,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "then everything must be reputation. That",
      "offset": 2533.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "is right there. That's all that would be",
      "offset": 2535.119,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "left. You couldn't have",
      "offset": 2536.8,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "disisconfirmation in a weaker sense",
      "offset": 2538,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "because that doesn't exist. I as I said",
      "offset": 2539.359,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "I'm not a skeptic. I'm an anti-keepic. I",
      "offset": 2542.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "think we know a lot of stuff. I think we",
      "offset": 2544.8,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "can make distinctions between reputation",
      "offset": 2546.48,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "and just negative evidence that's not",
      "offset": 2548.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "refuting. Now of course it's difficult.",
      "offset": 2550.04,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "It's an art. You have to decide on a",
      "offset": 2552.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "probability distribution to use to",
      "offset": 2555.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "assess these things. Yes, you do have to",
      "offset": 2557.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "do that at the end of the day or at",
      "offset": 2560.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "least enough constraints on probability",
      "offset": 2561.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "so that you can say like what the",
      "offset": 2563.599,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "likelihood ratio is or something like",
      "offset": 2565.28,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "that. I mean you you need some",
      "offset": 2566.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "probabistic information to do that. But",
      "offset": 2568.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "I think we can obtain such proistic",
      "offset": 2570.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "information by doing statistics. So I'm",
      "offset": 2572.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "not a skeptic at all. I mean I I don't",
      "offset": 2574.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "have a problem. So I kind of don't worry",
      "offset": 2577.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "about the skeptical arguments in",
      "offset": 2579.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "epistemology at all including an",
      "offset": 2581.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "induction. Um but let me just say one",
      "offset": 2582.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "more thing. I think Paer was also right",
      "offset": 2584.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "in his criticisms in some of his",
      "offset": 2586.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "criticisms of the logical positivist.",
      "offset": 2587.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "So, Carnap was probably the the the real",
      "offset": 2589.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "uh best exemplar of someone who tried to",
      "offset": 2592.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "develop a logical empiricist in",
      "offset": 2594.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "inductive logic. And a lot of what he",
      "offset": 2596.72,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "says in his work is great and useful.",
      "offset": 2599.76,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "But there's one I think key mistake that",
      "offset": 2602.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "he makes and and that a lot of people",
      "offset": 2605.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "have made and that is this. He thought",
      "offset": 2607.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and I think many people still think",
      "offset": 2609.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "amazingly that there must exist a single",
      "offset": 2610.8,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "probability function such that every",
      "offset": 2614.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "argument strength can be measured with",
      "offset": 2617.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "that one function. I think this is wrong",
      "offset": 2619.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "but I do think what do you mean by a",
      "offset": 2622.319,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "probability function in that sentence?",
      "offset": 2623.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "Yeah. So there must be some probability",
      "offset": 2626,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "distribution over the relevant",
      "offset": 2628.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "propositions. Okay. Right. that such",
      "offset": 2629.839,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "that for any argument as if there's this",
      "offset": 2632.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "this uh it's they used to call it well",
      "offset": 2635.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "some people called it like the super",
      "offset": 2637.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "babies probability function or something",
      "offset": 2639.359,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "that there's this one probability",
      "offset": 2641.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "function that can assess accurately the",
      "offset": 2642.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "strength of any conceivable argument and",
      "offset": 2644.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "I just think this is absurd it doesn't",
      "offset": 2646.64,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "exist there's no such thing but I will",
      "offset": 2648.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "but I do think there's a weaker claim",
      "offset": 2650.319,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "that is true I want to say that for",
      "offset": 2651.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "every argument there exists a suitable",
      "offset": 2654,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "probability",
      "offset": 2656.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "function such that when you use that",
      "offset": 2657.96,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "probability function to assess the",
      "offset": 2660.4,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "strength of you get a pretty accurate",
      "offset": 2661.599,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "assessment of how strong the argument",
      "offset": 2663.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "is. And so I just want to reverse the",
      "offset": 2664.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "quantifiers. This idea that there's one",
      "offset": 2666.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "in the sky that works for every",
      "offset": 2668.72,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "argument. No, that's what Caro thought.",
      "offset": 2670.079,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "He was wrong about that. But I think",
      "offset": 2671.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "it's true probably that for every",
      "offset": 2673.359,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "argument there's some suitable",
      "offset": 2674.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "probability distribution that works that",
      "offset": 2676.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "gives you the right assessment of what",
      "offset": 2679.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the evidence favors or you know how",
      "offset": 2680.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "strong the evidence is. Is Carnap's idea",
      "offset": 2682.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "either identical to or at least related",
      "offset": 2685.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to an idea that we could find the one",
      "offset": 2687.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "true set of priors for all the these",
      "offset": 2689.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "propositions? Yes, that's right. That's",
      "offset": 2691.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "another way of think about. If you're a",
      "offset": 2694.079,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "basian, then you'll think so-called",
      "offset": 2695.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "objective basians think that there's one",
      "offset": 2696.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "probability function that will rule them",
      "offset": 2699.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "all or something like that. And of",
      "offset": 2702,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "course, that just won't work. I mean,",
      "offset": 2703.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you can just it's very easy to to cook.",
      "offset": 2704.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "And this is what Carnapp did for about",
      "offset": 2706.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "40 years. He kept getting more and more",
      "offset": 2708.48,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "sophisticated counter examples for",
      "offset": 2710.8,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "whatever specification of the single",
      "offset": 2713.079,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "family of probability distributions you",
      "offset": 2715.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "know and I just think this is a fool's",
      "offset": 2716.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "errand you don't need to do that science",
      "offset": 2718.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the way sc the way I think about science",
      "offset": 2721.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "is you have a theory so this theory is",
      "offset": 2723.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "just probability calculus with your like",
      "offset": 2726,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "with your base factor and your",
      "offset": 2728.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "conditional probability okay that's your",
      "offset": 2729.68,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "theory of inductive logic and now to to",
      "offset": 2731.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "apply the theory you have to construct",
      "offset": 2735.359,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "models of particular arguments in",
      "offset": 2736.64,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "particular contexts. That is an art and",
      "offset": 2738.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "a science. It's going to involve a lot",
      "offset": 2742.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "of statistics. It's usually going to be",
      "offset": 2744,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "empirical. It's going to involve a lot",
      "offset": 2745.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "of extra work. It isn't going to be",
      "offset": 2747.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "knowable priori. But why should it be?",
      "offset": 2749.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Yeah. You know, I just so I mean this",
      "offset": 2752.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "that was the logical empiricist's dream",
      "offset": 2754.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "that it had to be noble priori and so",
      "offset": 2756.24,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "there had to be just this one",
      "offset": 2758.079,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "probability function. You could divine a",
      "offset": 2759.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "priori uh to to determine all the",
      "offset": 2761.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "answers. And I just think no, that's not",
      "offset": 2763.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "how science works. there are uncountably",
      "offset": 2764.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "many probability distributions. Don't",
      "offset": 2766.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "tie your hands by not allowing yourself",
      "offset": 2768.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to use ones that science tells you are",
      "offset": 2770.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "appropriate. Um, and so that's just now",
      "offset": 2773.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that's going to be empirical matter of",
      "offset": 2775.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "constructing models of real arguments.",
      "offset": 2777.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "And this is going to be hard work and",
      "offset": 2780,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "there's going to be it's going to in",
      "offset": 2781.44,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "many cases it'll be controversial. But",
      "offset": 2782.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "this is the same thing that happens when",
      "offset": 2784.16,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "you're constructing models in science.",
      "offset": 2785.52,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "You got to make all kinds of",
      "offset": 2787.359,
      "duration": 2.841
    },
    {
      "lang": "en",
      "text": "assumptions, idealizations,",
      "offset": 2788.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "approximations and it's going to be",
      "offset": 2790.2,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "controversial how to do that the right",
      "offset": 2791.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "way. Yeah, that's itself part of",
      "offset": 2793.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "science, you know, and who said it was",
      "offset": 2796,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "going to be easy. Nobody said it was",
      "offset": 2798.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "going to be easy. That's for absolutely",
      "offset": 2800,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "sure. I don't I don't think they did. Uh",
      "offset": 2801.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "but okay, as someone who lives in",
      "offset": 2804,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "Baltimore, um home of Eden Poe and the",
      "offset": 2806.8,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "Baltimore Ravens, I am very fond of what",
      "offset": 2810.96,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "we call the paradox of confirmation.",
      "offset": 2813.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Like as soon as you have this idea that",
      "offset": 2817.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "you're going to start confirming things,",
      "offset": 2819.2,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "you get in trouble and the philosophers",
      "offset": 2820.88,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "come along to tell you it's not going to",
      "offset": 2822.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "be so easy either.",
      "offset": 2823.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "Yes, there are many there are many",
      "offset": 2826.079,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "paradox of confiration, but I think",
      "offset": 2827.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you're thinking of a Hemple's par the",
      "offset": 2828.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Raven paradox. Hemple's paradox. Yeah,",
      "offset": 2830.64,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "this is a classic. Um, so the way this",
      "offset": 2832.64,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "one goes is it involves a specific kind",
      "offset": 2836.319,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "of hypothesis. Uh, something like this.",
      "offset": 2839.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "All ravens are black. That's a",
      "offset": 2841.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "hypothesis we could have, we could",
      "offset": 2843.839,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "formulate. Suppose we hypothesize that",
      "offset": 2845.44,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "all ribbons are black. And if if you",
      "offset": 2847.28,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "want that to work, the way we usually",
      "offset": 2851.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "think we're confirming that is we make a",
      "offset": 2854.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "lot of observations, you know. So we",
      "offset": 2856,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "observe a whole bunch of positive",
      "offset": 2858.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "instances. Uh and we think by the more",
      "offset": 2860,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "positive instances we observe, you know,",
      "offset": 2863.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "by and large, the the better supported",
      "offset": 2865.52,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "this hypothesis is. Okay. But that",
      "offset": 2868.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "assumes that even just a single uh",
      "offset": 2871.599,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "instance would provide some support and",
      "offset": 2874.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "maybe just a tiny amount but it'll raise",
      "offset": 2876.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the probability a little bit of the",
      "offset": 2878.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "hypothesis which is a plausible idea.",
      "offset": 2880.56,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "The problem is uh if you accept that",
      "offset": 2883.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "principle that a positive instance",
      "offset": 2887.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "provides some support for a a universal",
      "offset": 2889.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "claim. So like the observation of a",
      "offset": 2891.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "black raven should support a little bit",
      "offset": 2893.599,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "that all ravens are black. Uh, of course",
      "offset": 2894.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you need many to do a lot of confirming",
      "offset": 2897.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "but you but one does something right",
      "offset": 2898.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that's how you get started. The problem",
      "offset": 2900.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "with that is if you accept that and then",
      "offset": 2902.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you accept the following principle which",
      "offset": 2904.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "sounds very plausible that if if a piece",
      "offset": 2906.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "of evidence supports a hypothesis then",
      "offset": 2909.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "it supports anything logically",
      "offset": 2910.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "equivalent to that hypothesis. Sure.",
      "offset": 2912.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "That seems right. I mean logical",
      "offset": 2914.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "equivalence that's a really strong form",
      "offset": 2916.319,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "of equivalence. So anything that's",
      "offset": 2917.92,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "evidence for something should be",
      "offset": 2919.2,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "evidence for something logically",
      "offset": 2920.319,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "equivalent. In fact we would just think",
      "offset": 2921.44,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "they're the same hypothesis. Well,",
      "offset": 2922.72,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "okay. All ravens are black is logically",
      "offset": 2926.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "equivalent to all non-black things are",
      "offset": 2928.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "non-raven. And now what's a positive",
      "offset": 2931.319,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "instance of that hypothesis? Well, it",
      "offset": 2933.52,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "would be the observation of a non-black",
      "offset": 2935.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "non-raven. Okay, but now you get the",
      "offset": 2938.52,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "conclusion that the observing non-black",
      "offset": 2940.8,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "non-ravens confirms that all ravens are",
      "offset": 2942.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "black. Okay, that's that doesn't sound",
      "offset": 2945.079,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "good because it sounds like uh you can",
      "offset": 2947.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "engage in what Nelson Goodman used to",
      "offset": 2950.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "call indoor ornithology.",
      "offset": 2951.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "um you just observe a bunch of shoes,",
      "offset": 2954.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "you know, or you know, and or you know,",
      "offset": 2956.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "uh you observe a bunch of white shoes,",
      "offset": 2958.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you know, non a bunch of non-black",
      "offset": 2961.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "non-ravens, and you're going to get a",
      "offset": 2962.4,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "lot of confirmation for the hypothesis.",
      "offset": 2964.16,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "Well, that's definitely a problem. But",
      "offset": 2966.599,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "this is where the quantitative theory of",
      "offset": 2970.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "confirmation helps. So, yes, let's",
      "offset": 2972.559,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "suppose you get some confirmation,",
      "offset": 2975.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "right? But now that leaves open the",
      "offset": 2977.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "following question. Might it not be the",
      "offset": 2979.52,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "case that the amount of confirmation",
      "offset": 2982,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "provided by the observation of a",
      "offset": 2984.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "non-black number is much much less, you",
      "offset": 2985.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "know, in in the circumstances we think",
      "offset": 2987.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "we find ourselves in than the",
      "offset": 2989.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "observation of a black raven. And in",
      "offset": 2990.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "fact, given very plausible assumptions",
      "offset": 2993.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "about statistical sampling or however",
      "offset": 2995.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you're modeling, you know, the usual",
      "offset": 2997.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "statistical models of of observing these",
      "offset": 2999.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "things, um, given very plausible",
      "offset": 3001.28,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "assumptions about the world, you know,",
      "offset": 3004,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "here's one assumption. There are a lot",
      "offset": 3006.559,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "more non-black things than there are",
      "offset": 3008.64,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "ravens. That seems right. Okay. So that",
      "offset": 3011.48,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "and if you think that's true and it's",
      "offset": 3015.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "still true even if you suppose that all",
      "offset": 3018.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "ravens are black, that is that wouldn't",
      "offset": 3020.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "affect much the rate the relative",
      "offset": 3022.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "proportions",
      "offset": 3024.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "um then it just follows that you're",
      "offset": 3025.76,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "going to get more support by by of the",
      "offset": 3028.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "hypothesis by the observation of a black",
      "offset": 3031.359,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "raven than by the observation of a",
      "offset": 3032.96,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "non-black non-raven. So this is where",
      "offset": 3034.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the quantitative theory really helps.",
      "offset": 3036.079,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "And statistics gives us that. It gives",
      "offset": 3037.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "us a quantitative way to estimate how",
      "offset": 3039.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "much of an effect uh an observation has.",
      "offset": 3042.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "And so given very plausible assumptions,",
      "offset": 3045.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "it's just going to be yeah, you get it's",
      "offset": 3047.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "some evidence, but it's extremely weak",
      "offset": 3049.44,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "compared to the evidence you get from",
      "offset": 3051.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "black ravens. And you can make this much",
      "offset": 3053.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "more precise and you can show that in",
      "offset": 3055.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "general it's just much more informative",
      "offset": 3057.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to say sample from the ravens and see if",
      "offset": 3059.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "they're black than sample from the",
      "offset": 3061.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "non-black things and see if they're non-",
      "offset": 3064.079,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "ravens, right? Uh and you can just make",
      "offset": 3065.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "this very quantitative using the theory",
      "offset": 3068.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of confirmation just these b factors.",
      "offset": 3070,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "And given very plausible assumptions",
      "offset": 3072.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "about what we think the probability",
      "offset": 3074.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "distributions look like, it's just going",
      "offset": 3075.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "to follow that the best way to do the",
      "offset": 3077.839,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "experiment is to sample from the ravens",
      "offset": 3080.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "and see if they're all black as opposed",
      "offset": 3082.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "to sampling from the non-black objects",
      "offset": 3084.319,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "and seeing if they're not ravens. Well,",
      "offset": 3085.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and for the non- philosophers out there,",
      "offset": 3087.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "just to remind them that this notion of",
      "offset": 3089.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "confirmation is extremely weak, right?",
      "offset": 3092,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "When you say observing a white shoe",
      "offset": 3093.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "confirms that all ravens are black, it's",
      "offset": 3096.359,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "really it's closer to supports. You even",
      "offset": 3098.8,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "use supports a couple of times there as",
      "offset": 3100.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "as a synonym provides a tiny amount of",
      "offset": 3102.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "evidence that might be really really",
      "offset": 3104.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "tiny. Yeah, it could be a it's just a",
      "offset": 3106.16,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "some bump. It just means the probability",
      "offset": 3108.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "goes up, but it could go up and a tiny",
      "offset": 3110.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "amount. And in fact, this is what we",
      "offset": 3112.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "think happens when we sample from the",
      "offset": 3114.16,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "non-black things and see whether they're",
      "offset": 3115.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "non- ravens as opposed to sampling from",
      "offset": 3117.28,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "the ravens, seeing whether they're",
      "offset": 3119.28,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "black. We just think there's a much",
      "offset": 3120.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "larger effect there. So although there's",
      "offset": 3121.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "some effect, yeah, it's not like it's",
      "offset": 3124.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "totally gives you no information. And by",
      "offset": 3126.8,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "the way, it's plausible that you should",
      "offset": 3128.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "get some information because if you",
      "offset": 3129.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "observe a non-black non-raven, then what",
      "offset": 3132.4,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "you've done is you've ruled one object",
      "offset": 3134.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "out. You know that there's one object in",
      "offset": 3136.079,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "the universe that can't be a counter",
      "offset": 3137.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "example to the hypothesis. And so in",
      "offset": 3139.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that sense, yes, you've gotten maybe a",
      "offset": 3141.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "tiny bit of support, but it's it's",
      "offset": 3144,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "absolutely minuscule compared to what",
      "offset": 3146.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "happens when you sample from the Ravens",
      "offset": 3148.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "and see if they're all black. Okay,",
      "offset": 3149.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "good. So I'm I'm on board the the",
      "offset": 3151.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "confirmation train here. Um but we still",
      "offset": 3153.839,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "you mentioned in passing the idea of a",
      "offset": 3157.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "quantitative measure of this",
      "offset": 3159.92,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "confirmation factor. Um in one of the",
      "offset": 3161.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "papers that that you wrote that that I",
      "offset": 3164.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "actually read some of um you go through",
      "offset": 3166.8,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "different plausible suggestions for what",
      "offset": 3169.28,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the equation should be for giving you",
      "offset": 3172.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "what that confirmation factor is. And",
      "offset": 3175.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "and there's something called the",
      "offset": 3177.359,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "received view that uh would you call the",
      "offset": 3178.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "received view? Do other people also call",
      "offset": 3182.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "it the received view? I don't even know.",
      "offset": 3183.68,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "Uh well, it's just",
      "offset": 3185.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "I think it is just kind of the",
      "offset": 3187.88,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "conventional wisdom about how to think",
      "offset": 3190,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "about strength of arguments. Yeah.",
      "offset": 3191.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "Right. Okay. And you and that relates",
      "offset": 3192.88,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "this confirmation factor to a",
      "offset": 3194.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "conditional probability. And I know that",
      "offset": 3196.68,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "um some large fraction of your",
      "offset": 3199.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "intellectual life is spent thinking",
      "offset": 3202,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "about conditional probabilities. So why",
      "offset": 3203.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "don't you tell us what a conditional",
      "offset": 3205.119,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "probability is and why it might be",
      "offset": 3206.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "related to a confirmation?",
      "offset": 3208.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "Yeah. So, so, so one thing you",
      "offset": 3210.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "definitely want to know, it's just going",
      "offset": 3213.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "back to the disease case. One thing you",
      "offset": 3215.359,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "definitely want to know, maybe the most",
      "offset": 3217.04,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "important thing you want to know is how",
      "offset": 3218.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "probable is it that you have the disease",
      "offset": 3219.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "conditional on or given that you get a",
      "offset": 3222.24,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "positive result, right? That's called",
      "offset": 3224.72,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "the conditional probability. And the way",
      "offset": 3226.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "it works is you do this. You suppose",
      "offset": 3227.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "that you get a positive result and then",
      "offset": 3230.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "you ask yourself given that supposition,",
      "offset": 3231.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "supposing the world is that way, how",
      "offset": 3233.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "probable is it that I have the disease?",
      "offset": 3235.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Um, and that's sort of the natural way",
      "offset": 3237.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "of thinking about it. And so conditional",
      "offset": 3240.64,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "probabilities are essential to",
      "offset": 3241.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "induction. Um, but of course there's",
      "offset": 3243.88,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "many different kinds. There's many",
      "offset": 3246.72,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "different conditional probabilities.",
      "offset": 3248,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "There's the probability of H given E,",
      "offset": 3248.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that posterior probability. That's",
      "offset": 3250.8,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "really important. But there's also the",
      "offset": 3252.24,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "likelihood, the probability of E given",
      "offset": 3253.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "H, that true positive rate. And there's",
      "offset": 3255.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "also the probability of E given not H,",
      "offset": 3257.359,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "the false positive rate. E. So there's",
      "offset": 3258.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "actually evidence and hypothesis. Yeah,",
      "offset": 3260.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "E and H are evidence and hypothesis. So",
      "offset": 3263.359,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "E, let's say, is a positive test result.",
      "offset": 3265.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "H is that you have the disease and of",
      "offset": 3266.72,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "course what you want to know is how",
      "offset": 3268.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "probable is H given E right suppose E to",
      "offset": 3269.839,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "be true how pro and then if you learn E",
      "offset": 3272.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "then you update you update and you",
      "offset": 3274.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "accept as your new probability the old",
      "offset": 3277.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "conditional probability that's sort of",
      "offset": 3279.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the basian way of doing things um and",
      "offset": 3280.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "yeah you definitely want to know that of",
      "offset": 3283.119,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "course that's like that's a very good",
      "offset": 3284.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "thing to know but knowing that requires",
      "offset": 3286.16,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "you to know not just the true positive",
      "offset": 3290,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "rate and the false positive rate of the",
      "offset": 3292.8,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "test but also the prior the",
      "offset": 3294.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "unconditional prob the probability prior",
      "offset": 3295.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "to the evidence before learning how the",
      "offset": 3297.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "experiment turned out and of course",
      "offset": 3299.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "that's going to vary very greatly from",
      "offset": 3302.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "subject to subject from person to person",
      "offset": 3304.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "who's judging the evidence. So",
      "offset": 3307.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "conditional probability is super",
      "offset": 3310.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "important and I still want to say that",
      "offset": 3311.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "is one of the features that makes",
      "offset": 3313.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "something a strong argument. You",
      "offset": 3315.68,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "definitely want the you definitely want",
      "offset": 3317.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the hypothesis to be more probable than",
      "offset": 3318.559,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "not at the very least given the evidence",
      "offset": 3320.24,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "if you're going to believe it. If you",
      "offset": 3322.079,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "think it's a reason to believe it,",
      "offset": 3323.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "that's part of the story. But I want us",
      "offset": 3325.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "and that's the conventional view about",
      "offset": 3327.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "how strong the con the received view is.",
      "offset": 3328.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "If you want to know how strong an",
      "offset": 3331.119,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "argument is, just calculate that",
      "offset": 3332.079,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "posterior probability, the probability",
      "offset": 3333.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "of H given E and that tells you how",
      "offset": 3334.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "strong a reason is E is for believing H.",
      "offset": 3336.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "But that can't be right. It can't be",
      "offset": 3338.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "right because take you or me. If we take",
      "offset": 3341.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "a pregnancy test, yeah, look, the",
      "offset": 3344.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "likelihoods are still the same. If we",
      "offset": 3346.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "happen to get a posit, which is of",
      "offset": 3348.799,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "course possible because physics and",
      "offset": 3350.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "because things aren't impossible, we",
      "offset": 3353.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "could get a positive result. Okay. Um",
      "offset": 3354.88,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "well, we but we we don't think that's a",
      "offset": 3358.4,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "good reason to believe that we're",
      "offset": 3360.64,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "pregnant because we know we're not. So,",
      "offset": 3361.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "what that means is there's another",
      "offset": 3363.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "dimension to the assessment of the",
      "offset": 3365.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "strength of arguments and that is what",
      "offset": 3367.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "we've been calling confirmation. And",
      "offset": 3368.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "basically I want to say it's just it's",
      "offset": 3370.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "just the the ratio of those two error",
      "offset": 3372.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "rates. It's just the the base factor,",
      "offset": 3374.24,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "the likelihood ratio, whatever you want",
      "offset": 3375.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "to call it. That's the way we measure",
      "offset": 3377.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that second dimension of confirmation.",
      "offset": 3378.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "And so I want to say there's a I have a",
      "offset": 3381.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "I'm offering a two-dimensional theory of",
      "offset": 3383.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "argument strength. For an argu to be",
      "offset": 3384.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "strong, it's got to be probable. Sure.",
      "offset": 3386.4,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "Yeah. It should be more prob the",
      "offset": 3388.16,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "conclusion should be more probable than",
      "offset": 3389.599,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "not given the premise or in this case",
      "offset": 3390.799,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "the hypothesis should be more probable",
      "offset": 3392.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "than not given the evidence. But also",
      "offset": 3394.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the evidence should be relevant. If the",
      "offset": 3396.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "evidence is irrelevant, it's not a",
      "offset": 3398.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "reason to believe the hypothesis at all.",
      "offset": 3400.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "Right? So if you have an argument where",
      "offset": 3403.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the premise is just irrelevant, doesn't",
      "offset": 3404.799,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "affect the probability of the conclusion",
      "offset": 3406.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "at all, then I don't want to say that's",
      "offset": 3407.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "a strong argument because that it's not",
      "offset": 3410,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "a reason to believe the conclusion at",
      "offset": 3412.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "all. Okay? And so this was something",
      "offset": 3413.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "that the classical inductive logicians",
      "offset": 3416.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "just ignored. Not just Carnap, but if",
      "offset": 3418.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you read books on inductive logic all",
      "offset": 3420.799,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "the way up through Brian Scirms's book,",
      "offset": 3422.48,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "which is one of the state-of-the-art",
      "offset": 3423.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "books from the 2000s, um they just give",
      "offset": 3424.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "you this one dimension, the probability",
      "offset": 3427.839,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "of the conclusion given the premise. But",
      "offset": 3429.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "I just think that can't be the full",
      "offset": 3431.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "story because relevance, confirmation",
      "offset": 3432.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "also matters to as to whether something",
      "offset": 3435.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "should affect your beliefs. So, um let",
      "offset": 3437.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "me try to rephrase it because I'm not",
      "offset": 3440.24,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "sure I wrapped my brain completely",
      "offset": 3441.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "around it. Um the the the classical",
      "offset": 3443.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "story would say if the probability of",
      "offset": 3446,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the hypothesis given the evidence is",
      "offset": 3447.92,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "very high then that counts as",
      "offset": 3450.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "confirmation. But what if for example",
      "offset": 3451.799,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "the probability of the hypothesis is",
      "offset": 3454.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "just very high? What if we're already",
      "offset": 3456.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "convinced of it? Then it could be also",
      "offset": 3458.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "high given the evidence, but you",
      "offset": 3461.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "wouldn't count that as confirmation. Is",
      "offset": 3462.88,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "that the idea? That's right. That's",
      "offset": 3464.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "right. In fact, it could even be highly",
      "offset": 3465.839,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "probable given the evidence, but the",
      "offset": 3467.839,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "evidence makes it a little bit less",
      "offset": 3469.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "probable. Right. You definitely don't",
      "offset": 3471.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "want to say that's a reason to believe.",
      "offset": 3473.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "No, it if anything, it's a reason to",
      "offset": 3475.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "believe the hypothesis is false. Right?",
      "offset": 3477.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "It just so happens that it happens to",
      "offset": 3479.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "have still a high probability anyway",
      "offset": 3481.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "given the evidence, but that's probably",
      "offset": 3484.079,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "because it had such a high probability",
      "offset": 3487.04,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "to begin with. Okay? It's not it's not",
      "offset": 3488.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "that the evidence is a reason to believe",
      "offset": 3490.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "the hypothesis. And so when as logicians",
      "offset": 3492.319,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "what we want to know is not whether we",
      "offset": 3494.4,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "should believe the conclusion",
      "offset": 3496.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "simplicator but we want to know how",
      "offset": 3497.48,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "strong the the argument is as a reason",
      "offset": 3499.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "to believe the conclusion and that I",
      "offset": 3501.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "claim requires both probability and",
      "offset": 3504.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "relevance confirmation and simplictor is",
      "offset": 3506,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "weird philosopher talk for all else",
      "offset": 3508.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "being equal. Yeah that's right that's",
      "offset": 3510.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "right and sure if if the thing is",
      "offset": 3512.16,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "relevant then all that matters is the",
      "offset": 3514.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "probability but if it's not relevant",
      "offset": 3516.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "then it's not a strong argument I would",
      "offset": 3519.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "say. Good. So that sounds perfectly",
      "offset": 3520.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "plausible, but of course we're going to",
      "offset": 3524,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "want to know what is the way to know",
      "offset": 3525.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "whether something is relevant. Is there",
      "offset": 3527.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "is that just like a vibes based thing or",
      "offset": 3529.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "is there an equation?",
      "offset": 3531.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "There is an equation. There's and it is",
      "offset": 3534.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "just that the thing they give you when",
      "offset": 3536,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you buy the diagnostic test. They give",
      "offset": 3537.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you this ratio of the two error rates,",
      "offset": 3539.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the two likelihoods, the probability of",
      "offset": 3541.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "E given H and the probability of E given",
      "offset": 3543.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "not H. And you take that ratio, that's a",
      "offset": 3544.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "really good measure from an inductive",
      "offset": 3547.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "logical point of view. It's pretty much",
      "offset": 3549.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "the only one that's going to satisfy",
      "offset": 3550.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "these desitter we like. And so that's",
      "offset": 3552.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "how I propose. So I'm proposing a two",
      "offset": 3554.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "dimen. So you can visualize it as like a",
      "offset": 3556.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "cartisian space. The x-axis is the",
      "offset": 3558.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "conditional probability of the",
      "offset": 3561.04,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "conclusion given the premise. And the",
      "offset": 3562.16,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "y-axis is that likelihood ratio that is",
      "offset": 3564.559,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "that measures how much impact how",
      "offset": 3568.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "relevant uh the premise is to the",
      "offset": 3570.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "conclusion or the evidence is to the",
      "offset": 3573.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "hypothesis and sort of and yeah so so",
      "offset": 3574.559,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "there's no one number at the end of the",
      "offset": 3577.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "day. Okay. It's not like you add those",
      "offset": 3579.359,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "two together or you add their squares",
      "offset": 3580.64,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "together or whatever. It's just you got",
      "offset": 3582.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "to give me both numbers. Yes. And I",
      "offset": 3584.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "think this is a really fundamental thing",
      "offset": 3587.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that's so important to emphasize. I",
      "offset": 3589.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "think one of the real deepest mistakes",
      "offset": 3591.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "that was made in the history of",
      "offset": 3593.92,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "inductive logic was that they thought",
      "offset": 3594.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "there'd be a single measure on which you",
      "offset": 3596.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "could totally order all the arguments in",
      "offset": 3599.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "terms of their strength. A single",
      "offset": 3601.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "function that takes a premise and a",
      "offset": 3603.359,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "conclusion and a probability",
      "offset": 3605.68,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "distribution and gives you a single",
      "offset": 3606.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "number. I don't think this can be done.",
      "offset": 3608.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "I think what it gives you is a ordered",
      "offset": 3610.559,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "pair. Yeah, it gives you a probability",
      "offset": 3612.559,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "and a baze factor. Good. And that's all",
      "offset": 3615.04,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "I think in general that can be said.",
      "offset": 3618.559,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "Now, of course, you can say some things.",
      "offset": 3620.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "There's a there's some ordering because",
      "offset": 3621.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "if if the evidence if you move up both",
      "offset": 3623.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "in terms of probability and relevance,",
      "offset": 3626.88,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "well, then you've gotten stronger",
      "offset": 3628.24,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "because you've gotten stronger in both",
      "offset": 3629.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "dimensions. But these mixed cases, this",
      "offset": 3630.559,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "is the problem. cases where you have",
      "offset": 3633.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "improbability but high confirmation like",
      "offset": 3635.319,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "the base rate fallacy or cases like the",
      "offset": 3637.599,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "conjunction fallacy which also involve",
      "offset": 3640.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "relevance going one way, confirmation",
      "offset": 3643.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "going one way but probability going the",
      "offset": 3644.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "other way. And so these mixed cases",
      "offset": 3646.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "which I think it's no surprise they led",
      "offset": 3648.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to the Nobel Prize about concerning how",
      "offset": 3650.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "quote unquote bad people are at",
      "offset": 3653.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "probabistic reasoning. I think it's",
      "offset": 3654.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "because the cases are mixed that people",
      "offset": 3657.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "get confused. If you ask someone how",
      "offset": 3659.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "strong is an argument? Well, if it if",
      "offset": 3661.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that has two dimensions to it and one of",
      "offset": 3663.52,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "them's high and the other's",
      "offset": 3666.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "low, that's ambiguous. The question's",
      "offset": 3669.079,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "ambiguous. And so you you could you",
      "offset": 3671.68,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "might not blame them so much if they're",
      "offset": 3674.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "a little confused about those arguments",
      "offset": 3676.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "where you have high relevance and low",
      "offset": 3679.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "probability or, you know, high",
      "offset": 3680.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "probability and low relevance. Those are",
      "offset": 3683.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "hard cases to to assess. Yeah. Right.",
      "offset": 3684.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "for for most people because because they",
      "offset": 3687.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "realize both factors are relevant and",
      "offset": 3689.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "what they're being asked for is a single",
      "offset": 3691.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "summary a single assessment but maybe",
      "offset": 3693.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "there isn't maybe it's ambiguous maybe",
      "offset": 3696,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "it's strong in one sense but not in the",
      "offset": 3698.799,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "other and so I I in general want there",
      "offset": 3700.799,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "to just be two dimensions and so you I",
      "offset": 3703.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "don't think there's a total ordering a",
      "offset": 3706.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "single number you get for any argument",
      "offset": 3708.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "in any probability distribution there's",
      "offset": 3710.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "going to be two numbers I think in",
      "offset": 3712.24,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "general and has and I think that's one",
      "offset": 3713.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "of the mistakes yeah has everyone",
      "offset": 3715.359,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "basically agreed with your impeccable",
      "offset": 3716.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "logic here. Well, I mean, some people",
      "offset": 3718.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "have. So, there, you know, in",
      "offset": 3721.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "psychology, so we did I I had the",
      "offset": 3723.52,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "pleasure of working with some",
      "offset": 3726.24,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "psychologists on these reason quote",
      "offset": 3727.4,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "unquote reasoning fallacies. And yes,",
      "offset": 3729.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "there's a lot of experimental evidence",
      "offset": 3731.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "now that it's the mixed cases that are",
      "offset": 3733.359,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "hard and it's and they're hard because",
      "offset": 3735.839,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "they're mixed. And so if you fiddle with",
      "offset": 3737.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the confirmation that is the relevance,",
      "offset": 3739.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "you fiddle with that Y dimension, it's",
      "offset": 3741.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "really going to affect how good people",
      "offset": 3743.2,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "are making judgments about the X",
      "offset": 3744.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "dimension. And so and I think this is",
      "offset": 3746.16,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "because what people really care about is",
      "offset": 3749.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "not just how probable the conclusion is",
      "offset": 3751.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "given the premise. They care about how",
      "offset": 3753.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "strong is this as a reason to believe",
      "offset": 3755.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the conclusion. And intuitively they",
      "offset": 3757.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "know that depends not only on the",
      "offset": 3759.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "probability but on whether the evidence",
      "offset": 3760.96,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "is relevant, whether the evidence",
      "offset": 3762.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "confirms the hypothesis. And so there's",
      "offset": 3763.839,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "a lot of psychological evidence now that",
      "offset": 3766.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that that notion of confirmation really",
      "offset": 3768.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "is relevant to explaining what's going",
      "offset": 3770.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "on in these cases. So let's go through",
      "offset": 3772.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "some of these cases a little bit more",
      "offset": 3775.04,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "carefully because I'm sure that people",
      "offset": 3776.24,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "have kind of vaguely heard of them, but",
      "offset": 3777.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "you know, it's always good to be clear.",
      "offset": 3779.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "The the conjunction fallacy, I think you",
      "offset": 3780.799,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "already mentioned, and it is one of my",
      "offset": 3783.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "favorites because I was not fooled by it",
      "offset": 3785.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "when I first saw it, but uh I saw why I",
      "offset": 3787.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "could be fooled by it, so I'm",
      "offset": 3790.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "sympathetic. Yeah. Yeah. Let me let me",
      "offset": 3791.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "That's a great one. That's a great one.",
      "offset": 3794.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "So, um what the way that one works is",
      "offset": 3796.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you're given some evidence about a woman",
      "offset": 3798.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "named Linda. You're basically told that",
      "offset": 3800.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "she uh so she was she went to Berkeley",
      "offset": 3802.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "in the late60s. She participated in",
      "offset": 3805.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "anti-uclear demonstrations. She was very",
      "offset": 3807.92,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "active um politically and so on and so",
      "offset": 3809.92,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "forth. She was like a flower child and",
      "offset": 3813.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "so on and so forth. And that's the",
      "offset": 3815.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "evidence you're given. And now you're",
      "offset": 3817.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "asked, this is years later, you're",
      "offset": 3819.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "asked, okay, now I have two hypotheses",
      "offset": 3820.799,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "I'm going to give you about Linda",
      "offset": 3822.72,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "nowadays. Either she's a bank",
      "offset": 3824.76,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "teller or she's a feminist bank teller.",
      "offset": 3828.2,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "And you're asked which is more probable",
      "offset": 3831.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "given the evidence that I gave you. And",
      "offset": 3832.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "back in the day, a lot of people said",
      "offset": 3835.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "feminist bank teller was more probable",
      "offset": 3837.2,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "given that evidence. Of course, that's",
      "offset": 3839.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "impossible because feminist bank teller",
      "offset": 3841.799,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "entails bank teller. So every possible",
      "offset": 3845.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "world in which which she's a founder,",
      "offset": 3848.079,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "there is a world in which she's a bank",
      "offset": 3849.68,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "teller. And since probability is just a",
      "offset": 3850.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "measure of, you know, how big a class of",
      "offset": 3852.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "possible worlds is, it couldn't possibly",
      "offset": 3854.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "be that the conjunction is more probable",
      "offset": 3856.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "than one of its conjuncts that that that",
      "offset": 3858.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "would just violate basic logical and",
      "offset": 3861.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "probabilistic principles. So that can't",
      "offset": 3863.039,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "happen. So what's going on? Well, what",
      "offset": 3864.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "we showed in a paper that we wrote, and",
      "offset": 3868.319,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "there's been a lot of research on this",
      "offset": 3870.24,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "since then, is that two very simple",
      "offset": 3871.599,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "assumptions, if two very simple",
      "offset": 3874.92,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "assumptions hold, which I'm going to",
      "offset": 3876.799,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "give you in a second, then it's just",
      "offset": 3877.76,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "guaranteed that while yes, the the bank",
      "offset": 3880.28,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "teller hypothesis is going to be more",
      "offset": 3884,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "probable than the feminist bank teller",
      "offset": 3885.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "hypothesis, the evidence will actually",
      "offset": 3887.16,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "confirm the feminist bank teller",
      "offset": 3889.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "hypothesis more strongly. it'll be more",
      "offset": 3892.079,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "relevant to that conjunction than it is",
      "offset": 3894.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "to the first contract. And here are the",
      "offset": 3896.559,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "assumptions. They're very weak. First",
      "offset": 3898.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "assumption, the evidence isn't",
      "offset": 3900.119,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "positively relevant to whether she's a",
      "offset": 3902.24,
      "duration": 2.839
    },
    {
      "lang": "en",
      "text": "bank",
      "offset": 3903.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "teller. That seems plausible. Okay.",
      "offset": 3905.079,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Second assumption, suppose she is a bank",
      "offset": 3907.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "teller. The evidence I gave you still",
      "offset": 3910.039,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "positively relevant to some degree to",
      "offset": 3912.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "her being a feminist. Maybe a only a",
      "offset": 3914.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "tiny amount, but still still somewhat",
      "offset": 3915.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "relevant to her being a feminist. those",
      "offset": 3918.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "conditions entail that for any way of",
      "offset": 3920.64,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "measuring confirmation for any of the",
      "offset": 3922.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "measures. It turns out the evidence will",
      "offset": 3924.839,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "confirm the conjunction more strongly",
      "offset": 3927.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "than it confirms the conjunct. And so",
      "offset": 3929.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "these are cases, they're mixed cases.",
      "offset": 3932.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "You have a case where probability goes",
      "offset": 3934.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "one way, bank teller is more probable,",
      "offset": 3936.48,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "but bank teller is less relevant, right?",
      "offset": 3938.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "It's less well confirmed by the",
      "offset": 3941.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "evidence. And I think it's again no",
      "offset": 3943.28,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "surprise that just like in these rare",
      "offset": 3946.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "diagnostic testing cases, rare disease",
      "offset": 3949.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "cases which are called the base rate",
      "offset": 3951.28,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "fallacy cases which we already",
      "offset": 3952.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "discussed. Just like in those cases,",
      "offset": 3954.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "these cases involve one of the",
      "offset": 3956.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "dimensions of assessment probability",
      "offset": 3958.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "going one way and the other dimension of",
      "offset": 3960.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "assessment of the strength of argument",
      "offset": 3962,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "confirmation or relevance going the",
      "offset": 3963.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "other way. And I'm not at all surprised",
      "offset": 3964.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "that people defer to relevance. Right?",
      "offset": 3966.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "It makes sense. We already saw relevance",
      "offset": 3970.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "is in many ways more objective. It's",
      "offset": 3972.319,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "more invariant. It's it's it's sort of",
      "offset": 3974,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the language of science. The way science",
      "offset": 3976.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "understands evidence, it usually thinks",
      "offset": 3978.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "in terms of how much the evidence",
      "offset": 3980.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "confirms, not how probable hypothesis,",
      "offset": 3982.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and that depends on all these",
      "offset": 3984.64,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "idiosyncrasies about prior",
      "offset": 3986.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "probabilities. So I'm not at all",
      "offset": 3987.88,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "surprised that people do any of these",
      "offset": 3990.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "things. So I I say it's kind of makes",
      "offset": 3992.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "sense that when uh the confirmation goes",
      "offset": 3995.039,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "one way and probability goes another",
      "offset": 3997.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "way, deferring to the confirmation kind",
      "offset": 3999.359,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "of makes sense since there are many ways",
      "offset": 4001.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "in which confirmation is just more more",
      "offset": 4003.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "important, more informative, more",
      "offset": 4005.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "objective than than probability is. So I",
      "offset": 4006.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "have a slightly different or I had um",
      "offset": 4009.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "for a while after hearing about the",
      "offset": 4012.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "experimental results uh slightly",
      "offset": 4014.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "different hypothesis about what was",
      "offset": 4016.559,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "going on, but I'm not sure if it's",
      "offset": 4018.319,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "slightly different. So, let me uh",
      "offset": 4019.52,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "explain it to you and you tell me if",
      "offset": 4021.28,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "it's different. I I'm wondering whether",
      "offset": 4022.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "or not when people hear, you know, the",
      "offset": 4024.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "evidence, which in this case is Linda",
      "offset": 4026.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "went to Berkeley, she was a flower",
      "offset": 4028.96,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "child, she was an activist, and then",
      "offset": 4030.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "they're given the two hypotheses, she's",
      "offset": 4032.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "a bank teller, um and or she's a bank a",
      "offset": 4033.839,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "feminist bank teller. Um, implicitly",
      "offset": 4036.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "they assume that being a bank teller",
      "offset": 4040.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "means that you're a typical bank teller",
      "offset": 4042.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "and being a feminist bank teller assumes",
      "offset": 4045.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that you're a typical feminist bank",
      "offset": 4047.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "teller and the typical bank teller is",
      "offset": 4049.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "not feminist. So there's some sort of",
      "offset": 4051.359,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "interference or tension between the",
      "offset": 4054.24,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "hypothesis that she's a bank teller and",
      "offset": 4057.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "the evidence that she was a flower",
      "offset": 4059.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "child. Uh it's it's still a sort of a",
      "offset": 4061.039,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "mistake with the question phrased as it",
      "offset": 4063.599,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "was, but I mean that would be a way of",
      "offset": 4066.319,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "psychologizing why we make the mistake.",
      "offset": 4068.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "I'm not sure if it's the same as your",
      "offset": 4070.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "way or different. Well, yes. So, there",
      "offset": 4072.079,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "have been many uh proposals for",
      "offset": 4074.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "different things that might be going on.",
      "offset": 4077.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "One of them that was received a lot of",
      "offset": 4079.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "attention early on which is similar.",
      "offset": 4081.839,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "It's in some ways maybe you can tell me",
      "offset": 4083.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "I think it's related to what you were uh",
      "offset": 4084.799,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "saying",
      "offset": 4087.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "is it was originally postulated that",
      "offset": 4088.44,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "actually people were hearing the",
      "offset": 4090.96,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "question slightly different. They're",
      "offset": 4092.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "hearing it as feminist bank teller",
      "offset": 4093.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "versus non feminist bank teller. Yeah.",
      "offset": 4096,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "And actually there's definitive",
      "offset": 4099.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "psychological research that that's not",
      "offset": 4101.759,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "what's happening. So I can I can show I",
      "offset": 4103.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "can point you to papers that are just",
      "offset": 4105.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "absolutely stunning on this by some of",
      "offset": 4106.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "my psychological colleagues though.",
      "offset": 4108.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Okay. So there are experiments where",
      "offset": 4110.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "first they teach people how to do",
      "offset": 4113.92,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "deductive inferences. They teach them",
      "offset": 4115.839,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "how to in infer conjuncts from",
      "offset": 4117.759,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "conjunctions. They teach them all this",
      "offset": 4119.96,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "stuff and then they have them bet. They",
      "offset": 4122,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "have them do betting and they still a",
      "offset": 4125.199,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "lot of people bet more on the",
      "offset": 4127.759,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "conjunction even though they know that",
      "offset": 4129.64,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "the thing follows they've actually gone",
      "offset": 4132,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "through the logical exercise of it of it",
      "offset": 4133.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "following logically right that one",
      "offset": 4135.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "hypothesis entails the other. So this",
      "offset": 4137.839,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "has been controlled for I think in my",
      "offset": 4139.6,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "opinion this this particular hypothesis",
      "offset": 4141.199,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "is actually there's a lot of evidence",
      "offset": 4143.199,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "against it now. So I find the relevance",
      "offset": 4144.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "approach the confirmation approach um",
      "offset": 4147.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "more more plausible given all the",
      "offset": 4149.839,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "evidence u but of course this is you",
      "offset": 4152.08,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "know this is active area of research",
      "offset": 4154.239,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "there's some even more recent research",
      "offset": 4156.239,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "trying to refine the notion of relevance",
      "offset": 4158.239,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to go beyond confirmation and take into",
      "offset": 4159.92,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "account other pragmatic kinds of",
      "offset": 4161.759,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "relevance as well. Uh I I think that's",
      "offset": 4163.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "really fascinating research. But there's",
      "offset": 4165.52,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "pretty strong evidence now that this",
      "offset": 4167.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "this second dimension I'm calling it of",
      "offset": 4170.239,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "logic of argument strength is making a",
      "offset": 4172.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "significant difference. There may be",
      "offset": 4174.48,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "many other things that are making a",
      "offset": 4175.92,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "difference, but it's pretty clear it's",
      "offset": 4177.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "making a difference. I kind of love the",
      "offset": 4178.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "intersection of the actual psychology",
      "offset": 4180.56,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "experiments with the uh philosophical",
      "offset": 4183.04,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "reasoning at the most abstract level. It",
      "offset": 4186.319,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "does, you know, the rubber does hit the",
      "offset": 4188.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "road at some point. Oh, absolutely. I to",
      "offset": 4190.239,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "me that's that's one of the most",
      "offset": 4193.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "interesting areas of research in general",
      "offset": 4195.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "is that borderline between the",
      "offset": 4197.44,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "descriptive and the prescriptive. Yeah,",
      "offset": 4199.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "that's a really it's such a difficult",
      "offset": 4202.239,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "area but it's such an it's such an",
      "offset": 4204.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "important area because after all what",
      "offset": 4205.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "we're interested in is evidence for",
      "offset": 4208.4,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "humans. You know it's like you know this",
      "offset": 4210.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "is another weird thing about logical",
      "offset": 4213.679,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "empiricism. Who cares about evident if",
      "offset": 4214.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "it's if it's just some purely formal",
      "offset": 4218.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "logical relation between things? How",
      "offset": 4220.88,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "does that actually bear on what we ought",
      "offset": 4222.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to believe? So that's another problem",
      "offset": 4224.719,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "with the whole kind of logical",
      "offset": 4227.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "empiricist way of thinking. It's very",
      "offset": 4228.239,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "disembodied and abstract and it's just",
      "offset": 4230,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "unclear why it would ever have any",
      "offset": 4231.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "purchase on humans. Okay. So, let's um I",
      "offset": 4233.679,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "think one more example might seal the",
      "offset": 4236.96,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "deal here and and you suggested the four",
      "offset": 4239.36,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "card problem which I do remember look I",
      "offset": 4242.8,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "looked it up you had your paper but your",
      "offset": 4245.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "paper is full of like all these",
      "offset": 4247.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "equations and things so I just looked it",
      "offset": 4249.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "up on Wikipedia to remind me what it was",
      "offset": 4251.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and I do remember coming across the four",
      "offset": 4253.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "card problem and I that one I I did get",
      "offset": 4255.44,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "right just because I've uh done",
      "offset": 4257.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "probability problems before but but it",
      "offset": 4260.239,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "it's I I see the similarity here but the",
      "offset": 4262.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "argument plays out in a slightly",
      "offset": 4265.6,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "different way. So why don't you tell us",
      "offset": 4266.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "what the problem is? Yeah. So there's",
      "offset": 4267.76,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "this famous case uh of the waste and",
      "offset": 4270.4,
      "duration": 7.4
    },
    {
      "lang": "en",
      "text": "selection task is what it's called. Uh",
      "offset": 4273.92,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "and there's so the way it works is",
      "offset": 4277.8,
      "duration": 6.439
    },
    {
      "lang": "en",
      "text": "there's uh there's cards and now there's",
      "offset": 4281.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "different variants of it. So I'm trying",
      "offset": 4284.239,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "to remind myself of uh um the version",
      "offset": 4285.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that we that we actually worked on cuz I",
      "offset": 4288.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "don't want to talk about a version that",
      "offset": 4290.48,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "I don't. I actually know it. I I wrote",
      "offset": 4291.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "it down if you want me to give the the",
      "offset": 4293.84,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "problem and then you can explain this.",
      "offset": 4295.44,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "Yeah. Could you do that and then I can",
      "offset": 4296.88,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "Yeah. I mean the version that I know um",
      "offset": 4298.239,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "from your paper is that there are these",
      "offset": 4300.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "cards and you know that there's a number",
      "offset": 4302.159,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "on one side of the card, a letter on the",
      "offset": 4304.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "other side of the card. You know that.",
      "offset": 4307.199,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "And you're shown four cards. Um one says",
      "offset": 4309.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the letter D. The other says the letter",
      "offset": 4312.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "K. I don't know if this is for Daniel",
      "offset": 4315.28,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "Conorman or not. I don't know where",
      "offset": 4317.199,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "these letters came from. Um then it",
      "offset": 4318.239,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "shows the number three and the number",
      "offset": 4320.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "seven. Okay, so D K37. So obviously you",
      "offset": 4322.08,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "showed the letter side of two of them,",
      "offset": 4325.84,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "the number side of the other two. And",
      "offset": 4327.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "then the hypothesis is all cards that",
      "offset": 4328.88,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "have D on one side will necessarily have",
      "offset": 4332.56,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "three on the other side. And the",
      "offset": 4335.84,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "question is which cards do you have to",
      "offset": 4338.719,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "flip over to most efficiently test that",
      "offset": 4341.04,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "hypothesis that if D is on one side,",
      "offset": 4344.719,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "three is on the other side? And you've",
      "offset": 4347.28,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "shown DK37.",
      "offset": 4348.88,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "Yes. Yes. And so yeah, so this is this",
      "offset": 4352.239,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "is a great case. So we wrote this paper",
      "offset": 4356.159,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "a while back. Me and Jim Hawthorne wrote",
      "offset": 4358.8,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "this really it's my favorite paper I've",
      "offset": 4360.719,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "ever written still to this day. And so",
      "offset": 4362.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "it's about this w selection task which",
      "offset": 4365.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "people make a certain kind of mistake in",
      "offset": 4367.28,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "uh tend to and its relation to the",
      "offset": 4370.56,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "paradox of confirmation which we already",
      "offset": 4374.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "talked about. So, you remember back in",
      "offset": 4376.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "uh when we were talking about the",
      "offset": 4379.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "paradox of confirmation that it it's a",
      "offset": 4380,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "better strategy to sample from the",
      "offset": 4383.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "ravens and see whether they're black",
      "offset": 4385.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "than it is to sample from the non-black",
      "offset": 4388.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "things and check whether they're non-",
      "offset": 4390.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "ravens. And it's just more",
      "offset": 4392.32,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "confirmationally powerful to do to",
      "offset": 4394.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "sample from the ravens and check and see",
      "offset": 4396.719,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "if they're black. This turns out to be",
      "offset": 4398.159,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "an isomorphic problem. This is this",
      "offset": 4399.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "problem is basically the same problem.",
      "offset": 4401.92,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "Okay.",
      "offset": 4404.8,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "Um because so what hypothesis are we",
      "offset": 4406.28,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "being asked to test in this in this",
      "offset": 4410.239,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "case? So we've got the four cards D, K,",
      "offset": 4412.239,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "three, and seven. And what what",
      "offset": 4414.88,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "hypothesis are we being asked to test?",
      "offset": 4417.199,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "If D is on one side, then three is on",
      "offset": 4420.239,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "the back. That's right. So all D cards",
      "offset": 4422.719,
      "duration": 7.761
    },
    {
      "lang": "en",
      "text": "are three cards. Yes. Or you could just",
      "offset": 4426.88,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "say all D's are threes. Yep.",
      "offset": 4430.48,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "Okay.",
      "offset": 4433.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Now all D's are threes. Same structure",
      "offset": 4434.04,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "as all Rs are B's. All Ravens are",
      "offset": 4437.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "blacks. And exact and the same kinds of",
      "offset": 4439.44,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "things happen. So what you what you want",
      "offset": 4442.56,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "to do is if you think about back to the",
      "offset": 4446.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Raven case, what did we say? The best",
      "offset": 4449.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "strategy is look at the Ravens and then",
      "offset": 4450.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "check and see uh whether you know",
      "offset": 4453.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "whether they're black. The analogous",
      "offset": 4455.12,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "thing here would be check the D card and",
      "offset": 4456.8,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "and then turn it over and see whether",
      "offset": 4460.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it's a three on the other side. Mhm.",
      "offset": 4463.199,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "That it is exactly the analogous thing.",
      "offset": 4465.28,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "And you can and the same models will",
      "offset": 4467.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "show that that's the most efficient way",
      "offset": 4469.679,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "to to to respond to this. And in fact,",
      "offset": 4472.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "if you just use some very weak",
      "offset": 4475.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "assumptions about probability and you",
      "offset": 4477.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "use this confirmation measure that we",
      "offset": 4478.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "were talking about, then you can",
      "offset": 4480.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "actually rank the strategies in terms of",
      "offset": 4482.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "their confirmational power and it'll",
      "offset": 4485.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "turn out given very weak assumptions",
      "offset": 4488,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "about what's going on that D turning",
      "offset": 4490.32,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "over the D card is the best. Then next",
      "offset": 4492.8,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "turning over the three",
      "offset": 4496,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "card. Oh, sorry. No, that's what people",
      "offset": 4497.56,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "actually do. Sorry. Right. That's what",
      "offset": 4499.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "people actually do. So, what people",
      "offset": 4501.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "actually do, this is great because I",
      "offset": 4503.6,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "just actually did it. What people",
      "offset": 4505.12,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "actually do is they turn over the three",
      "offset": 4506.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "card. That's the second best strategy.",
      "offset": 4508.08,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "That isn't the second best strategy,",
      "offset": 4510.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "right? They think that they're trying to",
      "offset": 4512.239,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "confirm, but uh that's not the best way",
      "offset": 4513.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "to learn. Yes. What you should be doing",
      "offset": 4515.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "is looking for counter examples, right?",
      "offset": 4518.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Next. So, you should turn over the seven",
      "offset": 4520.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "card, right, and see whether it's a D,",
      "offset": 4522.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "right? Yes. Exactly. And this is exactly",
      "offset": 4525.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "we show because that we actually showed",
      "offset": 4527.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that the two cases the paradoxation and",
      "offset": 4529.6,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "the wasting desk are actually",
      "offset": 4531.6,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "isomeorphic. They have basically the",
      "offset": 4532.48,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "same structure and that you can use the",
      "offset": 4533.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "same kinds of probability models to",
      "offset": 4536.719,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "model them and when you do you get",
      "offset": 4538.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "exactly the prescriptions in both cases.",
      "offset": 4540.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "You get best thing sample from the",
      "offset": 4542.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "ravens see if they're black. Next best",
      "offset": 4545.92,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "thing is look at the uh non black look",
      "offset": 4548.08,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "right the non-black things and see if",
      "offset": 4553.92,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "they're ravens. Right. look for counter",
      "offset": 4555.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "examples, right? Same thing here. But",
      "offset": 4556.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "what people actually do in this wasting",
      "offset": 4559.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "task, which is really interesting, is",
      "offset": 4561.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "they they reverse those the second and",
      "offset": 4563.44,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "third strategy. So what they do is uh",
      "offset": 4566.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "they'll say D first, but then they'll",
      "offset": 4568.159,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "say three. Yeah. They'll say no, turn",
      "offset": 4569.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "over the three card when that's",
      "offset": 4572.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "definitely less informative. And here",
      "offset": 4574.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the Paparian intuition really is",
      "offset": 4576.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "correct. You should be trying to refute",
      "offset": 4578.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "next. You should be looking at the seven",
      "offset": 4581.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "card. And as I as I was saying the",
      "offset": 4583.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Paparian thing, it's a the kernel of",
      "offset": 4585.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "truth of popper comes out in this paper",
      "offset": 4587.199,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "because basically you can just show that",
      "offset": 4589.92,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "after sampling from or sampling the D",
      "offset": 4593.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "card and looking to see whether it's a",
      "offset": 4596.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "three, the next best thing is looking at",
      "offset": 4597.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the at the seven and seeing whether it's",
      "offset": 4600.56,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "a D. That's that's uh that's poppers",
      "offset": 4602.64,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "intuition basically. And people aren't",
      "offset": 4606.8,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "paparian, it turns out, because they",
      "offset": 4609.199,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "think turnover of the three card is",
      "offset": 4610.719,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "better than turnover the seven card. But",
      "offset": 4611.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "actually, it's very easy to show just",
      "offset": 4613.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "using very weak assumptions about",
      "offset": 4615.199,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "probability that that's wrong. And so I",
      "offset": 4616.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "in a way this is a vindicate it's a",
      "offset": 4620.159,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "basian vindication of popper. That's one",
      "offset": 4621.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of the things I like about this paper.",
      "offset": 4623.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "It it tells you the kernel of truth in",
      "offset": 4625.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "in the paparian falsificationism that in",
      "offset": 4627.92,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "this case going for the falsification is",
      "offset": 4630.32,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "better. M uh it's it's the second best",
      "offset": 4632.92,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "thing and not the third best thing which",
      "offset": 4636.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "is what people tend to think it is.",
      "offset": 4638.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Yeah. But the thing that so but the",
      "offset": 4640.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "thing that people tend to do they they",
      "offset": 4642.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "they reason if it can be called that",
      "offset": 4644.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "they think well your hypothesis is that",
      "offset": 4647.28,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "if there's a D on one side there's a",
      "offset": 4649.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "three on the other. If I flip over the",
      "offset": 4651.199,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "three and I see a D on the other side",
      "offset": 4653.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "that will confirm that will give some",
      "offset": 4656.239,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "evidence for this in the space of all",
      "offset": 4658,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "possible cards.",
      "offset": 4659.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "That's a more likely thing to see. Yes.",
      "offset": 4661.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "And and and it it will confirm but",
      "offset": 4664.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "because reputations are always more",
      "offset": 4667.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "powerful than non-refutations. Exactly.",
      "offset": 4669.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Yeah. That's the Paparian insight and",
      "offset": 4670.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that's why Popper was correct. So yes,",
      "offset": 4672.8,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "you're you're absolutely right. It's a",
      "offset": 4675.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "kind of confirmation bias. And uh in our",
      "offset": 4676.239,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "paper we actually prove given very weak",
      "offset": 4679.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "assumptions that the only way to get",
      "offset": 4681.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that ordering is if you come into the",
      "offset": 4683.28,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "experiment with a confirmation bias.",
      "offset": 4685.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "That is you think you're more likely to",
      "offset": 4687.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "see positive instances rather than",
      "offset": 4690.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "counter examples. Exactly. Right. Good.",
      "offset": 4692.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "And you can just prove that that just",
      "offset": 4695.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "follows from the very weak modeling",
      "offset": 4697.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "assumptions we have that the only way to",
      "offset": 4698.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "get that ordering is going to be if you",
      "offset": 4701.04,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "come in already thinking that you're",
      "offset": 4702.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "more likely to get confirming instances",
      "offset": 4704.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "rather than refuting instances which is",
      "offset": 4705.92,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "is is sort of the classic confirmation",
      "offset": 4708.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "bias. And it is but it's not it is a",
      "offset": 4710.239,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "bias. And I think that in this case, you",
      "offset": 4713.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "know, the parameters are sufficiently",
      "offset": 4715.12,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "clean that uh doing D and 7 is is",
      "offset": 4716.96,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "clearly the right uh strategy here. But",
      "offset": 4721.199,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "the real world of science is",
      "offset": 4724.4,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "complicated, right? I mean, I guess, you",
      "offset": 4725.76,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "know, we're getting late in the podcast.",
      "offset": 4727.199,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "We can uh let our hair down and and",
      "offset": 4728.64,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "think about uh less uh completely",
      "offset": 4730.4,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "logically rigorous deductions here. I",
      "offset": 4734.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "mean, are there lessons for how we",
      "offset": 4736.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "should do science? like scientists are",
      "offset": 4739.199,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "constantly arguing about what",
      "offset": 4741.6,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "experiments are the best ones to do. Um",
      "offset": 4743.96,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "obviously it has to do with the",
      "offset": 4747.719,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "probability that your different",
      "offset": 4750.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "hypotheses are true, your priors, which",
      "offset": 4751.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "of course we don't agree on, but also I",
      "offset": 4753.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "think you would argue um the relevance",
      "offset": 4756.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "of that experimental result to changing",
      "offset": 4758.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "your beliefs.",
      "offset": 4761.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Absolutely. I think when a great way to",
      "offset": 4763.12,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "think about experimental design is to to",
      "offset": 4766.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "think what you're doing is you're trying",
      "offset": 4768.719,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "to maximize the confirmational power of",
      "offset": 4770.32,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "the evidence generated and that could be",
      "offset": 4773.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "so that's neutral as to whether it's",
      "offset": 4776.64,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "negative negatively relevant evidence",
      "offset": 4778.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "which it might be or positively relevant",
      "offset": 4780.239,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "but what you want to do is maximize the",
      "offset": 4782,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "confirmational power and that's the",
      "offset": 4783.679,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "framework of this waist and and uh",
      "offset": 4785.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "hemple paper that we did yeah where",
      "offset": 4786.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "we're basically just a very simple",
      "offset": 4788.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "measure of confirmational power it's",
      "offset": 4790.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "basically just the absolute value of",
      "offset": 4792.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "this you know of this confirmation",
      "offset": 4794.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "measure that we have and if you just try",
      "offset": 4796.239,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "to maximize that then you can just you",
      "offset": 4798.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "can just figure out which strategies are",
      "offset": 4800.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "going to do that now just to to your",
      "offset": 4802.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "more broad question just speaking a",
      "offset": 4804.64,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "little bit more philosophically here",
      "offset": 4806.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "zooming out a little bit so as I said I",
      "offset": 4808.239,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "think this is a very elegant theory of",
      "offset": 4811.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "inductive logic now in when you're",
      "offset": 4813.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "actually applying a theory you have to",
      "offset": 4815.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "construct models and this is where all",
      "offset": 4817.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the hard work comes in you got to really",
      "offset": 4819.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "come up with not necessarily a a an",
      "offset": 4821.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "exact probability distribution, but you",
      "offset": 4823.76,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "have to have enough constraints on your",
      "offset": 4825.28,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "probabilities to be able to decide",
      "offset": 4828.239,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "whether the evidence in your experiment",
      "offset": 4830.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "favors one hypothesis over another. And",
      "offset": 4831.679,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "you might not need to give an exact",
      "offset": 4834.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "numerical probability distribution over",
      "offset": 4836.719,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "everything, but you'll need enough",
      "offset": 4838.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "constraints to determine what whether",
      "offset": 4839.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "favoring occurs, you know, in which",
      "offset": 4842.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "direction it goes in. And how do you do",
      "offset": 4843.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that? Well, it's going to be quite",
      "offset": 4846.08,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "difficult in many cases. It's going to",
      "offset": 4848.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "involve a lot of science, measurement,",
      "offset": 4850.719,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "statistics,",
      "offset": 4853.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "uh, a lot of also just theoretical",
      "offset": 4855.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "arguments and just trying to, you know,",
      "offset": 4857.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it it's so it's partly an art. Modeling",
      "offset": 4859.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "is not just a pure science, but this is",
      "offset": 4861.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "true in all branches of science. So what",
      "offset": 4863.6,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "I want to say is inductive logic is no",
      "offset": 4864.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "different than any other science. It",
      "offset": 4866.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "gives you a theory, but in order to",
      "offset": 4868.4,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "apply that theory, you have to construct",
      "offset": 4869.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "models. And that's really you got to get",
      "offset": 4871.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "in the trenches and do a lot of really",
      "offset": 4873.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "difficult science, a lot of statistics,",
      "offset": 4875.76,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "a lot of measurement, a lot of",
      "offset": 4878,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "idealization, whatever is suited to to",
      "offset": 4879.56,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "assessing that argument. And it's going",
      "offset": 4882.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to be case by case. It's going to be",
      "offset": 4884.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "each context. We have to do the best we",
      "offset": 4886.56,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "can to come up with the most plausible",
      "offset": 4888.4,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "constraints to tell us what the evidence",
      "offset": 4890.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "favors. That's all we can do, you know.",
      "offset": 4891.679,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "So I really think it it is a case- by",
      "offset": 4894,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "case thing of constructing models and",
      "offset": 4895.96,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "doing the best we can just like the rest",
      "offset": 4898.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of science when you know it all you know",
      "offset": 4899.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "people often say all models are false",
      "offset": 4902.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "which I agree with but that doesn't mean",
      "offset": 4904.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the theories are false. So you know when",
      "offset": 4906.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "you take general relativity and you try",
      "offset": 4909.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "to model actual situations with it well",
      "offset": 4911.76,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "what do you do? Well, you have to make",
      "offset": 4913.679,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "all kinds of approximations because you",
      "offset": 4914.719,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "can't solve the equations and then you",
      "offset": 4916.159,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "got to make all kinds of auxiliary",
      "offset": 4918.08,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "assumptions and all kinds of",
      "offset": 4919.36,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "measurements you got to do and you got",
      "offset": 4920.8,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "to do all kinds of statistics there to",
      "offset": 4921.92,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "figure all these things out and get",
      "offset": 4923.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "parameters right and all that. Okay,",
      "offset": 4925.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "those models of course are false because",
      "offset": 4927.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "they all involve idealization and",
      "offset": 4929.36,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "approximation and so on. But the but the",
      "offset": 4930.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "theory might be true. It certainly could",
      "offset": 4932.719,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "be at least a really good framework for",
      "offset": 4935.36,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "constructing models. And this is how I",
      "offset": 4938.88,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "think of the framework I'm offering for",
      "offset": 4940.639,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "inductive logic. Yeah, with its two",
      "offset": 4942.239,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "dimensions of assessment in order to",
      "offset": 4944.239,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "apply it. Yeah, you've got to you got to",
      "offset": 4946.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "fit in some adjustable parameters. You",
      "offset": 4948.56,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "got to tell me what the premises are,",
      "offset": 4950,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "what the conclusion is, and then you got",
      "offset": 4951.36,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "to tell me enough about the",
      "offset": 4953.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "probabilities over those things so that",
      "offset": 4954.719,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "I can get a judgment as to whether the",
      "offset": 4957.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "evidence favors the conclusion or not.",
      "offset": 4959.44,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "You know, is is the evidence relevant to",
      "offset": 4962.4,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "the conclusion? You may not be able to",
      "offset": 4964.719,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "say how probable the conclusion is, but",
      "offset": 4966.239,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "but at least you'd like to say how",
      "offset": 4967.92,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "relevant is the evidence. get some",
      "offset": 4970.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "assessment of how relevant it is. Yeah,",
      "offset": 4972.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I guess um I'm trying in real time here",
      "offset": 4973.92,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "and not quite succeeding to put this in",
      "offset": 4976.159,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "very very downto-earth terms. You know,",
      "offset": 4979.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "my favorite example of a non-frequentist",
      "offset": 4981.76,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "probability is uh is the dark matter a",
      "offset": 4984.88,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "weakly interacting massive particle, a",
      "offset": 4989.199,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "wimp, or is it an axion? That's another",
      "offset": 4991.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "candidate for the dark matter. Or is it",
      "offset": 4994.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "something else, a third category, you",
      "offset": 4996.4,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "know, thing something we haven't thought",
      "offset": 4997.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "of before. So obviously this is not a",
      "offset": 4999.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "frequentist kind of question, right?",
      "offset": 5001.199,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "This is something that we have some",
      "offset": 5003.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "priors we're going to update. But now",
      "offset": 5004.08,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "what I'm presuming is that your way of",
      "offset": 5006.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "thinking about this would help me answer",
      "offset": 5008.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the following question. If I had a",
      "offset": 5011.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "certain amount of money to build an",
      "offset": 5013.04,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "experiment and one experiment would",
      "offset": 5014.96,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "confirm like detect the wimp, right?",
      "offset": 5018.28,
      "duration": 7.72
    },
    {
      "lang": "en",
      "text": "detect that it is that um but the other",
      "offset": 5022.239,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "experiment would like tell me that it is",
      "offset": 5026,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "not an axion or something like that.",
      "offset": 5028.639,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "Could I somehow I I'm truly not able to",
      "offset": 5031.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "answer the question in real time, but",
      "offset": 5034.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "could I somehow judge which is more",
      "offset": 5035.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "useful depending on what my priors were",
      "offset": 5039.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "for those different hypotheses?",
      "offset": 5040.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Uh yeah, I think you could. I mean, what",
      "offset": 5043.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "you would need I mean you you may not",
      "offset": 5045.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "even need your priors. What you're going",
      "offset": 5048.159,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "to need are the likelihoods. you're",
      "offset": 5049.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "going to need, okay, how probable is it",
      "offset": 5051.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that we would have observed this",
      "offset": 5054.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "evidence, right, given the one",
      "offset": 5055.6,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "hypothesis versus given the other",
      "offset": 5057.36,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "hypothesis. So, you're going to have to",
      "offset": 5059.199,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "be able to compare those likelihoods.",
      "offset": 5060.719,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Yeah, that at the very least that will",
      "offset": 5062.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "give you some information about the",
      "offset": 5064.159,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "relevance dimension like does the",
      "offset": 5065.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "evidence favor one over the other. It",
      "offset": 5066.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "may not tell you the probabilities cuz",
      "offset": 5069.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "for that you're going to need priors,",
      "offset": 5070.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "but still it can give you a good amount",
      "offset": 5073.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "of information and it can tell you",
      "offset": 5075.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "something that the experiment is doing",
      "offset": 5076.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "something valuable. It's it's giving you",
      "offset": 5078.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "evidence that favors one of those",
      "offset": 5080.8,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "hypothesis over the other cuz it's more",
      "offset": 5082.159,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "relevant to one than it is to the other.",
      "offset": 5083.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Even if you don't know how probable they",
      "offset": 5085.52,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "are, that's fine. You may not know how",
      "offset": 5087.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "probable they are. So you may not know",
      "offset": 5089.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "whether to accept or reject, but you",
      "offset": 5090.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "still can say, \"Hey, this is this",
      "offset": 5093.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "evidence seems to favor the one",
      "offset": 5095.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "hypothesis over the other.\" And I think",
      "offset": 5097.36,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "that's generally how scientific",
      "offset": 5098.8,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "experiments actually work. As I was",
      "offset": 5100.639,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "saying before, when you're designing",
      "offset": 5102.719,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "experiment, you can't determine how",
      "offset": 5105.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "probable things are going to be. I mean",
      "offset": 5107.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you can given your priors or something",
      "offset": 5108.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "if you know you could yourself determine",
      "offset": 5110.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "but what you can do generally is you can",
      "offset": 5112.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "can design the experiment in such a way",
      "offset": 5116.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that it provides evidence that favors",
      "offset": 5117.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "one thing over another or is relevant to",
      "offset": 5120.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "to the experimental question. There is a",
      "offset": 5122.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "claim out there that I'm a little",
      "offset": 5125.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "sympathetic to that scientists should be",
      "offset": 5126.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "more open about what their priors",
      "offset": 5128.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "actually are. Like when we do an",
      "offset": 5130.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "experiment like we turn on Large Hadron",
      "offset": 5132.239,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "Collider and scientists said well we",
      "offset": 5133.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "could find all these new particles. tell",
      "offset": 5135.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "me what the probability is that I will",
      "offset": 5137.679,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "actually find these new particles which",
      "offset": 5139.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "which physicists at least never ever do.",
      "offset": 5141.199,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "I don't know if people in other fields",
      "offset": 5142.96,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "actually do that. Do you think it'll be",
      "offset": 5144.32,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "good that they, you know, put their",
      "offset": 5145.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "money where their mouth is in that way?",
      "offset": 5146.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Well, the great thing about So, I've",
      "offset": 5148.8,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "been thinking a lot about different",
      "offset": 5150.48,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "sciences because I'm working on this",
      "offset": 5151.52,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "project with a couple colleagues on the",
      "offset": 5153.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "replication crisis in science and the",
      "offset": 5154.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "different sciences are very radically",
      "offset": 5157.28,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "different in terms of how they're",
      "offset": 5159.04,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "dealing with replication and what",
      "offset": 5160.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "problems they have. Particle physics is",
      "offset": 5161.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "one is sort of like the gold standard. I",
      "offset": 5163.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "mean, the EV the experiments they do,",
      "offset": 5165.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the evidence they generate is so",
      "offset": 5168,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "confirmationally powerful that it almost",
      "offset": 5169.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "doesn't even matter what your priors",
      "offset": 5172.719,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "are, right? Like it it really doesn't.",
      "offset": 5174.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "It basically just swamps completely.",
      "offset": 5176.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "There's such large likelihood ratios",
      "offset": 5178.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "that you get from those experiments that",
      "offset": 5180.8,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "you come in with whatever prior you",
      "offset": 5182.639,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "want. You're going to basically come out",
      "offset": 5184.08,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "pretty sure that these particles exist",
      "offset": 5185.6,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "if you're paying attention to the",
      "offset": 5187.28,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "evidence. And so particle physics is",
      "offset": 5188.32,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "this is really a great example of where",
      "offset": 5189.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "we're designing experiments that are so",
      "offset": 5192.719,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "confirmationally powerful that it almost",
      "offset": 5194.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "doesn't even matter what your priors",
      "offset": 5196.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "are. But other sciences are not like",
      "offset": 5197.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "that. Other sciences it's much more",
      "offset": 5200.56,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "sensitive to your priors as as to what",
      "offset": 5203.52,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "attitude you're going to come out after",
      "offset": 5205.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "looking at the experiment. Um and also",
      "offset": 5206.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "it's even more controversial whether you",
      "offset": 5208.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "whether you have really relevant",
      "offset": 5211.76,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "evidence or not. even that is is",
      "offset": 5213.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "controversial in a lot of the special",
      "offset": 5216.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "sciences whereas in particle physics no",
      "offset": 5218.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you know the evidence is is very",
      "offset": 5220.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "relevant it it's extremely relevant and",
      "offset": 5222.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "so that's I I view that as kind of one",
      "offset": 5225.04,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "of the easy cases and you know like any",
      "offset": 5226.88,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "theory it's going to have cases it's",
      "offset": 5229.56,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "really good at explaining and it's going",
      "offset": 5232.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "to have anomalous cases and that goes",
      "offset": 5233.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "for the basian theory that I'm of",
      "offset": 5235.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "inductive logic that I'm offering um",
      "offset": 5237.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "it's a pluralist basian it's not it's",
      "offset": 5239.84,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "not saying you should use a particular",
      "offset": 5241.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "probability but it's from probability",
      "offset": 5243.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "function, right? Um it's basy in the",
      "offset": 5245.28,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "sense that I'm willing to put",
      "offset": 5247.36,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "probabilities over all the hypothesis,",
      "offset": 5248.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "right? Okay, which which non-basians",
      "offset": 5249.84,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "aren't willing to do. But in any event,",
      "offset": 5252,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "um look, it's a theory and it's going to",
      "offset": 5254.52,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "have limitations just like Newton's",
      "offset": 5257.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "theory wasn't able to explain, you know,",
      "offset": 5259.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "in any really plausible way the motion",
      "offset": 5261.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "of Mercury. I'm sure there are going to",
      "offset": 5263.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "be cases that we can find in science",
      "offset": 5265.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "where the where the theory I'm offering",
      "offset": 5267.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it's going to have be really challenged",
      "offset": 5269.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to come up with plausible models that",
      "offset": 5271.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "explain uh how much confirmation there",
      "offset": 5273.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "is in that case and you know but that's",
      "offset": 5275.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "the nature of science and so um even in",
      "offset": 5277.84,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "so I like to think there's a there's a",
      "offset": 5281.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "spectrum of cases there's easy cases",
      "offset": 5283.04,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "like particle physics or games of chance",
      "offset": 5284.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you know these are easy cases and then",
      "offset": 5286.719,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "you go down the spectrum and there's",
      "offset": 5289.04,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "really really much harder cases and much",
      "offset": 5290.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "more controvers cases but That's true",
      "offset": 5292.719,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "pretty much of any science. Okay. Well,",
      "offset": 5294.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "I think that we have confirmed that this",
      "offset": 5296.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "is a fun thing to talk about, but maybe",
      "offset": 5298.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "we haven't because my prior was so big",
      "offset": 5300.48,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "that it didn't actually wasn't actually",
      "offset": 5302.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "relevant the evidence we collected here.",
      "offset": 5304.719,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "But in any event, Brendan Fitson, thanks",
      "offset": 5306.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "very much for appearing on the Mindscape",
      "offset": 5308.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "podcast. Thank you so much, Sean. What a",
      "offset": 5310,
      "duration": 3.61
    },
    {
      "lang": "en",
      "text": "pleasure.",
      "offset": 5312.56,
      "duration": 19.04
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 5313.61,
      "duration": 20.99
    },
    {
      "lang": "en",
      "text": "la.",
      "offset": 5331.6,
      "duration": 3
    }
  ],
  "cleanText": "Hello everyone and welcome to the Mindscape podcast. I'm your host Sean Carroll. One of the things that I always like to say about science and how it gets done is that science never proves things. This is something that is an important feature of science, especially in the modern world where what science does, how it reaches conclusions, how trustworthy it is, these are all under contestation by different parts of society. So, it's important to understand what science is and how it actually reaches its conclusions. And the claim that science never proves things, which is something that most scientists would go along with me on, comes from a comparison to real proof in mathematics or for that matter in logic. You know, most scientists have taken some math classes, at least enough to know what it means to prove something in the old-fashioned sense of Euclid and geometry or Aristotle and logic, proving a conclusion from some well-articulated premises. Uh, in the philosophical study of logic, this is known as deductive reasoning. You have some premises and you reach a conclusion. And science just doesn't go that way, right? Uh, science looks at the world. It looks at all sorts of things in the world and it tries to figure out what the patterns are that the world follows, always knowing that tomorrow you might do a new experiment that will overturn your best guess as to what the pattern was. Or maybe someone will do something as simple as just thinking of a better pattern, right? A theoretical physicist coming up with a better idea for what the laws of physics really are. So if science doesn't prove things, if it just sort of comes closer and closer in some sense to getting it right, then what is what's going on? Uh, you know, one very common idea about what's going on is inductive logic rather than deductive logic. And inductive logic, we begin to see a pattern. You know, A B C D E F G. The next one is probably going to be H, right? Uh, because we think that probably you're just mentioning the alphabet in alphabetical order. But there's all sorts of paradoxes that come up when you do inductive logic. Like how do you know that it's not A B C D E F? That's a sequence of letters that that you could have. My old math teacher in college used to hate those SAT questions or standardized test questions that would give you a series of numbers and ask you to guess the next one because he said, I can I can make any number I want. I can come with a formula that would give you any number I want after the ones that you already showed me. So philosophers unsurprisingly are very interested in making as rigorous and careful as possible this idea of either induction or whatever should replace induction as the logic of understanding things in science. The names attached here go from old school names like David Hume and John Stewart Mill to relatively newer ones like Rudolph Carnap, Carl Hempel, um Carl Popper, for example. Uh, and it's still an ongoing thing. So this is something that lives at the intersection of how we think about science, but also how we think about probability, what probability is, um how conditional probabilities work, Bayesian logic, all that stuff. And that's what we're going to be talking about today. Today's guest is Branden Fitelson, who is a philosopher at Northeastern University. And it's, you know, it's it's eye-opening to me as someone who is now part-time in a philosophy department. Just a huge range of stuff that gets characterized as philosophy, right? Like some philosophers are saying, \"What is the good?\" Others are saying, \"What happens when an observation is made in quantum mechanics?\" and others are like doing pretty hardcore mathy logic and um well there's mathematical logic but there's also just big picture questions about logic. How does logic, how do probability, uh, how do these things get used both in a perfectly rational world and also in the slightly irrational world in which we live. We're going to be talking about both of those things and I think it's intrinsically interesting to understand probability and logic better but also super important to thinking about how science works. So, let's go.\n\n[Music]\n\nBranden Fitelson, welcome to the Mindscape podcast. Thank you so much for having me, Sean. I'm a big fan. I think what you're doing here is super important, especially nowadays. I hope you still think those things after we are done talking, but I I hope to make it true. So, we're talking about stuff that is dear to my heart. Um, we're talking about increasing the probability that something is right. We're talking about what probability is, how it fits in with uh learning about things. Obviously, science cares about this a lot. So, let's start at the very high level and you tell me what probability really is.\nWhat probability really is? Well, there's many kinds of probabilities. So, there's probabilities in science. So for instance, biology has its own conception of probability uh which shows up in the theory of natural selection especially and genetics. Um physics of course as you know better than I has uh lots to say about probability both in classical and quantum physics.\nUm yeah so and in economics uh we also use probability and in in many other special sciences. My interest in probability I started out as a physicist. So I started out in interested in probability and physics. That's how I got into it. But over the years I became more and more interested in the role probability plays in thinking about evidence and how strong arguments are. That is how strong something is as a reason for believing something else. And uh that's kind of the application of probability that I'm most interested in nowadays. And in that context, there's still many kinds of probabilities because when you're assessing the strength of an argument, it really depends on the context. So if you're playing a game of chance, say, and you're, you know, like poker, and a certain card comes up, and you're wondering, well, what effect does that have on my probability of winning this hand? Well, now you know what probabilities to use. They're given by, you know, the probabilities of a game of chance. Each card is equally likely to be drawn. And that allows you then to calculate the probability of any hand given, you know, what's left in the deck and so on. And so there it's very clear what probabilities to use to assess the strength of that as a reason for believing say that you'll win or lose the hand. In other contexts, it's much more difficult to say which probabilities are the appropriate ones. So for instance, if we're wondering whether a certain scientific theory is true, in fact, we might even be worried about whether a certain scientific theory of probability is true.\nAnd you might have two competing theories of what probability in a certain scientific context is like.\nWell, there how are you going to adjudicate how strong the arguments are? Well, you can't. It would be question begging to assume a notion of probability that say one of the theories adopts but the other rejects. That would just be question begging. So what you need is some more general notion of probability uh that will allow you to evaluate arguments even in those contexts. And as a philosopher, I want to go even more broad than that. I want to be able to assess arguments for the existence of God maybe or for ethical claims and so on. And as you get more and more abstract and these contexts get further and further away, say from games of chance, which is kind of the easiest case, it gets more and more controversial. What kinds of probabilities are the relevant ones?\nBut, you know, I think of this like any other science, Sean. I think probability theory, it's a theory. And then uh what you do when you're faced with a certain situation is you have to construct models of the theory. And okay, that's a very complicated process which involves making all kinds of assumptions and idealizations. Um and that's okay. Uh and the goal there is to try to come up with the best account of which probabilities we should use. Uh so that we're adjudicating this question of how strong the arguments are in a way that's not that's fair and reasonable. And uh that's really a case-by-case thing I think. So I was just a couple weeks ago at the uh retirement celebration conference for Barry Loewer, former Mindscape guest, and there was a talk by David Albert, former Mindscape guest. And uh in in part in response to things that I and others have been saying about quantum mechanics and self-locating probabilities, and David, you know, he was just unapologetically old school about it. He says the only sensible use of probability is when you have a frequency of something happening over and over again and you can sort of imagine taking a limit of it happening infinite number of times that and the ratio of the number of times where it looks like x rather than y that's the probability and you know I tried to say but okay come on we we certainly use probability in a much broader sense than that we talk about the probability of a sports team winning a thing even though we're not going to do it infinite number of times or even twice. Um, so I is there a consensus about this very basic question about the relationship between frequencies and probabilities versus just a more epistemic like this is my best guess kind of thing,\nright? Okay, good. Yeah. So there's lots of, you know, what used to be called interpretations of probability, but I would just call them theories of probability. There, as I say, there are many. The frequency theory, well, it's a very strange theory actually. I mean it started off um as an actual finite frequency theory where you know the probability of some event is actually just given by the actual frequency of some event in some population. So for instance suppose you have a coin and it's been tossed exactly five times, three heads and two tails and then it's destroyed. Well according to the actual frequency theory the probability is uh you know three fifths that it's heads. Wow. Um and in fact if there's any odd number of tosses actual odd number of to then you can't get an even you can't get one half. So even if you have a fair coin if it's tossed an odd number of times then according to the actual frequency view uh the probability it isn't fair. It can't so so the actual frequency view was a non-starter right that's not going to work so also you can't get irrational values you can't get you know you can only get rational values and that seems wrong because physics has all kinds of irrational value problem. Okay. So then people said, \"Well, okay, maybe what we'll do is we'll talk about hypothetical infinite extensions of the actual experiment.\" Okay. Well, what what does that mean? Uh they say think they say things like, \"Well, it's what would have happened had you continued indefinitely that initial sequence of five tosses.\" And I want to say well here's that's very hard to understand because there's uncountably many such extensions and on almost all of them there's no limiting frequency. So it's true that for any real number you can get that as the limiting frequency of an infinite sequence but it's also true that almost all of the sequences don't have they diverge in their in their limiting frequency. And sorry, sorry. This is uh this sounds like you're paraphrasing some technical result with the use of the idea of almost all. That's a that's a technical math term. Yes, that's right. I I just mean uh well, it's not all. There's like a there's like a relatively small number of sequences that will converge. But it's sort of like it's sort of like if you pick a real number at random, it's it's like what are the chances of getting a rational number? Pretty small. there most of them are not rational um by any reasonable measure of most and the same thing is true here you have all these sequences well which one um and so then you've got to say well which hypothetical infinite extensions are the ones that actually give you the real probability and I just think this is the wrong this is just the wrong way to go my view is I like to make an analogy uh with measurement in general say in physics so you might think you might ask yourself what is mass say it Suppose just for the sake of argument that we're in a Newtonian universe and mass just behaves the way Newton thought it did. Just for the sake of argument and then you think well what is mass anyway? Well my view about what mass is in such universe is it's whatever the theory says it is. It's it's the functional role played by that concept and all the laws and that's a very complicated thing. There's no easy way to summarize. It's just whatever Newton's theory says it is. But you might be tempted by a different view. We might think, well, wait, maybe it's just frequencies. Maybe it's just what you do is you make measurements and then you take an average and maybe if you take infinitely many measurements and you take the limiting value of the average, maybe that's what the mass of the object is. No. No. If you're lucky, that is if you're most of if you're lucky, then if you were to do that, of course you can't do it, but if you were to do that, then if you're lucky, you would get something very close to the actual mass. But that isn't what the mass is. And I want to say the same thing about probability. Suppose you're doing some quantum mechanical experiment, right? You can make measurements. That's what you do. You make me you make a lot of measurements and you take averages and you do statistics and that's how you estimate the probability that something will be observed in a quantum mechanical system. But that's not what the probability is. The probability is what the theory says it is and whatever that is. So one property it has is you know you use Bourne's rule to calculate what the probability is. Okay, that's a really complicated theoretical story. But the but the probability isn't any sequence of measurements. It's not any limiting frequency that's a symptom of this property of probability. But the property is what the theory says it is. So I just think the frequency views got everything backwards. frequencies are just the way we maybe know about probabilities, but they're not what the probabilities are. So that that's my view. Oh, I I'm very sympathetic to that. How is that how does that view fit in with the sort of classic divide between thinking that probabilities are mostly epistemic? They're about our knowledge versus that probabilities latch on to some objective chances out there in the world. Oh, I think certainly there are objective probabilities. As I said, I think not just in physics but also in biology. I think each theory has its own concept of probability in it. At least the probabilistic theories do. And what probability is in those systems is whatever the theory says it is. It's just like mass. Um so that\n\n\nI have a very flatfooted view of that. And so in quantum mechanics, well, we know how to calculate probabilities. The theory tells us to. You know, in statistical mechanics, we can also calculate probabilities as well. Um, and we can do that as well, you know, but uh, and now you might wonder about the interpretation of those probabilities, but you can certainly calculate things which obey the laws of probability in statistical mechanics, and so in that sense at least, they are probabilities. They satisfy the formal principles of probability. Um, and so, yeah, I mean, I, I, so I want to say, certainly there are objective probabilities, no, no question. I'm a scientific realist, so, you know, if a theory, if I accept a theory and the theory says there's a thing, then there's that thing. That's it. So, I, I'm, I'm a realist. So I don't have any problem with that.\n\nHowever, the problem is, and you know, where things get really tricky, I think, and this is what got me really interested in other notions of probability. The tricky thing is, as I said, suppose there's a dispute about the nature of probability in some physical context, right? There's a dispute about that. You have two theories. One theory says probability behaves like this. Another theory says behaves like that. And then you do experiments. Okay. And you try to use that data to adjudicate, you know, does the evidence favor the one theory of probability over the other?\n\nWell, whatever probability you can you're using there, you got to be very careful because you don't want to beg any questions. So, you don't want to use the probability that the one theory says is correct, but the other says it's incorrect to do the very calculations of how strong the arguments are. That would be question begging. So, I think what you in those settings, you need some other notion of probability. And that's where I think the epistemic notion comes in. I think you need it in at least these contexts where uh, you're actually trying to adjudicate different physical theories of probability, say you can't use what one theory says to adjudicate because that would just beg the question against the other theory. And so I think in those context at least, you're going to need some other notion of probability, something neutral, like a, like a judge is impartial. So you need some impartial notion of probability. And I think this is the kind of notion that statisticians have been trying to come up with, uh, you know, ever since that early work in genetics, which is where it all really started with Fiser and and Haldane and all those kinds of people, um, and Pearson. Um, so, but I, this is where I think Bayesianism is helpful, the Bayesian approach, because at least in these contexts where we're not sure, we're uncertain what the correct theory of probability is. We need something that's, it feels like it's got to be epistemic, at least it's got to be neutral, and it's got to be something you can use to adjudicate, does the evidence favor one theory of probability, say over another? And uh, and for that matter, like I said, you want to adjudicate debates in other areas where who knows what the probability of Newton's theory is? I mean, even if there, even if there are objective physical probabilities, it's hard to imagine how they would tell us what the probability is that Newton's theory is true, good, or I mean, it's just what would that mean? So, so I think in those contexts where we're adjudicating physical theory, say Newton versus Einstein or two different versions of quantum theory or something else, we're going to need a some other notion of probability. And that's where I think the Bayesian approach is. You kind of need something like that because you need something neutral.\n\nI think I would have said uh, 15 minutes ago that I don't believe that there is any such thing as objective probability in the world. I think that uh, there's the world and we describe the world the best we can, and maybe we uh, have incomplete information, so we appeal to some probability, but there's some exact description of it also. But and of course, if you're judging between different theories of the world, then you have some epistemic view of probability. But now you're pointing out that okay, but there's a notion of a thing that appears in a theory, uh, whether it's quantum mechanics or genetics or whatever, and that thing obeys the laws of probability, it adds up to one and whatever, and we might as well call that objective.\n\nYeah. Yeah. I mean, just like I would want to call mass objective. Um, I would say the probability in quantum mechanics that's delivered by, you know, the Born rule or whatever, however you calculate it, whatever that is. Um, it's some real thing. It's just as real as mass or any other theoretical quantity. It seems to me that theory that the theory implicitly defines through its laws. So yeah, I mean, again, I'm a realist though, so I have to just fuss up to that. Um, but but as I say, even if you're not a realist, even if you think, okay, maybe there's different kinds of probabilities, but none of them is objective in in the relevant sense. Still, if you want to know whether some evidence favors one of those theories over another one, and you want that to be a probabilistic inference, which is it is, because it's not going to be deductive. I mean, after all, scientific evidence doesn't entail the answer to these questions. It doesn't deductively guarantee that one theory is true and the other is false. It just at best makes it favors one over another. And that's going to have to be, I think, the best way to model that is probabilistically. But then you need a general framework of probability that's going to have to be, I don't know, epistemic or or something less objective in that sense, because otherwise it would it would run the risk of just begging the question. So good. This leads us right into where I wanted to go, which is the uh, idea of induction and how in the early days people tried to hope that inductive reasoning, you know, looking at many, many examples and generalizing, would be a kind of logic that would fit the scientific process. And then other people point out that there are problems with induction. So I mean, pretend we're in the philosophy 101 class, like what are the problems that people have with induction?\n\nWell, of course, in philosophy, you know, in epistemology generally, you generally start out with the really, really hard problems, like skepticism, and and induction is no, is no different. Uh, when you're studying philosophy of induction, you tend to start with these skeptical arguments. Um, you know, like David Hume was was had a kind of skeptical arguments. He's like, well, okay, you say there are these arguments that are, you know, that don't guarantee the truth of their conclusions if their premises are true. Well, their conclusions, maybe they're quote unquote probably true, but they're not guaranteed to be true like in mathematics. And he he gave this dilemma. He said, well, let's think about how that would actually work. So suppose, you know, you've observed the sun rising a, you know, a million times and you infer that on the basis of that historical evidence that the sun will rise tomorrow.\n\nHe points, Hume points out that well, that argument assumes some kind of principle of regularity of nature, that you know, the past, the future will resemble the past. And now if you ask how are you going to justify that premise that the future will resemble the past? Well, you can't give a deductive argument for it because how would you do that? I mean, nothing you've observed is going to entail that the future will resemble the past. In other words, there'll always be some chance that you can't rule out with certainty that the future won't resemble the past. Uh, so it won't be a deductive argument. And then if it's an inductive, it just feels like now it's going to beg the question because, well, wait, what are you going to do? Reason as follows. In the past, the future has resembled the past. So therefore in the future, the and now you're just, it's now you're just circular. But now it's just a circular argument because you're assuming the very principle that you mean to justify in order to justify the argument. So you know, philosophy always starts with these skeptical arguments. I mean, but you, you don't have to worry about induction. I mean, this happens in every field. Like why believe there's an external world? After all, you can't rule out with certainty that there's an evil demon or that you're in a simulation or etc, etc, etc, you know. So what you, I think what you got to do, uh, when you're doing philosophy, the sort of the first thing you have to do in any of these domains is figure out how you're going to respond to the skeptic, that is, what are you going, what are you going to say, why do you think that there's an external world? For let's start there and then we'll get to induction. Well, why do you think there's an external world? Well, um, I can only speak for myself, the reason I think there's an external world is when I think about everything that I take myself to know, you know, everything I take to be evidence about the world, you all my observations, you know, everything I take to be true. And I think, well, what's the best explanation of all of that? To me, I don't see any way to plausibly explain all that stuff without postulating the existence of an external world that is mind independent in many ways. Uh, and that's why I think there's a mind-ended external world. Uh, and now I want to take the same anti-sceptical view about induction.\n\nI think, well, how do you explain, say, the success of science or what appears to be the progress of science? Well, uh, I don't know, but it seems hard for me to be able to explain that unless there weren't some principles of when evidence actually does favor one scientific theory over another, uh, and does provide reason to believe one rather than the other. Uh, and so what I tend to do is think about historical cases of that look like real scientific progress and then what's the best way to explain that. So for instance, when uh, when Einstein's general relativity of general relativity overtook Newton's theory of celestial motion, there were a lot of experiments that were crucial. One was the motion of Mercury. The motion of Mercury, Mercury moves in this very strange way around the sun, and it was known that was known for a long time that it had this strange motion.\n\nWell, uh, the Newtonians tried their best to give explanations of that and, uh, in the past they had had similar episodes, but they were able to explain it by some missing mass that they found, you know, that was in the universe that they didn't know about. And but eventually they realized now there's no, there isn't going to be the right hidden mass here. It's Newton's theory is just not going to be able to predict this. Uh, this is just a a thing that Newton's theory can't explain, can't predict. And then Einstein comes along and gives a theory that explains all the stuff Newton's theory could explain and this thing too and a bunch of other stuff that it couldn't explain. I, that just now I want to say, well, that just seems to make it more probable that Einstein's story is true or at least more probable that, you know, that would be the better bet to make, that would be the more acceptable theory. And I, I think a probabilistic way of modeling that is just the best way that I know to model it. And so again, I just think, well, what's the best explanation of these episodes of scientific progress? And to me, part of that has to be, well, there just must be cases where the evidence really does favor one theory over another. Not that it guarantees that one's true, the other is false or anything like that, but it sort of raises the probability of one more than the other. And I just think I don't know how else to explain science episodes of scientific progress unless something like that is true. Um, so I, so I believe that something like that is true. Now the details of it are difficult to to work out, but I think this is what statisticians, as I said, have largely been trying to figure out, uh, how those inferences work, like when we have an experiment and we think the evidence favors one theory of another, what's the right way to use probability, right, to model that? And there's a lot of disagreement, of course, in statistics between Bayesians and classical stat, there's all kinds of different schools, but one thing they all agree on is there are episodes where the evidence favors one theory over another, and probability is an is an indispensable part of the explanation. Why I do think they all agree on that much, it might be unfair of me, but I do think that it's a very common phase in an individual's philosophical maturation to realize that not everything can be established on rock hard foundations that you agree with 100%, like sometimes you just got to say this is the best we can do with what we got.\n\nAbsolutely. Absolutely. I think most of the time we're kind of in that in that situation and that's okay. So I think, but you know, that's the nature of these inferences. As I said, it's not like deduction. You don't have the certainty of mathematics in these kinds of inferences. So you know, there's going to be something that's underdetermined. You know, it's not going to exactly determine completely what our attitude should be. There's going to be some wiggle room, some leeway. So in a way, you're always making something of a leap of faith when you do one of these amplitative or inductive inferences. And I just think you kind of have to live with that, you know, and do the best you can. And this leads us right into, you're very good at this. You're just bringing us along on the logical train of thought that we need to be on, um, the idea of confirmation. Uh, to try, what we're trying to do is to formalize this idea, like you just said, that you know, Einstein's theory is simple. It fits the data. Newton's theory doesn't fit the data in some sense. Einstein has now become more probably right than Newton. What sense is that? And confirmation is one of the words that gets batted around. I want you to really sort of carefully explain to us what that's supposed to mean because I think many people informally think that if you've confirmed something, you know it's true 100%. And that's not how philosophers use the word.\n\nNo, that's right. That's right. So yeah, in in ordinary language, the word confirmation has very strong connotations, but in the philosophy of induction, confirmation is actually a very weak, it's actually a very weak claim. And um, I think a helpful, I like to use simple examples. I think a nice, nice example to use is one of diagnostic testing. I, I always like this example, and in a, and in a way, I think it's kind of fully general because in a way, you can think of scientific experiments as a kind of diagnostic test where you're testing the world to see whether some hypothesis is true or false. And so when you design an experiment, you really are in a way designing a diagnostic test. Um, and\n\n\nSo, but let's think about diagnostic testing.\nSo, for instance, um there are many diagnostic tests that are very reliable that you can buy in the store now.\nSo, for instance, you could buy a pregnancy test or an HIV test.\nUm, any of these tests that you buy, if you read the box, you'll notice something very interesting on the box.\nThere's things they tell you, and there's things they don't tell you.\nSo, one thing they tell you for sure is what they call the true positive rate and the false positive rate of the test, right?\nSo, the true positive rate is something like this.\nSuppose that you have the disease, then how probable would it be that you would get a positive result from this test?\nAnd then on the other, the false positive rate is, suppose you don't have the disease, then how probable is a positive result?\nAnd the great thing about these diagnostic tests is you can determine those error rates in the laboratory.\nYou don't need to know anything about the subjects, the particular subjects that are using it, and so on.\nAnd that's why they can put that information on the box.\nIt's very reliably known.\nWell, that ratio of the true positive rate to the false positive rate is called a Bayes factor.\nIt's also called a likelihood ratio.\nAnd it doesn't determine how probable the hypothesis is given a positive result.\nIt doesn't determine that.\nIn order to know that, how probable it is that you have the disease, you have to plug in what's called a prior probability.\nUh, an a priori probability, Philosophers call it.\nAnd what is that?\nWell, that's something like the probability, you, how probable you think it is before looking at the evidence.\nOkay.\nWell, what that, what is that?\nWell, of course, um the guys who design the test, they can't tell you what that is.\nThat's going to depend very sensibly on things about you.\nSo, for instance, suppose it's a pregnancy test.\nUm, and if someone takes a pregnancy test and they get a positive result, well, they'll know the likelihood ratio.\nThey'll know the error rates, you know, uh, false positive and true positive.\nSo, they'll know how reliable the test is in that sense.\nBut to get how probable it is that they're pregnant, well, they need to know a lot about maybe their own behavior in recent days and so on, which of course the designers of the experiment can't know and and shouldn't and don't need to know in order to know the error rates, right?\nSo, for just, just to put an example on this, um, so if there is a pregnancy test that the likelihood is very high, like, you know, it is claimed that, uh, if it comes out positive, the likelihood you're pregnant is very, is very large, but if I took a pregnancy test of that form, I am biologically incapable of becoming pregnant.\nI know that pretty with pretty high probability.\nSo, if I happen to get a positive, I would not conclude that my probability in being pregnant is high because my prior is so low.\nExactly.\nExactly.\nIn fact, it might even be zero, you know, depending on the case, but it'll be very close to zero.\nAnd that's exactly the distinction that I want to make.\nThis distinction between that base factor, that how reliable the test is, which is just the ratio really of those two error rates, that could be really high, but all that tells you is what to multiply the prior by to get the posterior.\nBasically, it's like a multiplier.\nSo, if you start off low, but not that low, and then you get a really reliable test, well, maybe it's a multiplier by a factor of a thousand, well, then you're going to have a reasonably high probability.\nBut if you start really, really low, then even if you have a pretty high factor, a multiplicative base factor, still you're going to end up low.\nAnd this, people are very bad at making these inferences.\nThis is something that Conor and Tverki discovered back in the 80s.\nThey called it the base rate fallacy.\nAnd when people are given, uh, an example like this, where, okay, so you have a reliable test for a rare disease, they're told the disease is rare, like one in a thousand, and then they're given pretty good error rates, and they say, well, and then they're asked how probable is it that the person has disease, and often people give a very high number.\nAnd in fact, interestingly, the numbers tend to cluster around basically the Bayes factor if you normalize it to a 0 to 1 scale.\nAnd I don't think this is a coincidence.\nI think what's happening here is you have two factors.\nThere are two things that are relevant here.\nThere's how probable it is that you have disease, the probability of the disease, and then there's the how confirmation.\nThere's how much the evidence confirms, and that's just how much does it change?\nHow much does it raise the probability?\nAnd I think in these cases, what you have is low probability but high confirmation.\nThat can be very confusing, right?\nBecause both of these things are relevant to, quote unquote, how strong the argument is, but that is how strong the evidence is as a reason to believe that the disease is present.\nBut they go in different directions.\nSo, it can be very confusing.\nAnd then you might, there's still a residual question.\nWell, why would people defer to the relevance to the confirmation number, right, when they're asked about probability?\nUm, I think this is not a crazy thing to do at all.\nAs we said, those error rates are objective and invariant in a really important sense.\nYou can just discover them in laboratories.\nUh, you could just by working with the causal structure of the test and the chemicals you're looking for, you can be pretty confident about those error rates independently of the prior probability.\nAnd so there's something more objective, yeah, about those numbers.\nAnd you know, there's something really ironic about the conventional research because if you read their own paper, well, that's a scientific paper, and so what do scientific papers do?\nWell, they generally design an experiment and then perform an experiment, and the experiment generates evidence.\nWhat do they tell you about the experiment?\nWhat do they tell you about how to interpret that evidence?\nDo they tell you how probable their hypothesis is to be true given the evidence?\nOf course, they don't.\nJust like the diagnostic test maker can't tell you how probable it is that you have disease.\nThat relies on this prior information that they don't know.\nScience is the same way.\nWhen you design an experiment, what you're really doing is trying to get maximum confirmational power out of the experiment.\nYou want it to be as much of a multiplier of that prior probability as you can.\nUh, either a multiplier or a divider.\nIf it's, if it's evidence against, then okay, then it's kind of a divider of how probabilities, it makes it smaller, makes the probability smaller, but the point is, it's not probability that you're, you, you can't maximize the probability that your hypothesis is true.\nThat depends on the prior, and different scientists are going to have different priors when they, when they look at experiments.\nSo, all you can tell people basically is what the likelihood ratio, what that base factor is of your experiment, including Conan Tverki's own experiment.\nSo, there's this real irony.\nThey're implicitly criticizing human beings for being bad at doing a thing that their own paper doesn't require scientists reading the paper to do.\nIn the big picture, I, I was a little cheeky.\nI put this idea as, um, everyone's entitled to their own priors.\nNo one's entitled to their own likelihoods.\nExactly.\nAnd I think that's exactly right.\nAnd so I think there's something not irrational here about deferring to the likelihood information.\nAfter all, that's the objective.\nThat's the invariant information that we can know.\nAnd, uh, and that's how science works, right?\nScientific papers, they basically report base factors or something about whether the evidence favors one theory over another.\nThey don't tell you how probable it is that one theory is true or the other theory is true.\nThey know that's going to depend on these priors.\nAnd they don't know the prior probabilities of their readership.\nDepends on what their readership knows.\nAnd so our self-appointed task is to come up with a formal understanding of this idea of confirmation.\nLike, clearly it's important.\nI mean, maybe you have your own priors.\nUh, maybe you disagree or maybe you agree about them.\nBut we should be able to quantify how much the new evidence is confirming, uh, our theories.\nAnd it's also, like you say, but maybe it's worth emphasizing, it's weaker than entailment than from deductive logic.\nWe're familiar from high school, uh, P and if P then Q, therefore Q, like that sounds solid, that sounds logic to us, and we want a logic of confirmation.\nYes.\nYes.\nAnd and we can have one, and and basically those base factors, they give it to you.\nUm, one thing that's really interesting about this literature, and is this is really what my, this is what I really got interested in when I was in graduate school.\nI wrote my dissertation on this.\nIf you look in the literature on probability, statistics, Bayesianism, any of that literature, there's lots of measures of this confirmation.\nThere's lots of measures of, say, degree of correlation.\nSo, correlation is another word for confirmation.\nIt's just when one thing raises the probability of another, right?\nUm, there's lots of measures of how strong that confirmation is.\nOne thing you could do is just take the posterior probability and subtract off the prior probability.\nAnd you could say, well, how, that's one way of measuring how much of a difference the evidence made to the hypothesis.\nBut there's many ways to do it because it turns out that you can define correlation in in many equivalent ways.\nSo, one way is the, the posterior is greater than the prior.\nThat's one way.\nBut another way is that the true positive rate is greater than the false positive rate.\nRight.\nUh, or greater than one minus the false pro.\nSo, the probability of the evidence given the hypothesis is greater than the probability evidence given the denial of the hypothesis.\nYeah.\nAnd that's equivalent qualitatively.\nThose are going to be true at this.\nBut if you define measures based on those inequalities, they're actually different.\nThey don't agree on which thing is better confirmed than which.\nThey actually disagree on orderings of how well confirmed hypotheses are.\nSo, they can't be measuring the same directionction.\nIt's, it's either it's being confirmed or disisconfirmed, but they don't agree on how much.\nExactly.\nAnd so if you want to measure it, which of course we do, we want to know how much.\nUh, then you've got to pick one of these many, and there's dozens of measures, and they all disagree.\nAnd I, and I, this is what I survey in my dissertation.\nUm, and so you've got to pick one.\nNow, the, the good news is that if you're an inductive logician, which is a certain tradition that I'm a member of, you've got, you actually have a criterion that allows you to narrow things down to a unique measure.\nAnd it turns out to be the base factor, the same thing that people report on the boxes of the diagnostic tests.\nAnd it's a very simple criterion.\nThe criterion is, however we're measuring this confirmation, it should be such that it generalizes entailment in the following sense.\nIf the evidence did entail the hypothesis, if it guaranteed that the hypothesis was true, then that should receive a maximal value of confirmation.\nAnd if it refuted the hypothesis, entailed that it was false, falsified it, then that should be a minimal value.\nJust add that as a criterion, and you're basically uniquely down to this base factor.\nGood.\nAnd so that gives us, if we're in the framework of inductive logic now, we actually do have a unique way of measuring, and it just turns out, and I'm not sure this is a coincidence, but it turns out it's the very same base factor that they tell you when you buy a diagnostic test.\nGood.\nYeah.\nI'm now going to look in stores for diagnostic tests that tell me what my priors should be.\nBut Right.\nThat's right.\nIt's a probability 9/10en that you're pregnant, no matter who you are.\nSo, just this might be a tiny little aside, but I remember when I was young and taking my first philosophy of science course, um, when we came to Carl Pauper, uh, we were taught that his notion of falsification was supposed to be a better thing to think than the old-fashioned logical positivist notion of confirmation.\nI, I know now that we weren't actually told what that old-fashioned logical positivist notion of confirmation actually was, or at least it didn't become clear to me.\nBut what is the difference between those two ideas?\nYeah.\nSo, this is, that's a great question.\nSo, there, so I think Pa was right in a sense.\nThere is an important asymmetry when you think about degrees of confirmation.\nSo, let's think about how strongly does something that refutes, what's the confirmational impact of that versus something that's that doesn't refute?\nWell, as I just said, our criterion requires reputation to be, that's the worst, that's the most negatively relevant you can be.\nAnd so in this sense, this is the kernel of truth of what Popper said.\nRefuting evidence is more powerful than non-refuting evidence.\nGood.\nUh, as a negative evidence, and that's absolutely true.\nHe's absolutely right about that.\nThat's in fact one of the criteria that we use to get down to a unique the base factor measure.\nSo, I think Popper, what he, what he wasn't right about was that all there is is reputation.\nSo, Paer had this weird view that there's no such thing as inductive arguments here.\nI think he was influenced by Hume.\nI think he really got hooked on that, uh, skeptical argument, and he thought, well, the only arguments that could be compelling must be deductive.\nSo, there aren't any inductive arguments.\nSo, well, then everything must be reputation.\nThat is right there.\nThat's all that would be left.\nYou couldn't have disisconfirmation in a weaker sense because that doesn't exist.\nI, as I said, I'm not a skeptic.\nI'm an anti-skeptic.\nI think we know a lot of stuff.\nI think we can make distinctions between reputation and just negative evidence that's not refuting.\nNow, of course, it's difficult.\nIt's an art.\nYou have to decide on a probability distribution to use to assess these things.\nYes, you do have to do that at the end of the day, or at least enough constraints on probability so that you can say like what the likelihood ratio is or something like that.\nI mean, you, you need some probabilistic information to do that.\nBut I think we can obtain such proistic information by doing statistics.\nSo, I'm not a skeptic at all.\nI mean, I, I don't have a problem.\nSo, I kind of don't worry about the skeptical arguments in epistemology at all, including an induction.\nUm, but let me just say one more thing.\nI think Paer was also right in his criticisms in some of his criticisms of the logical positivist.\nSo, Carnap was probably the, the, the real, uh, best exemplar of someone who tried to develop a logical empiricist in ind\n\n\nInductive logic. And a lot of what he\nsays in his work is great and useful.\nBut there's one I think key mistake that\nhe makes, and that a lot of people\nhave made, and that is this. He thought,\nand I think many people still think,\namazingly, that there must exist a single\nprobability function such that every\nargument strength can be measured with\nthat one function. I think this is wrong,\nbut I do think, what do you mean by a\nprobability function in that sentence?\nYeah. So there must be some probability\ndistribution over the relevant\npropositions. Okay. Right. That such\nthat for any argument, as if there's this\nthis uh, it's they used to call it, well,\nsome people called it like the super\nbabies probability function or something,\nthat there's this one probability\nfunction that can assess accurately the\nstrength of any conceivable argument, and\nI just think this is absurd, it doesn't\nexist, there's no such thing. But I will\nbut I do think there's a weaker claim\nthat is true. I want to say that for\nevery argument, there exists a suitable\nprobability\nfunction such that when you use that\nprobability function to assess the\nstrength of, you get a pretty accurate\nassessment of how strong the argument\nis. And so I just want to reverse the\nquantifiers. This idea that there's one\nin the sky that works for every\nargument. No, that's what Carnap thought.\nHe was wrong about that. But I think\nit's true, probably, that for every\nargument, there's some suitable\nprobability distribution that works, that\ngives you the right assessment of what\nthe evidence favors, or, you know, how\nstrong the evidence is. Is Carnap's idea\neither identical to or at least related\nto an idea that we could find the one\ntrue set of priors for all the these\npropositions? Yes, that's right. That's\nanother way of think about. If you're a\nBayesian, then you'll think so-called\nobjective Bayesians think that there's one\nprobability function that will rule them\nall or something like that. And of\ncourse, that just won't work. I mean,\nyou can just it's very easy to to cook.\nAnd this is what Carnap did for about\n40 years. He kept getting more and more\nsophisticated counter examples for\nwhatever specification of the single\nfamily of probability distributions, you\nknow, and I just think this is a fool's\nerrand, you don't need to do that.\nScience, the way, the way I think about\nscience, is you have a theory, so this\ntheory is just probability calculus with\nyour like with your base factor and your\nconditional probability, okay, that's your\ntheory of inductive logic. And now to to\napply the theory, you have to construct\nmodels of particular arguments in\nparticular contexts. That is an art and\na science. It's going to involve a lot\nof statistics. It's usually going to be\nempirical. It's going to involve a lot\nof extra work. It isn't going to be\nknowable a priori. But why should it be?\nYeah. You know, I just so I mean this\nthat was the logical empiricist's dream\nthat it had to be noble a priori, and so\nthere had to be just this one\nprobability function. You could divine a\npriori uh to to determine all the\nanswers. And I just think no, that's not\nhow science works. There are uncountably\nmany probability distributions. Don't\ntie your hands by not allowing yourself\nto use ones that science tells you are\nappropriate. Um, and so that's just now\nthat's going to be empirical matter of\nconstructing models of real arguments.\nAnd this is going to be hard work, and\nthere's going to be it's going to, in\nmany cases, it'll be controversial. But\nthis is the same thing that happens when\nyou're constructing models in science.\nYou got to make all kinds of\nassumptions, idealizations,\napproximations, and it's going to be\ncontroversial how to do that the right\nway. Yeah, that's itself part of\nscience, you know, and who said it was\ngoing to be easy? Nobody said it was\ngoing to be easy. That's for absolutely\nsure. I don't, I don't think they did. Uh\nbut okay, as someone who lives in\nBaltimore, um, home of Eden Poe and the\nBaltimore Ravens, I am very fond of what\nwe call the paradox of confirmation.\nLike as soon as you have this idea that\nyou're going to start confirming things,\nyou get in trouble, and the philosophers\ncome along to tell you it's not going to\nbe so easy either.\nYes, there are many there are many\nparadox of confirmation, but I think\nyou're thinking of a Hemple's par, the\nRaven paradox. Hemple's paradox. Yeah,\nthis is a classic. Um, so the way this\none goes is it involves a specific kind\nof hypothesis. Uh, something like this.\nAll ravens are black. That's a\nhypothesis we could have, we could\nformulate. Suppose we hypothesize that\nall ribbons are black. And if if you\nwant that to work, the way we usually\nthink we're confirming that is we make a\nlot of observations, you know. So we\nobserve a whole bunch of positive\ninstances. Uh, and we think by the more\npositive instances we observe, you know,\nby and large, the the better supported\nthis hypothesis is. Okay. But that\nassumes that even just a single uh\ninstance would provide some support, and\nmaybe just a tiny amount, but it'll raise\nthe probability a little bit of the\nhypothesis, which is a plausible idea.\nThe problem is, uh, if you accept that\nprinciple that a positive instance\nprovides some support for a a universal\nclaim. So like the observation of a\nblack raven should support a little bit\nthat all ravens are black. Uh, of course\nyou need many to do a lot of confirming,\nbut you but one does something, right?\nThat's how you get started. The problem\nwith that is if you accept that and then\nyou accept the following principle, which\nsounds very plausible, that if if a piece\nof evidence supports a hypothesis, then\nit supports anything logically\nequivalent to that hypothesis. Sure.\nThat seems right. I mean, logical\nequivalence, that's a really strong form\nof equivalence. So anything that's\nevidence for something should be\nevidence for something logically\nequivalent. In fact, we would just think\nthey're the same hypothesis. Well,\nokay. All ravens are black is logically\nequivalent to all non-black things are\nnon-raven. And now what's a positive\ninstance of that hypothesis? Well, it\nwould be the observation of a non-black\nnon-raven. Okay, but now you get the\nconclusion that the observing non-black\nnon-ravens confirms that all ravens are\nblack. Okay, that's that doesn't sound\ngood because it sounds like uh you can\nengage in what Nelson Goodman used to\ncall indoor ornithology.\nUm, you just observe a bunch of shoes,\nyou know, or you know, and or you know,\nuh, you observe a bunch of white shoes,\nyou know, non a bunch of non-black\nnon-ravens, and you're going to get a\nlot of confirmation for the hypothesis.\nWell, that's definitely a problem. But\nthis is where the quantitative theory of\nconfirmation helps. So, yes, let's\nsuppose you get some confirmation,\nright? But now that leaves open the\nfollowing question. Might it not be the\ncase that the amount of confirmation\nprovided by the observation of a\nnon-black number is much much less, you\nknow, in in the circumstances we think\nwe find ourselves in than the\nobservation of a black raven. And in\nfact, given very plausible assumptions\nabout statistical sampling or however\nyou're modeling, you know, the usual\nstatistical models of of observing these\nthings, um, given very plausible\nassumptions about the world, you know,\nhere's one assumption. There are a lot\nmore non-black things than there are\nravens. That seems right. Okay. So that\nand if you think that's true and it's\nstill true even if you suppose that all\nravens are black, that is that wouldn't\naffect much the rate the relative\nproportions\num then it just follows that you're\ngoing to get more support by by of the\nhypothesis by the observation of a black\nraven than by the observation of a\nnon-black non-raven. So this is where\nthe quantitative theory really helps.\nAnd statistics gives us that. It gives\nus a quantitative way to estimate how\nmuch of an effect uh an observation has.\nAnd so given very plausible assumptions,\nit's just going to be yeah, you get it's\nsome evidence, but it's extremely weak\ncompared to the evidence you get from\nblack ravens. And you can make this much\nmore precise, and you can show that in\ngeneral it's just much more informative\nto say sample from the ravens and see if\nthey're black than sample from the\nnon-black things and see if they're non-\nravens, right? Uh, and you can just make\nthis very quantitative using the theory\nof confirmation, just these b factors.\nAnd given very plausible assumptions\nabout what we think the probability\ndistributions look like, it's just going\nto follow that the best way to do the\nexperiment is to sample from the ravens\nand see if they're all black as opposed\nto sampling from the non-black objects\nand seeing if they're not ravens. Well,\nand for the non- philosophers out there,\njust to remind them that this notion of\nconfirmation is extremely weak, right?\nWhen you say observing a white shoe\nconfirms that all ravens are black, it's\nreally it's closer to supports. You even\nuse supports a couple of times there as\nas a synonym provides a tiny amount of\nevidence that might be really really\ntiny. Yeah, it could be a it's just a\nsome bump. It just means the probability\ngoes up, but it could go up and a tiny\namount. And in fact, this is what we\nthink happens when we sample from the\nnon-black things and see whether they're\nnon- ravens as opposed to sampling from\nthe ravens, seeing whether they're\nblack. We just think there's a much\nlarger effect there. So although there's\nsome effect, yeah, it's not like it's\ntotally gives you no information. And by\nthe way, it's plausible that you should\nget some information because if you\nobserve a non-black non-raven, then what\nyou've done is you've ruled one object\nout. You know that there's one object in\nthe universe that can't be a counter\nexample to the hypothesis. And so in\nthat sense, yes, you've gotten maybe a\ntiny bit of support, but it's it's\nabsolutely minuscule compared to what\nhappens when you sample from the Ravens\nand see if they're all black. Okay,\ngood. So I'm I'm on board the the\nconfirmation train here. Um but we still\nyou mentioned in passing the idea of a\nquantitative measure of this\nconfirmation factor. Um in one of the\npapers that that you wrote that that I\nactually read some of, um, you go through\ndifferent plausible suggestions for what\nthe equation should be for giving you\nwhat that confirmation factor is. And\nand there's something called the\nreceived view that uh would you call the\nreceived view? Do other people also call\nit the received view? I don't even know.\nUh well, it's just\nI think it is just kind of the\nconventional wisdom about how to think\nabout strength of arguments. Yeah.\nRight. Okay. And you and that relates\nthis confirmation factor to a\nconditional probability. And I know that\num some large fraction of your\nintellectual life is spent thinking\nabout conditional probabilities. So why\ndon't you tell us what a conditional\nprobability is and why it might be\nrelated to a confirmation?\nYeah. So, so, so one thing you\ndefinitely want to know, it's just going\nback to the disease case. One thing you\ndefinitely want to know, maybe the most\nimportant thing you want to know is how\nprobable is it that you have the disease\nconditional on or given that you get a\npositive result, right? That's called\nthe conditional probability. And the way\nit works is you do this. You suppose\nthat you get a positive result and then\nyou ask yourself given that supposition,\nsupposing the world is that way, how\nprobable is it that I have the disease?\nUm, and that's sort of the natural way\nof thinking about it. And so conditional\nprobabilities are essential to\ninduction. Um, but of course there's\nmany different kinds. There's many\ndifferent conditional probabilities.\nThere's the probability of H given E,\nthat posterior probability. That's\nreally important. But there's also the\nlikelihood, the probability of E given\nH, that true positive rate. And there's\nalso the probability of E given not H,\nthe false positive rate. E. So there's\nactually evidence and hypothesis. Yeah,\nE and H are evidence and hypothesis. So\nE, let's say, is a positive test result.\nH is that you have the disease and of\ncourse what you want to know is how\nprobable is H given E, right? Suppose E to\nbe true, how pro, and then if you learn E,\nthen you update, you update, and you\naccept as your new probability the old\nconditional probability, that's sort of\nthe Bayesian way of doing things. Um, and\nyeah, you definitely want to know that, of\ncourse, that's like that's a very good\nthing to know, but knowing that requires\nyou to know not just the true positive\nrate and the false positive rate of the\ntest, but also the prior, the\nunconditional prob, the probability prior\nto the evidence before learning how the\nexperiment turned out, and of course\nthat's going to vary very greatly from\nsubject to subject, from person to person\nwho's judging the evidence. So\nconditional probability is super\nimportant, and I still want to say that\nis one of the features that makes\nsomething a strong argument. You\ndefinitely want the you definitely want\nthe hypothesis to be more probable than\nnot at the very least given the evidence\nif you're going to believe it. If you\nthink it's a reason to believe it,\nthat's part of the story. But I want us\nand that's the conventional view about\nhow strong the con, the received view is.\nIf you want to know how strong an\nargument is, just calculate that\nposterior probability, the probability\nof H given E, and that tells you how\nstrong a reason is E is for believing H.\nBut that can't be right. It can't be\nright because take you or me. If we take\na pregnancy test, yeah, look, the\nlikelihoods are still the same. If we\nhappen to get a posit, which is of\ncourse possible because physics and\nbecause things aren't impossible, we\ncould get a positive result. Okay. Um\nwell, we but we we don't think that's a\ngood reason to believe that we're\npregnant because we know we're not. So,\nwhat that means is there's another\ndimension to the assessment of the\nstrength of arguments, and that is what\nwe've been calling confirmation. And\nbasically I want to say it's just it's\njust the the ratio of those two error\nrates. It's just the the base factor,\nthe likelihood ratio, whatever you want\nto call it. That's the way we measure\nthat second dimension of confirmation.\nAnd so I want to say there's a I have a\nI'm offering a two-dimensional theory of\nargument strength. For an argu to be\nstrong, it's got to be probable. Sure.\nYeah. It should be more prob, the\nconclusion should be more probable than\nnot given the premise, or in this case\nthe hypothesis should be more probable\nthan not given the evidence. But also\nthe evidence should be relevant. If the\nevidence is irrelevant, it's not a\nreason to believe the hypothesis at all.\nRight? So if you have an argument where\nthe premise is just irrelevant, doesn't\naffect the probability\n\n\nIf the conclusion at all, then I don't want to say that's a strong argument because that it's not a reason to believe the conclusion at all. Okay? And so this was something that the classical inductive logicians just ignored. Not just Carnap, but if you read books on inductive logic all the way up through Brian Scirms's book, which is one of the state-of-the-art books from the 2000s, they just give you this one dimension, the probability of the conclusion given the premise. But I just think that can't be the full story because relevance, confirmation also matters as to whether something should affect your beliefs. So, let me try to rephrase it because I'm not sure I wrapped my brain completely around it. The classical story would say if the probability of the hypothesis given the evidence is very high then that counts as confirmation. But what if for example the probability of the hypothesis is just very high? What if we're already convinced of it? Then it could be also high given the evidence, but you wouldn't count that as confirmation. Is that the idea? That's right. In fact, it could even be highly probable given the evidence, but the evidence makes it a little bit less probable. Right. You definitely don't want to say that's a reason to believe. No, if anything, it's a reason to believe the hypothesis is false. Right? It just so happens that it happens to have still a high probability anyway given the evidence, but that's probably because it had such a high probability to begin with. Okay? It's not that the evidence is a reason to believe the hypothesis. And so when as logicians what we want to know is not whether we should believe the conclusion simpliciter, but we want to know how strong the argument is as a reason to believe the conclusion, and that I claim requires both probability and relevance confirmation, and simpliciter is weird philosopher talk for all else being equal. Yeah, that's right, and sure, if the thing is relevant, then all that matters is the probability, but if it's not relevant, then it's not a strong argument I would say. Good. So that sounds perfectly plausible, but of course we're going to want to know what is the way to know whether something is relevant. Is there is that just like a vibes-based thing or is there an equation?\nThere is an equation. There's and it is just that the thing they give you when you buy the diagnostic test. They give you this ratio of the two error rates, the two likelihoods, the probability of E given H and the probability of E given not H. And you take that ratio, that's a really good measure from an inductive logical point of view. It's pretty much the only one that's going to satisfy these desiderata we like. And so that's how I propose. So I'm proposing a two dimen. So you can visualize it as like a Cartesian space. The x-axis is the conditional probability of the conclusion given the premise. And the y-axis is that likelihood ratio that is that measures how much impact, how relevant the premise is to the conclusion or the evidence is to the hypothesis and sort of and yeah, so so there's no one number at the end of the day. Okay. It's not like you add those two together or you add their squares together or whatever. It's just you got to give me both numbers. Yes. And I think this is a really fundamental thing that's so important to emphasize. I think one of the real deepest mistakes that was made in the history of inductive logic was that they thought there'd be a single measure on which you could totally order all the arguments in terms of their strength. A single function that takes a premise and a conclusion and a probability distribution and gives you a single number. I don't think this can be done. I think what it gives you is a ordered pair. Yeah, it gives you a probability and a Bayes factor. Good. And that's all I think in general that can be said.\nNow, of course, you can say some things. There's a there's some ordering because if if the evidence if you move up both in terms of probability and relevance, well, then you've gotten stronger because you've gotten stronger in both dimensions. But these mixed cases, this is the problem. Cases where you have improbability but high confirmation like the base rate fallacy or cases like the conjunction fallacy which also involve relevance going one way, confirmation going one way but probability going the other way. And so these mixed cases which I think it's no surprise they led to the Nobel Prize about concerning how quote unquote bad people are at probabilistic reasoning. I think it's because the cases are mixed that people get confused. If you ask someone how strong is an argument? Well, if it if that has two dimensions to it and one of them's high and the other's low, that's ambiguous. The question's ambiguous. And so you you could you might not blame them so much if they're a little confused about those arguments where you have high relevance and low probability or, you know, high probability and low relevance. Those are hard cases to to assess. Yeah. Right.\nFor most people because because they realize both factors are relevant and what they're being asked for is a single summary, a single assessment, but maybe there isn't, maybe it's ambiguous, maybe it's strong in one sense but not in the other, and so I I in general want there to just be two dimensions and so you I don't think there's a total ordering, a single number you get for any argument in any probability distribution, there's going to be two numbers I think in general and has and I think that's one of the mistakes. Yeah, has everyone basically agreed with your impeccable logic here? Well, I mean, some people have. So, there, you know, in psychology, so we did I I had the pleasure of working with some psychologists on these reason quote unquote reasoning fallacies. And yes, there's a lot of experimental evidence now that it's the mixed cases that are hard and it's and they're hard because they're mixed. And so if you fiddle with the confirmation that is the relevance, you fiddle with that Y dimension, it's really going to affect how good people are making judgments about the X dimension. And so and I think this is because what people really care about is not just how probable the conclusion is given the premise. They care about how strong is this as a reason to believe the conclusion. And intuitively they know that depends not only on the probability but on whether the evidence is relevant, whether the evidence confirms the hypothesis. And so there's a lot of psychological evidence now that that that notion of confirmation really is relevant to explaining what's going on in these cases. So let's go through some of these cases a little bit more carefully because I'm sure that people have kind of vaguely heard of them, but you know, it's always good to be clear.\nThe conjunction fallacy, I think you already mentioned, and it is one of my favorites because I was not fooled by it when I first saw it, but I saw why I could be fooled by it, so I'm sympathetic. Yeah. Yeah. Let me let me\nThat's a great one. That's a great one. So, um what the way that one works is you're given some evidence about a woman named Linda. You're basically told that she uh so she was she went to Berkeley in the late 60s. She participated in anti-nuclear demonstrations. She was very active politically and so on and so forth. She was like a flower child and so on and so forth. And that's the evidence you're given. And now you're asked, this is years later, you're asked, okay, now I have two hypotheses I'm going to give you about Linda nowadays. Either she's a bank teller or she's a feminist bank teller. And you're asked which is more probable given the evidence that I gave you. And back in the day, a lot of people said feminist bank teller was more probable given that evidence. Of course, that's impossible because feminist bank teller entails bank teller. So every possible world in which which she's a founder, there is a world in which she's a bank teller. And since probability is just a measure of, you know, how big a class of possible worlds is, it couldn't possibly be that the conjunction is more probable than one of its conjuncts that that that would just violate basic logical and probabilistic principles. So that can't happen. So what's going on? Well, what we showed in a paper that we wrote, and there's been a lot of research on this since then, is that two very simple assumptions, if two very simple assumptions hold, which I'm going to give you in a second, then it's just guaranteed that while yes, the the bank teller hypothesis is going to be more probable than the feminist bank teller hypothesis, the evidence will actually confirm the feminist bank teller hypothesis more strongly. It'll be more relevant to that conjunction than it is to the first contract. And here are the assumptions. They're very weak. First assumption, the evidence isn't positively relevant to whether she's a bank teller. That seems plausible. Okay. Second assumption, suppose she is a bank teller. The evidence I gave you still positively relevant to some degree to her being a feminist. Maybe a only a tiny amount, but still still somewhat relevant to her being a feminist. Those conditions entail that for any way of measuring confirmation for any of the measures. It turns out the evidence will confirm the conjunction more strongly than it confirms the conjunct. And so these are cases, they're mixed cases. You have a case where probability goes one way, bank teller is more probable, but bank teller is less relevant, right? It's less well confirmed by the evidence. And I think it's again no surprise that just like in these rare diagnostic testing cases, rare disease cases which are called the base rate fallacy cases which we already discussed. Just like in those cases, these cases involve one of the dimensions of assessment probability going one way and the other dimension of assessment of the strength of argument confirmation or relevance going the other way. And I'm not at all surprised that people defer to relevance. Right? It makes sense. We already saw relevance is in many ways more objective. It's more invariant. It's it's it's sort of the language of science. The way science understands evidence, it usually thinks in terms of how much the evidence confirms, not how probable hypothesis, and that depends on all these idiosyncrasies about prior probabilities. So I'm not at all surprised that people do any of these things. So I I say it's kind of makes sense that when the confirmation goes one way and probability goes another way, deferring to the confirmation kind of makes sense since there are many ways in which confirmation is just more more important, more informative, more objective than than probability is. So I have a slightly different or I had um for a while after hearing about the experimental results slightly different hypothesis about what was going on, but I'm not sure if it's slightly different. So, let me explain it to you and you tell me if it's different. I I'm wondering whether or not when people hear, you know, the evidence, which in this case is Linda went to Berkeley, she was a flower child, she was an activist, and then they're given the two hypotheses, she's a bank teller, um and or she's a bank a feminist bank teller. Um, implicitly they assume that being a bank teller means that you're a typical bank teller and being a feminist bank teller assumes that you're a typical feminist bank teller and the typical bank teller is not feminist. So there's some sort of interference or tension between the hypothesis that she's a bank teller and the evidence that she was a flower child. Uh it's it's still a sort of a mistake with the question phrased as it was, but I mean that would be a way of psychologizing why we make the mistake. I'm not sure if it's the same as your way or different. Well, yes. So, there have been many proposals for different things that might be going on. One of them that was received a lot of attention early on which is similar. It's in some ways maybe you can tell me I think it's related to what you were saying is it was originally postulated that actually people were hearing the question slightly different. They're hearing it as feminist bank teller versus non feminist bank teller. Yeah. And actually there's definitive psychological research that that's not what's happening. So I can I can show I can point you to papers that are just absolutely stunning on this by some of my psychological colleagues though.\nOkay. So there are experiments where first they teach people how to do deductive inferences. They teach them how to infer conjuncts from conjunctions. They teach them all this stuff and then they have them bet. They have them do betting and they still a lot of people bet more on the conjunction even though they know that the thing follows they've actually gone through the logical exercise of it of it following logically right that one hypothesis entails the other. So this has been controlled for I think in my opinion this this particular hypothesis is actually there's a lot of evidence against it now. So I find the relevance approach the confirmation approach more more plausible given all the evidence, but of course this is you know this is active area of research there's some even more recent research trying to refine the notion of relevance to go beyond confirmation and take into account other pragmatic kinds of relevance as well. I I think that's really fascinating research. But there's pretty strong evidence now that this this second dimension I'm calling it of logic of argument strength is making a significant difference. There may be many other things that are making a difference, but it's pretty clear it's making a difference. I kind of love the intersection of the actual psychology experiments with the philosophical reasoning at the most abstract level. It does, you know, the rubber does hit the road at some point. Oh, absolutely. To me that's that's one of the most interesting areas of research in general is that borderline between the descriptive and the prescriptive. Yeah, that's a really it's such a difficult area but it's such an it's such an important area because after all what we're interested in is evidence for humans. You know it's like you know this is another weird thing about logical empiricism. Who cares about evident if it's if it's just some purely formal logical relation between things? How does that actually bear on what we ought to believe? So that's another problem with the whole kind of logical empiricist way of thinking. It's very disembodied and abstract and it's just unclear why it would ever have any purchase on humans. Okay. So, let's um I think one more example might seal the deal here and and you suggested the four card problem which I do\n\n\nRemember, look, I looked it up. You had your paper, but your paper is full of like all these equations and things, so I just looked it up on Wikipedia to remind me what it was. And I do remember coming across the four card problem, and I, that one, I did get right just because I've uh, done probability problems before, but but it's, I see the similarity here, but the argument plays out in a slightly different way. So why don't you tell us what the problem is?\n\nYeah. So there's this famous case, uh, of the Wason selection task is what it's called. Uh, and there's, so the way it works is there's uh, there's cards, and now there's different variants of it. So I'm trying to remind myself of uh, um, the version that we that we actually worked on, 'cause I don't want to talk about a version that I don't. I actually know it. I, I wrote it down if you want me to give the problem and then you can explain this.\n\nYeah. Could you do that and then I can...\n\nYeah. I mean, the version that I know, um, from your paper is that there are these cards, and you know that there's a number on one side of the card, a letter on the other side of the card. You know that. And you're shown four cards. Um, one says the letter D. The other says the letter K. I don't know if this is for Daniel Conorman or not. I don't know where these letters came from. Um, then it shows the number three and the number seven. Okay, so D, K, 3, 7. So obviously you showed the letter side of two of them, the number side of the other two. And then the hypothesis is all cards that have D on one side will necessarily have three on the other side. And the question is which cards do you have to flip over to most efficiently test that hypothesis that if D is on one side, three is on the other side? And you've shown D, K, 3, 7.\n\nYes. Yes. And so yeah, so this is this is a great case. So we wrote this paper a while back. Me and Jim Hawthorne wrote this, really, it's my favorite paper I've ever written still to this day. And so it's about this Wason selection task, which people make a certain kind of mistake in, uh, tend to, and its relation to the paradox of confirmation, which we already talked about. So, you remember back in uh, when we were talking about the paradox of confirmation, that it, it's a better strategy to sample from the ravens and see whether they're black than it is to sample from the non-black things and check whether they're non-ravens. And it's just more confirmationally powerful to do to sample from the ravens and check and see if they're black. This turns out to be an isomorphic problem. This is this problem is basically the same problem. Okay.\n\nUm, because so what hypothesis are we being asked to test in this in this case? So we've got the four cards D, K, three, and seven. And what what hypothesis are we being asked to test?\n\nIf D is on one side, then three is on the back.\n\nThat's right. So all D cards are three cards.\n\nYes. Or you could just say all D's are threes.\n\nYep. Okay.\n\nNow all D's are threes. Same structure as all Rs are B's. All Ravens are blacks. And exact and the same kinds of things happen. So what you what you want to do is, if you think about back to the Raven case, what did we say? The best strategy is look at the ravens and then check and see uh, whether you know, whether they're black. The analogous thing here would be check the D card and and then turn it over and see whether it's a three on the other side. Mhm. That it is exactly the analogous thing. And you can and the same models will show that that's the most efficient way to to to respond to this. And in fact, if you just use some very weak assumptions about probability and you use this confirmation measure that we were talking about, then you can actually rank the strategies in terms of their confirmational power, and it'll turn out, given very weak assumptions about what's going on, that D, turning over the D card is the best. Then next, turning over the three card. Oh, sorry. No, that's what people actually do. Sorry. Right. That's what people actually do. So, what people actually do, this is great because I just actually did it. What people actually do is they turn over the three card. That's the second best strategy. That isn't the second best strategy, right? They think that they're trying to confirm, but uh, that's not the best way to learn.\n\nYes. What you should be doing is looking for counter examples, right? Next. So, you should turn over the seven card, right, and see whether it's a D, right?\n\nYes. Exactly. And this is exactly, we show because that we actually showed that the two cases, the paradoxation and the wasting desk, are actually isomorphic. They have basically the same structure, and that you can use the same kinds of probability models to model them, and when you do, you get exactly the prescriptions in both cases. You get best thing, sample from the ravens, see if they're black. Next best thing is look at the uh, non-black, look, right, the non-black things and see if they're ravens. Right. Look for counter examples, right? Same thing here. But what people actually do in this wasting task, which is really interesting, is they, they reverse those, the second and third strategy. So what they do is uh, they'll say D first, but then they'll say three.\n\nYeah. They'll say no, turn over the three card when that's definitely less informative. And here the Paparian intuition really is correct. You should be trying to refute next. You should be looking at the seven card. And as I, as I was saying the Paparian thing, it's a, the kernel of truth of Popper comes out in this paper because basically you can just show that after sampling from or sampling the D card and looking to see whether it's a three, the next best thing is looking at the at the seven and seeing whether it's a D. That's that's uh, that's Popper's intuition basically. And people aren't Paparian, it turns out, because they think turnover of the three card is better than turnover the seven card. But actually, it's very easy to show just using very weak assumptions about probability that that's wrong. And so I, in a way, this is a vindicate, it's a Bayesian vindication of Popper. That's one of the things I like about this paper. It, it tells you the kernel of truth in in the Paparian falsificationism that in this case, going for the falsification is better. M, uh, it's it's the second best thing and not the third best thing, which is what people tend to think it is.\n\nYeah. But the thing that, so but the thing that people tend to do, they, they, they reason, if it can be called that, they think, well, your hypothesis is that if there's a D on one side, there's a three on the other. If I flip over the three and I see a D on the other side, that will confirm, that will give some evidence for this in the space of all possible cards.\n\nThat's a more likely thing to see.\n\nYes. And and and it will confirm, but because reputations are always more powerful than non-refutations.\n\nExactly. Yeah. That's the Paparian insight, and that's why Popper was correct. So yes, you're you're absolutely right. It's a kind of confirmation bias. And uh, in our paper, we actually prove, given very weak assumptions, that the only way to get that ordering is if you come into the experiment with a confirmation bias. That is, you think you're more likely to see positive instances rather than counter examples.\n\nExactly. Right. Good. And you can just prove that that just follows from the very weak modeling assumptions we have, that the only way to get that ordering is going to be if you come in already thinking that you're more likely to get confirming instances rather than refuting instances, which is is sort of the classic confirmation bias. And it is, but it's not, it is a bias. And I think that in this case, you know, the parameters are sufficiently clean that uh, doing D and 7 is is clearly the right uh, strategy here. But the real world of science is complicated, right? I mean, I guess, you know, we're getting late in the podcast. We can uh, let our hair down and and think about uh, less uh, completely logically rigorous deductions here. I mean, are there lessons for how we should do science? Like scientists are constantly arguing about what experiments are the best ones to do. Um, obviously it has to do with the probability that your different hypotheses are true, your priors, which of course we don't agree on, but also I think you would argue, um, the relevance of that experimental result to changing your beliefs.\n\nAbsolutely. I think when a great way to think about experimental design is to to think what you're doing is you're trying to maximize the confirmational power of the evidence generated, and that could be, so that's neutral as to whether it's negative, negatively relevant evidence, which it might be, or positively relevant, but what you want to do is maximize the confirmational power, and that's the framework of this waste and and uh, Hempel paper that we did, yeah, where we're basically just a very simple measure of confirmational power. It's basically just the absolute value of this, you know, of this confirmation measure that we have, and if you just try to maximize that, then you can just, you can just figure out which strategies are going to do that. Now, just to to your more broad question, just speaking a little bit more philosophically here, zooming out a little bit. So as I said, I think this is a very elegant theory of inductive logic. Now, when you're actually applying a theory, you have to construct models, and this is where all the hard work comes in. You got to really come up with not necessarily a a an exact probability distribution, but you have to have enough constraints on your probabilities to be able to decide whether the evidence in your experiment favors one hypothesis over another. And you might not need to give an exact numerical probability distribution over everything, but you'll need enough constraints to determine what whether favoring occurs, you know, in which direction it goes in. And how do you do that? Well, it's going to be quite difficult in many cases. It's going to involve a lot of science, measurement, statistics, uh, a lot of also just theoretical arguments and just trying to, you know, it, it's so it's partly an art. Modeling is not just a pure science, but this is true in all branches of science. So what I want to say is inductive logic is no different than any other science. It gives you a theory, but in order to apply that theory, you have to construct models. And that's really, you got to get in the trenches and do a lot of really difficult science, a lot of statistics, a lot of measurement, a lot of idealization, whatever is suited to to assessing that argument. And it's going to be case by case. It's going to be each context. We have to do the best we can to come up with the most plausible constraints to tell us what the evidence favors. That's all we can do, you know. So I really think it it is a case- by-case thing of constructing models and doing the best we can, just like the rest of science, when you know, it all, you know, people often say all models are false, which I agree with, but that doesn't mean the theories are false. So you know, when you take general relativity and you try to model actual situations with it, well, what do you do? Well, you have to make all kinds of approximations because you can't solve the equations, and then you got to make all kinds of auxiliary assumptions and all kinds of measurements you got to do, and you got to do all kinds of statistics there to figure all these things out and get parameters right and all that. Okay, those models, of course, are false because they all involve idealization and approximation and so on. But the, but the theory might be true. It certainly could be, at least a really good framework for constructing models. And this is how I think of the framework I'm offering for inductive logic. Yeah, with its two dimensions of assessment in order to apply it. Yeah, you've got to, you got to fit in some adjustable parameters. You got to tell me what the premises are, what the conclusion is, and then you got to tell me enough about the probabilities over those things so that I can get a judgment as to whether the evidence favors the conclusion or not. You know, is is the evidence relevant to the conclusion? You may not be able to say how probable the conclusion is, but but at least you'd like to say how relevant is the evidence. Get some assessment of how relevant it is.\n\nYeah, I guess, um, I'm trying in real time here and not quite succeeding to put this in very, very down-to-earth terms. You know, my favorite example of a non-frequentist probability is uh, is the dark matter a weakly interacting massive particle, a wimp, or is it an axion? That's another candidate for the dark matter. Or is it something else, a third category, you know, thing, something we haven't thought of before. So obviously this is not a frequentist kind of question, right? This is something that we have some priors we're going to update. But now what I'm presuming is that your way of thinking about this would help me answer the following question. If I had a certain amount of money to build an experiment, and one experiment would confirm, like, detect the wimp, right? Detect that it is that, um, but the other experiment would like tell me that it is not an axion or something like that. Could I somehow, I, I'm truly not able to answer the question in real time, but could I somehow judge which is more useful depending on what my priors were for those different hypotheses?\n\nUh, yeah, I think you could. I mean, what you would need, I mean, you, you may not even need your priors. What you're going to need are the likelihoods. You're going to need, okay, how probable is it that we would have observed this evidence, right, given the one hypothesis versus given the other hypothesis. So, you're going to have to be able to compare those likelihoods.\n\nYeah, that at the very least, that will give you some information about the relevance dimension, like, does the evidence favor one over the other. It may not tell you the probabilities, 'cause for that you're going to need priors, but still, it can give you a good amount of information, and it can tell you something that the experiment is doing something valuable. It's it's giving you evidence that favors one of those hypotheses over the other, 'cause it's more relevant to one than it is to the other. Even if you don't know how probable they are, that's fine. You may not know how probable they are. So you may not know whether to accept or reject, but you still can say, \"Hey, this is\n\n\n\"Evidence seems to favor the one\nhypothesis over the other.\" And I think\nthat's generally how scientific\nexperiments actually work. As I was\nsaying before, when you're designing\nexperiment, you can't determine how\nprobable things are going to be. I mean\nyou can given your priors or something\nif you know you could yourself determine\nbut what you can do generally is you can\ndesign the experiment in such a way\nthat it provides evidence that favors\none thing over another or is relevant to\nthe experimental question. There is a\nclaim out there that I'm a little\nsympathetic to that scientists should be\nmore open about what their priors\nactually are. Like when we do an\nexperiment like we turn on Large Hadron\nCollider and scientists said well we\ncould find all these new particles. Tell\nme what the probability is that I will\nactually find these new particles which\nphysicists at least never ever do.\nI don't know if people in other fields\nactually do that. Do you think it'll be\ngood that they, you know, put their\nmoney where their mouth is in that way?\nWell, the great thing about So, I've\nbeen thinking a lot about different\nsciences because I'm working on this\nproject with a couple colleagues on the\nreplication crisis in science and the\ndifferent sciences are very radically\ndifferent in terms of how they're\ndealing with replication and what\nproblems they have. Particle physics is\none is sort of like the gold standard. I\nmean, the experiments they do,\nthe evidence they generate is so\nconfirmationally powerful that it almost\ndoesn't even matter what your priors\nare, right? Like it it really doesn't.\nIt basically just swamps completely.\nThere's such large likelihood ratios\nthat you get from those experiments that\nyou come in with whatever prior you\nwant. You're going to basically come out\npretty sure that these particles exist\nif you're paying attention to the\nevidence. And so particle physics is\nthis is really a great example of where\nwe're designing experiments that are so\nconfirmationally powerful that it almost\ndoesn't even matter what your priors\nare. But other sciences are not like\nthat. Other sciences it's much more\nsensitive to your priors as as to what\nattitude you're going to come out after\nlooking at the experiment. Um and also\nit's even more controversial whether you\nwhether you have really relevant\nevidence or not. Even that is is\ncontroversial in a lot of the special\nsciences whereas in particle physics no\nyou know the evidence is is very\nrelevant it it's extremely relevant and\nso that's I I view that as kind of one\nof the easy cases and you know like any\ntheory it's going to have cases it's\nreally good at explaining and it's going\nto have anomalous cases and that goes\nfor the basian theory that I'm of\ninductive logic that I'm offering um\nit's a pluralist basian it's not it's\nnot saying you should use a particular\nprobability but it's from probability\nfunction, right? Um it's basy in the\nsense that I'm willing to put\nprobabilities over all the hypothesis,\nright? Okay, which which non-basians\naren't willing to do. But in any event,\num look, it's a theory and it's going to\nhave limitations just like Newton's\ntheory wasn't able to explain, you know,\nin any really plausible way the motion\nof Mercury. I'm sure there are going to\nbe cases that we can find in science\nwhere the where the theory I'm offering\nit's going to have be really challenged\nto come up with plausible models that\nexplain uh how much confirmation there\nis in that case and you know but that's\nthe nature of science and so um even in\nso I like to think there's a there's a\nspectrum of cases there's easy cases\nlike particle physics or games of chance\nyou know these are easy cases and then\nyou go down the spectrum and there's\nreally really much harder cases and much\nmore controvers cases but That's true\npretty much of any science. Okay. Well,\nI think that we have confirmed that this\nis a fun thing to talk about, but maybe\nwe haven't because my prior was so big\nthat it didn't actually wasn't actually\nrelevant the evidence we collected here.\nBut in any event, Branden Fitelson, thanks\nvery much for appearing on the Mindscape\npodcast. Thank you so much, Sean. What a\npleasure.\n[Music]\nla.\n",
  "dumpedAt": "2025-07-21T18:43:25.529Z"
}